{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c6e025f",
   "metadata": {},
   "source": [
    "# Project MTI865 - Heart segmentation using UNet \n",
    "\n",
    "---\n",
    "\n",
    "# Model training - CE-DSC with Transformation consistency (MSE) \n",
    "\n",
    "$$\n",
    "\\mathcal{L} = \\frac{1}{n_{l}} \\left(w_{CE} \\mathcal{L}_{CE} + w_{DSC} \\mathcal{L}_{DSC} \\right)  + \\frac{\\alpha_{TC}}{n_{u}} \\mathcal{L}_{TC-MSE}\n",
    "$$\n",
    "\n",
    "PAS ENCORE IMPLEMENTÉ !!!! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31b841f",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6b07cf2f-b81d-43ef-907a-c49fed2d95ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.transforms import v2\n",
    "from progressBar import printProgressBar\n",
    "\n",
    "import medicalDataLoader\n",
    "import argparse\n",
    "import utils\n",
    "\n",
    "from UNet_Base import *\n",
    "import random\n",
    "import torch\n",
    "import pdb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8e976350-3fd5-4406-8511-86a06a9b4494",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6136411",
   "metadata": {},
   "source": [
    "## Loading data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "19e19f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "batch_size_val = 4\n",
    "batch_size_unlabel = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "37a65765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image and mask transformations\n",
    "transform = v2.Compose([\n",
    "    v2.ToTensor(),\n",
    "    v2.Normalize(mean=[0.137], std=[0.1733]) # Normalisation values for the training set (mean and std) \n",
    "])\n",
    "\n",
    "mask_transform = v2.Compose([\n",
    "    v2.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "029239f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Fonction de regroupement pour le DataLoader.\n",
    "\n",
    "    Args:\n",
    "    -----\n",
    "        batch (list): Liste de tuples (image, masque, chemin de l'image).\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "        imgs_tensor (torch.Tensor): Batch d'images.\n",
    "        masks_tensor (torch.Tensor): Batch de masques.\n",
    "        img_paths (list): Liste des chemins des images.\n",
    "    \"\"\"\n",
    "    imgs = []\n",
    "    masks = []\n",
    "    img_paths = []\n",
    "\n",
    "    for item in batch:\n",
    "        img, mask, img_path = item[0], item[1], item[2]\n",
    "        imgs.append(img)\n",
    "        img_paths.append(img_path)\n",
    "        \n",
    "        # Si le masque est None, ajouter un tenseur de zéros correspondant à sa taille\n",
    "        if mask is not None:\n",
    "            masks.append(mask)\n",
    "        else:\n",
    "            masks.append(torch.zeros_like(img[0, :, :]))  # Même taille que le canal de l'image (assumant CxHxW)\n",
    "\n",
    "    # Stack les images et les masques\n",
    "    imgs_tensor = torch.stack(imgs)  # Tensor de forme (B, C, H, W)\n",
    "    masks_tensor = torch.stack(masks)  # Tensor de forme (B, H, W)\n",
    "\n",
    "    return imgs_tensor, masks_tensor, img_paths\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3566dc5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dataset: ./data/ \n",
      "Found 204 items in train\n",
      "First item:  ('./data/train\\\\Img\\\\patient006_01_1.png', './data/train\\\\GT\\\\patient006_01_1.png')\n",
      "Found 74 items in val\n",
      "First item:  ('./data/val\\\\Img\\\\patient001_01_1.png', './data/val\\\\GT\\\\patient001_01_1.png')\n",
      "Found 1004 items in train-unlabelled\n",
      "First item:  ('./data/train\\\\Img-Unlabeled\\\\patient007_01_1.png', None)\n",
      "Train set:  204\n",
      "Validation set:  74\n",
      "Image shape:  torch.Size([1, 256, 256])\n",
      "Mask shape:  torch.Size([1, 256, 256])\n",
      "Number of batches:  102\n",
      "Image shape:  torch.Size([1, 256, 256])\n",
      "Mask shape:  torch.Size([1, 256, 256])\n",
      "Number of batches:  19\n",
      "Image shape:  torch.Size([1, 256, 256])\n",
      "Mask shape:  torch.Size([1, 256, 256])\n",
      "Number of batches:  126\n"
     ]
    }
   ],
   "source": [
    "# Define dataloaders\n",
    "root_dir = './data/'\n",
    "print(' Dataset: {} '.format(root_dir))\n",
    "\n",
    "supervised_set = medicalDataLoader.MedicalImageDataset(\n",
    "    'train',\n",
    "    root_dir,\n",
    "    transform=transform,\n",
    "    mask_transform=mask_transform,\n",
    "    augment=True,\n",
    "    equalize=False)\n",
    "\n",
    "\n",
    "supervised_loader = DataLoader(\n",
    "    supervised_set,\n",
    "    batch_size=batch_size,\n",
    "    worker_init_fn=np.random.seed(0),\n",
    "    num_workers=0,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "val_set = medicalDataLoader.MedicalImageDataset(\n",
    "    'val',  \n",
    "    root_dir,\n",
    "    transform=transform,\n",
    "    mask_transform=mask_transform,\n",
    "    equalize=False)\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_set,\n",
    "    batch_size=batch_size_val,\n",
    "    worker_init_fn=np.random.seed(0),\n",
    "    num_workers=0,\n",
    "    shuffle=False)\n",
    "\n",
    "unsupervised_set = medicalDataLoader.MedicalImageDataset(\n",
    "    'train-unlabelled',\n",
    "    root_dir,\n",
    "    transform=transform,\n",
    "    mask_transform=mask_transform,\n",
    "    augment=False,\n",
    "    equalize=False)\n",
    "\n",
    "unsupervised_loader = DataLoader(\n",
    "    unsupervised_set,\n",
    "    batch_size=batch_size_unlabel,\n",
    "    worker_init_fn=np.random.seed(0),\n",
    "    num_workers=0,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "\n",
    "print('Train set: ', len(supervised_set))\n",
    "print('Validation set: ', len(val_set))\n",
    "\n",
    "n_train_label = len(supervised_set)\n",
    "n_train_unlabel = len(unsupervised_set)\n",
    "\n",
    "# shape of the image a  nd mask\n",
    "img, mask, _ = supervised_set[0]\n",
    "print('Image shape: ', img.shape)\n",
    "print('Mask shape: ', mask.shape)\n",
    "print('Number of batches: ', len(supervised_loader))\n",
    "\n",
    "img, mask, _ = val_set[0]\n",
    "print('Image shape: ', img.shape)\n",
    "print('Mask shape: ', mask.shape)\n",
    "print('Number of batches: ', len(val_loader))\n",
    "\n",
    "img, _, __ = unsupervised_set[0]\n",
    "print('Image shape: ', img.shape)\n",
    "print('Mask shape: ', mask.shape)\n",
    "print('Number of batches: ', len(unsupervised_loader))\n",
    "\n",
    "\n",
    "# print('First of the supervised set')\n",
    "# img, mask, path_tuple = supervised_set[0]\n",
    "# print(img)\n",
    "# print(mask)\n",
    "# print(path_tuple)\n",
    "\n",
    "# print('First of the unsupervised set')\n",
    "# img, mask, path_tuple = unsupervised_set[0]\n",
    "# print(img)\n",
    "# print(mask)\n",
    "# print(path_tuple)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef7c545",
   "metadata": {},
   "source": [
    "## Model using both labeled and unlabeled data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db31076c",
   "metadata": {},
   "source": [
    "### Hyperparameters of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "369d8a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters saved to models/TransformationConsistencyL2Model-150epochs0.0005lr0.1alphaTC1e-05wd/params.txt\n",
      "Parameters saved to models/TransformationConsistencyL2Model-150epochs0.0005lr0.1alphaTC1e-05wd/params.txt\n"
     ]
    }
   ],
   "source": [
    "# Parameters \n",
    "lr =  0.0005    # Learning Rate\n",
    "total_epochs = 150  # Number of epochs\n",
    "weight_TC = 0.1 # Alpha parameter for the consistency loss term \n",
    "weight_decay = 1e-5  # Weight decay\n",
    "ce_loss_weight = 0.7 # Cross Entropy Loss Weight proportion\n",
    "dice_loss_weight = 0.3 # Dice Loss Weight proportion \n",
    "\n",
    "modelName = f\"TransformationConsistencyL2Model-{total_epochs}epochs{lr}lr{weight_TC}alphaTC{weight_decay}wd\"\n",
    "model_dir = f\"models/{modelName}\"\n",
    "# write params in a file \n",
    "param_dict = {\n",
    "    \"lr\": lr,\n",
    "    \"total_epochs\": total_epochs,\n",
    "    \"weight_TC\": weight_TC,\n",
    "    \"weight_decay\": weight_decay,\n",
    "    \"ce_loss_weight\": ce_loss_weight,\n",
    "    \"dice_loss_weight\": dice_loss_weight,\n",
    "    \"modelName\": modelName,\n",
    "    \"model\": \"ALL\"\n",
    "}\n",
    "\n",
    "\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "with open(f\"{model_dir}/params.txt\", 'w') as f:\n",
    "    print(param_dict, file=f)\n",
    "\n",
    "print(f\"Parameters saved to {model_dir}/params.txt\")\n",
    "\n",
    "print(f\"Parameters saved to {model_dir}/params.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cf0784",
   "metadata": {},
   "source": [
    "### Transformation consistency regularisation\n",
    "\n",
    "The transformation consistency consists in the principle that transformation T suchs as rotation and flipping should affect the mask f(y) only by the same rotation, which means that f and T should be symetrical. In this implementation, we used the 2-norm to measure the difference, and we included it in the optimisation problem.  $\\mathcal{L}_{TC}(y_u) = \\|f(T(y_u))-T(F(y))\\|_2$. \n",
    "Il est aussi possible de faire une régularisation avec la CE : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "16443fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "class ConsistencyRegularization(nn.Module):\n",
    "    def __init__(self, transformation_fn, loss_fn=nn.MSELoss()):\n",
    "        \"\"\"\n",
    "        Régularisation basée sur la consistance à la transformation.\n",
    "\n",
    "        Args:\n",
    "        -----\n",
    "            transformation_fn (callable): Fonction d'augmentation/transformation appliquée aux images.\n",
    "            loss_fn (callable): Fonction de perte utilisée pour comparer les prédictions (par défaut MSELoss). Aussi possible d'utiliser \n",
    "                                nn.KLDivLoss ou nn.BCELoss.\n",
    "        \"\"\"\n",
    "        super(ConsistencyRegularization, self).__init__()\n",
    "        self.transformation_fn = transformation_fn\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def forward(self, model, images):\n",
    "        \"\"\"\n",
    "        Calcule la perte de consistance.\n",
    "\n",
    "        Args:\n",
    "            model (torch.nn.Module): Le modèle de segmentation.\n",
    "            images (torch.Tensor): Batch d'images d'entrée.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: La perte de consistance.\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            # Prédictions de base\n",
    "            original_predictions = F.softmax(model(images), dim=1)\n",
    "\n",
    "        # Augmenter les images\n",
    "        augmented_images = self.transformation_fn(images)\n",
    "\n",
    "        # Prédictions pour les images augmentées\n",
    "        augmented_predictions = F.softmax(model(augmented_images), dim=1)\n",
    "\n",
    "        # Calcul de la perte de consistance\n",
    "        consistency_loss = self.loss_fn(original_predictions, augmented_predictions)\n",
    "\n",
    "        return consistency_loss\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "657ddeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_transformation_fn(images):\n",
    "  \n",
    "    # Random horizontal flip\n",
    "    if np.random.random() > 0.5:\n",
    "        images = torch.flip(images, dims=[2])\n",
    "    # Random vertical flip\n",
    "    if np.random.random() > 0.5:\n",
    "        images = torch.flip(images, dims=[3])\n",
    "    # Random rotation of random angle\n",
    "    if np.random.random() > 0.5:\n",
    "        angle = np.random.randint(0, 360)\n",
    "        images = torch.rot90(images, k=angle//90, dims=[2, 3])\n",
    "    return images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f5c928",
   "metadata": {},
   "source": [
    "### Training of the model \n",
    "\n",
    "At each epoch, the model sees once every exemple of unlabeled data, and sees several time the labeled data. We first train it with the labeled data, and then we train it on the unsupervised data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186cae12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "~~~~~~~~  Starting the training... ~~~~~~\n",
      "----------------------------------------\n",
      "Using device: cpu\n",
      "~~~~~~~~~~~ Creating the UNet model ~~~~~~~~~~\n",
      " Model Name: TransformationConsistencyL2Model-150epochs0.0005lr0.1alphaTC1e-05wd\n",
      "Total params: 60,664\n",
      "~~~~~~~~~~~ Starting the training ~~~~~~~~~~\n",
      "Number of batches:  126\n",
      "[Training] Epoch: 0 [>              ] 0.8% Loss: 0.9108, Epoch 0, Batch 0, CE_loss: 0.7725708484649658, Dice_loss: 0.13722284138202667, Consistency_loss: 0.0009954068809747696\n",
      "[Training] Epoch: 0 [>              ] 1.6% Loss: 0.8993, Epoch 0, Batch 1, CE_loss: 0.7535857558250427, Dice_loss: 0.13303980231285095, Consistency_loss: 0.0011002167593687773\n",
      "[Training] Epoch: 0 [>              ] 2.4% Loss: 0.8975, Epoch 0, Batch 2, CE_loss: 0.7586720585823059, Dice_loss: 0.13444791734218597, Consistency_loss: 0.000873930228408426\n",
      "[Training] Epoch: 0 [>              ] 3.2% Loss: 0.8966, Epoch 0, Batch 3, CE_loss: 0.7587300539016724, Dice_loss: 0.13419631123542786, Consistency_loss: 0.0009093969129025936\n",
      "[Training] Epoch: 0 [>              ] 4.0% Loss: 0.8982, Epoch 0, Batch 4, CE_loss: 0.7673879861831665, Dice_loss: 0.136295348405838, Consistency_loss: 0.0010337727144360542\n",
      "[Training] Epoch: 0 [>              ] 4.8% Loss: 0.8965, Epoch 0, Batch 5, CE_loss: 0.7535868287086487, Dice_loss: 0.1333218812942505, Consistency_loss: 0.0009648850536905229\n",
      "[Training] Epoch: 0 [>              ] 5.6% Loss: 0.8932, Epoch 0, Batch 6, CE_loss: 0.7415248155593872, Dice_loss: 0.13101941347122192, Consistency_loss: 0.000913401076104492\n",
      "[Training] Epoch: 0 [>              ] 6.3% Loss: 0.8891, Epoch 0, Batch 7, CE_loss: 0.7308022379875183, Dice_loss: 0.1288844347000122, Consistency_loss: 0.0010644558351486921\n",
      "[Training] Epoch: 0 [=>             ] 7.1% Loss: 0.8839, Epoch 0, Batch 8, CE_loss: 0.7152242064476013, Dice_loss: 0.12566494941711426, Consistency_loss: 0.0011166930198669434\n",
      "[Training] Epoch: 0 [=>             ] 7.9% Loss: 0.8842, Epoch 0, Batch 9, CE_loss: 0.7527521848678589, Dice_loss: 0.13338200747966766, Consistency_loss: 0.0007789676892571151\n",
      "[Training] Epoch: 0 [=>             ] 8.7% Loss: 0.8816, Epoch 0, Batch 10, CE_loss: 0.7265456318855286, Dice_loss: 0.127899631857872, Consistency_loss: 0.0008983029401861131\n",
      "[Training] Epoch: 0 [=>             ] 9.5% Loss: 0.8781, Epoch 0, Batch 11, CE_loss: 0.7141567468643188, Dice_loss: 0.12536977231502533, Consistency_loss: 0.0007328876527026296\n",
      "[Training] Epoch: 0 [=>             ] 10.3% Loss: 0.8763, Epoch 0, Batch 12, CE_loss: 0.7257803082466125, Dice_loss: 0.1276547908782959, Consistency_loss: 0.0008873617625795305\n",
      "[Training] Epoch: 0 [=>             ] 11.1% Loss: 0.8750, Epoch 0, Batch 13, CE_loss: 0.7290677428245544, Dice_loss: 0.12870390713214874, Consistency_loss: 0.0008468345040455461\n",
      "[Training] Epoch: 0 [=>             ] 11.9% Loss: 0.8726, Epoch 0, Batch 14, CE_loss: 0.712178111076355, Dice_loss: 0.1247713640332222, Consistency_loss: 0.0007584683480672538\n",
      "[Training] Epoch: 0 [=>             ] 12.7% Loss: 0.8711, Epoch 0, Batch 15, CE_loss: 0.722143828868866, Dice_loss: 0.12683239579200745, Consistency_loss: 0.0005784784443676472\n",
      "[Training] Epoch: 0 [==>            ] 13.5% Loss: 0.8686, Epoch 0, Batch 16, CE_loss: 0.7039651274681091, Dice_loss: 0.12324444949626923, Consistency_loss: 0.0005630396190099418\n",
      "[Training] Epoch: 0 [==>            ] 14.3% Loss: 0.8659, Epoch 0, Batch 17, CE_loss: 0.6975579857826233, Dice_loss: 0.12187240272760391, Consistency_loss: 0.0005714680883102119\n",
      "[Training] Epoch: 0 [==>            ] 15.1% Loss: 0.8629, Epoch 0, Batch 18, CE_loss: 0.6878814697265625, Dice_loss: 0.12007782608270645, Consistency_loss: 0.0005991501966491342\n",
      "[Training] Epoch: 0 [==>            ] 15.9% Loss: 0.8600, Epoch 0, Batch 19, CE_loss: 0.6847409009933472, Dice_loss: 0.11939984560012817, Consistency_loss: 0.000669208646286279\n",
      "[Training] Epoch: 0 [==>            ] 16.7% Loss: 0.8573, Epoch 0, Batch 20, CE_loss: 0.6847425103187561, Dice_loss: 0.11944212764501572, Consistency_loss: 0.0007338272989727557\n",
      "[Training] Epoch: 0 [==>            ] 17.5% Loss: 0.8547, Epoch 0, Batch 21, CE_loss: 0.6804035902023315, Dice_loss: 0.11849579960107803, Consistency_loss: 0.0007014937000349164\n",
      "[Training] Epoch: 0 [==>            ] 18.3% Loss: 0.8524, Epoch 0, Batch 22, CE_loss: 0.6826421022415161, Dice_loss: 0.11914248764514923, Consistency_loss: 0.0005808998830616474\n",
      "[Training] Epoch: 0 [==>            ] 19.0% Loss: 0.8501, Epoch 0, Batch 23, CE_loss: 0.6794100403785706, Dice_loss: 0.11823619157075882, Consistency_loss: 6.038658739271341e-06\n",
      "[Training] Epoch: 0 [==>            ] 19.8% Loss: 0.8488, Epoch 0, Batch 24, CE_loss: 0.6950744986534119, Dice_loss: 0.12136561423540115, Consistency_loss: 0.0007661783020012081\n",
      "[Training] Epoch: 0 [===>           ] 20.6% Loss: 0.8468, Epoch 0, Batch 25, CE_loss: 0.6785759925842285, Dice_loss: 0.11799626797437668, Consistency_loss: 0.0007701335707679391\n",
      "[Training] Epoch: 0 [===>           ] 21.4% Loss: 0.8453, Epoch 0, Batch 26, CE_loss: 0.6841185092926025, Dice_loss: 0.11888007819652557, Consistency_loss: 0.0007662961143068969\n",
      "[Training] Epoch: 0 [===>           ] 22.2% Loss: 0.8431, Epoch 0, Batch 27, CE_loss: 0.6684288382530212, Dice_loss: 0.11562331020832062, Consistency_loss: 0.000519788998644799\n",
      "[Training] Epoch: 0 [===>           ] 23.0% Loss: 0.8415, Epoch 0, Batch 28, CE_loss: 0.6789687871932983, Dice_loss: 0.11776545643806458, Consistency_loss: 0.0005851112655363977\n",
      "[Training] Epoch: 0 [===>           ] 23.8% Loss: 0.8393, Epoch 0, Batch 29, CE_loss: 0.6599399447441101, Dice_loss: 0.11413102596998215, Consistency_loss: 0.0005947467288933694\n",
      "[Training] Epoch: 0 [===>           ] 24.6% Loss: 0.8374, Epoch 0, Batch 30, CE_loss: 0.6648085117340088, Dice_loss: 0.11489135771989822, Consistency_loss: 5.577622232522117e-06\n",
      "[Training] Epoch: 0 [===>           ] 25.4% Loss: 0.8353, Epoch 0, Batch 31, CE_loss: 0.6565685272216797, Dice_loss: 0.11304495483636856, Consistency_loss: 0.0007310336804948747\n",
      "[Training] Epoch: 0 [===>           ] 26.2% Loss: 0.8331, Epoch 0, Batch 32, CE_loss: 0.650300920009613, Dice_loss: 0.11183004826307297, Consistency_loss: 0.0007279286510311067\n",
      "[Training] Epoch: 0 [====>          ] 27.0% Loss: 0.8313, Epoch 0, Batch 33, CE_loss: 0.6582808494567871, Dice_loss: 0.11334947496652603, Consistency_loss: 0.0006502476753666997\n",
      "[Training] Epoch: 0 [====>          ] 27.8% Loss: 0.8294, Epoch 0, Batch 34, CE_loss: 0.6518891453742981, Dice_loss: 0.11223561316728592, Consistency_loss: 0.0006250999867916107\n",
      "[Training] Epoch: 0 [====>          ] 28.6% Loss: 0.8271, Epoch 0, Batch 35, CE_loss: 0.6377424597740173, Dice_loss: 0.10925648361444473, Consistency_loss: 0.0006510770763270557\n",
      "[Training] Epoch: 0 [====>          ] 29.4% Loss: 0.8252, Epoch 0, Batch 36, CE_loss: 0.644687831401825, Dice_loss: 0.11066913604736328, Consistency_loss: 0.0006449567154049873\n",
      "[Training] Epoch: 0 [====>          ] 30.2% Loss: 0.8240, Epoch 0, Batch 37, CE_loss: 0.6653342843055725, Dice_loss: 0.11467701941728592, Consistency_loss: 0.0005071964114904404\n",
      "[Training] Epoch: 0 [====>          ] 31.0% Loss: 0.8219, Epoch 0, Batch 38, CE_loss: 0.6343384981155396, Dice_loss: 0.10820351541042328, Consistency_loss: 0.0006166316452436149\n",
      "[Training] Epoch: 0 [====>          ] 31.7% Loss: 0.8201, Epoch 0, Batch 39, CE_loss: 0.6378811597824097, Dice_loss: 0.10892836004495621, Consistency_loss: 0.0005346212419681251\n",
      "[Training] Epoch: 0 [====>          ] 32.5% Loss: 0.8185, Epoch 0, Batch 40, CE_loss: 0.6439825296401978, Dice_loss: 0.11030323803424835, Consistency_loss: 0.0005973116494715214\n",
      "[Training] Epoch: 0 [=====>         ] 33.3% Loss: 0.8171, Epoch 0, Batch 41, CE_loss: 0.6490388512611389, Dice_loss: 0.11112506687641144, Consistency_loss: 0.0005388199351727962\n",
      "[Training] Epoch: 0 [=====>         ] 34.1% Loss: 0.8153, Epoch 0, Batch 42, CE_loss: 0.631430983543396, Dice_loss: 0.1075701117515564, Consistency_loss: 2.8030244720866904e-06\n",
      "[Training] Epoch: 0 [=====>         ] 34.9% Loss: 0.8138, Epoch 0, Batch 43, CE_loss: 0.6408033967018127, Dice_loss: 0.10907182842493057, Consistency_loss: 0.0006997092859819531\n",
      "[Training] Epoch: 0 [=====>         ] 35.7% Loss: 0.8127, Epoch 0, Batch 44, CE_loss: 0.652345597743988, Dice_loss: 0.11133240908384323, Consistency_loss: 0.0006684251129627228\n",
      "[Training] Epoch: 0 [=====>         ] 36.5% Loss: 0.8115, Epoch 0, Batch 45, CE_loss: 0.6462019681930542, Dice_loss: 0.11027257889509201, Consistency_loss: 0.000518957560416311\n",
      "[Training] Epoch: 0 [=====>         ] 37.3% Loss: 0.8098, Epoch 0, Batch 46, CE_loss: 0.6233348250389099, Dice_loss: 0.10559041053056717, Consistency_loss: 3.841425041173352e-06\n",
      "[Training] Epoch: 0 [=====>         ] 38.1% Loss: 0.8082, Epoch 0, Batch 47, CE_loss: 0.6293891668319702, Dice_loss: 0.10672187060117722, Consistency_loss: 4.239977442921372e-06\n",
      "[Training] Epoch: 0 [=====>         ] 38.9% Loss: 0.8067, Epoch 0, Batch 48, CE_loss: 0.6262146234512329, Dice_loss: 0.10589077323675156, Consistency_loss: 0.0006451362278312445\n",
      "[Training] Epoch: 0 [=====>         ] 39.7% Loss: 0.8051, Epoch 0, Batch 49, CE_loss: 0.6228426694869995, Dice_loss: 0.10531163960695267, Consistency_loss: 0.0006441231234930456\n",
      "[Training] Epoch: 0 [======>        ] 40.5% Loss: 0.8036, Epoch 0, Batch 50, CE_loss: 0.6208065748214722, Dice_loss: 0.10473044216632843, Consistency_loss: 0.0006224117241799831\n",
      "[Training] Epoch: 0 [======>        ] 41.3% Loss: 0.8022, Epoch 0, Batch 51, CE_loss: 0.627069354057312, Dice_loss: 0.10587937384843826, Consistency_loss: 0.0005469160969369113\n",
      "[Training] Epoch: 0 [======>        ] 42.1% Loss: 0.8008, Epoch 0, Batch 52, CE_loss: 0.6205188035964966, Dice_loss: 0.10464463382959366, Consistency_loss: 3.4711299576883903e-06\n",
      "[Training] Epoch: 0 [======>        ] 42.9% Loss: 0.7992, Epoch 0, Batch 53, CE_loss: 0.6122877597808838, Dice_loss: 0.1029101088643074, Consistency_loss: 0.0006774834473617375\n",
      "[Training] Epoch: 0 [======>        ] 43.7% Loss: 0.7977, Epoch 0, Batch 54, CE_loss: 0.6146059036254883, Dice_loss: 0.10315559059381485, Consistency_loss: 0.000519552209880203\n",
      "[Training] Epoch: 0 [======>        ] 44.4% Loss: 0.7964, Epoch 0, Batch 55, CE_loss: 0.6174351572990417, Dice_loss: 0.10377441346645355, Consistency_loss: 0.0005094418302178383\n",
      "[Training] Epoch: 0 [======>        ] 45.2% Loss: 0.7951, Epoch 0, Batch 56, CE_loss: 0.6206982135772705, Dice_loss: 0.10426285117864609, Consistency_loss: 0.00032779775210656226\n",
      "[Training] Epoch: 0 [======>        ] 46.0% Loss: 0.7935, Epoch 0, Batch 57, CE_loss: 0.6020527482032776, Dice_loss: 0.10069113969802856, Consistency_loss: 0.0005316915339790285\n",
      "[Training] Epoch: 0 [=======>       ] 46.8% Loss: 0.7919, Epoch 0, Batch 58, CE_loss: 0.5955226421356201, Dice_loss: 0.09920666366815567, Consistency_loss: 2.239998138975352e-06\n",
      "[Training] Epoch: 0 [=======>       ] 47.6% Loss: 0.7906, Epoch 0, Batch 59, CE_loss: 0.6152799725532532, Dice_loss: 0.10298279672861099, Consistency_loss: 1.8608812979437062e-06\n",
      "[Training] Epoch: 0 [=======>       ] 48.4% Loss: 0.7894, Epoch 0, Batch 60, CE_loss: 0.6141951084136963, Dice_loss: 0.10279242694377899, Consistency_loss: 2.3210939161799615e-06\n",
      "[Training] Epoch: 0 [=======>       ] 49.2% Loss: 0.7879, Epoch 0, Batch 61, CE_loss: 0.5931473970413208, Dice_loss: 0.09850668907165527, Consistency_loss: 0.0006176025490276515\n",
      "[Training] Epoch: 0 [=======>       ] 50.0% Loss: 0.7864, Epoch 0, Batch 62, CE_loss: 0.5969469547271729, Dice_loss: 0.09922084957361221, Consistency_loss: 0.0003984794020652771\n",
      "[Training] Epoch: 0 [=======>       ] 50.8% Loss: 0.7852, Epoch 0, Batch 63, CE_loss: 0.6073776483535767, Dice_loss: 0.10120051354169846, Consistency_loss: 0.0004468914121389389\n",
      "[Training] Epoch: 0 [=======>       ] 51.6% Loss: 0.7836, Epoch 0, Batch 64, CE_loss: 0.583834171295166, Dice_loss: 0.09652424603700638, Consistency_loss: 0.00045543108717538416\n",
      "[Training] Epoch: 0 [=======>       ] 52.4% Loss: 0.7822, Epoch 0, Batch 65, CE_loss: 0.5928763151168823, Dice_loss: 0.0981382355093956, Consistency_loss: 0.0004199397808406502\n",
      "[Training] Epoch: 0 [=======>       ] 53.2% Loss: 0.7808, Epoch 0, Batch 66, CE_loss: 0.5922372341156006, Dice_loss: 0.09803647547960281, Consistency_loss: 0.000534989929292351\n",
      "[Training] Epoch: 0 [========>      ] 54.0% Loss: 0.7797, Epoch 0, Batch 67, CE_loss: 0.6011939644813538, Dice_loss: 0.09992758929729462, Consistency_loss: 2.2587419152841903e-06\n",
      "[Training] Epoch: 0 [========>      ] 54.8% Loss: 0.7784, Epoch 0, Batch 68, CE_loss: 0.5907233953475952, Dice_loss: 0.09760399162769318, Consistency_loss: 0.0004384475469123572\n",
      "[Training] Epoch: 0 [========>      ] 55.6% Loss: 0.7772, Epoch 0, Batch 69, CE_loss: 0.5972112417221069, Dice_loss: 0.09881733357906342, Consistency_loss: 0.0005375559558160603\n",
      "[Training] Epoch: 0 [========>      ] 56.3% Loss: 0.7760, Epoch 0, Batch 70, CE_loss: 0.5954325199127197, Dice_loss: 0.0983065739274025, Consistency_loss: 0.00054932915372774\n",
      "[Training] Epoch: 0 [========>      ] 57.1% Loss: 0.7747, Epoch 0, Batch 71, CE_loss: 0.5824529528617859, Dice_loss: 0.09568965435028076, Consistency_loss: 0.0005150163196958601\n",
      "[Training] Epoch: 0 [========>      ] 57.9% Loss: 0.7734, Epoch 0, Batch 72, CE_loss: 0.587834358215332, Dice_loss: 0.09667355567216873, Consistency_loss: 0.000614773656707257\n",
      "[Training] Epoch: 0 [========>      ] 58.7% Loss: 0.7722, Epoch 0, Batch 73, CE_loss: 0.5859885215759277, Dice_loss: 0.09619557112455368, Consistency_loss: 0.000497898377943784\n",
      "[Training] Epoch: 0 [========>      ] 59.5% Loss: 0.7708, Epoch 0, Batch 74, CE_loss: 0.5709033608436584, Dice_loss: 0.09318982064723969, Consistency_loss: 0.0005301025230437517\n",
      "[Training] Epoch: 0 [=========>     ] 60.3% Loss: 0.7694, Epoch 0, Batch 75, CE_loss: 0.5728744268417358, Dice_loss: 0.09354036301374435, Consistency_loss: 2.4038658921199385e-06\n",
      "[Training] Epoch: 0 [=========>     ] 61.1% Loss: 0.7679, Epoch 0, Batch 76, CE_loss: 0.5649589896202087, Dice_loss: 0.09187431633472443, Consistency_loss: 0.0004457199538592249\n",
      "[Training] Epoch: 0 [=========>     ] 61.9% Loss: 0.7668, Epoch 0, Batch 77, CE_loss: 0.5828377604484558, Dice_loss: 0.09540151804685593, Consistency_loss: 0.0006328377057798207\n",
      "[Training] Epoch: 0 [=========>     ] 62.7% Loss: 0.7656, Epoch 0, Batch 78, CE_loss: 0.5782988667488098, Dice_loss: 0.09425821900367737, Consistency_loss: 0.000564276531804353\n",
      "[Training] Epoch: 0 [=========>     ] 63.5% Loss: 0.7644, Epoch 0, Batch 79, CE_loss: 0.5758258104324341, Dice_loss: 0.09394534677267075, Consistency_loss: 0.0004978333017788827\n",
      "[Training] Epoch: 0 [=========>     ] 64.3% Loss: 0.7631, Epoch 0, Batch 80, CE_loss: 0.5647570490837097, Dice_loss: 0.09143640846014023, Consistency_loss: 0.0003743475244846195\n",
      "[Training] Epoch: 0 [=========>     ] 65.1% Loss: 0.7618, Epoch 0, Batch 81, CE_loss: 0.5642293095588684, Dice_loss: 0.09131845831871033, Consistency_loss: 0.0006707109860144556\n",
      "[Training] Epoch: 0 [=========>     ] 65.9% Loss: 0.7604, Epoch 0, Batch 82, CE_loss: 0.5587437748908997, Dice_loss: 0.09027211368083954, Consistency_loss: 0.0005622474709525704\n",
      "[Training] Epoch: 0 [==========>    ] 66.7% Loss: 0.7594, Epoch 0, Batch 83, CE_loss: 0.5765020847320557, Dice_loss: 0.09374134987592697, Consistency_loss: 0.0005628387443721294\n",
      "[Training] Epoch: 0 [==========>    ] 67.5% Loss: 0.7582, Epoch 0, Batch 84, CE_loss: 0.5683258175849915, Dice_loss: 0.09209675341844559, Consistency_loss: 1.897624656521657e-06\n",
      "[Training] Epoch: 0 [==========>    ] 68.3% Loss: 0.7569, Epoch 0, Batch 85, CE_loss: 0.5569326877593994, Dice_loss: 0.08963444828987122, Consistency_loss: 0.0005450114258565009\n",
      "[Training] Epoch: 0 [==========>    ] 69.0% Loss: 0.7556, Epoch 0, Batch 86, CE_loss: 0.550848662853241, Dice_loss: 0.08853251487016678, Consistency_loss: 0.00046987636596895754\n",
      "[Training] Epoch: 0 [==========>    ] 69.8% Loss: 0.7546, Epoch 0, Batch 87, CE_loss: 0.5740115642547607, Dice_loss: 0.09304855018854141, Consistency_loss: 0.0005252067930996418\n",
      "[Training] Epoch: 0 [==========>    ] 70.6% Loss: 0.7534, Epoch 0, Batch 88, CE_loss: 0.5623510479927063, Dice_loss: 0.09052540361881256, Consistency_loss: 0.0005329977720975876\n",
      "[Training] Epoch: 0 [==========>    ] 71.4% Loss: 0.7522, Epoch 0, Batch 89, CE_loss: 0.5543748140335083, Dice_loss: 0.08917447924613953, Consistency_loss: 0.0005329817649908364\n",
      "[Training] Epoch: 0 [==========>    ] 72.2% Loss: 0.7510, Epoch 0, Batch 90, CE_loss: 0.553211510181427, Dice_loss: 0.08883010596036911, Consistency_loss: 0.0004998811637051404\n",
      "[Training] Epoch: 0 [==========>    ] 73.0% Loss: 0.7497, Epoch 0, Batch 91, CE_loss: 0.5458980798721313, Dice_loss: 0.08738486468791962, Consistency_loss: 0.0005760650965385139\n",
      "[Training] Epoch: 0 [===========>   ] 73.8% Loss: 0.7487, Epoch 0, Batch 92, CE_loss: 0.5602908730506897, Dice_loss: 0.08993440866470337, Consistency_loss: 0.00045443890849128366\n",
      "[Training] Epoch: 0 [===========>   ] 74.6% Loss: 0.7477, Epoch 0, Batch 93, CE_loss: 0.562074601650238, Dice_loss: 0.09004563838243484, Consistency_loss: 0.0003235061594750732\n",
      "[Training] Epoch: 0 [===========>   ] 75.4% Loss: 0.7464, Epoch 0, Batch 94, CE_loss: 0.5382000803947449, Dice_loss: 0.08536452054977417, Consistency_loss: 0.0006187519757077098\n",
      "[Training] Epoch: 0 [===========>   ] 76.2% Loss: 0.7451, Epoch 0, Batch 95, CE_loss: 0.5367239117622375, Dice_loss: 0.08535323292016983, Consistency_loss: 0.0005635832203552127\n",
      "[Training] Epoch: 0 [===========>   ] 77.0% Loss: 0.7438, Epoch 0, Batch 96, CE_loss: 0.5357413291931152, Dice_loss: 0.08488547801971436, Consistency_loss: 0.0005701998597942293\n",
      "[Training] Epoch: 0 [===========>   ] 77.8% Loss: 0.7427, Epoch 0, Batch 97, CE_loss: 0.5497381091117859, Dice_loss: 0.0875704437494278, Consistency_loss: 0.00035343802301213145\n",
      "[Training] Epoch: 0 [===========>   ] 78.6% Loss: 0.7414, Epoch 0, Batch 98, CE_loss: 0.53022301197052, Dice_loss: 0.08376045525074005, Consistency_loss: 0.0004344318003859371\n",
      "[Training] Epoch: 0 [===========>   ] 79.4% Loss: 0.7401, Epoch 0, Batch 99, CE_loss: 0.5302652716636658, Dice_loss: 0.08349072933197021, Consistency_loss: 0.0004175624344497919\n",
      "[Training] Epoch: 0 [============>  ] 80.2% Loss: 0.7391, Epoch 0, Batch 100, CE_loss: 0.5486692786216736, Dice_loss: 0.08736541867256165, Consistency_loss: 1.1665717920550378e-06\n",
      "[Training] Epoch: 0 [============>  ] 81.0% Loss: 0.7381, Epoch 0, Batch 101, CE_loss: 0.5453142523765564, Dice_loss: 0.08651936054229736, Consistency_loss: 0.00038894431781955063\n",
      "[Training] Epoch: 0 [============>  ] 81.7% Loss: 0.7369, Epoch 0, Batch 102, CE_loss: 0.5372952818870544, Dice_loss: 0.08464568108320236, Consistency_loss: 0.0005523908184841275\n",
      "[Training] Epoch: 0 [============>  ] 82.5% Loss: 0.7357, Epoch 0, Batch 103, CE_loss: 0.5270969867706299, Dice_loss: 0.0826016217470169, Consistency_loss: 0.0003369019250385463\n",
      "[Training] Epoch: 0 [============>  ] 83.3% Loss: 0.7346, Epoch 0, Batch 104, CE_loss: 0.5329407453536987, Dice_loss: 0.08377552032470703, Consistency_loss: 0.0005610520020127296\n",
      "[Training] Epoch: 0 [============>  ] 84.1% Loss: 0.7333, Epoch 0, Batch 105, CE_loss: 0.5208805799484253, Dice_loss: 0.08122424781322479, Consistency_loss: 0.0006818808033131063\n",
      "[Training] Epoch: 0 [============>  ] 84.9% Loss: 0.7323, Epoch 0, Batch 106, CE_loss: 0.5325436592102051, Dice_loss: 0.0836547315120697, Consistency_loss: 0.0005036070360802114\n",
      "[Training] Epoch: 0 [============>  ] 85.7% Loss: 0.7313, Epoch 0, Batch 107, CE_loss: 0.5386832356452942, Dice_loss: 0.0846179649233818, Consistency_loss: 0.0006415318930521607\n",
      "[Training] Epoch: 0 [============>  ] 86.5% Loss: 0.7300, Epoch 0, Batch 108, CE_loss: 0.5120527744293213, Dice_loss: 0.07949259877204895, Consistency_loss: 1.0981335663018399e-06\n",
      "[Training] Epoch: 0 [=============> ] 87.3% Loss: 0.7288, Epoch 0, Batch 109, CE_loss: 0.5222814083099365, Dice_loss: 0.08158906549215317, Consistency_loss: 1.0243268206977518e-06\n",
      "[Training] Epoch: 0 [=============> ] 88.1% Loss: 0.7276, Epoch 0, Batch 110, CE_loss: 0.5144878029823303, Dice_loss: 0.07993310689926147, Consistency_loss: 0.0006168193649500608\n",
      "[Training] Epoch: 0 [=============> ] 88.9% Loss: 0.7263, Epoch 0, Batch 111, CE_loss: 0.5044098496437073, Dice_loss: 0.07796584814786911, Consistency_loss: 8.788343848209479e-07\n",
      "[Training] Epoch: 0 [=============> ] 89.7% Loss: 0.7255, Epoch 0, Batch 112, CE_loss: 0.543341875076294, Dice_loss: 0.08550113439559937, Consistency_loss: 0.0004892435972578824\n",
      "[Training] Epoch: 0 [=============> ] 90.5% Loss: 0.7244, Epoch 0, Batch 113, CE_loss: 0.5182180404663086, Dice_loss: 0.08040318638086319, Consistency_loss: 0.0005011159810237586\n",
      "[Training] Epoch: 0 [=============> ] 91.3% Loss: 0.7232, Epoch 0, Batch 114, CE_loss: 0.508219301700592, Dice_loss: 0.07867852598428726, Consistency_loss: 0.00048596240230835974\n",
      "[Training] Epoch: 0 [=============> ] 92.1% Loss: 0.7220, Epoch 0, Batch 115, CE_loss: 0.5106412768363953, Dice_loss: 0.07888231426477432, Consistency_loss: 0.0003879521682392806\n",
      "[Training] Epoch: 0 [=============> ] 92.9% Loss: 0.7210, Epoch 0, Batch 116, CE_loss: 0.5200179219245911, Dice_loss: 0.08071547001600266, Consistency_loss: 0.0005820213700644672\n",
      "[Training] Epoch: 0 [==============>] 93.7% Loss: 0.7200, Epoch 0, Batch 117, CE_loss: 0.5203408598899841, Dice_loss: 0.08075785636901855, Consistency_loss: 0.0002957997203338891\n",
      "[Training] Epoch: 0 [==============>] 94.4% Loss: 0.7189, Epoch 0, Batch 118, CE_loss: 0.5118942856788635, Dice_loss: 0.0790821760892868, Consistency_loss: 0.0005446326686069369\n",
      "[Training] Epoch: 0 [==============>] 95.2% Loss: 0.7177, Epoch 0, Batch 119, CE_loss: 0.49515312910079956, Dice_loss: 0.07559412717819214, Consistency_loss: 0.0005136034451425076\n",
      "[Training] Epoch: 0 [==============>] 96.0% Loss: 0.7167, Epoch 0, Batch 120, CE_loss: 0.5175319314002991, Dice_loss: 0.07993803173303604, Consistency_loss: 0.000246243376750499\n",
      "[Training] Epoch: 0 [==============>] 96.8% Loss: 0.7156, Epoch 0, Batch 121, CE_loss: 0.5119928121566772, Dice_loss: 0.07892119884490967, Consistency_loss: 0.0001782560721039772\n",
      "[Training] Epoch: 0 [==============>] 97.6% Loss: 0.7146, Epoch 0, Batch 122, CE_loss: 0.5046755075454712, Dice_loss: 0.07755445688962936, Consistency_loss: 0.00037233714829199016\n",
      "[Training] Epoch: 0 [==============>] 98.4% Loss: 0.7136, Epoch 0, Batch 123, CE_loss: 0.5126675367355347, Dice_loss: 0.07891303300857544, Consistency_loss: 0.00027984086773358285\n",
      "[Training] Epoch: 0 [==============>] 99.2% Loss: 0.7125, Epoch 0, Batch 124, CE_loss: 0.5003950595855713, Dice_loss: 0.0762980580329895, Consistency_loss: 0.0006239675567485392\n",
      "[Training] Epoch: 0 [DONE]                                 \n",
      "Epoch 0, Batch 125, CE_loss: 0.5078166127204895, Dice_loss: 0.07787846773862839, Consistency_loss: 0.0007032376597635448\n",
      "Epoch 0, Batch 125, CE_loss: 0.5078166127204895, Dice_loss: 0.07787846773862839, Consistency_loss: 0.0007032376597635448\n",
      "[Validation] Epoch: 0 [DONE]                                 \n",
      "[Epoch: 0, TrainLoss: 0.7115, TrainDice: 0.1016, ValLoss: 0.7191                                             \n",
      "Number of batches:  126\n",
      "[Training] Epoch: 1 [>              ] 0.8% Loss: 0.5780, Epoch 1, Batch 0, CE_loss: 0.5012713670730591, Dice_loss: 0.07644420117139816, Consistency_loss: 0.00030046942993067205\n",
      "[Training] Epoch: 1 [>              ] 1.6% Loss: 0.5768, Epoch 1, Batch 1, CE_loss: 0.4989299774169922, Dice_loss: 0.07615097612142563, Consistency_loss: 0.00045057013630867004\n",
      "[Training] Epoch: 1 [>              ] 2.4% Loss: 0.5751, Epoch 1, Batch 2, CE_loss: 0.49635836482048035, Dice_loss: 0.07541020959615707, Consistency_loss: 8.637739483674522e-07\n",
      "[Training] Epoch: 1 [>              ] 3.2% Loss: 0.5702, Epoch 1, Batch 3, CE_loss: 0.48239338397979736, Dice_loss: 0.07271213084459305, Consistency_loss: 0.0003299455565866083\n",
      "[Training] Epoch: 1 [>              ] 4.0% Loss: 0.5695, Epoch 1, Batch 4, CE_loss: 0.49176454544067383, Dice_loss: 0.07434289157390594, Consistency_loss: 0.0005645028431899846\n",
      "[Training] Epoch: 1 [>              ] 4.8% Loss: 0.5672, Epoch 1, Batch 5, CE_loss: 0.48274439573287964, Dice_loss: 0.07266808301210403, Consistency_loss: 0.0005311387358233333\n",
      "[Training] Epoch: 1 [>              ] 5.6% Loss: 0.5676, Epoch 1, Batch 6, CE_loss: 0.49468329548835754, Dice_loss: 0.07489520311355591, Consistency_loss: 9.626830888009863e-07\n",
      "[Training] Epoch: 1 [>              ] 6.3% Loss: 0.5669, Epoch 1, Batch 7, CE_loss: 0.4881087839603424, Dice_loss: 0.07356052100658417, Consistency_loss: 0.0005618092254735529\n",
      "[Training] Epoch: 1 [=>             ] 7.1% Loss: 0.5654, Epoch 1, Batch 8, CE_loss: 0.48132309317588806, Dice_loss: 0.07220715284347534, Consistency_loss: 0.00028037160518579185\n",
      "[Training] Epoch: 1 [=>             ] 7.9% Loss: 0.5642, Epoch 1, Batch 9, CE_loss: 0.48106199502944946, Dice_loss: 0.07223182916641235, Consistency_loss: 7.717730454714911e-07\n",
      "[Training] Epoch: 1 [=>             ] 8.7% Loss: 0.5637, Epoch 1, Batch 10, CE_loss: 0.48535460233688354, Dice_loss: 0.0728084072470665, Consistency_loss: 0.0006759663228876889\n",
      "[Training] Epoch: 1 [=>             ] 9.5% Loss: 0.5652, Epoch 1, Batch 11, CE_loss: 0.5037634968757629, Dice_loss: 0.07643097639083862, Consistency_loss: 0.0006031525554135442\n",
      "[Training] Epoch: 1 [=>             ] 10.3% Loss: 0.5647, Epoch 1, Batch 12, CE_loss: 0.48542389273643494, Dice_loss: 0.07285234332084656, Consistency_loss: 0.0005158332642167807\n",
      "[Training] Epoch: 1 [=>             ] 11.1% Loss: 0.5642, Epoch 1, Batch 13, CE_loss: 0.48489317297935486, Dice_loss: 0.07284478843212128, Consistency_loss: 1.1446250027802307e-06\n",
      "[Training] Epoch: 1 [=>             ] 11.9% Loss: 0.5638, Epoch 1, Batch 14, CE_loss: 0.48611122369766235, Dice_loss: 0.07289991527795792, Consistency_loss: 9.504765330348164e-07\n",
      "[Training] Epoch: 1 [=>             ] 12.7% Loss: 0.5638, Epoch 1, Batch 15, CE_loss: 0.48935824632644653, Dice_loss: 0.07332555949687958, Consistency_loss: 0.00040501035982742906\n",
      "[Training] Epoch: 1 [==>            ] 13.5% Loss: 0.5633, Epoch 1, Batch 16, CE_loss: 0.4827796518802643, Dice_loss: 0.07206258177757263, Consistency_loss: 0.0003641412768047303\n",
      "[Training] Epoch: 1 [==>            ] 14.3% Loss: 0.5618, Epoch 1, Batch 17, CE_loss: 0.46726474165916443, Dice_loss: 0.0692322626709938, Consistency_loss: 0.0006087973015382886\n",
      "[Training] Epoch: 1 [==>            ] 15.1% Loss: 0.5623, Epoch 1, Batch 18, CE_loss: 0.4963529407978058, Dice_loss: 0.07472926378250122, Consistency_loss: 0.0006497267750091851\n",
      "[Training] Epoch: 1 [==>            ] 15.9% Loss: 0.5611, Epoch 1, Batch 19, CE_loss: 0.4685595631599426, Dice_loss: 0.06899645924568176, Consistency_loss: 0.0006190698477439582\n",
      "[Training] Epoch: 1 [==>            ] 16.7% Loss: 0.5612, Epoch 1, Batch 20, CE_loss: 0.48851650953292847, Dice_loss: 0.07311241328716278, Consistency_loss: 0.0006669021677225828\n",
      "[Training] Epoch: 1 [==>            ] 17.5% Loss: 0.5603, Epoch 1, Batch 21, CE_loss: 0.47070878744125366, Dice_loss: 0.06969200074672699, Consistency_loss: 0.0006153333815746009\n",
      "[Training] Epoch: 1 [==>            ] 18.3% Loss: 0.5597, Epoch 1, Batch 22, CE_loss: 0.4766441583633423, Dice_loss: 0.07052911818027496, Consistency_loss: 0.0006649142596870661\n",
      "[Training] Epoch: 1 [==>            ] 19.0% Loss: 0.5585, Epoch 1, Batch 23, CE_loss: 0.46242791414260864, Dice_loss: 0.06789330393075943, Consistency_loss: 0.0005196462734602392\n",
      "[Training] Epoch: 1 [==>            ] 19.8% Loss: 0.5584, Epoch 1, Batch 24, CE_loss: 0.4834894835948944, Dice_loss: 0.07195664197206497, Consistency_loss: 0.0005640048766508698\n",
      "[Training] Epoch: 1 [===>           ] 20.6% Loss: 0.5569, Epoch 1, Batch 25, CE_loss: 0.45274674892425537, Dice_loss: 0.06601431965827942, Consistency_loss: 0.0005571056972257793\n",
      "[Training] Epoch: 1 [===>           ] 21.4% Loss: 0.5561, Epoch 1, Batch 26, CE_loss: 0.4649321436882019, Dice_loss: 0.06816935539245605, Consistency_loss: 0.0004470681888051331\n",
      "[Training] Epoch: 1 [===>           ] 22.2% Loss: 0.5552, Epoch 1, Batch 27, CE_loss: 0.46505019068717957, Dice_loss: 0.06829658150672913, Consistency_loss: 7.236985197778267e-07\n",
      "[Training] Epoch: 1 [===>           ] 23.0% Loss: 0.5544, Epoch 1, Batch 28, CE_loss: 0.46315649151802063, Dice_loss: 0.06778406351804733, Consistency_loss: 0.0006295967032201588\n",
      "[Training] Epoch: 1 [===>           ] 23.8% Loss: 0.5539, Epoch 1, Batch 29, CE_loss: 0.46953943371772766, Dice_loss: 0.06898055225610733, Consistency_loss: 0.00038369925459846854\n",
      "[Training] Epoch: 1 [===>           ] 24.6% Loss: 0.5533, Epoch 1, Batch 30, CE_loss: 0.4666791558265686, Dice_loss: 0.06840276718139648, Consistency_loss: 0.0006303982227109373\n",
      "[Training] Epoch: 1 [===>           ] 25.4% Loss: 0.5528, Epoch 1, Batch 31, CE_loss: 0.46741849184036255, Dice_loss: 0.06839229166507721, Consistency_loss: 0.000494650099426508\n",
      "[Training] Epoch: 1 [===>           ] 26.2% Loss: 0.5521, Epoch 1, Batch 32, CE_loss: 0.4620850384235382, Dice_loss: 0.06738289445638657, Consistency_loss: 0.0006140472833067179\n",
      "[Training] Epoch: 1 [====>          ] 27.0% Loss: 0.5521, Epoch 1, Batch 33, CE_loss: 0.48000168800354004, Dice_loss: 0.07086868584156036, Consistency_loss: 1.2914309763800702e-06\n",
      "[Training] Epoch: 1 [====>          ] 27.8% Loss: 0.5513, Epoch 1, Batch 34, CE_loss: 0.4583738446235657, Dice_loss: 0.06667131185531616, Consistency_loss: 0.0006406292668543756\n",
      "[Training] Epoch: 1 [====>          ] 28.6% Loss: 0.5511, Epoch 1, Batch 35, CE_loss: 0.4726714491844177, Dice_loss: 0.06942253559827805, Consistency_loss: 0.0007097049965523183\n",
      "[Training] Epoch: 1 [====>          ] 29.4% Loss: 0.5501, Epoch 1, Batch 36, CE_loss: 0.44964662194252014, Dice_loss: 0.06475266069173813, Consistency_loss: 0.0005743531510233879\n",
      "[Training] Epoch: 1 [====>          ] 30.2% Loss: 0.5492, Epoch 1, Batch 37, CE_loss: 0.45099905133247375, Dice_loss: 0.06501596421003342, Consistency_loss: 0.0006821022252552211\n",
      "[Training] Epoch: 1 [====>          ] 31.0% Loss: 0.5486, Epoch 1, Batch 38, CE_loss: 0.4579121470451355, Dice_loss: 0.06632858514785767, Consistency_loss: 0.00056496198521927\n",
      "[Training] Epoch: 1 [====>          ] 31.7% Loss: 0.5474, Epoch 1, Batch 39, CE_loss: 0.43799370527267456, Dice_loss: 0.06254542618989944, Consistency_loss: 0.0005945555749349296\n",
      "[Training] Epoch: 1 [====>          ] 32.5% Loss: 0.5465, Epoch 1, Batch 40, CE_loss: 0.44757014513015747, Dice_loss: 0.06429504603147507, Consistency_loss: 6.582360470019921e-07\n",
      "[Training] Epoch: 1 [=====>         ] 33.3% Loss: 0.5461, Epoch 1, Batch 41, CE_loss: 0.46095848083496094, Dice_loss: 0.06686797738075256, Consistency_loss: 0.0005642750184051692\n",
      "[Training] Epoch: 1 [=====>         ] 34.1% Loss: 0.5457, Epoch 1, Batch 42, CE_loss: 0.46168142557144165, Dice_loss: 0.06709977239370346, Consistency_loss: 0.0004224821168463677\n",
      "[Training] Epoch: 1 [=====>         ] 34.9% Loss: 0.5449, Epoch 1, Batch 43, CE_loss: 0.44494184851646423, Dice_loss: 0.0638580471277237, Consistency_loss: 0.0006458769203163683\n",
      "[Training] Epoch: 1 [=====>         ] 35.7% Loss: 0.5437, Epoch 1, Batch 44, CE_loss: 0.4309287965297699, Dice_loss: 0.06089590862393379, Consistency_loss: 0.0006343786953948438\n",
      "[Training] Epoch: 1 [=====>         ] 36.5% Loss: 0.5427, Epoch 1, Batch 45, CE_loss: 0.4348991811275482, Dice_loss: 0.061668261885643005, Consistency_loss: 0.000716612150426954\n",
      "[Training] Epoch: 1 [=====>         ] 37.3% Loss: 0.5417, Epoch 1, Batch 46, CE_loss: 0.43320009112358093, Dice_loss: 0.06146526336669922, Consistency_loss: 0.0004113025206606835\n",
      "[Training] Epoch: 1 [=====>         ] 38.1% Loss: 0.5410, Epoch 1, Batch 47, CE_loss: 0.44416344165802, Dice_loss: 0.06329433619976044, Consistency_loss: 0.0005475726793520153\n",
      "[Training] Epoch: 1 [=====>         ] 38.9% Loss: 0.5404, Epoch 1, Batch 48, CE_loss: 0.44831544160842896, Dice_loss: 0.06426375359296799, Consistency_loss: 0.0005832644528709352\n",
      "[Training] Epoch: 1 [=====>         ] 39.7% Loss: 0.5397, Epoch 1, Batch 49, CE_loss: 0.4409123659133911, Dice_loss: 0.06289064884185791, Consistency_loss: 0.0005089044570922852\n",
      "[Training] Epoch: 1 [======>        ] 40.5% Loss: 0.5391, Epoch 1, Batch 50, CE_loss: 0.44281744956970215, Dice_loss: 0.06317426264286041, Consistency_loss: 1.6806496887511457e-06\n",
      "[Training] Epoch: 1 [======>        ] 41.3% Loss: 0.5380, Epoch 1, Batch 51, CE_loss: 0.4235704243183136, Dice_loss: 0.05934301018714905, Consistency_loss: 1.6045049733293126e-06\n",
      "[Training] Epoch: 1 [======>        ] 42.1% Loss: 0.5371, Epoch 1, Batch 52, CE_loss: 0.4315863847732544, Dice_loss: 0.06094561144709587, Consistency_loss: 0.0007139410590752959\n",
      "[Training] Epoch: 1 [======>        ] 42.9% Loss: 0.5363, Epoch 1, Batch 53, CE_loss: 0.4321017563343048, Dice_loss: 0.0607791431248188, Consistency_loss: 0.0007132443133741617\n",
      "[Training] Epoch: 1 [======>        ] 43.7% Loss: 0.5353, Epoch 1, Batch 54, CE_loss: 0.4193505346775055, Dice_loss: 0.05850743129849434, Consistency_loss: 0.00040997183532454073\n",
      "[Training] Epoch: 1 [======>        ] 44.4% Loss: 0.5346, Epoch 1, Batch 55, CE_loss: 0.43490713834762573, Dice_loss: 0.061333153396844864, Consistency_loss: 0.0004742445598822087\n",
      "[Training] Epoch: 1 [======>        ] 45.2% Loss: 0.5336, Epoch 1, Batch 56, CE_loss: 0.4190504848957062, Dice_loss: 0.05827180668711662, Consistency_loss: 0.0002779215283226222\n",
      "[Training] Epoch: 1 [======>        ] 46.0% Loss: 0.5327, Epoch 1, Batch 57, CE_loss: 0.4230044186115265, Dice_loss: 0.0590515062212944, Consistency_loss: 0.0005894125788472593\n",
      "[Training] Epoch: 1 [=======>       ] 46.8% Loss: 0.5321, Epoch 1, Batch 58, CE_loss: 0.4341469407081604, Dice_loss: 0.060991887003183365, Consistency_loss: 0.000779430556576699\n",
      "[Training] Epoch: 1 [=======>       ] 47.6% Loss: 0.5313, Epoch 1, Batch 59, CE_loss: 0.4231914281845093, Dice_loss: 0.05898689106106758, Consistency_loss: 0.0006934883422218263\n",
      "[Training] Epoch: 1 [=======>       ] 48.4% Loss: 0.5304, Epoch 1, Batch 60, CE_loss: 0.4215976297855377, Dice_loss: 0.05867771431803703, Consistency_loss: 0.0005522587453015149\n",
      "[Training] Epoch: 1 [=======>       ] 49.2% Loss: 0.5298, Epoch 1, Batch 61, CE_loss: 0.4284380376338959, Dice_loss: 0.05978308990597725, Consistency_loss: 0.0005027544102631509\n",
      "[Training] Epoch: 1 [=======>       ] 50.0% Loss: 0.5290, Epoch 1, Batch 62, CE_loss: 0.42475900053977966, Dice_loss: 0.05929987132549286, Consistency_loss: 0.0004186212026979774\n",
      "[Training] Epoch: 1 [=======>       ] 50.8% Loss: 0.5283, Epoch 1, Batch 63, CE_loss: 0.4209449589252472, Dice_loss: 0.0583147294819355, Consistency_loss: 0.00043006386840716004\n",
      "[Training] Epoch: 1 [=======>       ] 51.6% Loss: 0.5272, Epoch 1, Batch 64, CE_loss: 0.4006376266479492, Dice_loss: 0.05447344854474068, Consistency_loss: 0.00046467920765280724\n",
      "[Training] Epoch: 1 [=======>       ] 52.4% Loss: 0.5261, Epoch 1, Batch 65, CE_loss: 0.40376120805740356, Dice_loss: 0.055113837122917175, Consistency_loss: 0.000359284138539806\n",
      "[Training] Epoch: 1 [=======>       ] 53.2% Loss: 0.5256, Epoch 1, Batch 66, CE_loss: 0.43159499764442444, Dice_loss: 0.06005692481994629, Consistency_loss: 0.0005301219061948359\n",
      "[Training] Epoch: 1 [========>      ] 54.0% Loss: 0.5245, Epoch 1, Batch 67, CE_loss: 0.39764219522476196, Dice_loss: 0.05371294543147087, Consistency_loss: 0.0006913253455422819\n",
      "[Training] Epoch: 1 [========>      ] 54.8% Loss: 0.5239, Epoch 1, Batch 68, CE_loss: 0.42355579137802124, Dice_loss: 0.058717984706163406, Consistency_loss: 0.0003991780977230519\n",
      "[Training] Epoch: 1 [========>      ] 55.6% Loss: 0.5232, Epoch 1, Batch 69, CE_loss: 0.4158462882041931, Dice_loss: 0.0572284460067749, Consistency_loss: 0.0006427131011150777\n",
      "[Training] Epoch: 1 [========>      ] 56.3% Loss: 0.5227, Epoch 1, Batch 70, CE_loss: 0.4280441999435425, Dice_loss: 0.05946546047925949, Consistency_loss: 1.5000214261817746e-06\n",
      "[Training] Epoch: 1 [========>      ] 57.1% Loss: 0.5222, Epoch 1, Batch 71, CE_loss: 0.4271068572998047, Dice_loss: 0.059254515916109085, Consistency_loss: 0.0004980558296665549\n",
      "[Training] Epoch: 1 [========>      ] 57.9% Loss: 0.5215, Epoch 1, Batch 72, CE_loss: 0.4156613349914551, Dice_loss: 0.05708402767777443, Consistency_loss: 0.00045166444033384323\n",
      "[Training] Epoch: 1 [========>      ] 58.7% Loss: 0.5210, Epoch 1, Batch 73, CE_loss: 0.42147570848464966, Dice_loss: 0.058257125318050385, Consistency_loss: 0.0005031208274886012\n",
      "[Training] Epoch: 1 [========>      ] 59.5% Loss: 0.5206, Epoch 1, Batch 74, CE_loss: 0.43211597204208374, Dice_loss: 0.06010961905121803, Consistency_loss: 0.0005116513930261135\n",
      "[Training] Epoch: 1 [=========>     ] 60.3% Loss: 0.5199, Epoch 1, Batch 75, CE_loss: 0.41011378169059753, Dice_loss: 0.05609144642949104, Consistency_loss: 0.000608355738222599\n",
      "[Training] Epoch: 1 [=========>     ] 61.1% Loss: 0.5192, Epoch 1, Batch 76, CE_loss: 0.41150569915771484, Dice_loss: 0.0563272126019001, Consistency_loss: 1.957686208697851e-06\n",
      "[Training] Epoch: 1 [=========>     ] 61.9% Loss: 0.5182, Epoch 1, Batch 77, CE_loss: 0.38898253440856934, Dice_loss: 0.05202220752835274, Consistency_loss: 0.0006373722571879625\n",
      "[Training] Epoch: 1 [=========>     ] 62.7% Loss: 0.5174, Epoch 1, Batch 78, CE_loss: 0.3965090811252594, Dice_loss: 0.05345659703016281, Consistency_loss: 0.0004095683980267495\n",
      "[Training] Epoch: 1 [=========>     ] 63.5% Loss: 0.5166, Epoch 1, Batch 79, CE_loss: 0.4012013077735901, Dice_loss: 0.05417628958821297, Consistency_loss: 0.0005425454583019018\n",
      "[Training] Epoch: 1 [=========>     ] 64.3% Loss: 0.5160, Epoch 1, Batch 80, CE_loss: 0.4113919734954834, Dice_loss: 0.05615825206041336, Consistency_loss: 2.3435561615769984e-06\n",
      "[Training] Epoch: 1 [=========>     ] 65.1% Loss: 0.5152, Epoch 1, Batch 81, CE_loss: 0.3965023159980774, Dice_loss: 0.05330531299114227, Consistency_loss: 0.0004491905856411904\n",
      "[Training] Epoch: 1 [=========>     ] 65.9% Loss: 0.5145, Epoch 1, Batch 82, CE_loss: 0.3998797535896301, Dice_loss: 0.05379006639122963, Consistency_loss: 0.0004416124429553747\n",
      "[Training] Epoch: 1 [==========>    ] 66.7% Loss: 0.5138, Epoch 1, Batch 83, CE_loss: 0.4067191183567047, Dice_loss: 0.055187974125146866, Consistency_loss: 0.00037467735819518566\n",
      "[Training] Epoch: 1 [==========>    ] 67.5% Loss: 0.5130, Epoch 1, Batch 84, CE_loss: 0.39352884888648987, Dice_loss: 0.052537448704242706, Consistency_loss: 0.00036612022086046636\n",
      "[Training] Epoch: 1 [==========>    ] 68.3% Loss: 0.5123, Epoch 1, Batch 85, CE_loss: 0.3941022753715515, Dice_loss: 0.05261063948273659, Consistency_loss: 0.0006036843406036496\n",
      "[Training] Epoch: 1 [==========>    ] 69.0% Loss: 0.5116, Epoch 1, Batch 86, CE_loss: 0.40240269899368286, Dice_loss: 0.05431631579995155, Consistency_loss: 0.00045555984252132475\n",
      "[Training] Epoch: 1 [==========>    ] 69.8% Loss: 0.5112, Epoch 1, Batch 87, CE_loss: 0.41232553124427795, Dice_loss: 0.056126996874809265, Consistency_loss: 0.0004839745524805039\n",
      "[Training] Epoch: 1 [==========>    ] 70.6% Loss: 0.5105, Epoch 1, Batch 88, CE_loss: 0.39761874079704285, Dice_loss: 0.053281109780073166, Consistency_loss: 0.0006103718187659979\n",
      "[Training] Epoch: 1 [==========>    ] 71.4% Loss: 0.5099, Epoch 1, Batch 89, CE_loss: 0.40024733543395996, Dice_loss: 0.053713489323854446, Consistency_loss: 0.000471965700853616\n",
      "[Training] Epoch: 1 [==========>    ] 72.2% Loss: 0.5093, Epoch 1, Batch 90, CE_loss: 0.4003770649433136, Dice_loss: 0.05373468995094299, Consistency_loss: 0.0003817648102995008\n",
      "[Training] Epoch: 1 [==========>    ] 73.0% Loss: 0.5084, Epoch 1, Batch 91, CE_loss: 0.38353967666625977, Dice_loss: 0.050637006759643555, Consistency_loss: 2.9768764306936646e-06\n",
      "[Training] Epoch: 1 [===========>   ] 73.8% Loss: 0.5077, Epoch 1, Batch 92, CE_loss: 0.38853463530540466, Dice_loss: 0.05140883848071098, Consistency_loss: 0.0005062724812887609\n",
      "[Training] Epoch: 1 [===========>   ] 74.6% Loss: 0.5070, Epoch 1, Batch 93, CE_loss: 0.3908075988292694, Dice_loss: 0.05180737003684044, Consistency_loss: 0.0004625593719538301\n",
      "[Training] Epoch: 1 [===========>   ] 75.4% Loss: 0.5062, Epoch 1, Batch 94, CE_loss: 0.37642988562583923, Dice_loss: 0.04938453063368797, Consistency_loss: 0.0006464856560342014\n",
      "[Training] Epoch: 1 [===========>   ] 76.2% Loss: 0.5055, Epoch 1, Batch 95, CE_loss: 0.38835254311561584, Dice_loss: 0.05140398442745209, Consistency_loss: 0.0007219814579002559\n",
      "[Training] Epoch: 1 [===========>   ] 77.0% Loss: 0.5048, Epoch 1, Batch 96, CE_loss: 0.38586434721946716, Dice_loss: 0.05094624683260918, Consistency_loss: 0.0006668733549304307\n",
      "[Training] Epoch: 1 [===========>   ] 77.8% Loss: 0.5040, Epoch 1, Batch 97, CE_loss: 0.3798738718032837, Dice_loss: 0.04972504451870918, Consistency_loss: 0.0007635108777321875\n",
      "[Training] Epoch: 1 [===========>   ] 78.6% Loss: 0.5031, Epoch 1, Batch 98, CE_loss: 0.3658575713634491, Dice_loss: 0.04721482843160629, Consistency_loss: 0.00034240478998981416\n",
      "[Training] Epoch: 1 [===========>   ] 79.4% Loss: 0.5024, Epoch 1, Batch 99, CE_loss: 0.38337641954421997, Dice_loss: 0.050271544605493546, Consistency_loss: 0.0006044684560038149\n",
      "[Training] Epoch: 1 [============>  ] 80.2% Loss: 0.5016, Epoch 1, Batch 100, CE_loss: 0.37356290221214294, Dice_loss: 0.04851140081882477, Consistency_loss: 0.0005837777280248702\n",
      "[Training] Epoch: 1 [============>  ] 81.0% Loss: 0.5010, Epoch 1, Batch 101, CE_loss: 0.387515664100647, Dice_loss: 0.0510706752538681, Consistency_loss: 0.00033455280936323106\n",
      "[Training] Epoch: 1 [============>  ] 81.7% Loss: 0.5004, Epoch 1, Batch 102, CE_loss: 0.3841674029827118, Dice_loss: 0.0504557341337204, Consistency_loss: 0.0006331877084448934\n",
      "[Training] Epoch: 1 [============>  ] 82.5% Loss: 0.4999, Epoch 1, Batch 103, CE_loss: 0.3998081386089325, Dice_loss: 0.053205106407403946, Consistency_loss: 3.4392401175864507e-06\n",
      "[Training] Epoch: 1 [============>  ] 83.3% Loss: 0.4992, Epoch 1, Batch 104, CE_loss: 0.37454909086227417, Dice_loss: 0.048609327524900436, Consistency_loss: 0.0004818933957722038\n",
      "[Training] Epoch: 1 [============>  ] 84.1% Loss: 0.4986, Epoch 1, Batch 105, CE_loss: 0.38111498951911926, Dice_loss: 0.04984293878078461, Consistency_loss: 0.0005519457045011222\n",
      "[Training] Epoch: 1 [============>  ] 84.9% Loss: 0.4979, Epoch 1, Batch 106, CE_loss: 0.3759502172470093, Dice_loss: 0.04874163120985031, Consistency_loss: 0.0004378856101538986\n",
      "[Training] Epoch: 1 [============>  ] 85.7% Loss: 0.4971, Epoch 1, Batch 107, CE_loss: 0.3709929585456848, Dice_loss: 0.04787701368331909, Consistency_loss: 0.0005779149942100048\n",
      "[Training] Epoch: 1 [============>  ] 86.5% Loss: 0.4963, Epoch 1, Batch 108, CE_loss: 0.35872527956962585, Dice_loss: 0.04568658769130707, Consistency_loss: 0.00038529557059518993\n",
      "[Training] Epoch: 1 [=============> ] 87.3% Loss: 0.4957, Epoch 1, Batch 109, CE_loss: 0.3816055357456207, Dice_loss: 0.04973990470170975, Consistency_loss: 0.0007098002824932337\n",
      "[Training] Epoch: 1 [=============> ] 88.1% Loss: 0.4950, Epoch 1, Batch 110, CE_loss: 0.36776140332221985, Dice_loss: 0.04725755751132965, Consistency_loss: 3.4765748750942294e-06\n",
      "[Training] Epoch: 1 [=============> ] 88.9% Loss: 0.4941, Epoch 1, Batch 111, CE_loss: 0.35287147760391235, Dice_loss: 0.04445816949009895, Consistency_loss: 4.035542588098906e-06\n",
      "[Training] Epoch: 1 [=============> ] 89.7% Loss: 0.4935, Epoch 1, Batch 112, CE_loss: 0.37083837389945984, Dice_loss: 0.04787183552980423, Consistency_loss: 0.0007447098614647985\n",
      "[Training] Epoch: 1 [=============> ] 90.5% Loss: 0.4929, Epoch 1, Batch 113, CE_loss: 0.376674085855484, Dice_loss: 0.048700202256441116, Consistency_loss: 0.0005722867790609598\n",
      "[Training] Epoch: 1 [=============> ] 91.3% Loss: 0.4922, Epoch 1, Batch 114, CE_loss: 0.3677217364311218, Dice_loss: 0.047173988074064255, Consistency_loss: 0.000516826577950269\n",
      "[Training] Epoch: 1 [=============> ] 92.1% Loss: 0.4915, Epoch 1, Batch 115, CE_loss: 0.3641594350337982, Dice_loss: 0.04651884734630585, Consistency_loss: 0.0003707993892021477\n",
      "[Training] Epoch: 1 [=============> ] 92.9% Loss: 0.4908, Epoch 1, Batch 116, CE_loss: 0.35872262716293335, Dice_loss: 0.045393526554107666, Consistency_loss: 0.0006348665338009596\n",
      "[Training] Epoch: 1 [==============>] 93.7% Loss: 0.4903, Epoch 1, Batch 117, CE_loss: 0.38823583722114563, Dice_loss: 0.05090615525841713, Consistency_loss: 3.5462519463180797e-06\n",
      "[Training] Epoch: 1 [==============>] 94.4% Loss: 0.4895, Epoch 1, Batch 118, CE_loss: 0.35091716051101685, Dice_loss: 0.043903712183237076, Consistency_loss: 0.0002761105424724519\n",
      "[Training] Epoch: 1 [==============>] 95.2% Loss: 0.4889, Epoch 1, Batch 119, CE_loss: 0.3734893500804901, Dice_loss: 0.04798592999577522, Consistency_loss: 3.891142114298418e-06\n",
      "[Training] Epoch: 1 [==============>] 96.0% Loss: 0.4881, Epoch 1, Batch 120, CE_loss: 0.347467303276062, Dice_loss: 0.04337911680340767, Consistency_loss: 0.0004083569219801575\n",
      "[Training] Epoch: 1 [==============>] 96.8% Loss: 0.4878, Epoch 1, Batch 121, CE_loss: 0.3930146098136902, Dice_loss: 0.05157449096441269, Consistency_loss: 0.00016299802518915385\n",
      "[Training] Epoch: 1 [==============>] 97.6% Loss: 0.4870, Epoch 1, Batch 122, CE_loss: 0.3477884829044342, Dice_loss: 0.043595150113105774, Consistency_loss: 0.00037640761001966894\n",
      "[Training] Epoch: 1 [==============>] 98.4% Loss: 0.4863, Epoch 1, Batch 123, CE_loss: 0.3519211411476135, Dice_loss: 0.044142141938209534, Consistency_loss: 0.0002872647310141474\n",
      "[Training] Epoch: 1 [==============>] 99.2% Loss: 0.4855, Epoch 1, Batch 124, CE_loss: 0.35109156370162964, Dice_loss: 0.04391573742032051, Consistency_loss: 1.0543817552388646e-05\n",
      "[Training] Epoch: 1 [DONE]                                 \n",
      "Epoch 1, Batch 125, CE_loss: 0.3661465048789978, Dice_loss: 0.046707820147275925, Consistency_loss: 0.0008050270262174308\n",
      "Epoch 1, Batch 125, CE_loss: 0.3661465048789978, Dice_loss: 0.046707820147275925, Consistency_loss: 0.0008050270262174308\n",
      "[Validation] Epoch: 1 [DONE]                                 \n",
      "[Epoch: 1, TrainLoss: 0.4850, TrainDice: 0.0595, ValLoss: 0.5002                                             \n",
      "Number of batches:  126\n",
      "[Training] Epoch: 2 [>              ] 0.8% Loss: 0.4027, Epoch 2, Batch 0, CE_loss: 0.3571275472640991, Dice_loss: 0.04501454904675484, Consistency_loss: 0.0005303077632561326\n",
      "[Training] Epoch: 2 [>              ] 1.6% Loss: 0.3993, Epoch 2, Batch 1, CE_loss: 0.3514648973941803, Dice_loss: 0.04396413266658783, Consistency_loss: 0.0005885569262318313\n",
      "[Training] Epoch: 2 [>              ] 2.4% Loss: 0.3972, Epoch 2, Batch 2, CE_loss: 0.3488335907459259, Dice_loss: 0.04342058300971985, Consistency_loss: 0.0005765907117165625\n",
      "[Training] Epoch: 2 [>              ] 3.2% Loss: 0.3941, Epoch 2, Batch 3, CE_loss: 0.3420460522174835, Dice_loss: 0.042182907462120056, Consistency_loss: 0.0007510815630666912\n",
      "[Training] Epoch: 2 [>              ] 4.0% Loss: 0.4015, Epoch 2, Batch 4, CE_loss: 0.3812789022922516, Dice_loss: 0.04919827729463577, Consistency_loss: 0.0005194823606871068\n",
      "[Training] Epoch: 2 [>              ] 4.8% Loss: 0.4029, Epoch 2, Batch 5, CE_loss: 0.36401379108428955, Dice_loss: 0.04615071415901184, Consistency_loss: 5.004990725865355e-06\n",
      "[Training] Epoch: 2 [>              ] 5.6% Loss: 0.4026, Epoch 2, Batch 6, CE_loss: 0.35544174909591675, Dice_loss: 0.0446246899664402, Consistency_loss: 0.0003796647069975734\n",
      "[Training] Epoch: 2 [>              ] 6.3% Loss: 0.4032, Epoch 2, Batch 7, CE_loss: 0.36140549182891846, Dice_loss: 0.04557734727859497, Consistency_loss: 0.000644543266389519\n",
      "[Training] Epoch: 2 [=>             ] 7.1% Loss: 0.4033, Epoch 2, Batch 8, CE_loss: 0.35806214809417725, Dice_loss: 0.045048490166664124, Consistency_loss: 0.0008003669790923595\n",
      "[Training] Epoch: 2 [=>             ] 7.9% Loss: 0.4011, Epoch 2, Batch 9, CE_loss: 0.3392067551612854, Dice_loss: 0.04169450327754021, Consistency_loss: 0.000771805876865983\n",
      "[Training] Epoch: 2 [=>             ] 8.7% Loss: 0.4006, Epoch 2, Batch 10, CE_loss: 0.35051092505455017, Dice_loss: 0.043687544763088226, Consistency_loss: 0.0006452102097682655\n",
      "[Training] Epoch: 2 [=>             ] 9.5% Loss: 0.4008, Epoch 2, Batch 11, CE_loss: 0.35741910338401794, Dice_loss: 0.044939205050468445, Consistency_loss: 0.0006634455057792366\n",
      "[Training] Epoch: 2 [=>             ] 10.3% Loss: 0.3996, Epoch 2, Batch 12, CE_loss: 0.3424650728702545, Dice_loss: 0.04227384924888611, Consistency_loss: 0.0008050046744756401\n",
      "[Training] Epoch: 2 [=>             ] 11.1% Loss: 0.3981, Epoch 2, Batch 13, CE_loss: 0.3367546498775482, Dice_loss: 0.04139983654022217, Consistency_loss: 0.0007109045400284231\n",
      "[Training] Epoch: 2 [=>             ] 11.9% Loss: 0.3963, Epoch 2, Batch 14, CE_loss: 0.3308904469013214, Dice_loss: 0.040082164108753204, Consistency_loss: 0.0006087041110731661\n",
      "[Training] Epoch: 2 [=>             ] 12.7% Loss: 0.3944, Epoch 2, Batch 15, CE_loss: 0.325370728969574, Dice_loss: 0.039133671671152115, Consistency_loss: 0.00040772013016976416\n",
      "[Training] Epoch: 2 [==>            ] 13.5% Loss: 0.3930, Epoch 2, Batch 16, CE_loss: 0.3296523988246918, Dice_loss: 0.039883099496364594, Consistency_loss: 0.0006129665998741984\n",
      "[Training] Epoch: 2 [==>            ] 14.3% Loss: 0.3929, Epoch 2, Batch 17, CE_loss: 0.34894394874572754, Dice_loss: 0.04325130209326744, Consistency_loss: 0.0005930817569606006\n",
      "[Training] Epoch: 2 [==>            ] 15.1% Loss: 0.3918, Epoch 2, Batch 18, CE_loss: 0.33134543895721436, Dice_loss: 0.03992589935660362, Consistency_loss: 0.000394967122701928\n",
      "[Training] Epoch: 2 [==>            ] 15.9% Loss: 0.3909, Epoch 2, Batch 19, CE_loss: 0.33348146080970764, Dice_loss: 0.04031990468502045, Consistency_loss: 0.000268648931523785\n",
      "[Training] Epoch: 2 [==>            ] 16.7% Loss: 0.3904, Epoch 2, Batch 20, CE_loss: 0.33821433782577515, Dice_loss: 0.04109691455960274, Consistency_loss: 0.0006832978106103837\n",
      "[Training] Epoch: 2 [==>            ] 17.5% Loss: 0.3905, Epoch 2, Batch 21, CE_loss: 0.3488219082355499, Dice_loss: 0.04311906918883324, Consistency_loss: 0.0006683924584649503\n",
      "[Training] Epoch: 2 [==>            ] 18.3% Loss: 0.3903, Epoch 2, Batch 22, CE_loss: 0.3420713543891907, Dice_loss: 0.04183199256658554, Consistency_loss: 0.0005929864128120244\n",
      "[Training] Epoch: 2 [==>            ] 19.0% Loss: 0.3905, Epoch 2, Batch 23, CE_loss: 0.35212400555610657, Dice_loss: 0.043695226311683655, Consistency_loss: 0.0005977743421681225\n",
      "[Training] Epoch: 2 [==>            ] 19.8% Loss: 0.3903, Epoch 2, Batch 24, CE_loss: 0.3438419997692108, Dice_loss: 0.04194939136505127, Consistency_loss: 0.0005585020990110934\n",
      "[Training] Epoch: 2 [===>           ] 20.6% Loss: 0.3903, Epoch 2, Batch 25, CE_loss: 0.3465655744075775, Dice_loss: 0.04268450662493706, Consistency_loss: 2.450057763780933e-06\n",
      "[Training] Epoch: 2 [===>           ] 21.4% Loss: 0.3893, Epoch 2, Batch 26, CE_loss: 0.32307177782058716, Dice_loss: 0.03847964107990265, Consistency_loss: 0.0004673594667110592\n",
      "[Training] Epoch: 2 [===>           ] 22.2% Loss: 0.3893, Epoch 2, Batch 27, CE_loss: 0.34654152393341064, Dice_loss: 0.04255058243870735, Consistency_loss: 0.000359198049409315\n",
      "[Training] Epoch: 2 [===>           ] 23.0% Loss: 0.3893, Epoch 2, Batch 28, CE_loss: 0.34717869758605957, Dice_loss: 0.042793143540620804, Consistency_loss: 0.0008411990711465478\n",
      "[Training] Epoch: 2 [===>           ] 23.8% Loss: 0.3886, Epoch 2, Batch 29, CE_loss: 0.32860350608825684, Dice_loss: 0.03943230211734772, Consistency_loss: 0.0006676166667602956\n",
      "[Training] Epoch: 2 [===>           ] 24.6% Loss: 0.3872, Epoch 2, Batch 30, CE_loss: 0.3084900677204132, Dice_loss: 0.03589848056435585, Consistency_loss: 0.0006433306843973696\n",
      "[Training] Epoch: 2 [===>           ] 25.4% Loss: 0.3868, Epoch 2, Batch 31, CE_loss: 0.33178508281707764, Dice_loss: 0.03999146819114685, Consistency_loss: 0.0007247792673297226\n",
      "[Training] Epoch: 2 [===>           ] 26.2% Loss: 0.3867, Epoch 2, Batch 32, CE_loss: 0.341348260641098, Dice_loss: 0.04175955429673195, Consistency_loss: 5.321312983141979e-06\n",
      "[Training] Epoch: 2 [====>          ] 27.0% Loss: 0.3858, Epoch 2, Batch 33, CE_loss: 0.32011649012565613, Dice_loss: 0.03808734193444252, Consistency_loss: 8.658125807414763e-06\n",
      "[Training] Epoch: 2 [====>          ] 27.8% Loss: 0.3860, Epoch 2, Batch 34, CE_loss: 0.34957605600357056, Dice_loss: 0.043130066245794296, Consistency_loss: 6.7580717768578324e-06\n",
      "[Training] Epoch: 2 [====>          ] 28.6% Loss: 0.3852, Epoch 2, Batch 35, CE_loss: 0.318432092666626, Dice_loss: 0.03768550232052803, Consistency_loss: 0.0006271595484577119\n",
      "[Training] Epoch: 2 [====>          ] 29.4% Loss: 0.3848, Epoch 2, Batch 36, CE_loss: 0.3289584517478943, Dice_loss: 0.03947878256440163, Consistency_loss: 0.0005579597200267017\n",
      "[Training] Epoch: 2 [====>          ] 30.2% Loss: 0.3846, Epoch 2, Batch 37, CE_loss: 0.33815646171569824, Dice_loss: 0.04114774242043495, Consistency_loss: 9.287212378694676e-06\n",
      "[Training] Epoch: 2 [====>          ] 31.0% Loss: 0.3835, Epoch 2, Batch 38, CE_loss: 0.3038936257362366, Dice_loss: 0.03513406217098236, Consistency_loss: 0.0006009999779053032\n",
      "[Training] Epoch: 2 [====>          ] 31.7% Loss: 0.3828, Epoch 2, Batch 39, CE_loss: 0.31814441084861755, Dice_loss: 0.03768610954284668, Consistency_loss: 0.00045061056152917445\n",
      "[Training] Epoch: 2 [====>          ] 32.5% Loss: 0.3826, Epoch 2, Batch 40, CE_loss: 0.33300888538360596, Dice_loss: 0.040125489234924316, Consistency_loss: 0.0004278401902411133\n",
      "[Training] Epoch: 2 [=====>         ] 33.3% Loss: 0.3821, Epoch 2, Batch 41, CE_loss: 0.3228567838668823, Dice_loss: 0.03834192827343941, Consistency_loss: 0.0004798060399480164\n",
      "[Training] Epoch: 2 [=====>         ] 34.1% Loss: 0.3810, Epoch 2, Batch 42, CE_loss: 0.3016830384731293, Dice_loss: 0.034553103148937225, Consistency_loss: 0.0004481163341552019\n",
      "[Training] Epoch: 2 [=====>         ] 34.9% Loss: 0.3807, Epoch 2, Batch 43, CE_loss: 0.32953310012817383, Dice_loss: 0.039520662277936935, Consistency_loss: 0.00036029351758770645\n",
      "[Training] Epoch: 2 [=====>         ] 35.7% Loss: 0.3796, Epoch 2, Batch 44, CE_loss: 0.2967275381088257, Dice_loss: 0.03390619903802872, Consistency_loss: 0.000788236444350332\n",
      "[Training] Epoch: 2 [=====>         ] 36.5% Loss: 0.3792, Epoch 2, Batch 45, CE_loss: 0.320735365152359, Dice_loss: 0.03804319351911545, Consistency_loss: 0.0004163291887380183\n",
      "[Training] Epoch: 2 [=====>         ] 37.3% Loss: 0.3790, Epoch 2, Batch 46, CE_loss: 0.33027416467666626, Dice_loss: 0.039580509066581726, Consistency_loss: 4.50735706181149e-06\n",
      "[Training] Epoch: 2 [=====>         ] 38.1% Loss: 0.3785, Epoch 2, Batch 47, CE_loss: 0.3151315748691559, Dice_loss: 0.03695376217365265, Consistency_loss: 0.0005913412314839661\n",
      "[Training] Epoch: 2 [=====>         ] 38.9% Loss: 0.3776, Epoch 2, Batch 48, CE_loss: 0.3026588261127472, Dice_loss: 0.0346330851316452, Consistency_loss: 0.0005413505132310092\n",
      "[Training] Epoch: 2 [=====>         ] 39.7% Loss: 0.3772, Epoch 2, Batch 49, CE_loss: 0.3193221390247345, Dice_loss: 0.03761674091219902, Consistency_loss: 0.00046666126581840217\n",
      "[Training] Epoch: 2 [======>        ] 40.5% Loss: 0.3769, Epoch 2, Batch 50, CE_loss: 0.32127293944358826, Dice_loss: 0.03787001967430115, Consistency_loss: 7.3123637776006944e-06\n",
      "[Training] Epoch: 2 [======>        ] 41.3% Loss: 0.3760, Epoch 2, Batch 51, CE_loss: 0.29663655161857605, Dice_loss: 0.03365142643451691, Consistency_loss: 0.00064205372473225\n",
      "[Training] Epoch: 2 [======>        ] 42.1% Loss: 0.3756, Epoch 2, Batch 52, CE_loss: 0.316045343875885, Dice_loss: 0.03701910749077797, Consistency_loss: 0.0006478879950009286\n",
      "[Training] Epoch: 2 [======>        ] 42.9% Loss: 0.3749, Epoch 2, Batch 53, CE_loss: 0.30556991696357727, Dice_loss: 0.03521786257624626, Consistency_loss: 0.0007020070333965123\n",
      "[Training] Epoch: 2 [======>        ] 43.7% Loss: 0.3741, Epoch 2, Batch 54, CE_loss: 0.2963859438896179, Dice_loss: 0.033531296998262405, Consistency_loss: 0.0005339017370715737\n",
      "[Training] Epoch: 2 [======>        ] 44.4% Loss: 0.3739, Epoch 2, Batch 55, CE_loss: 0.3236578404903412, Dice_loss: 0.03841177374124527, Consistency_loss: 6.549665158672724e-06\n",
      "[Training] Epoch: 2 [======>        ] 45.2% Loss: 0.3733, Epoch 2, Batch 56, CE_loss: 0.3033646047115326, Dice_loss: 0.034730806946754456, Consistency_loss: 0.0005670794635079801\n",
      "[Training] Epoch: 2 [======>        ] 46.0% Loss: 0.3726, Epoch 2, Batch 57, CE_loss: 0.2970496416091919, Dice_loss: 0.03371178358793259, Consistency_loss: 0.0006005173781886697\n",
      "[Training] Epoch: 2 [=======>       ] 46.8% Loss: 0.3721, Epoch 2, Batch 58, CE_loss: 0.3091527819633484, Dice_loss: 0.03566789999604225, Consistency_loss: 0.0005638924776576459\n",
      "[Training] Epoch: 2 [=======>       ] 47.6% Loss: 0.3715, Epoch 2, Batch 59, CE_loss: 0.3024638593196869, Dice_loss: 0.03455100953578949, Consistency_loss: 0.0008535560336895287\n",
      "[Training] Epoch: 2 [=======>       ] 48.4% Loss: 0.3710, Epoch 2, Batch 60, CE_loss: 0.3021615445613861, Dice_loss: 0.03462815284729004, Consistency_loss: 0.000744677905458957\n",
      "[Training] Epoch: 2 [=======>       ] 49.2% Loss: 0.3704, Epoch 2, Batch 61, CE_loss: 0.3000730574131012, Dice_loss: 0.034188225865364075, Consistency_loss: 0.0007281600846908987\n",
      "[Training] Epoch: 2 [=======>       ] 50.0% Loss: 0.3697, Epoch 2, Batch 62, CE_loss: 0.2942810654640198, Dice_loss: 0.033204201608896255, Consistency_loss: 0.00045982105075381696\n",
      "[Training] Epoch: 2 [=======>       ] 50.8% Loss: 0.3694, Epoch 2, Batch 63, CE_loss: 0.3113919496536255, Dice_loss: 0.03614237532019615, Consistency_loss: 0.0005660561146214604\n",
      "[Training] Epoch: 2 [=======>       ] 51.6% Loss: 0.3691, Epoch 2, Batch 64, CE_loss: 0.3144860863685608, Dice_loss: 0.03655175119638443, Consistency_loss: 0.0005719101172871888\n",
      "[Training] Epoch: 2 [=======>       ] 52.4% Loss: 0.3687, Epoch 2, Batch 65, CE_loss: 0.307031512260437, Dice_loss: 0.0351865328848362, Consistency_loss: 0.0003136148152407259\n",
      "[Training] Epoch: 2 [=======>       ] 53.2% Loss: 0.3682, Epoch 2, Batch 66, CE_loss: 0.3026926517486572, Dice_loss: 0.034454621374607086, Consistency_loss: 0.0004693262744694948\n",
      "[Training] Epoch: 2 [========>      ] 54.0% Loss: 0.3678, Epoch 2, Batch 67, CE_loss: 0.3044748306274414, Dice_loss: 0.034864891320466995, Consistency_loss: 0.0006399282719939947\n",
      "[Training] Epoch: 2 [========>      ] 54.8% Loss: 0.3674, Epoch 2, Batch 68, CE_loss: 0.303285151720047, Dice_loss: 0.034659042954444885, Consistency_loss: 4.066390374646289e-06\n",
      "[Training] Epoch: 2 [========>      ] 55.6% Loss: 0.3669, Epoch 2, Batch 69, CE_loss: 0.2955796718597412, Dice_loss: 0.03341664373874664, Consistency_loss: 0.0005946023156866431\n",
      "[Training] Epoch: 2 [========>      ] 56.3% Loss: 0.3662, Epoch 2, Batch 70, CE_loss: 0.2857111692428589, Dice_loss: 0.03172379359602928, Consistency_loss: 0.0007660682895220816\n",
      "[Training] Epoch: 2 [========>      ] 57.1% Loss: 0.3658, Epoch 2, Batch 71, CE_loss: 0.30619028210639954, Dice_loss: 0.03514004126191139, Consistency_loss: 0.0007121190428733826\n",
      "[Training] Epoch: 2 [========>      ] 57.9% Loss: 0.3651, Epoch 2, Batch 72, CE_loss: 0.2822907865047455, Dice_loss: 0.03102073259651661, Consistency_loss: 5.64062929697684e-06\n",
      "[Training] Epoch: 2 [========>      ] 58.7% Loss: 0.3649, Epoch 2, Batch 73, CE_loss: 0.3116675019264221, Dice_loss: 0.03598812222480774, Consistency_loss: 0.00038418106851167977\n",
      "[Training] Epoch: 2 [========>      ] 59.5% Loss: 0.3642, Epoch 2, Batch 74, CE_loss: 0.28434693813323975, Dice_loss: 0.031348418444395065, Consistency_loss: 0.0004557641805149615\n",
      "[Training] Epoch: 2 [=========>     ] 60.3% Loss: 0.3639, Epoch 2, Batch 75, CE_loss: 0.3032709062099457, Dice_loss: 0.034690335392951965, Consistency_loss: 0.0005696926964446902\n",
      "[Training] Epoch: 2 [=========>     ] 61.1% Loss: 0.3634, Epoch 2, Batch 76, CE_loss: 0.2905251085758209, Dice_loss: 0.032351404428482056, Consistency_loss: 0.00038617386599071324\n",
      "[Training] Epoch: 2 [=========>     ] 61.9% Loss: 0.3630, Epoch 2, Batch 77, CE_loss: 0.29938799142837524, Dice_loss: 0.034081749618053436, Consistency_loss: 0.0006415763637050986\n",
      "[Training] Epoch: 2 [=========>     ] 62.7% Loss: 0.3625, Epoch 2, Batch 78, CE_loss: 0.2931659519672394, Dice_loss: 0.03302396833896637, Consistency_loss: 5.170361419004621e-06\n",
      "[Training] Epoch: 2 [=========>     ] 63.5% Loss: 0.3620, Epoch 2, Batch 79, CE_loss: 0.28700217604637146, Dice_loss: 0.03189883381128311, Consistency_loss: 0.0003744012792594731\n",
      "[Training] Epoch: 2 [=========>     ] 64.3% Loss: 0.3615, Epoch 2, Batch 80, CE_loss: 0.28772440552711487, Dice_loss: 0.0318828821182251, Consistency_loss: 8.68522602104349e-06\n",
      "[Training] Epoch: 2 [=========>     ] 65.1% Loss: 0.3611, Epoch 2, Batch 81, CE_loss: 0.2941977083683014, Dice_loss: 0.033122286200523376, Consistency_loss: 0.0007217547972686589\n",
      "[Training] Epoch: 2 [=========>     ] 65.9% Loss: 0.3605, Epoch 2, Batch 82, CE_loss: 0.2812187671661377, Dice_loss: 0.030945586040616035, Consistency_loss: 0.0005567484768107533\n",
      "[Training] Epoch: 2 [==========>    ] 66.7% Loss: 0.3599, Epoch 2, Batch 83, CE_loss: 0.28326576948165894, Dice_loss: 0.031211007386446, Consistency_loss: 0.000651458918582648\n",
      "[Training] Epoch: 2 [==========>    ] 67.5% Loss: 0.3594, Epoch 2, Batch 84, CE_loss: 0.2829817235469818, Dice_loss: 0.031167171895503998, Consistency_loss: 0.0007210710900835693\n",
      "[Training] Epoch: 2 [==========>    ] 68.3% Loss: 0.3593, Epoch 2, Batch 85, CE_loss: 0.31358861923217773, Dice_loss: 0.03637300059199333, Consistency_loss: 0.00039821938844397664\n",
      "[Training] Epoch: 2 [==========>    ] 69.0% Loss: 0.3587, Epoch 2, Batch 86, CE_loss: 0.27568915486335754, Dice_loss: 0.029943922534585, Consistency_loss: 0.0005531333736144006\n",
      "[Training] Epoch: 2 [==========>    ] 69.8% Loss: 0.3584, Epoch 2, Batch 87, CE_loss: 0.299976646900177, Dice_loss: 0.034165069460868835, Consistency_loss: 4.397337306727422e-06\n",
      "[Training] Epoch: 2 [==========>    ] 70.6% Loss: 0.3580, Epoch 2, Batch 88, CE_loss: 0.2873702645301819, Dice_loss: 0.03188022971153259, Consistency_loss: 0.0007455273298546672\n",
      "[Training] Epoch: 2 [==========>    ] 71.4% Loss: 0.3576, Epoch 2, Batch 89, CE_loss: 0.29385578632354736, Dice_loss: 0.03303778916597366, Consistency_loss: 0.0006410676869563758\n",
      "[Training] Epoch: 2 [==========>    ] 72.2% Loss: 0.3573, Epoch 2, Batch 90, CE_loss: 0.29253917932510376, Dice_loss: 0.03269822895526886, Consistency_loss: 0.00036399162490852177\n",
      "[Training] Epoch: 2 [==========>    ] 73.0% Loss: 0.3570, Epoch 2, Batch 91, CE_loss: 0.2959664762020111, Dice_loss: 0.033361148089170456, Consistency_loss: 0.0005784002714790404\n",
      "[Training] Epoch: 2 [===========>   ] 73.8% Loss: 0.3564, Epoch 2, Batch 92, CE_loss: 0.27542346715927124, Dice_loss: 0.029714012518525124, Consistency_loss: 0.00031095254234969616\n",
      "[Training] Epoch: 2 [===========>   ] 74.6% Loss: 0.3559, Epoch 2, Batch 93, CE_loss: 0.2718433439731598, Dice_loss: 0.02934877760708332, Consistency_loss: 0.00047395555884577334\n",
      "[Training] Epoch: 2 [===========>   ] 75.4% Loss: 0.3555, Epoch 2, Batch 94, CE_loss: 0.2926385998725891, Dice_loss: 0.03271584212779999, Consistency_loss: 0.000703492492903024\n",
      "[Training] Epoch: 2 [===========>   ] 76.2% Loss: 0.3552, Epoch 2, Batch 95, CE_loss: 0.28660428524017334, Dice_loss: 0.03175272420048714, Consistency_loss: 0.0007560881203971803\n",
      "[Training] Epoch: 2 [===========>   ] 77.0% Loss: 0.3547, Epoch 2, Batch 96, CE_loss: 0.27565717697143555, Dice_loss: 0.029942456632852554, Consistency_loss: 1.302356304222485e-05\n",
      "[Training] Epoch: 2 [===========>   ] 77.8% Loss: 0.3547, Epoch 2, Batch 97, CE_loss: 0.3239208459854126, Dice_loss: 0.03800337016582489, Consistency_loss: 0.0007383247721008956\n",
      "[Training] Epoch: 2 [===========>   ] 78.6% Loss: 0.3543, Epoch 2, Batch 98, CE_loss: 0.27852797508239746, Dice_loss: 0.030355015769600868, Consistency_loss: 0.00031566174584440887\n",
      "[Training] Epoch: 2 [===========>   ] 79.4% Loss: 0.3538, Epoch 2, Batch 99, CE_loss: 0.2744132876396179, Dice_loss: 0.02973083034157753, Consistency_loss: 0.0005914868088439107\n",
      "[Training] Epoch: 2 [============>  ] 80.2% Loss: 0.3532, Epoch 2, Batch 100, CE_loss: 0.26286444067955017, Dice_loss: 0.027797726914286613, Consistency_loss: 6.272769041970605e-06\n",
      "[Training] Epoch: 2 [============>  ] 81.0% Loss: 0.3528, Epoch 2, Batch 101, CE_loss: 0.2875264585018158, Dice_loss: 0.0319199413061142, Consistency_loss: 0.00036152437678538263\n",
      "[Training] Epoch: 2 [============>  ] 81.7% Loss: 0.3525, Epoch 2, Batch 102, CE_loss: 0.2856767475605011, Dice_loss: 0.03146369755268097, Consistency_loss: 0.00028780786669813097\n",
      "[Training] Epoch: 2 [============>  ] 82.5% Loss: 0.3523, Epoch 2, Batch 103, CE_loss: 0.3000437617301941, Dice_loss: 0.03387924283742905, Consistency_loss: 0.0003502397157717496\n",
      "[Training] Epoch: 2 [============>  ] 83.3% Loss: 0.3518, Epoch 2, Batch 104, CE_loss: 0.2687367796897888, Dice_loss: 0.028670571744441986, Consistency_loss: 0.0006035012775100768\n",
      "[Training] Epoch: 2 [============>  ] 84.1% Loss: 0.3515, Epoch 2, Batch 105, CE_loss: 0.2903442084789276, Dice_loss: 0.0324285514652729, Consistency_loss: 0.0005639965529553592\n",
      "[Training] Epoch: 2 [============>  ] 84.9% Loss: 0.3511, Epoch 2, Batch 106, CE_loss: 0.27571043372154236, Dice_loss: 0.029844064265489578, Consistency_loss: 0.0004309634678065777\n",
      "[Training] Epoch: 2 [============>  ] 85.7% Loss: 0.3507, Epoch 2, Batch 107, CE_loss: 0.2792964279651642, Dice_loss: 0.030651696026325226, Consistency_loss: 0.000497175904456526\n",
      "[Training] Epoch: 2 [============>  ] 86.5% Loss: 0.3501, Epoch 2, Batch 108, CE_loss: 0.25728264451026917, Dice_loss: 0.026902101933956146, Consistency_loss: 9.087124453799333e-06\n",
      "[Training] Epoch: 2 [=============> ] 87.3% Loss: 0.3496, Epoch 2, Batch 109, CE_loss: 0.26412516832351685, Dice_loss: 0.027934912592172623, Consistency_loss: 6.847256827313686e-06\n",
      "[Training] Epoch: 2 [=============> ] 88.1% Loss: 0.3491, Epoch 2, Batch 110, CE_loss: 0.2648729383945465, Dice_loss: 0.0280376598238945, Consistency_loss: 0.0005724686780013144\n",
      "[Training] Epoch: 2 [=============> ] 88.9% Loss: 0.3489, Epoch 2, Batch 111, CE_loss: 0.29453009366989136, Dice_loss: 0.033025603741407394, Consistency_loss: 0.0006013135425746441\n",
      "[Training] Epoch: 2 [=============> ] 89.7% Loss: 0.3485, Epoch 2, Batch 112, CE_loss: 0.2722776234149933, Dice_loss: 0.02928721159696579, Consistency_loss: 0.0007486326503567398\n",
      "[Training] Epoch: 2 [=============> ] 90.5% Loss: 0.3480, Epoch 2, Batch 113, CE_loss: 0.2633211016654968, Dice_loss: 0.02784576453268528, Consistency_loss: 0.000629190937615931\n",
      "[Training] Epoch: 2 [=============> ] 91.3% Loss: 0.3475, Epoch 2, Batch 114, CE_loss: 0.2626330554485321, Dice_loss: 0.027645448222756386, Consistency_loss: 0.0006542724440805614\n",
      "[Training] Epoch: 2 [=============> ] 92.1% Loss: 0.3471, Epoch 2, Batch 115, CE_loss: 0.2724670469760895, Dice_loss: 0.029345514252781868, Consistency_loss: 9.512487849860918e-06\n",
      "[Training] Epoch: 2 [=============> ] 92.9% Loss: 0.3465, Epoch 2, Batch 116, CE_loss: 0.2507212460041046, Dice_loss: 0.02573332004249096, Consistency_loss: 0.0006137691088952124\n",
      "[Training] Epoch: 2 [==============>] 93.7% Loss: 0.3460, Epoch 2, Batch 117, CE_loss: 0.2627834677696228, Dice_loss: 0.027702661231160164, Consistency_loss: 0.00031158782076090574\n",
      "[Training] Epoch: 2 [==============>] 94.4% Loss: 0.3456, Epoch 2, Batch 118, CE_loss: 0.266506552696228, Dice_loss: 0.028301643207669258, Consistency_loss: 0.0006408115150406957\n",
      "[Training] Epoch: 2 [==============>] 95.2% Loss: 0.3453, Epoch 2, Batch 119, CE_loss: 0.2817683219909668, Dice_loss: 0.030871959403157234, Consistency_loss: 7.2310353971261065e-06\n",
      "[Training] Epoch: 2 [==============>] 96.0% Loss: 0.3447, Epoch 2, Batch 120, CE_loss: 0.24509264528751373, Dice_loss: 0.024739526212215424, Consistency_loss: 0.00019643839914351702\n",
      "[Training] Epoch: 2 [==============>] 96.8% Loss: 0.3445, Epoch 2, Batch 121, CE_loss: 0.28475168347358704, Dice_loss: 0.031220771372318268, Consistency_loss: 0.00021585205104202032\n",
      "[Training] Epoch: 2 [==============>] 97.6% Loss: 0.3439, Epoch 2, Batch 122, CE_loss: 0.25079256296157837, Dice_loss: 0.025769324973225594, Consistency_loss: 0.00040410389192402363\n",
      "[Training] Epoch: 2 [==============>] 98.4% Loss: 0.3434, Epoch 2, Batch 123, CE_loss: 0.25012847781181335, Dice_loss: 0.025667615234851837, Consistency_loss: 0.00036237554741092026\n",
      "[Training] Epoch: 2 [==============>] 99.2% Loss: 0.3430, Epoch 2, Batch 124, CE_loss: 0.26675766706466675, Dice_loss: 0.02837756648659706, Consistency_loss: 0.0007243098807521164\n",
      "[Training] Epoch: 2 [DONE]                                 \n",
      "Epoch 2, Batch 125, CE_loss: 0.25820833444595337, Dice_loss: 0.026850808411836624, Consistency_loss: 0.000747809826862067\n",
      "Epoch 2, Batch 125, CE_loss: 0.25820833444595337, Dice_loss: 0.026850808411836624, Consistency_loss: 0.000747809826862067\n",
      "[Validation] Epoch: 2 [DONE]                                 \n",
      "[Epoch: 2, TrainLoss: 0.3425, TrainDice: 0.0355, ValLoss: 0.3791                                             \n",
      "Number of batches:  126\n",
      "[Training] Epoch: 3 [>              ] 0.8% Loss: 0.3031, Epoch 3, Batch 0, CE_loss: 0.2735096514225006, Dice_loss: 0.029535511508584023, Consistency_loss: 1.4410418771149125e-05\n",
      "[Training] Epoch: 3 [>              ] 1.6% Loss: 0.2948, Epoch 3, Batch 1, CE_loss: 0.25902700424194336, Dice_loss: 0.026937488466501236, Consistency_loss: 0.0004942163941450417\n",
      "[Training] Epoch: 3 [>              ] 2.4% Loss: 0.2896, Epoch 3, Batch 2, CE_loss: 0.25267863273620605, Dice_loss: 0.026030205190181732, Consistency_loss: 0.0004535228945314884\n",
      "[Training] Epoch: 3 [>              ] 3.2% Loss: 0.2897, Epoch 3, Batch 3, CE_loss: 0.26207974553108215, Dice_loss: 0.027581648901104927, Consistency_loss: 0.0003080636088270694\n",
      "[Training] Epoch: 3 [>              ] 4.0% Loss: 0.2898, Epoch 3, Batch 4, CE_loss: 0.2621665894985199, Dice_loss: 0.027655230835080147, Consistency_loss: 0.00029017592896707356\n",
      "[Training] Epoch: 3 [>              ] 4.8% Loss: 0.2867, Epoch 3, Batch 5, CE_loss: 0.24582688510417938, Dice_loss: 0.02493090182542801, Consistency_loss: 0.00046235445188358426\n",
      "[Training] Epoch: 3 [>              ] 5.6% Loss: 0.2879, Epoch 3, Batch 6, CE_loss: 0.2663327157497406, Dice_loss: 0.028262624517083168, Consistency_loss: 0.0004905408131889999\n",
      "[Training] Epoch: 3 [>              ] 6.3% Loss: 0.2881, Epoch 3, Batch 7, CE_loss: 0.2615015506744385, Dice_loss: 0.027408333495259285, Consistency_loss: 0.0006544750649482012\n",
      "[Training] Epoch: 3 [=>             ] 7.1% Loss: 0.2882, Epoch 3, Batch 8, CE_loss: 0.2617282569408417, Dice_loss: 0.027623364701867104, Consistency_loss: 0.000193055733689107\n",
      "[Training] Epoch: 3 [=>             ] 7.9% Loss: 0.2856, Epoch 3, Batch 9, CE_loss: 0.2376563847064972, Dice_loss: 0.023523760959506035, Consistency_loss: 0.00019451511616352946\n",
      "[Training] Epoch: 3 [=>             ] 8.7% Loss: 0.2847, Epoch 3, Batch 10, CE_loss: 0.2503318786621094, Dice_loss: 0.025696851313114166, Consistency_loss: 0.0005102097638882697\n",
      "[Training] Epoch: 3 [=>             ] 9.5% Loss: 0.2833, Epoch 3, Batch 11, CE_loss: 0.2427271008491516, Dice_loss: 0.024325571954250336, Consistency_loss: 0.0005119828856550157\n",
      "[Training] Epoch: 3 [=>             ] 10.3% Loss: 0.2837, Epoch 3, Batch 12, CE_loss: 0.2607307732105255, Dice_loss: 0.027224207296967506, Consistency_loss: 0.0005637329304590821\n",
      "[Training] Epoch: 3 [=>             ] 11.1% Loss: 0.2845, Epoch 3, Batch 13, CE_loss: 0.26621586084365845, Dice_loss: 0.02841031737625599, Consistency_loss: 0.0002463506243657321\n",
      "[Training] Epoch: 3 [=>             ] 11.9% Loss: 0.2829, Epoch 3, Batch 14, CE_loss: 0.23605309426784515, Dice_loss: 0.023461811244487762, Consistency_loss: 0.0005256457370705903\n",
      "[Training] Epoch: 3 [=>             ] 12.7% Loss: 0.2830, Epoch 3, Batch 15, CE_loss: 0.25695300102233887, Dice_loss: 0.026849808171391487, Consistency_loss: 0.0005842230748385191\n",
      "[Training] Epoch: 3 [==>            ] 13.5% Loss: 0.2839, Epoch 3, Batch 16, CE_loss: 0.2691701352596283, Dice_loss: 0.02892335131764412, Consistency_loss: 0.00021006081078667194\n",
      "[Training] Epoch: 3 [==>            ] 14.3% Loss: 0.2831, Epoch 3, Batch 17, CE_loss: 0.24416567385196686, Dice_loss: 0.02459459751844406, Consistency_loss: 0.00037928804522380233\n",
      "[Training] Epoch: 3 [==>            ] 15.1% Loss: 0.2831, Epoch 3, Batch 18, CE_loss: 0.2560853362083435, Dice_loss: 0.026665279641747475, Consistency_loss: 0.0005276279989629984\n",
      "[Training] Epoch: 3 [==>            ] 15.9% Loss: 0.2839, Epoch 3, Batch 19, CE_loss: 0.26954612135887146, Dice_loss: 0.029011854901909828, Consistency_loss: 0.0007121845846995711\n",
      "[Training] Epoch: 3 [==>            ] 16.7% Loss: 0.2835, Epoch 3, Batch 20, CE_loss: 0.24992568790912628, Dice_loss: 0.02575133554637432, Consistency_loss: 0.0005480480031110346\n",
      "[Training] Epoch: 3 [==>            ] 17.5% Loss: 0.2827, Epoch 3, Batch 21, CE_loss: 0.2405116707086563, Dice_loss: 0.024214090779423714, Consistency_loss: 0.0002856074715964496\n",
      "[Training] Epoch: 3 [==>            ] 18.3% Loss: 0.2827, Epoch 3, Batch 22, CE_loss: 0.2553273141384125, Dice_loss: 0.02666901797056198, Consistency_loss: 0.00070137286093086\n",
      "[Training] Epoch: 3 [==>            ] 19.0% Loss: 0.2820, Epoch 3, Batch 23, CE_loss: 0.24119685590267181, Dice_loss: 0.02421087957918644, Consistency_loss: 0.0006737096118740737\n",
      "[Training] Epoch: 3 [==>            ] 19.8% Loss: 0.2813, Epoch 3, Batch 24, CE_loss: 0.2395758032798767, Dice_loss: 0.023854942992329597, Consistency_loss: 0.0006707583670504391\n",
      "[Training] Epoch: 3 [===>           ] 20.6% Loss: 0.2805, Epoch 3, Batch 25, CE_loss: 0.23734784126281738, Dice_loss: 0.02368473820388317, Consistency_loss: 0.0006672934978269041\n",
      "[Training] Epoch: 3 [===>           ] 21.4% Loss: 0.2794, Epoch 3, Batch 26, CE_loss: 0.22898320853710175, Dice_loss: 0.022318322211503983, Consistency_loss: 1.1720373549906071e-05\n",
      "[Training] Epoch: 3 [===>           ] 22.2% Loss: 0.2795, Epoch 3, Batch 27, CE_loss: 0.2542269825935364, Dice_loss: 0.026375047862529755, Consistency_loss: 0.0004764223995152861\n",
      "[Training] Epoch: 3 [===>           ] 23.0% Loss: 0.2795, Epoch 3, Batch 28, CE_loss: 0.2523978054523468, Dice_loss: 0.025970373302698135, Consistency_loss: 0.0005115338135510683\n",
      "[Training] Epoch: 3 [===>           ] 23.8% Loss: 0.2787, Epoch 3, Batch 29, CE_loss: 0.23259565234184265, Dice_loss: 0.02279510349035263, Consistency_loss: 7.283138984348625e-06\n",
      "[Training] Epoch: 3 [===>           ] 24.6% Loss: 0.2782, Epoch 3, Batch 30, CE_loss: 0.23940321803092957, Dice_loss: 0.023694125935435295, Consistency_loss: 5.970966867607785e-06\n",
      "[Training] Epoch: 3 [===>           ] 25.4% Loss: 0.2772, Epoch 3, Batch 31, CE_loss: 0.22526727616786957, Dice_loss: 0.021635064855217934, Consistency_loss: 0.0005006474093534052\n",
      "[Training] Epoch: 3 [===>           ] 26.2% Loss: 0.2776, Epoch 3, Batch 32, CE_loss: 0.26111143827438354, Dice_loss: 0.02727244235575199, Consistency_loss: 0.0005863367696292698\n",
      "[Training] Epoch: 3 [====>          ] 27.0% Loss: 0.2782, Epoch 3, Batch 33, CE_loss: 0.269505113363266, Dice_loss: 0.028813013806939125, Consistency_loss: 0.00036080635618418455\n",
      "[Training] Epoch: 3 [====>          ] 27.8% Loss: 0.2779, Epoch 3, Batch 34, CE_loss: 0.24343761801719666, Dice_loss: 0.024610091000795364, Consistency_loss: 0.00035248868516646326\n",
      "[Training] Epoch: 3 [====>          ] 28.6% Loss: 0.2773, Epoch 3, Batch 35, CE_loss: 0.23208996653556824, Dice_loss: 0.02263345569372177, Consistency_loss: 0.0005341536598280072\n",
      "[Training] Epoch: 3 [====>          ] 29.4% Loss: 0.2770, Epoch 3, Batch 36, CE_loss: 0.24362599849700928, Dice_loss: 0.024626711383461952, Consistency_loss: 0.0006303629488684237\n",
      "[Training] Epoch: 3 [====>          ] 30.2% Loss: 0.2772, Epoch 3, Batch 37, CE_loss: 0.2550809979438782, Dice_loss: 0.026425007730722427, Consistency_loss: 0.0005421786918304861\n",
      "[Training] Epoch: 3 [====>          ] 31.0% Loss: 0.2766, Epoch 3, Batch 38, CE_loss: 0.23049235343933105, Dice_loss: 0.022579461336135864, Consistency_loss: 0.0004238982801325619\n",
      "[Training] Epoch: 3 [====>          ] 31.7% Loss: 0.2756, Epoch 3, Batch 39, CE_loss: 0.21669499576091766, Dice_loss: 0.020374372601509094, Consistency_loss: 0.0004685063031502068\n",
      "[Training] Epoch: 3 [====>          ] 32.5% Loss: 0.2752, Epoch 3, Batch 40, CE_loss: 0.2350752353668213, Dice_loss: 0.023301182314753532, Consistency_loss: 0.00029939934029243886\n",
      "[Training] Epoch: 3 [=====>         ] 33.3% Loss: 0.2747, Epoch 3, Batch 41, CE_loss: 0.23212888836860657, Dice_loss: 0.022808201611042023, Consistency_loss: 0.0004188762104604393\n",
      "[Training] Epoch: 3 [=====>         ] 34.1% Loss: 0.2747, Epoch 3, Batch 42, CE_loss: 0.24850167334079742, Dice_loss: 0.025528568774461746, Consistency_loss: 0.0004361737228464335\n",
      "[Training] Epoch: 3 [=====>         ] 34.9% Loss: 0.2747, Epoch 3, Batch 43, CE_loss: 0.2466239482164383, Dice_loss: 0.025266239419579506, Consistency_loss: 0.0007686287281103432\n",
      "[Training] Epoch: 3 [=====>         ] 35.7% Loss: 0.2747, Epoch 3, Batch 44, CE_loss: 0.24822209775447845, Dice_loss: 0.02571750432252884, Consistency_loss: 0.0007409321842715144\n",
      "[Training] Epoch: 3 [=====>         ] 36.5% Loss: 0.2745, Epoch 3, Batch 45, CE_loss: 0.2402038276195526, Dice_loss: 0.024358276277780533, Consistency_loss: 0.000831032928545028\n",
      "[Training] Epoch: 3 [=====>         ] 37.3% Loss: 0.2738, Epoch 3, Batch 46, CE_loss: 0.22142384946346283, Dice_loss: 0.02118774503469467, Consistency_loss: 0.0006443934980779886\n",
      "[Training] Epoch: 3 [=====>         ] 38.1% Loss: 0.2733, Epoch 3, Batch 47, CE_loss: 0.22709842026233673, Dice_loss: 0.022181877866387367, Consistency_loss: 0.0006714339833706617\n",
      "[Training] Epoch: 3 [=====>         ] 38.9% Loss: 0.2731, Epoch 3, Batch 48, CE_loss: 0.23809999227523804, Dice_loss: 0.023922229185700417, Consistency_loss: 0.0006741514662280679\n",
      "[Training] Epoch: 3 [=====>         ] 39.7% Loss: 0.2727, Epoch 3, Batch 49, CE_loss: 0.23243597149848938, Dice_loss: 0.02311549335718155, Consistency_loss: 0.0006751508335582912\n",
      "[Training] Epoch: 3 [======>        ] 40.5% Loss: 0.2723, Epoch 3, Batch 50, CE_loss: 0.22952914237976074, Dice_loss: 0.022382069379091263, Consistency_loss: 0.0006737283547408879\n",
      "[Training] Epoch: 3 [======>        ] 41.3% Loss: 0.2718, Epoch 3, Batch 51, CE_loss: 0.22093141078948975, Dice_loss: 0.02117389440536499, Consistency_loss: 2.1769907107227482e-05\n",
      "[Training] Epoch: 3 [======>        ] 42.1% Loss: 0.2712, Epoch 3, Batch 52, CE_loss: 0.21866855025291443, Dice_loss: 0.020812654867768288, Consistency_loss: 1.177468857349595e-05\n",
      "[Training] Epoch: 3 [======>        ] 42.9% Loss: 0.2706, Epoch 3, Batch 53, CE_loss: 0.2207033932209015, Dice_loss: 0.021042922511696815, Consistency_loss: 0.000592521857470274\n",
      "[Training] Epoch: 3 [======>        ] 43.7% Loss: 0.2700, Epoch 3, Batch 54, CE_loss: 0.21449187397956848, Dice_loss: 0.019993625581264496, Consistency_loss: 1.4197291420714464e-05\n",
      "[Training] Epoch: 3 [======>        ] 44.4% Loss: 0.2697, Epoch 3, Batch 55, CE_loss: 0.23048867285251617, Dice_loss: 0.022597575560212135, Consistency_loss: 0.00045483745634555817\n",
      "[Training] Epoch: 3 [======>        ] 45.2% Loss: 0.2694, Epoch 3, Batch 56, CE_loss: 0.22928237915039062, Dice_loss: 0.02238694205880165, Consistency_loss: 4.863608864980051e-06\n",
      "[Training] Epoch: 3 [======>        ] 46.0% Loss: 0.2693, Epoch 3, Batch 57, CE_loss: 0.24255745112895966, Dice_loss: 0.024576732888817787, Consistency_loss: 7.051638476696098e-06\n",
      "[Training] Epoch: 3 [=======>       ] 46.8% Loss: 0.2687, Epoch 3, Batch 58, CE_loss: 0.2107381671667099, Dice_loss: 0.019370369613170624, Consistency_loss: 8.206409802369308e-06\n",
      "[Training] Epoch: 3 [=======>       ] 47.6% Loss: 0.2685, Epoch 3, Batch 59, CE_loss: 0.23641911149024963, Dice_loss: 0.0233737975358963, Consistency_loss: 0.0005354457534849644\n",
      "[Training] Epoch: 3 [=======>       ] 48.4% Loss: 0.2679, Epoch 3, Batch 60, CE_loss: 0.21225599944591522, Dice_loss: 0.01973094791173935, Consistency_loss: 6.929437404323835e-06\n",
      "[Training] Epoch: 3 [=======>       ] 49.2% Loss: 0.2681, Epoch 3, Batch 61, CE_loss: 0.2501063048839569, Dice_loss: 0.025563491508364677, Consistency_loss: 0.0006260544178076088\n",
      "[Training] Epoch: 3 [=======>       ] 50.0% Loss: 0.2678, Epoch 3, Batch 62, CE_loss: 0.22981010377407074, Dice_loss: 0.022547150030732155, Consistency_loss: 0.00023681441962253302\n",
      "[Training] Epoch: 3 [=======>       ] 50.8% Loss: 0.2673, Epoch 3, Batch 63, CE_loss: 0.21621651947498322, Dice_loss: 0.02039068192243576, Consistency_loss: 0.00034188010613434017\n",
      "[Training] Epoch: 3 [=======>       ] 51.6% Loss: 0.2668, Epoch 3, Batch 64, CE_loss: 0.21285732090473175, Dice_loss: 0.019858835265040398, Consistency_loss: 7.022998033789918e-06\n",
      "[Training] Epoch: 3 [=======>       ] 52.4% Loss: 0.2665, Epoch 3, Batch 65, CE_loss: 0.22380098700523376, Dice_loss: 0.021524468436837196, Consistency_loss: 0.00039878764073364437\n",
      "[Training] Epoch: 3 [=======>       ] 53.2% Loss: 0.2663, Epoch 3, Batch 66, CE_loss: 0.23246823251247406, Dice_loss: 0.022802799940109253, Consistency_loss: 0.00042275848682038486\n",
      "[Training] Epoch: 3 [========>      ] 54.0% Loss: 0.2659, Epoch 3, Batch 67, CE_loss: 0.21925659477710724, Dice_loss: 0.020826585590839386, Consistency_loss: 0.0004249571938998997\n",
      "[Training] Epoch: 3 [========>      ] 54.8% Loss: 0.2655, Epoch 3, Batch 68, CE_loss: 0.21435117721557617, Dice_loss: 0.02003239095211029, Consistency_loss: 0.00043988428660668433\n",
      "[Training] Epoch: 3 [========>      ] 55.6% Loss: 0.2653, Epoch 3, Batch 69, CE_loss: 0.23073239624500275, Dice_loss: 0.022617656737565994, Consistency_loss: 0.0004747349885292351\n",
      "[Training] Epoch: 3 [========>      ] 56.3% Loss: 0.2654, Epoch 3, Batch 70, CE_loss: 0.24329063296318054, Dice_loss: 0.024798544123768806, Consistency_loss: 0.0005601774901151657\n",
      "[Training] Epoch: 3 [========>      ] 57.1% Loss: 0.2650, Epoch 3, Batch 71, CE_loss: 0.2152695655822754, Dice_loss: 0.020202800631523132, Consistency_loss: 0.0005926286685280502\n",
      "[Training] Epoch: 3 [========>      ] 57.9% Loss: 0.2646, Epoch 3, Batch 72, CE_loss: 0.22122608125209808, Dice_loss: 0.021158669143915176, Consistency_loss: 7.205642759799957e-06\n",
      "[Training] Epoch: 3 [========>      ] 58.7% Loss: 0.2642, Epoch 3, Batch 73, CE_loss: 0.21461975574493408, Dice_loss: 0.020289383828639984, Consistency_loss: 0.00037835389957763255\n",
      "[Training] Epoch: 3 [========>      ] 59.5% Loss: 0.2637, Epoch 3, Batch 74, CE_loss: 0.205327570438385, Dice_loss: 0.018978167325258255, Consistency_loss: 0.0006288820295594633\n",
      "[Training] Epoch: 3 [=========>     ] 60.3% Loss: 0.2633, Epoch 3, Batch 75, CE_loss: 0.21410433948040009, Dice_loss: 0.020022548735141754, Consistency_loss: 0.00041622878052294254\n",
      "[Training] Epoch: 3 [=========>     ] 61.1% Loss: 0.2634, Epoch 3, Batch 76, CE_loss: 0.23993359506130219, Dice_loss: 0.02440342679619789, Consistency_loss: 0.0006406761240214109\n",
      "[Training] Epoch: 3 [=========>     ] 61.9% Loss: 0.2630, Epoch 3, Batch 77, CE_loss: 0.21449688076972961, Dice_loss: 0.02012448012828827, Consistency_loss: 0.0003831603971775621\n",
      "[Training] Epoch: 3 [=========>     ] 62.7% Loss: 0.2627, Epoch 3, Batch 78, CE_loss: 0.2177012413740158, Dice_loss: 0.020845144987106323, Consistency_loss: 0.00040406614425592124\n",
      "[Training] Epoch: 3 [=========>     ] 63.5% Loss: 0.2627, Epoch 3, Batch 79, CE_loss: 0.23666825890541077, Dice_loss: 0.023674894124269485, Consistency_loss: 0.0004333343531470746\n",
      "[Training] Epoch: 3 [=========>     ] 64.3% Loss: 0.2623, Epoch 3, Batch 80, CE_loss: 0.2112625539302826, Dice_loss: 0.019668979570269585, Consistency_loss: 1.4001346244185697e-05\n",
      "[Training] Epoch: 3 [=========>     ] 65.1% Loss: 0.2622, Epoch 3, Batch 81, CE_loss: 0.23031532764434814, Dice_loss: 0.022889364510774612, Consistency_loss: 0.0005224462365731597\n",
      "[Training] Epoch: 3 [=========>     ] 65.9% Loss: 0.2620, Epoch 3, Batch 82, CE_loss: 0.22453872859477997, Dice_loss: 0.021973077207803726, Consistency_loss: 0.0005490262992680073\n",
      "[Training] Epoch: 3 [==========>    ] 66.7% Loss: 0.2616, Epoch 3, Batch 83, CE_loss: 0.20829474925994873, Dice_loss: 0.01918218471109867, Consistency_loss: 0.0003532232658471912\n",
      "[Training] Epoch: 3 [==========>    ] 67.5% Loss: 0.2613, Epoch 3, Batch 84, CE_loss: 0.21425102651119232, Dice_loss: 0.020325511693954468, Consistency_loss: 0.0005799976061098278\n",
      "[Training] Epoch: 3 [==========>    ] 68.3% Loss: 0.2610, Epoch 3, Batch 85, CE_loss: 0.213018536567688, Dice_loss: 0.02020644024014473, Consistency_loss: 0.00038667680928483605\n",
      "[Training] Epoch: 3 [==========>    ] 69.0% Loss: 0.2606, Epoch 3, Batch 86, CE_loss: 0.2115134596824646, Dice_loss: 0.019915126264095306, Consistency_loss: 1.969809272850398e-05\n",
      "[Training] Epoch: 3 [==========>    ] 69.8% Loss: 0.2602, Epoch 3, Batch 87, CE_loss: 0.20097683370113373, Dice_loss: 0.01846807450056076, Consistency_loss: 0.00048811809392645955\n",
      "[Training] Epoch: 3 [==========>    ] 70.6% Loss: 0.2596, Epoch 3, Batch 88, CE_loss: 0.19289129972457886, Dice_loss: 0.017029721289873123, Consistency_loss: 0.0006452698144130409\n",
      "[Training] Epoch: 3 [==========>    ] 71.4% Loss: 0.2592, Epoch 3, Batch 89, CE_loss: 0.2084622085094452, Dice_loss: 0.019408080726861954, Consistency_loss: 0.0005279406323097646\n",
      "[Training] Epoch: 3 [==========>    ] 72.2% Loss: 0.2589, Epoch 3, Batch 90, CE_loss: 0.2098526805639267, Dice_loss: 0.01969398558139801, Consistency_loss: 2.2163370886119083e-05\n",
      "[Training] Epoch: 3 [==========>    ] 73.0% Loss: 0.2586, Epoch 3, Batch 91, CE_loss: 0.2096741497516632, Dice_loss: 0.01960355043411255, Consistency_loss: 0.000586294278036803\n",
      "[Training] Epoch: 3 [===========>   ] 73.8% Loss: 0.2581, Epoch 3, Batch 92, CE_loss: 0.1949790120124817, Dice_loss: 0.01730513945221901, Consistency_loss: 1.397801679559052e-05\n",
      "[Training] Epoch: 3 [===========>   ] 74.6% Loss: 0.2580, Epoch 3, Batch 93, CE_loss: 0.2252647429704666, Dice_loss: 0.022135771811008453, Consistency_loss: 0.00026030250592157245\n",
      "[Training] Epoch: 3 [===========>   ] 75.4% Loss: 0.2577, Epoch 3, Batch 94, CE_loss: 0.2102779597043991, Dice_loss: 0.019756106659770012, Consistency_loss: 1.2776830772054382e-05\n",
      "[Training] Epoch: 3 [===========>   ] 76.2% Loss: 0.2575, Epoch 3, Batch 95, CE_loss: 0.21365660429000854, Dice_loss: 0.020260147750377655, Consistency_loss: 0.00044149949098937213\n",
      "[Training] Epoch: 3 [===========>   ] 77.0% Loss: 0.2570, Epoch 3, Batch 96, CE_loss: 0.19747935235500336, Dice_loss: 0.01764276623725891, Consistency_loss: 0.0005121825961396098\n",
      "[Training] Epoch: 3 [===========>   ] 77.8% Loss: 0.2566, Epoch 3, Batch 97, CE_loss: 0.2008645385503769, Dice_loss: 0.01825808361172676, Consistency_loss: 1.6593152395216748e-05\n",
      "[Training] Epoch: 3 [===========>   ] 78.6% Loss: 0.2564, Epoch 3, Batch 98, CE_loss: 0.21227383613586426, Dice_loss: 0.020118489861488342, Consistency_loss: 0.0004958493518643081\n",
      "[Training] Epoch: 3 [===========>   ] 79.4% Loss: 0.2562, Epoch 3, Batch 99, CE_loss: 0.2166443020105362, Dice_loss: 0.02070099487900734, Consistency_loss: 0.0004918969934806228\n",
      "[Training] Epoch: 3 [============>  ] 80.2% Loss: 0.2560, Epoch 3, Batch 100, CE_loss: 0.21353164315223694, Dice_loss: 0.02017805352807045, Consistency_loss: 0.0005057397647760808\n",
      "[Training] Epoch: 3 [============>  ] 81.0% Loss: 0.2555, Epoch 3, Batch 101, CE_loss: 0.18719607591629028, Dice_loss: 0.016113264486193657, Consistency_loss: 0.0005366012919694185\n",
      "[Training] Epoch: 3 [============>  ] 81.7% Loss: 0.2553, Epoch 3, Batch 102, CE_loss: 0.21276098489761353, Dice_loss: 0.02017834782600403, Consistency_loss: 0.0005579680437222123\n",
      "[Training] Epoch: 3 [============>  ] 82.5% Loss: 0.2548, Epoch 3, Batch 103, CE_loss: 0.18665534257888794, Dice_loss: 0.016259515658020973, Consistency_loss: 0.0003629398124758154\n",
      "[Training] Epoch: 3 [============>  ] 83.3% Loss: 0.2544, Epoch 3, Batch 104, CE_loss: 0.20040589570999146, Dice_loss: 0.01843085326254368, Consistency_loss: 2.455450885463506e-05\n",
      "[Training] Epoch: 3 [============>  ] 84.1% Loss: 0.2542, Epoch 3, Batch 105, CE_loss: 0.20943376421928406, Dice_loss: 0.019734058529138565, Consistency_loss: 1.742319182085339e-05\n",
      "[Training] Epoch: 3 [============>  ] 84.9% Loss: 0.2536, Epoch 3, Batch 106, CE_loss: 0.1797066479921341, Dice_loss: 0.014978877268731594, Consistency_loss: 1.73030039150035e-05\n",
      "[Training] Epoch: 3 [============>  ] 85.7% Loss: 0.2537, Epoch 3, Batch 107, CE_loss: 0.23307353258132935, Dice_loss: 0.02321057766675949, Consistency_loss: 0.0004436075687408447\n",
      "[Training] Epoch: 3 [============>  ] 86.5% Loss: 0.2535, Epoch 3, Batch 108, CE_loss: 0.21404066681861877, Dice_loss: 0.02030421607196331, Consistency_loss: 1.0543796634010505e-05\n",
      "[Training] Epoch: 3 [=============> ] 87.3% Loss: 0.2534, Epoch 3, Batch 109, CE_loss: 0.2250695526599884, Dice_loss: 0.022112704813480377, Consistency_loss: 1.2942732610099483e-05\n",
      "[Training] Epoch: 3 [=============> ] 88.1% Loss: 0.2534, Epoch 3, Batch 110, CE_loss: 0.22299087047576904, Dice_loss: 0.021447990089654922, Consistency_loss: 0.0005603525205515325\n",
      "[Training] Epoch: 3 [=============> ] 88.9% Loss: 0.2530, Epoch 3, Batch 111, CE_loss: 0.20007795095443726, Dice_loss: 0.018223760649561882, Consistency_loss: 0.0005034552305005491\n",
      "[Training] Epoch: 3 [=============> ] 89.7% Loss: 0.2528, Epoch 3, Batch 112, CE_loss: 0.20926183462142944, Dice_loss: 0.019834989681839943, Consistency_loss: 0.0005011632456444204\n",
      "[Training] Epoch: 3 [=============> ] 90.5% Loss: 0.2526, Epoch 3, Batch 113, CE_loss: 0.20604601502418518, Dice_loss: 0.019190847873687744, Consistency_loss: 0.0006846331525593996\n",
      "[Training] Epoch: 3 [=============> ] 91.3% Loss: 0.2521, Epoch 3, Batch 114, CE_loss: 0.1834908425807953, Dice_loss: 0.01572384312748909, Consistency_loss: 0.0003934619599021971\n",
      "[Training] Epoch: 3 [=============> ] 92.1% Loss: 0.2520, Epoch 3, Batch 115, CE_loss: 0.21706897020339966, Dice_loss: 0.02101920358836651, Consistency_loss: 0.0005201852764002979\n",
      "[Training] Epoch: 3 [=============> ] 92.9% Loss: 0.2519, Epoch 3, Batch 116, CE_loss: 0.21806855499744415, Dice_loss: 0.020949680358171463, Consistency_loss: 0.0003434250829741359\n",
      "[Training] Epoch: 3 [==============>] 93.7% Loss: 0.2516, Epoch 3, Batch 117, CE_loss: 0.19794777035713196, Dice_loss: 0.018105510622262955, Consistency_loss: 0.00028878674493171275\n",
      "[Training] Epoch: 3 [==============>] 94.4% Loss: 0.2513, Epoch 3, Batch 118, CE_loss: 0.19852694869041443, Dice_loss: 0.018320515751838684, Consistency_loss: 0.00026618861011229455\n",
      "[Training] Epoch: 3 [==============>] 95.2% Loss: 0.2511, Epoch 3, Batch 119, CE_loss: 0.20484715700149536, Dice_loss: 0.019241515547037125, Consistency_loss: 0.0003232584276702255\n",
      "[Training] Epoch: 3 [==============>] 96.0% Loss: 0.2508, Epoch 3, Batch 120, CE_loss: 0.19490808248519897, Dice_loss: 0.01779813878238201, Consistency_loss: 0.00047846176312305033\n",
      "[Training] Epoch: 3 [==============>] 96.8% Loss: 0.2505, Epoch 3, Batch 121, CE_loss: 0.1934221237897873, Dice_loss: 0.017413366585969925, Consistency_loss: 0.0001182332998723723\n",
      "[Training] Epoch: 3 [==============>] 97.6% Loss: 0.2500, Epoch 3, Batch 122, CE_loss: 0.18057966232299805, Dice_loss: 0.01550388429313898, Consistency_loss: 0.00012741379032377154\n",
      "[Training] Epoch: 3 [==============>] 98.4% Loss: 0.2496, Epoch 3, Batch 123, CE_loss: 0.18162980675697327, Dice_loss: 0.015485000796616077, Consistency_loss: 0.00035886940895579755\n",
      "[Training] Epoch: 3 [==============>] 99.2% Loss: 0.2492, Epoch 3, Batch 124, CE_loss: 0.18002904951572418, Dice_loss: 0.015083742327988148, Consistency_loss: 0.0004774359113071114\n",
      "[Training] Epoch: 3 [DONE]                                 \n",
      "Epoch 3, Batch 125, CE_loss: 0.2040509432554245, Dice_loss: 0.019009942188858986, Consistency_loss: 0.0004536249616649002\n",
      "Epoch 3, Batch 125, CE_loss: 0.2040509432554245, Dice_loss: 0.019009942188858986, Consistency_loss: 0.0004536249616649002\n",
      "[Validation] Epoch: 3 [DONE]                                 \n",
      "[Epoch: 3, TrainLoss: 0.2490, TrainDice: 0.0221, ValLoss: 0.2943                                             \n",
      "Number of batches:  126\n",
      "[Training] Epoch: 4 [>              ] 0.8% Loss: 0.1969, Epoch 4, Batch 0, CE_loss: 0.1810564398765564, Dice_loss: 0.015473905950784683, Consistency_loss: 0.0003681178786791861\n",
      "[Training] Epoch: 4 [>              ] 1.6% Loss: 0.2112, Epoch 4, Batch 1, CE_loss: 0.20597121119499207, Dice_loss: 0.0192309208214283, Consistency_loss: 0.00036975234979763627\n",
      "[Training] Epoch: 4 [>              ] 2.4% Loss: 0.2068, Epoch 4, Batch 2, CE_loss: 0.18202760815620422, Dice_loss: 0.015616733580827713, Consistency_loss: 0.00027141222381033003\n",
      "[Training] Epoch: 4 [>              ] 3.2% Loss: 0.2051, Epoch 4, Batch 3, CE_loss: 0.18396031856536865, Dice_loss: 0.015914110466837883, Consistency_loss: 8.155791874742135e-06\n",
      "[Training] Epoch: 4 [>              ] 4.0% Loss: 0.2073, Epoch 4, Batch 4, CE_loss: 0.1977984756231308, Dice_loss: 0.01798047497868538, Consistency_loss: 0.00045840369421057403\n",
      "[Training] Epoch: 4 [>              ] 4.8% Loss: 0.2077, Epoch 4, Batch 5, CE_loss: 0.19236908853054047, Dice_loss: 0.01717359572649002, Consistency_loss: 1.1650556189124472e-05\n",
      "[Training] Epoch: 4 [>              ] 5.6% Loss: 0.2063, Epoch 4, Batch 6, CE_loss: 0.18235106766223907, Dice_loss: 0.015602562576532364, Consistency_loss: 9.35484695219202e-06\n",
      "[Training] Epoch: 4 [>              ] 6.3% Loss: 0.2039, Epoch 4, Batch 7, CE_loss: 0.17229370772838593, Dice_loss: 0.014229190535843372, Consistency_loss: 0.0005363746895454824\n",
      "[Training] Epoch: 4 [=>             ] 7.1% Loss: 0.2059, Epoch 4, Batch 8, CE_loss: 0.20280146598815918, Dice_loss: 0.018929539248347282, Consistency_loss: 1.2996570148970932e-05\n",
      "[Training] Epoch: 4 [=>             ] 7.9% Loss: 0.2095, Epoch 4, Batch 9, CE_loss: 0.22018490731716156, Dice_loss: 0.02139447070658207, Consistency_loss: 0.0005658813170157373\n",
      "[Training] Epoch: 4 [=>             ] 8.7% Loss: 0.2091, Epoch 4, Batch 10, CE_loss: 0.1881730705499649, Dice_loss: 0.0166719239205122, Consistency_loss: 1.106518175220117e-05\n",
      "[Training] Epoch: 4 [=>             ] 9.5% Loss: 0.2076, Epoch 4, Batch 11, CE_loss: 0.1763029247522354, Dice_loss: 0.014884445816278458, Consistency_loss: 0.000415807735407725\n",
      "[Training] Epoch: 4 [=>             ] 10.3% Loss: 0.2080, Epoch 4, Batch 12, CE_loss: 0.19495829939842224, Dice_loss: 0.017583373934030533, Consistency_loss: 0.0005337424809113145\n",
      "[Training] Epoch: 4 [=>             ] 11.1% Loss: 0.2085, Epoch 4, Batch 13, CE_loss: 0.19614095985889435, Dice_loss: 0.01790672354400158, Consistency_loss: 0.0004796960565727204\n",
      "[Training] Epoch: 4 [=>             ] 11.9% Loss: 0.2082, Epoch 4, Batch 14, CE_loss: 0.18754033744335175, Dice_loss: 0.016707757487893105, Consistency_loss: 0.0003579049080144614\n",
      "[Training] Epoch: 4 [=>             ] 12.7% Loss: 0.2078, Epoch 4, Batch 15, CE_loss: 0.18477971851825714, Dice_loss: 0.01593564823269844, Consistency_loss: 0.00019591933232732117\n",
      "[Training] Epoch: 4 [==>            ] 13.5% Loss: 0.2072, Epoch 4, Batch 16, CE_loss: 0.18155501782894135, Dice_loss: 0.01567574217915535, Consistency_loss: 0.0001619587856112048\n",
      "[Training] Epoch: 4 [==>            ] 14.3% Loss: 0.2075, Epoch 4, Batch 17, CE_loss: 0.19504138827323914, Dice_loss: 0.01757444255053997, Consistency_loss: 0.00030865342705510557\n",
      "[Training] Epoch: 4 [==>            ] 15.1% Loss: 0.2065, Epoch 4, Batch 18, CE_loss: 0.1742582470178604, Dice_loss: 0.014601928181946278, Consistency_loss: 0.00042873580241575837\n",
      "[Training] Epoch: 4 [==>            ] 15.9% Loss: 0.2060, Epoch 4, Batch 19, CE_loss: 0.18114686012268066, Dice_loss: 0.015605933032929897, Consistency_loss: 1.5223922673612833e-05\n",
      "[Training] Epoch: 4 [==>            ] 16.7% Loss: 0.2060, Epoch 4, Batch 20, CE_loss: 0.18775026500225067, Dice_loss: 0.016834475100040436, Consistency_loss: 0.00043719500536099076\n",
      "[Training] Epoch: 4 [==>            ] 17.5% Loss: 0.2054, Epoch 4, Batch 21, CE_loss: 0.1777997463941574, Dice_loss: 0.01519106701016426, Consistency_loss: 0.0004495872126426548\n",
      "[Training] Epoch: 4 [==>            ] 18.3% Loss: 0.2046, Epoch 4, Batch 22, CE_loss: 0.17172880470752716, Dice_loss: 0.014291945844888687, Consistency_loss: 0.0003900165611412376\n",
      "[Training] Epoch: 4 [==>            ] 19.0% Loss: 0.2037, Epoch 4, Batch 23, CE_loss: 0.16800835728645325, Dice_loss: 0.013637566938996315, Consistency_loss: 0.0005049345782026649\n",
      "[Training] Epoch: 4 [==>            ] 19.8% Loss: 0.2038, Epoch 4, Batch 24, CE_loss: 0.18921470642089844, Dice_loss: 0.016780132427811623, Consistency_loss: 0.00048518498078919947\n",
      "[Training] Epoch: 4 [===>           ] 20.6% Loss: 0.2042, Epoch 4, Batch 25, CE_loss: 0.1965050846338272, Dice_loss: 0.017626969143748283, Consistency_loss: 1.2200694982311688e-05\n",
      "[Training] Epoch: 4 [===>           ] 21.4% Loss: 0.2036, Epoch 4, Batch 26, CE_loss: 0.17311322689056396, Dice_loss: 0.014547632075846195, Consistency_loss: 0.0004260317946318537\n",
      "[Training] Epoch: 4 [===>           ] 22.2% Loss: 0.2030, Epoch 4, Batch 27, CE_loss: 0.17230793833732605, Dice_loss: 0.014402863569557667, Consistency_loss: 1.7477310393587686e-05\n",
      "[Training] Epoch: 4 [===>           ] 23.0% Loss: 0.2040, Epoch 4, Batch 28, CE_loss: 0.21082057058811188, Dice_loss: 0.020446963608264923, Consistency_loss: 0.0003645078686531633\n",
      "[Training] Epoch: 4 [===>           ] 23.8% Loss: 0.2039, Epoch 4, Batch 29, CE_loss: 0.18598926067352295, Dice_loss: 0.016251156106591225, Consistency_loss: 0.00045209494419395924\n",
      "[Training] Epoch: 4 [===>           ] 24.6% Loss: 0.2037, Epoch 4, Batch 30, CE_loss: 0.18161575496196747, Dice_loss: 0.016011446714401245, Consistency_loss: 0.0005081690032966435\n",
      "[Training] Epoch: 4 [===>           ] 25.4% Loss: 0.2036, Epoch 4, Batch 31, CE_loss: 0.18265073001384735, Dice_loss: 0.01620042696595192, Consistency_loss: 1.472118037781911e-05\n",
      "[Training] Epoch: 4 [===>           ] 26.2% Loss: 0.2035, Epoch 4, Batch 32, CE_loss: 0.1841532289981842, Dice_loss: 0.01636665314435959, Consistency_loss: 2.0064560885657556e-05\n",
      "[Training] Epoch: 4 [====>          ] 27.0% Loss: 0.2041, Epoch 4, Batch 33, CE_loss: 0.20431748032569885, Dice_loss: 0.018966061994433403, Consistency_loss: 0.0006087559158913791\n",
      "[Training] Epoch: 4 [====>          ] 27.8% Loss: 0.2043, Epoch 4, Batch 34, CE_loss: 0.19181807339191437, Dice_loss: 0.017556622624397278, Consistency_loss: 0.00037736096419394016\n",
      "[Training] Epoch: 4 [====>          ] 28.6% Loss: 0.2039, Epoch 4, Batch 35, CE_loss: 0.17622826993465424, Dice_loss: 0.015218550339341164, Consistency_loss: 0.0004495765606407076\n",
      "[Training] Epoch: 4 [====>          ] 29.4% Loss: 0.2038, Epoch 4, Batch 36, CE_loss: 0.18275488913059235, Dice_loss: 0.016250137239694595, Consistency_loss: 0.0004980225930921733\n",
      "[Training] Epoch: 4 [====>          ] 30.2% Loss: 0.2037, Epoch 4, Batch 37, CE_loss: 0.1828426569700241, Dice_loss: 0.016294706612825394, Consistency_loss: 0.0004931723233312368\n",
      "[Training] Epoch: 4 [====>          ] 31.0% Loss: 0.2038, Epoch 4, Batch 38, CE_loss: 0.19194914400577545, Dice_loss: 0.01759914495050907, Consistency_loss: 0.0005241324543021619\n",
      "[Training] Epoch: 4 [====>          ] 31.7% Loss: 0.2037, Epoch 4, Batch 39, CE_loss: 0.18345829844474792, Dice_loss: 0.01636364869773388, Consistency_loss: 2.1259076675050892e-05\n",
      "[Training] Epoch: 4 [====>          ] 32.5% Loss: 0.2033, Epoch 4, Batch 40, CE_loss: 0.1710917204618454, Dice_loss: 0.014560104347765446, Consistency_loss: 1.9737728507607244e-05\n",
      "[Training] Epoch: 4 [=====>         ] 33.3% Loss: 0.2030, Epoch 4, Batch 41, CE_loss: 0.1751382052898407, Dice_loss: 0.015114936977624893, Consistency_loss: 0.00027504409081302583\n",
      "[Training] Epoch: 4 [=====>         ] 34.1% Loss: 0.2034, Epoch 4, Batch 42, CE_loss: 0.20192378759384155, Dice_loss: 0.018978023901581764, Consistency_loss: 0.0004134567570872605\n",
      "[Training] Epoch: 4 [=====>         ] 34.9% Loss: 0.2037, Epoch 4, Batch 43, CE_loss: 0.19735316932201385, Dice_loss: 0.018560636788606644, Consistency_loss: 0.00039937064866535366\n",
      "[Training] Epoch: 4 [=====>         ] 35.7% Loss: 0.2031, Epoch 4, Batch 44, CE_loss: 0.16327960789203644, Dice_loss: 0.013247260823845863, Consistency_loss: 0.0005891076871193945\n",
      "[Training] Epoch: 4 [=====>         ] 36.5% Loss: 0.2033, Epoch 4, Batch 45, CE_loss: 0.1940464973449707, Dice_loss: 0.01794031262397766, Consistency_loss: 0.0003850458306260407\n",
      "[Training] Epoch: 4 [=====>         ] 37.3% Loss: 0.2028, Epoch 4, Batch 46, CE_loss: 0.16566728055477142, Dice_loss: 0.013836551457643509, Consistency_loss: 0.0005660172901116312\n",
      "[Training] Epoch: 4 [=====>         ] 38.1% Loss: 0.2030, Epoch 4, Batch 47, CE_loss: 0.1928189992904663, Dice_loss: 0.017774203792214394, Consistency_loss: 0.0005690201069228351\n",
      "[Training] Epoch: 4 [=====>         ] 38.9% Loss: 0.2032, Epoch 4, Batch 48, CE_loss: 0.1953384280204773, Dice_loss: 0.01841505616903305, Consistency_loss: 2.2743010049453005e-05\n",
      "[Training] Epoch: 4 [=====>         ] 39.7% Loss: 0.2030, Epoch 4, Batch 49, CE_loss: 0.17784827947616577, Dice_loss: 0.015593406744301319, Consistency_loss: 0.000575886806473136\n",
      "[Training] Epoch: 4 [======>        ] 40.5% Loss: 0.2036, Epoch 4, Batch 50, CE_loss: 0.20938099920749664, Dice_loss: 0.020220709964632988, Consistency_loss: 0.0005958002875559032\n",
      "[Training] Epoch: 4 [======>        ] 41.3% Loss: 0.2035, Epoch 4, Batch 51, CE_loss: 0.18531674146652222, Dice_loss: 0.01684662513434887, Consistency_loss: 1.4335537343868054e-05\n",
      "[Training] Epoch: 4 [======>        ] 42.1% Loss: 0.2034, Epoch 4, Batch 52, CE_loss: 0.17897365987300873, Dice_loss: 0.015833161771297455, Consistency_loss: 0.0003575517039280385\n",
      "[Training] Epoch: 4 [======>        ] 42.9% Loss: 0.2034, Epoch 4, Batch 53, CE_loss: 0.18578220903873444, Dice_loss: 0.016926169395446777, Consistency_loss: 0.0003931287210434675\n",
      "[Training] Epoch: 4 [======>        ] 43.7% Loss: 0.2028, Epoch 4, Batch 54, CE_loss: 0.15819235146045685, Dice_loss: 0.012692365795373917, Consistency_loss: 0.0002095578092848882\n",
      "[Training] Epoch: 4 [======>        ] 44.4% Loss: 0.2031, Epoch 4, Batch 55, CE_loss: 0.20147615671157837, Dice_loss: 0.01901659369468689, Consistency_loss: 0.0003341936389915645\n",
      "[Training] Epoch: 4 [======>        ] 45.2% Loss: 0.2030, Epoch 4, Batch 56, CE_loss: 0.17990316450595856, Dice_loss: 0.015991929918527603, Consistency_loss: 0.00010795180423883721\n",
      "[Training] Epoch: 4 [======>        ] 46.0% Loss: 0.2025, Epoch 4, Batch 57, CE_loss: 0.162171870470047, Dice_loss: 0.013120017014443874, Consistency_loss: 6.451277386076981e-06\n",
      "[Training] Epoch: 4 [=======>       ] 46.8% Loss: 0.2021, Epoch 4, Batch 58, CE_loss: 0.16566240787506104, Dice_loss: 0.013381469994783401, Consistency_loss: 0.0003507098008412868\n",
      "[Training] Epoch: 4 [=======>       ] 47.6% Loss: 0.2019, Epoch 4, Batch 59, CE_loss: 0.17089486122131348, Dice_loss: 0.014385679736733437, Consistency_loss: 0.00042869901517406106\n",
      "[Training] Epoch: 4 [=======>       ] 48.4% Loss: 0.2015, Epoch 4, Batch 60, CE_loss: 0.16777417063713074, Dice_loss: 0.013872483745217323, Consistency_loss: 0.0005038133240304887\n",
      "[Training] Epoch: 4 [=======>       ] 49.2% Loss: 0.2015, Epoch 4, Batch 61, CE_loss: 0.1808794140815735, Dice_loss: 0.015751434490084648, Consistency_loss: 0.0004603792622219771\n",
      "[Training] Epoch: 4 [=======>       ] 50.0% Loss: 0.2008, Epoch 4, Batch 62, CE_loss: 0.1501273661851883, Dice_loss: 0.011141691356897354, Consistency_loss: 0.00022025863290764391\n",
      "[Training] Epoch: 4 [=======>       ] 50.8% Loss: 0.2011, Epoch 4, Batch 63, CE_loss: 0.20248958468437195, Dice_loss: 0.018993526697158813, Consistency_loss: 0.00019398103177081794\n",
      "[Training] Epoch: 4 [=======>       ] 51.6% Loss: 0.2009, Epoch 4, Batch 64, CE_loss: 0.16829340159893036, Dice_loss: 0.014174115844070911, Consistency_loss: 0.0003302970726508647\n",
      "[Training] Epoch: 4 [=======>       ] 52.4% Loss: 0.2004, Epoch 4, Batch 65, CE_loss: 0.15492109954357147, Dice_loss: 0.012095377780497074, Consistency_loss: 1.3652308552991599e-05\n",
      "[Training] Epoch: 4 [=======>       ] 53.2% Loss: 0.2002, Epoch 4, Batch 66, CE_loss: 0.17428359389305115, Dice_loss: 0.014944509603083134, Consistency_loss: 0.00025712777278386056\n",
      "[Training] Epoch: 4 [========>      ] 54.0% Loss: 0.2000, Epoch 4, Batch 67, CE_loss: 0.17215688526630402, Dice_loss: 0.014807519502937794, Consistency_loss: 0.00039506491157226264\n",
      "[Training] Epoch: 4 [========>      ] 54.8% Loss: 0.1994, Epoch 4, Batch 68, CE_loss: 0.14952543377876282, Dice_loss: 0.01118706539273262, Consistency_loss: 0.0002717653405852616\n",
      "[Training] Epoch: 4 [========>      ] 55.6% Loss: 0.1991, Epoch 4, Batch 69, CE_loss: 0.16472484171390533, Dice_loss: 0.01367094274610281, Consistency_loss: 2.8971484425710514e-05\n",
      "[Training] Epoch: 4 [========>      ] 56.3% Loss: 0.1990, Epoch 4, Batch 70, CE_loss: 0.17479290068149567, Dice_loss: 0.01527058519423008, Consistency_loss: 0.0009575376170687377\n",
      "[Training] Epoch: 4 [========>      ] 57.1% Loss: 0.1989, Epoch 4, Batch 71, CE_loss: 0.171896830201149, Dice_loss: 0.014674401842057705, Consistency_loss: 0.0008955455268733203\n",
      "[Training] Epoch: 4 [========>      ] 57.9% Loss: 0.1988, Epoch 4, Batch 72, CE_loss: 0.17700599133968353, Dice_loss: 0.015818042680621147, Consistency_loss: 2.0650350052164868e-05\n",
      "[Training] Epoch: 4 [========>      ] 58.7% Loss: 0.1984, Epoch 4, Batch 73, CE_loss: 0.15992309153079987, Dice_loss: 0.013150782324373722, Consistency_loss: 0.0003528508823364973\n",
      "[Training] Epoch: 4 [========>      ] 59.5% Loss: 0.1985, Epoch 4, Batch 74, CE_loss: 0.18248721957206726, Dice_loss: 0.016601113602519035, Consistency_loss: 0.0004690991772804409\n",
      "[Training] Epoch: 4 [=========>     ] 60.3% Loss: 0.1984, Epoch 4, Batch 75, CE_loss: 0.1774052530527115, Dice_loss: 0.015893815085291862, Consistency_loss: 0.0006870882934890687\n",
      "[Training] Epoch: 4 [=========>     ] 61.1% Loss: 0.1979, Epoch 4, Batch 76, CE_loss: 0.14795933663845062, Dice_loss: 0.011109450832009315, Consistency_loss: 0.000494351435918361\n",
      "[Training] Epoch: 4 [=========>     ] 61.9% Loss: 0.1974, Epoch 4, Batch 77, CE_loss: 0.14939014613628387, Dice_loss: 0.01161223091185093, Consistency_loss: 0.00042213601409457624\n",
      "[Training] Epoch: 4 [=========>     ] 62.7% Loss: 0.1973, Epoch 4, Batch 78, CE_loss: 0.17433717846870422, Dice_loss: 0.01522897556424141, Consistency_loss: 0.0002871364413294941\n",
      "[Training] Epoch: 4 [=========>     ] 63.5% Loss: 0.1971, Epoch 4, Batch 79, CE_loss: 0.16642780601978302, Dice_loss: 0.014202109538018703, Consistency_loss: 0.0003911358362529427\n",
      "[Training] Epoch: 4 [=========>     ] 64.3% Loss: 0.1966, Epoch 4, Batch 80, CE_loss: 0.14297592639923096, Dice_loss: 0.01050417497754097, Consistency_loss: 0.0004426076484378427\n",
      "[Training] Epoch: 4 [=========>     ] 65.1% Loss: 0.1963, Epoch 4, Batch 81, CE_loss: 0.16276562213897705, Dice_loss: 0.01359137985855341, Consistency_loss: 0.00045850840979255736\n",
      "[Training] Epoch: 4 [=========>     ] 65.9% Loss: 0.1959, Epoch 4, Batch 82, CE_loss: 0.14530856907367706, Dice_loss: 0.011259421706199646, Consistency_loss: 0.0006062426837161183\n",
      "[Training] Epoch: 4 [==========>    ] 66.7% Loss: 0.1955, Epoch 4, Batch 83, CE_loss: 0.15342113375663757, Dice_loss: 0.011862999759614468, Consistency_loss: 0.00046861713053658605\n",
      "[Training] Epoch: 4 [==========>    ] 67.5% Loss: 0.1951, Epoch 4, Batch 84, CE_loss: 0.14509935677051544, Dice_loss: 0.010994902811944485, Consistency_loss: 3.2233470847131684e-05\n",
      "[Training] Epoch: 4 [==========>    ] 68.3% Loss: 0.1950, Epoch 4, Batch 85, CE_loss: 0.1713591367006302, Dice_loss: 0.014816970564424992, Consistency_loss: 0.0002623662876430899\n",
      "[Training] Epoch: 4 [==========>    ] 69.0% Loss: 0.1947, Epoch 4, Batch 86, CE_loss: 0.155891552567482, Dice_loss: 0.012630772776901722, Consistency_loss: 0.0004672428185585886\n",
      "[Training] Epoch: 4 [==========>    ] 69.8% Loss: 0.1944, Epoch 4, Batch 87, CE_loss: 0.15706117451190948, Dice_loss: 0.012653536163270473, Consistency_loss: 1.589563544257544e-05\n",
      "[Training] Epoch: 4 [==========>    ] 70.6% Loss: 0.1941, Epoch 4, Batch 88, CE_loss: 0.15593357384204865, Dice_loss: 0.012635413557291031, Consistency_loss: 0.00035875008325092494\n",
      "[Training] Epoch: 4 [==========>    ] 71.4% Loss: 0.1941, Epoch 4, Batch 89, CE_loss: 0.17570625245571136, Dice_loss: 0.015309611335396767, Consistency_loss: 0.0003149044350720942\n",
      "[Training] Epoch: 4 [==========>    ] 72.2% Loss: 0.1938, Epoch 4, Batch 90, CE_loss: 0.1559387892484665, Dice_loss: 0.012802774086594582, Consistency_loss: 0.000328230787999928\n",
      "[Training] Epoch: 4 [==========>    ] 73.0% Loss: 0.1935, Epoch 4, Batch 91, CE_loss: 0.15436848998069763, Dice_loss: 0.012554776854813099, Consistency_loss: 0.00044349502422846854\n",
      "[Training] Epoch: 4 [===========>   ] 73.8% Loss: 0.1935, Epoch 4, Batch 92, CE_loss: 0.1810249388217926, Dice_loss: 0.016291219741106033, Consistency_loss: 0.0003670373116619885\n",
      "[Training] Epoch: 4 [===========>   ] 74.6% Loss: 0.1935, Epoch 4, Batch 93, CE_loss: 0.17291004955768585, Dice_loss: 0.015265006572008133, Consistency_loss: 2.7819900424219668e-05\n",
      "[Training] Epoch: 4 [===========>   ] 75.4% Loss: 0.1930, Epoch 4, Batch 94, CE_loss: 0.13704924285411835, Dice_loss: 0.009958479553461075, Consistency_loss: 0.0005921970005147159\n",
      "[Training] Epoch: 4 [===========>   ] 76.2% Loss: 0.1928, Epoch 4, Batch 95, CE_loss: 0.15648551285266876, Dice_loss: 0.01283760741353035, Consistency_loss: 3.230993388569914e-05\n",
      "[Training] Epoch: 4 [===========>   ] 77.0% Loss: 0.1925, Epoch 4, Batch 96, CE_loss: 0.1573232263326645, Dice_loss: 0.013154510408639908, Consistency_loss: 0.0005180839798413217\n",
      "[Training] Epoch: 4 [===========>   ] 77.8% Loss: 0.1922, Epoch 4, Batch 97, CE_loss: 0.14512720704078674, Dice_loss: 0.011371592059731483, Consistency_loss: 5.128687553224154e-05\n",
      "[Training] Epoch: 4 [===========>   ] 78.6% Loss: 0.1920, Epoch 4, Batch 98, CE_loss: 0.15817709267139435, Dice_loss: 0.01321137323975563, Consistency_loss: 2.290524571435526e-05\n",
      "[Training] Epoch: 4 [===========>   ] 79.4% Loss: 0.1918, Epoch 4, Batch 99, CE_loss: 0.16040511429309845, Dice_loss: 0.013541803695261478, Consistency_loss: 0.0004491202998906374\n",
      "[Training] Epoch: 4 [============>  ] 80.2% Loss: 0.1917, Epoch 4, Batch 100, CE_loss: 0.16738183796405792, Dice_loss: 0.014638853259384632, Consistency_loss: 0.00032246726914308965\n",
      "[Training] Epoch: 4 [============>  ] 81.0% Loss: 0.1914, Epoch 4, Batch 101, CE_loss: 0.15473997592926025, Dice_loss: 0.012678408995270729, Consistency_loss: 1.6820378732518293e-05\n",
      "[Training] Epoch: 4 [============>  ] 81.7% Loss: 0.1910, Epoch 4, Batch 102, CE_loss: 0.13395516574382782, Dice_loss: 0.00951110478490591, Consistency_loss: 0.00011443521361798048\n",
      "[Training] Epoch: 4 [============>  ] 82.5% Loss: 0.1909, Epoch 4, Batch 103, CE_loss: 0.1661633849143982, Dice_loss: 0.014321262016892433, Consistency_loss: 0.00011839241778943688\n",
      "[Training] Epoch: 4 [============>  ] 83.3% Loss: 0.1907, Epoch 4, Batch 104, CE_loss: 0.15521471202373505, Dice_loss: 0.012631935067474842, Consistency_loss: 0.0004976913915015757\n",
      "[Training] Epoch: 4 [============>  ] 84.1% Loss: 0.1902, Epoch 4, Batch 105, CE_loss: 0.1352739930152893, Dice_loss: 0.009812146425247192, Consistency_loss: 0.00034590280847623944\n",
      "[Training] Epoch: 4 [============>  ] 84.9% Loss: 0.1902, Epoch 4, Batch 106, CE_loss: 0.17119577527046204, Dice_loss: 0.014837623573839664, Consistency_loss: 0.00033126171911135316\n",
      "[Training] Epoch: 4 [============>  ] 85.7% Loss: 0.1898, Epoch 4, Batch 107, CE_loss: 0.13738851249217987, Dice_loss: 0.010328803211450577, Consistency_loss: 0.0003100596077274531\n",
      "[Training] Epoch: 4 [============>  ] 86.5% Loss: 0.1896, Epoch 4, Batch 108, CE_loss: 0.15617124736309052, Dice_loss: 0.013066158629953861, Consistency_loss: 0.00023791116836946458\n",
      "[Training] Epoch: 4 [=============> ] 87.3% Loss: 0.1893, Epoch 4, Batch 109, CE_loss: 0.1390201598405838, Dice_loss: 0.010308471508324146, Consistency_loss: 0.0001858466275734827\n",
      "[Training] Epoch: 4 [=============> ] 88.1% Loss: 0.1889, Epoch 4, Batch 110, CE_loss: 0.14326520264148712, Dice_loss: 0.010780531913042068, Consistency_loss: 0.0003440601867623627\n",
      "[Training] Epoch: 4 [=============> ] 88.9% Loss: 0.1885, Epoch 4, Batch 111, CE_loss: 0.13420259952545166, Dice_loss: 0.009823438711464405, Consistency_loss: 2.1213680156506598e-05\n",
      "[Training] Epoch: 4 [=============> ] 89.7% Loss: 0.1882, Epoch 4, Batch 112, CE_loss: 0.1356705129146576, Dice_loss: 0.00986739993095398, Consistency_loss: 0.00030845237779431045\n",
      "[Training] Epoch: 4 [=============> ] 90.5% Loss: 0.1880, Epoch 4, Batch 113, CE_loss: 0.15742886066436768, Dice_loss: 0.013309184461832047, Consistency_loss: 0.00020749078248627484\n",
      "[Training] Epoch: 4 [=============> ] 91.3% Loss: 0.1879, Epoch 4, Batch 114, CE_loss: 0.15648400783538818, Dice_loss: 0.01277926005423069, Consistency_loss: 0.00022582952806260437\n",
      "[Training] Epoch: 4 [=============> ] 92.1% Loss: 0.1875, Epoch 4, Batch 115, CE_loss: 0.13526158034801483, Dice_loss: 0.010037881322205067, Consistency_loss: 0.00016538408817723393\n",
      "[Training] Epoch: 4 [=============> ] 92.9% Loss: 0.1872, Epoch 4, Batch 116, CE_loss: 0.14669378101825714, Dice_loss: 0.011676845140755177, Consistency_loss: 0.00029024455579929054\n",
      "[Training] Epoch: 4 [==============>] 93.7% Loss: 0.1871, Epoch 4, Batch 117, CE_loss: 0.1594010889530182, Dice_loss: 0.013541419059038162, Consistency_loss: 9.808350114326458e-06\n",
      "[Training] Epoch: 4 [==============>] 94.4% Loss: 0.1868, Epoch 4, Batch 118, CE_loss: 0.1380518525838852, Dice_loss: 0.01044323481619358, Consistency_loss: 0.000219359717448242\n",
      "[Training] Epoch: 4 [==============>] 95.2% Loss: 0.1865, Epoch 4, Batch 119, CE_loss: 0.14106017351150513, Dice_loss: 0.010559428483247757, Consistency_loss: 0.00010744992323452607\n",
      "[Training] Epoch: 4 [==============>] 96.0% Loss: 0.1864, Epoch 4, Batch 120, CE_loss: 0.1583733707666397, Dice_loss: 0.013357133604586124, Consistency_loss: 0.0002675061987247318\n",
      "[Training] Epoch: 4 [==============>] 96.8% Loss: 0.1860, Epoch 4, Batch 121, CE_loss: 0.13405829668045044, Dice_loss: 0.009809393435716629, Consistency_loss: 1.392723061144352e-05\n",
      "[Training] Epoch: 4 [==============>] 97.6% Loss: 0.1859, Epoch 4, Batch 122, CE_loss: 0.1535888910293579, Dice_loss: 0.01275535300374031, Consistency_loss: 0.00014318316243588924\n",
      "[Training] Epoch: 4 [==============>] 98.4% Loss: 0.1858, Epoch 4, Batch 123, CE_loss: 0.15897230803966522, Dice_loss: 0.013569341041147709, Consistency_loss: 0.00047586261644028127\n",
      "[Training] Epoch: 4 [==============>] 99.2% Loss: 0.1855, Epoch 4, Batch 124, CE_loss: 0.1439216136932373, Dice_loss: 0.011447185650467873, Consistency_loss: 0.000689301872625947\n",
      "[Training] Epoch: 4 [DONE]                                 \n",
      "Epoch 4, Batch 125, CE_loss: 0.14466255903244019, Dice_loss: 0.011563834734261036, Consistency_loss: 0.00041198061080649495\n",
      "Epoch 4, Batch 125, CE_loss: 0.14466255903244019, Dice_loss: 0.011563834734261036, Consistency_loss: 0.00041198061080649495\n",
      "[Validation] Epoch: 4 [DONE]                                 \n",
      "[Epoch: 4, TrainLoss: 0.1853, TrainDice: 0.0145, ValLoss: 0.2284                                             \n",
      "Number of batches:  126\n",
      "[Training] Epoch: 5 [>              ] 0.8% Loss: 0.1643, Epoch 5, Batch 0, CE_loss: 0.15141209959983826, Dice_loss: 0.012695137411355972, Consistency_loss: 0.00023185151803772897\n",
      "[Training] Epoch: 5 [>              ] 1.6% Loss: 0.1630, Epoch 5, Batch 1, CE_loss: 0.14948640763759613, Dice_loss: 0.011942241340875626, Consistency_loss: 0.00029456205083988607\n",
      "[Training] Epoch: 5 [>              ] 2.4% Loss: 0.1522, Epoch 5, Batch 2, CE_loss: 0.12213517725467682, Dice_loss: 0.00800102949142456, Consistency_loss: 0.0003054140543099493\n",
      "[Training] Epoch: 5 [>              ] 3.2% Loss: 0.1647, Epoch 5, Batch 3, CE_loss: 0.18472406268119812, Dice_loss: 0.017403729259967804, Consistency_loss: 0.00026863397215493023\n",
      "[Training] Epoch: 5 [>              ] 4.0% Loss: 0.1702, Epoch 5, Batch 4, CE_loss: 0.1763182282447815, Dice_loss: 0.015747839584946632, Consistency_loss: 1.9931194401578978e-05\n",
      "[Training] Epoch: 5 [>              ] 4.8% Loss: 0.1718, Epoch 5, Batch 5, CE_loss: 0.16540731489658356, Dice_loss: 0.01464225072413683, Consistency_loss: 1.4478107914328575e-05\n",
      "[Training] Epoch: 5 [>              ] 5.6% Loss: 0.1698, Epoch 5, Batch 6, CE_loss: 0.1455846130847931, Dice_loss: 0.011706304736435413, Consistency_loss: 1.4257515431381762e-05\n",
      "[Training] Epoch: 5 [>              ] 6.3% Loss: 0.1711, Epoch 5, Batch 7, CE_loss: 0.16520115733146667, Dice_loss: 0.014478967525064945, Consistency_loss: 0.0004750641237478703\n",
      "[Training] Epoch: 5 [=>             ] 7.1% Loss: 0.1699, Epoch 5, Batch 8, CE_loss: 0.1483195722103119, Dice_loss: 0.012307128868997097, Consistency_loss: 0.0003573412250261754\n",
      "[Training] Epoch: 5 [=>             ] 7.9% Loss: 0.1711, Epoch 5, Batch 9, CE_loss: 0.16640357673168182, Dice_loss: 0.014765927568078041, Consistency_loss: 0.0003024366742465645\n",
      "[Training] Epoch: 5 [=>             ] 8.7% Loss: 0.1692, Epoch 5, Batch 10, CE_loss: 0.13912300765514374, Dice_loss: 0.010918298736214638, Consistency_loss: 0.0004764484183397144\n",
      "[Training] Epoch: 5 [=>             ] 9.5% Loss: 0.1698, Epoch 5, Batch 11, CE_loss: 0.16109181940555573, Dice_loss: 0.014087882824242115, Consistency_loss: 0.00039555877447128296\n",
      "[Training] Epoch: 5 [=>             ] 10.3% Loss: 0.1693, Epoch 5, Batch 12, CE_loss: 0.1507948637008667, Dice_loss: 0.012263900600373745, Consistency_loss: 0.0003598577459342778\n",
      "[Training] Epoch: 5 [=>             ] 11.1% Loss: 0.1680, Epoch 5, Batch 13, CE_loss: 0.14058874547481537, Dice_loss: 0.011063987389206886, Consistency_loss: 0.0005201950552873313\n",
      "[Training] Epoch: 5 [=>             ] 11.9% Loss: 0.1674, Epoch 5, Batch 14, CE_loss: 0.1456718146800995, Dice_loss: 0.011888069100677967, Consistency_loss: 0.00028062303317710757\n",
      "[Training] Epoch: 5 [=>             ] 12.7% Loss: 0.1668, Epoch 5, Batch 15, CE_loss: 0.14620564877986908, Dice_loss: 0.011818376369774342, Consistency_loss: 0.00017671134264674038\n",
      "[Training] Epoch: 5 [==>            ] 13.5% Loss: 0.1656, Epoch 5, Batch 16, CE_loss: 0.13573037087917328, Dice_loss: 0.01046597957611084, Consistency_loss: 0.0004660457489080727\n",
      "[Training] Epoch: 5 [==>            ] 14.3% Loss: 0.1636, Epoch 5, Batch 17, CE_loss: 0.12155715376138687, Dice_loss: 0.008284226059913635, Consistency_loss: 0.00045416373177431524\n",
      "[Training] Epoch: 5 [==>            ] 15.1% Loss: 0.1631, Epoch 5, Batch 18, CE_loss: 0.14111004769802094, Dice_loss: 0.011127922683954239, Consistency_loss: 0.00028571454458869994\n",
      "[Training] Epoch: 5 [==>            ] 15.9% Loss: 0.1619, Epoch 5, Batch 19, CE_loss: 0.12958931922912598, Dice_loss: 0.009488314390182495, Consistency_loss: 0.0003700027009472251\n",
      "[Training] Epoch: 5 [==>            ] 16.7% Loss: 0.1630, Epoch 5, Batch 20, CE_loss: 0.17086908221244812, Dice_loss: 0.015250969678163528, Consistency_loss: 0.0001562605466460809\n",
      "[Training] Epoch: 5 [==>            ] 17.5% Loss: 0.1632, Epoch 5, Batch 21, CE_loss: 0.1532861292362213, Dice_loss: 0.012732581235468388, Consistency_loss: 1.2168638022558298e-05\n",
      "[Training] Epoch: 5 [==>            ] 18.3% Loss: 0.1631, Epoch 5, Batch 22, CE_loss: 0.1484133005142212, Dice_loss: 0.012298071756958961, Consistency_loss: 0.00018498225836083293\n",
      "[Training] Epoch: 5 [==>            ] 19.0% Loss: 0.1630, Epoch 5, Batch 23, CE_loss: 0.14823076128959656, Dice_loss: 0.011965897865593433, Consistency_loss: 0.0004323728790041059\n",
      "[Training] Epoch: 5 [==>            ] 19.8% Loss: 0.1620, Epoch 5, Batch 24, CE_loss: 0.13030780851840973, Dice_loss: 0.009461591020226479, Consistency_loss: 1.0137811841559596e-05\n",
      "[Training] Epoch: 5 [===>           ] 20.6% Loss: 0.1616, Epoch 5, Batch 25, CE_loss: 0.13843677937984467, Dice_loss: 0.010627207346260548, Consistency_loss: 0.00024906385806389153\n",
      "[Training] Epoch: 5 [===>           ] 21.4% Loss: 0.1610, Epoch 5, Batch 26, CE_loss: 0.1357293576002121, Dice_loss: 0.010534510016441345, Consistency_loss: 0.00025101506616920233\n",
      "[Training] Epoch: 5 [===>           ] 22.2% Loss: 0.1600, Epoch 5, Batch 27, CE_loss: 0.1240328848361969, Dice_loss: 0.008626413531601429, Consistency_loss: 0.00022289487242233008\n",
      "[Training] Epoch: 5 [===>           ] 23.0% Loss: 0.1596, Epoch 5, Batch 28, CE_loss: 0.13870951533317566, Dice_loss: 0.010994553565979004, Consistency_loss: 0.0001876536844065413\n",
      "[Training] Epoch: 5 [===>           ] 23.8% Loss: 0.1593, Epoch 5, Batch 29, CE_loss: 0.13822023570537567, Dice_loss: 0.010779226198792458, Consistency_loss: 2.219478483311832e-05\n",
      "[Training] Epoch: 5 [===>           ] 24.6% Loss: 0.1589, Epoch 5, Batch 30, CE_loss: 0.136891707777977, Dice_loss: 0.010816875845193863, Consistency_loss: 0.00040607876144349575\n",
      "[Training] Epoch: 5 [===>           ] 25.4% Loss: 0.1588, Epoch 5, Batch 31, CE_loss: 0.1414797604084015, Dice_loss: 0.011475992389023304, Consistency_loss: 0.0002919569087680429\n",
      "[Training] Epoch: 5 [===>           ] 26.2% Loss: 0.1591, Epoch 5, Batch 32, CE_loss: 0.15771321952342987, Dice_loss: 0.013514847494661808, Consistency_loss: 1.4051957805349957e-05\n",
      "[Training] Epoch: 5 [====>          ] 27.0% Loss: 0.1582, Epoch 5, Batch 33, CE_loss: 0.11986123770475388, Dice_loss: 0.008172995410859585, Consistency_loss: 0.0003978545719292015\n",
      "[Training] Epoch: 5 [====>          ] 27.8% Loss: 0.1575, Epoch 5, Batch 34, CE_loss: 0.12473364919424057, Dice_loss: 0.008865497075021267, Consistency_loss: 0.0005014000344090164\n",
      "[Training] Epoch: 5 [====>          ] 28.6% Loss: 0.1573, Epoch 5, Batch 35, CE_loss: 0.13816025853157043, Dice_loss: 0.010828712955117226, Consistency_loss: 0.0003322868433315307\n",
      "[Training] Epoch: 5 [====>          ] 29.4% Loss: 0.1570, Epoch 5, Batch 36, CE_loss: 0.1362072378396988, Dice_loss: 0.010223686695098877, Consistency_loss: 0.00035303932963870466\n",
      "[Training] Epoch: 5 [====>          ] 30.2% Loss: 0.1570, Epoch 5, Batch 37, CE_loss: 0.14359648525714874, Dice_loss: 0.011860049329698086, Consistency_loss: 0.00037425695336423814\n",
      "[Training] Epoch: 5 [====>          ] 31.0% Loss: 0.1570, Epoch 5, Batch 38, CE_loss: 0.14300435781478882, Dice_loss: 0.011769757606089115, Consistency_loss: 0.00047520306543447077\n",
      "[Training] Epoch: 5 [====>          ] 31.7% Loss: 0.1566, Epoch 5, Batch 39, CE_loss: 0.13165821135044098, Dice_loss: 0.010139644145965576, Consistency_loss: 1.7162883523269556e-05\n",
      "[Training] Epoch: 5 [====>          ] 32.5% Loss: 0.1558, Epoch 5, Batch 40, CE_loss: 0.11817967891693115, Dice_loss: 0.007966527715325356, Consistency_loss: 0.0003025780024472624\n",
      "[Training] Epoch: 5 [=====>         ] 33.3% Loss: 0.1560, Epoch 5, Batch 41, CE_loss: 0.14943315088748932, Dice_loss: 0.012431458570063114, Consistency_loss: 0.00027982491883449256\n",
      "[Training] Epoch: 5 [=====>         ] 34.1% Loss: 0.1558, Epoch 5, Batch 42, CE_loss: 0.13517746329307556, Dice_loss: 0.01071098167449236, Consistency_loss: 0.00028950683190487325\n",
      "[Training] Epoch: 5 [=====>         ] 34.9% Loss: 0.1569, Epoch 5, Batch 43, CE_loss: 0.18808043003082275, Dice_loss: 0.01760299876332283, Consistency_loss: 0.0002299771149409935\n",
      "[Training] Epoch: 5 [=====>         ] 35.7% Loss: 0.1561, Epoch 5, Batch 44, CE_loss: 0.11500612646341324, Dice_loss: 0.007750511635094881, Consistency_loss: 2.641246646817308e-05\n",
      "[Training] Epoch: 5 [=====>         ] 36.5% Loss: 0.1562, Epoch 5, Batch 45, CE_loss: 0.14751876890659332, Dice_loss: 0.01235251221805811, Consistency_loss: 0.0005543243605643511\n",
      "[Training] Epoch: 5 [=====>         ] 37.3% Loss: 0.1562, Epoch 5, Batch 46, CE_loss: 0.14382223784923553, Dice_loss: 0.011714771389961243, Consistency_loss: 0.0004025468078907579\n",
      "[Training] Epoch: 5 [=====>         ] 38.1% Loss: 0.1565, Epoch 5, Batch 47, CE_loss: 0.15327942371368408, Dice_loss: 0.01336895301938057, Consistency_loss: 0.00043779058614745736\n",
      "[Training] Epoch: 5 [=====>         ] 38.9% Loss: 0.1563, Epoch 5, Batch 48, CE_loss: 0.13961154222488403, Dice_loss: 0.011311081238090992, Consistency_loss: 2.9926217393949628e-05\n",
      "[Training] Epoch: 5 [=====>         ] 39.7% Loss: 0.1562, Epoch 5, Batch 49, CE_loss: 0.1369844377040863, Dice_loss: 0.01106482744216919, Consistency_loss: 0.0004614188801497221\n",
      "[Training] Epoch: 5 [======>        ] 40.5% Loss: 0.1562, Epoch 5, Batch 50, CE_loss: 0.14241643249988556, Dice_loss: 0.011873281560838223, Consistency_loss: 2.667316402948927e-05\n",
      "[Training] Epoch: 5 [======>        ] 41.3% Loss: 0.1560, Epoch 5, Batch 51, CE_loss: 0.13851425051689148, Dice_loss: 0.011341908946633339, Consistency_loss: 0.0006153451977297664\n",
      "[Training] Epoch: 5 [======>        ] 42.1% Loss: 0.1561, Epoch 5, Batch 52, CE_loss: 0.14878137409687042, Dice_loss: 0.012900701723992825, Consistency_loss: 1.4752624338143505e-05\n",
      "[Training] Epoch: 5 [======>        ] 42.9% Loss: 0.1558, Epoch 5, Batch 53, CE_loss: 0.12839321792125702, Dice_loss: 0.009801561012864113, Consistency_loss: 1.759352562658023e-05\n",
      "[Training] Epoch: 5 [======>        ] 43.7% Loss: 0.1559, Epoch 5, Batch 54, CE_loss: 0.1458999514579773, Dice_loss: 0.01233369205147028, Consistency_loss: 0.00022254337090998888\n",
      "[Training] Epoch: 5 [======>        ] 44.4% Loss: 0.1558, Epoch 5, Batch 55, CE_loss: 0.14095012843608856, Dice_loss: 0.01166313886642456, Consistency_loss: 0.00013728930207435042\n",
      "[Training] Epoch: 5 [======>        ] 45.2% Loss: 0.1557, Epoch 5, Batch 56, CE_loss: 0.14016523957252502, Dice_loss: 0.011669754981994629, Consistency_loss: 0.0002838695072568953\n",
      "[Training] Epoch: 5 [======>        ] 46.0% Loss: 0.1557, Epoch 5, Batch 57, CE_loss: 0.14156825840473175, Dice_loss: 0.011878636665642262, Consistency_loss: 0.0002181615273002535\n",
      "[Training] Epoch: 5 [=======>       ] 46.8% Loss: 0.1557, Epoch 5, Batch 58, CE_loss: 0.14398708939552307, Dice_loss: 0.012260270304977894, Consistency_loss: 4.518530477071181e-05\n",
      "[Training] Epoch: 5 [=======>       ] 47.6% Loss: 0.1553, Epoch 5, Batch 59, CE_loss: 0.1200285330414772, Dice_loss: 0.008653244934976101, Consistency_loss: 0.0005802868399769068\n",
      "[Training] Epoch: 5 [=======>       ] 48.4% Loss: 0.1549, Epoch 5, Batch 60, CE_loss: 0.12492232024669647, Dice_loss: 0.00954245962202549, Consistency_loss: 0.0006830590427853167\n",
      "[Training] Epoch: 5 [=======>       ] 49.2% Loss: 0.1546, Epoch 5, Batch 61, CE_loss: 0.12482301145792007, Dice_loss: 0.009406346827745438, Consistency_loss: 0.00042118559940718114\n",
      "[Training] Epoch: 5 [=======>       ] 50.0% Loss: 0.1544, Epoch 5, Batch 62, CE_loss: 0.13140712678432465, Dice_loss: 0.01025585550814867, Consistency_loss: 0.0005105898599140346\n",
      "[Training] Epoch: 5 [=======>       ] 50.8% Loss: 0.1545, Epoch 5, Batch 63, CE_loss: 0.1453695297241211, Dice_loss: 0.012148682028055191, Consistency_loss: 0.0004594852216541767\n",
      "[Training] Epoch: 5 [=======>       ] 51.6% Loss: 0.1551, Epoch 5, Batch 64, CE_loss: 0.17819124460220337, Dice_loss: 0.016791246831417084, Consistency_loss: 0.000416843278799206\n",
      "[Training] Epoch: 5 [=======>       ] 52.4% Loss: 0.1549, Epoch 5, Batch 65, CE_loss: 0.13136495649814606, Dice_loss: 0.010515815578401089, Consistency_loss: 0.00039649225072935224\n",
      "[Training] Epoch: 5 [=======>       ] 53.2% Loss: 0.1545, Epoch 5, Batch 66, CE_loss: 0.11759740114212036, Dice_loss: 0.008355922065675259, Consistency_loss: 0.00022356165573000908\n",
      "[Training] Epoch: 5 [========>      ] 54.0% Loss: 0.1541, Epoch 5, Batch 67, CE_loss: 0.12093675881624222, Dice_loss: 0.008337656036019325, Consistency_loss: 0.00021070009097456932\n",
      "[Training] Epoch: 5 [========>      ] 54.8% Loss: 0.1541, Epoch 5, Batch 68, CE_loss: 0.14094801247119904, Dice_loss: 0.011641968041658401, Consistency_loss: 1.9804736439255066e-05\n",
      "[Training] Epoch: 5 [========>      ] 55.6% Loss: 0.1536, Epoch 5, Batch 69, CE_loss: 0.11237842589616776, Dice_loss: 0.007442844100296497, Consistency_loss: 0.00027087723719887435\n",
      "[Training] Epoch: 5 [========>      ] 56.3% Loss: 0.1533, Epoch 5, Batch 70, CE_loss: 0.12207161635160446, Dice_loss: 0.008679870516061783, Consistency_loss: 0.0006845970056019723\n",
      "[Training] Epoch: 5 [========>      ] 57.1% Loss: 0.1532, Epoch 5, Batch 71, CE_loss: 0.13320927321910858, Dice_loss: 0.010614681988954544, Consistency_loss: 0.000594341370742768\n",
      "[Training] Epoch: 5 [========>      ] 57.9% Loss: 0.1529, Epoch 5, Batch 72, CE_loss: 0.12190484255552292, Dice_loss: 0.008822894655168056, Consistency_loss: 2.7520527510205284e-05\n",
      "[Training] Epoch: 5 [========>      ] 58.7% Loss: 0.1528, Epoch 5, Batch 73, CE_loss: 0.134561687707901, Dice_loss: 0.010485452599823475, Consistency_loss: 0.0003597171453293413\n",
      "[Training] Epoch: 5 [========>      ] 59.5% Loss: 0.1525, Epoch 5, Batch 74, CE_loss: 0.12221191823482513, Dice_loss: 0.009262517094612122, Consistency_loss: 0.0005332108121365309\n",
      "[Training] Epoch: 5 [=========>     ] 60.3% Loss: 0.1520, Epoch 5, Batch 75, CE_loss: 0.11077485233545303, Dice_loss: 0.007384470198303461, Consistency_loss: 0.0006307916482910514\n",
      "[Training] Epoch: 5 [=========>     ] 61.1% Loss: 0.1519, Epoch 5, Batch 76, CE_loss: 0.1319761723279953, Dice_loss: 0.01041904091835022, Consistency_loss: 0.0006872373051010072\n",
      "[Training] Epoch: 5 [=========>     ] 61.9% Loss: 0.1523, Epoch 5, Batch 77, CE_loss: 0.16350942850112915, Dice_loss: 0.015221143141388893, Consistency_loss: 0.00043720463872887194\n",
      "[Training] Epoch: 5 [=========>     ] 62.7% Loss: 0.1526, Epoch 5, Batch 78, CE_loss: 0.1634264439344406, Dice_loss: 0.014733857475221157, Consistency_loss: 0.0005256648291833699\n",
      "[Training] Epoch: 5 [=========>     ] 63.5% Loss: 0.1531, Epoch 5, Batch 79, CE_loss: 0.17232953011989594, Dice_loss: 0.01616545021533966, Consistency_loss: 0.00040273173362948\n",
      "[Training] Epoch: 5 [=========>     ] 64.3% Loss: 0.1530, Epoch 5, Batch 80, CE_loss: 0.13459263741970062, Dice_loss: 0.011043182574212551, Consistency_loss: 0.000678614538628608\n",
      "[Training] Epoch: 5 [=========>     ] 65.1% Loss: 0.1527, Epoch 5, Batch 81, CE_loss: 0.12219926714897156, Dice_loss: 0.009320846758782864, Consistency_loss: 0.0010354382684454322\n",
      "[Training] Epoch: 5 [=========>     ] 65.9% Loss: 0.1525, Epoch 5, Batch 82, CE_loss: 0.12666158378124237, Dice_loss: 0.009843993932008743, Consistency_loss: 0.0008499498362652957\n",
      "[Training] Epoch: 5 [==========>    ] 66.7% Loss: 0.1525, Epoch 5, Batch 83, CE_loss: 0.13966955244541168, Dice_loss: 0.011877563782036304, Consistency_loss: 0.0005413994658738375\n",
      "[Training] Epoch: 5 [==========>    ] 67.5% Loss: 0.1525, Epoch 5, Batch 84, CE_loss: 0.13497693836688995, Dice_loss: 0.011310231871902943, Consistency_loss: 2.868387491616886e-05\n",
      "[Training] Epoch: 5 [==========>    ] 68.3% Loss: 0.1526, Epoch 5, Batch 85, CE_loss: 0.1476307064294815, Dice_loss: 0.012975070625543594, Consistency_loss: 0.0008050310425460339\n",
      "[Training] Epoch: 5 [==========>    ] 69.0% Loss: 0.1524, Epoch 5, Batch 86, CE_loss: 0.1265363097190857, Dice_loss: 0.010001197457313538, Consistency_loss: 0.0007417475571855903\n",
      "[Training] Epoch: 5 [==========>    ] 69.8% Loss: 0.1522, Epoch 5, Batch 87, CE_loss: 0.12654583156108856, Dice_loss: 0.009906256571412086, Consistency_loss: 0.00026142693241126835\n",
      "[Training] Epoch: 5 [==========>    ] 70.6% Loss: 0.1521, Epoch 5, Batch 88, CE_loss: 0.13446158170700073, Dice_loss: 0.010855088010430336, Consistency_loss: 0.00036623291089199483\n",
      "[Training] Epoch: 5 [==========>    ] 71.4% Loss: 0.1520, Epoch 5, Batch 89, CE_loss: 0.12999297678470612, Dice_loss: 0.010318663902580738, Consistency_loss: 0.00020228417997714132\n",
      "[Training] Epoch: 5 [==========>    ] 72.2% Loss: 0.1518, Epoch 5, Batch 90, CE_loss: 0.1265610158443451, Dice_loss: 0.009620476514101028, Consistency_loss: 0.0003208077687304467\n",
      "[Training] Epoch: 5 [==========>    ] 73.0% Loss: 0.1515, Epoch 5, Batch 91, CE_loss: 0.11300098150968552, Dice_loss: 0.008004928007721901, Consistency_loss: 0.00036867448943667114\n",
      "[Training] Epoch: 5 [===========>   ] 73.8% Loss: 0.1516, Epoch 5, Batch 92, CE_loss: 0.14305676519870758, Dice_loss: 0.011867756024003029, Consistency_loss: 1.2172078641015105e-05\n",
      "[Training] Epoch: 5 [===========>   ] 74.6% Loss: 0.1514, Epoch 5, Batch 93, CE_loss: 0.12504492700099945, Dice_loss: 0.009411451406776905, Consistency_loss: 0.00021809509780723602\n",
      "[Training] Epoch: 5 [===========>   ] 75.4% Loss: 0.1513, Epoch 5, Batch 94, CE_loss: 0.12940168380737305, Dice_loss: 0.010092535987496376, Consistency_loss: 0.0002976208634208888\n",
      "[Training] Epoch: 5 [===========>   ] 76.2% Loss: 0.1513, Epoch 5, Batch 95, CE_loss: 0.1417488306760788, Dice_loss: 0.012121502310037613, Consistency_loss: 2.0977799067622982e-05\n",
      "[Training] Epoch: 5 [===========>   ] 77.0% Loss: 0.1512, Epoch 5, Batch 96, CE_loss: 0.1313190460205078, Dice_loss: 0.010540053248405457, Consistency_loss: 0.0002772541774902493\n",
      "[Training] Epoch: 5 [===========>   ] 77.8% Loss: 0.1511, Epoch 5, Batch 97, CE_loss: 0.1328982710838318, Dice_loss: 0.010786530561745167, Consistency_loss: 0.00034833583049476147\n",
      "[Training] Epoch: 5 [===========>   ] 78.6% Loss: 0.1509, Epoch 5, Batch 98, CE_loss: 0.1251426786184311, Dice_loss: 0.00955561175942421, Consistency_loss: 2.7515521651366726e-05\n",
      "[Training] Epoch: 5 [===========>   ] 79.4% Loss: 0.1506, Epoch 5, Batch 99, CE_loss: 0.10873110592365265, Dice_loss: 0.007408762350678444, Consistency_loss: 2.9526001526392065e-05\n",
      "[Training] Epoch: 5 [============>  ] 80.2% Loss: 0.1502, Epoch 5, Batch 100, CE_loss: 0.10647718608379364, Dice_loss: 0.007190814707428217, Consistency_loss: 0.00036422896664589643\n",
      "[Training] Epoch: 5 [============>  ] 81.0% Loss: 0.1499, Epoch 5, Batch 101, CE_loss: 0.10413303226232529, Dice_loss: 0.006706524174660444, Consistency_loss: 0.0003812827344518155\n",
      "[Training] Epoch: 5 [============>  ] 81.7% Loss: 0.1497, Epoch 5, Batch 102, CE_loss: 0.12147369980812073, Dice_loss: 0.009356627240777016, Consistency_loss: 0.00014011500752530992\n",
      "[Training] Epoch: 5 [============>  ] 82.5% Loss: 0.1496, Epoch 5, Batch 103, CE_loss: 0.13538052141666412, Dice_loss: 0.011598596349358559, Consistency_loss: 0.00038477638736367226\n",
      "[Training] Epoch: 5 [============>  ] 83.3% Loss: 0.1496, Epoch 5, Batch 104, CE_loss: 0.13606879115104675, Dice_loss: 0.011059660464525223, Consistency_loss: 0.0006267350981943309\n",
      "[Training] Epoch: 5 [============>  ] 84.1% Loss: 0.1494, Epoch 5, Batch 105, CE_loss: 0.11209294199943542, Dice_loss: 0.007918864488601685, Consistency_loss: 0.0006432629306800663\n",
      "[Training] Epoch: 5 [============>  ] 84.9% Loss: 0.1491, Epoch 5, Batch 106, CE_loss: 0.11709435284137726, Dice_loss: 0.008872381411492825, Consistency_loss: 0.0005992020596750081\n",
      "[Training] Epoch: 5 [============>  ] 85.7% Loss: 0.1490, Epoch 5, Batch 107, CE_loss: 0.12266352772712708, Dice_loss: 0.009592912159860134, Consistency_loss: 0.0004131440946366638\n",
      "[Training] Epoch: 5 [============>  ] 86.5% Loss: 0.1488, Epoch 5, Batch 108, CE_loss: 0.12391731142997742, Dice_loss: 0.009426597505807877, Consistency_loss: 0.00033467341563664377\n",
      "[Training] Epoch: 5 [=============> ] 87.3% Loss: 0.1491, Epoch 5, Batch 109, CE_loss: 0.15926942229270935, Dice_loss: 0.013839680701494217, Consistency_loss: 0.0003155033045914024\n",
      "[Training] Epoch: 5 [=============> ] 88.1% Loss: 0.1490, Epoch 5, Batch 110, CE_loss: 0.12916383147239685, Dice_loss: 0.01053638756275177, Consistency_loss: 1.2237767805345356e-05\n",
      "[Training] Epoch: 5 [=============> ] 88.9% Loss: 0.1487, Epoch 5, Batch 111, CE_loss: 0.1045711413025856, Dice_loss: 0.00688780564814806, Consistency_loss: 0.0003076479770243168\n",
      "[Training] Epoch: 5 [=============> ] 89.7% Loss: 0.1486, Epoch 5, Batch 112, CE_loss: 0.1297997534275055, Dice_loss: 0.010741148144006729, Consistency_loss: 1.3840774954587687e-05\n",
      "[Training] Epoch: 5 [=============> ] 90.5% Loss: 0.1482, Epoch 5, Batch 113, CE_loss: 0.09739132970571518, Dice_loss: 0.0060850027948617935, Consistency_loss: 1.94961903616786e-05\n",
      "[Training] Epoch: 5 [=============> ] 91.3% Loss: 0.1482, Epoch 5, Batch 114, CE_loss: 0.14059624075889587, Dice_loss: 0.011885100975632668, Consistency_loss: 0.0002955733798444271\n",
      "[Training] Epoch: 5 [=============> ] 92.1% Loss: 0.1479, Epoch 5, Batch 115, CE_loss: 0.1072477400302887, Dice_loss: 0.007356691639870405, Consistency_loss: 0.00020268101070541888\n",
      "[Training] Epoch: 5 [=============> ] 92.9% Loss: 0.1479, Epoch 5, Batch 116, CE_loss: 0.12863077223300934, Dice_loss: 0.010107118636369705, Consistency_loss: 0.00046813805238343775\n",
      "[Training] Epoch: 5 [==============>] 93.7% Loss: 0.1475, Epoch 5, Batch 117, CE_loss: 0.10116999596357346, Dice_loss: 0.006459099240601063, Consistency_loss: 6.817539542680606e-06\n",
      "[Training] Epoch: 5 [==============>] 94.4% Loss: 0.1474, Epoch 5, Batch 118, CE_loss: 0.12409655749797821, Dice_loss: 0.009728756733238697, Consistency_loss: 0.0002685945073608309\n",
      "[Training] Epoch: 5 [==============>] 95.2% Loss: 0.1474, Epoch 5, Batch 119, CE_loss: 0.1371089369058609, Dice_loss: 0.011384180746972561, Consistency_loss: 0.00011585006723180413\n",
      "[Training] Epoch: 5 [==============>] 96.0% Loss: 0.1474, Epoch 5, Batch 120, CE_loss: 0.1296176165342331, Dice_loss: 0.010524917393922806, Consistency_loss: 0.00014236800780054182\n",
      "[Training] Epoch: 5 [==============>] 96.8% Loss: 0.1471, Epoch 5, Batch 121, CE_loss: 0.10293013602495193, Dice_loss: 0.006829065270721912, Consistency_loss: 0.00019438455638010055\n",
      "[Training] Epoch: 5 [==============>] 97.6% Loss: 0.1470, Epoch 5, Batch 122, CE_loss: 0.13123667240142822, Dice_loss: 0.010967946611344814, Consistency_loss: 0.00014652928803116083\n",
      "[Training] Epoch: 5 [==============>] 98.4% Loss: 0.1469, Epoch 5, Batch 123, CE_loss: 0.12698550522327423, Dice_loss: 0.010166823863983154, Consistency_loss: 0.00022850088134873658\n",
      "[Training] Epoch: 5 [==============>] 99.2% Loss: 0.1468, Epoch 5, Batch 124, CE_loss: 0.11954601109027863, Dice_loss: 0.009315276518464088, Consistency_loss: 2.8561522412928753e-05\n",
      "[Training] Epoch: 5 [DONE]                                 \n",
      "Epoch 5, Batch 125, CE_loss: 0.1398749053478241, Dice_loss: 0.012249738909304142, Consistency_loss: 0.000576815044041723\n",
      "Epoch 5, Batch 125, CE_loss: 0.1398749053478241, Dice_loss: 0.012249738909304142, Consistency_loss: 0.000576815044041723\n",
      "[Validation] Epoch: 5 [DONE]                                 \n",
      "[Epoch: 5, TrainLoss: 0.1468, TrainDice: 0.0108, ValLoss: 0.1952                                             \n",
      "Number of batches:  126\n",
      "[Training] Epoch: 6 [>              ] 0.8% Loss: 0.1080, Epoch 6, Batch 0, CE_loss: 0.10115032643079758, Dice_loss: 0.006500065792351961, Consistency_loss: 0.0003061945899389684\n",
      "[Training] Epoch: 6 [>              ] 1.6% Loss: 0.1188, Epoch 6, Batch 1, CE_loss: 0.12015216797590256, Dice_loss: 0.009459543973207474, Consistency_loss: 2.5887629817589186e-05\n",
      "[Training] Epoch: 6 [>              ] 2.4% Loss: 0.1198, Epoch 6, Batch 2, CE_loss: 0.11365802586078644, Dice_loss: 0.008184215985238552, Consistency_loss: 1.8809711036738008e-05\n",
      "[Training] Epoch: 6 [>              ] 3.2% Loss: 0.1271, Epoch 6, Batch 3, CE_loss: 0.1369754821062088, Dice_loss: 0.011552033014595509, Consistency_loss: 0.0002944258158095181\n",
      "[Training] Epoch: 6 [>              ] 4.0% Loss: 0.1246, Epoch 6, Batch 4, CE_loss: 0.10685815662145615, Dice_loss: 0.007497739978134632, Consistency_loss: 0.0004142643010709435\n",
      "[Training] Epoch: 6 [>              ] 4.8% Loss: 0.1280, Epoch 6, Batch 5, CE_loss: 0.1335379034280777, Dice_loss: 0.010962555184960365, Consistency_loss: 0.0002531562640797347\n",
      "[Training] Epoch: 6 [>              ] 5.6% Loss: 0.1339, Epoch 6, Batch 6, CE_loss: 0.1554609090089798, Dice_loss: 0.013496259227395058, Consistency_loss: 0.0002593339595478028\n",
      "[Training] Epoch: 6 [>              ] 6.3% Loss: 0.1325, Epoch 6, Batch 7, CE_loss: 0.11438166350126266, Dice_loss: 0.008533671498298645, Consistency_loss: 0.0002726115344557911\n",
      "[Training] Epoch: 6 [=>             ] 7.1% Loss: 0.1367, Epoch 6, Batch 8, CE_loss: 0.15581023693084717, Dice_loss: 0.01431191060692072, Consistency_loss: 0.0003374283842276782\n",
      "[Training] Epoch: 6 [=>             ] 7.9% Loss: 0.1350, Epoch 6, Batch 9, CE_loss: 0.11040449142456055, Dice_loss: 0.008117303252220154, Consistency_loss: 0.00032920707599259913\n",
      "[Training] Epoch: 6 [=>             ] 8.7% Loss: 0.1334, Epoch 6, Batch 10, CE_loss: 0.10935112088918686, Dice_loss: 0.007742965593934059, Consistency_loss: 0.0003865408361889422\n",
      "[Training] Epoch: 6 [=>             ] 9.5% Loss: 0.1349, Epoch 6, Batch 11, CE_loss: 0.13937008380889893, Dice_loss: 0.011771571822464466, Consistency_loss: 0.0003019595460500568\n",
      "[Training] Epoch: 6 [=>             ] 10.3% Loss: 0.1342, Epoch 6, Batch 12, CE_loss: 0.11593635380268097, Dice_loss: 0.009115263819694519, Consistency_loss: 0.00047578761586919427\n",
      "[Training] Epoch: 6 [=>             ] 11.1% Loss: 0.1356, Epoch 6, Batch 13, CE_loss: 0.140865296125412, Dice_loss: 0.012678113766014576, Consistency_loss: 0.0005833641043864191\n",
      "[Training] Epoch: 6 [=>             ] 11.9% Loss: 0.1336, Epoch 6, Batch 14, CE_loss: 0.09916355460882187, Dice_loss: 0.006547987926751375, Consistency_loss: 0.00034931153641082346\n",
      "[Training] Epoch: 6 [=>             ] 12.7% Loss: 0.1325, Epoch 6, Batch 15, CE_loss: 0.10862695425748825, Dice_loss: 0.007834617048501968, Consistency_loss: 4.0807095501804724e-05\n",
      "[Training] Epoch: 6 [==>            ] 13.5% Loss: 0.1307, Epoch 6, Batch 16, CE_loss: 0.09531430155038834, Dice_loss: 0.006056678481400013, Consistency_loss: 5.371254155761562e-05\n",
      "[Training] Epoch: 6 [==>            ] 14.3% Loss: 0.1297, Epoch 6, Batch 17, CE_loss: 0.10537750273942947, Dice_loss: 0.00733419694006443, Consistency_loss: 0.0004321163578424603\n",
      "[Training] Epoch: 6 [==>            ] 15.1% Loss: 0.1292, Epoch 6, Batch 18, CE_loss: 0.11085139960050583, Dice_loss: 0.008063141256570816, Consistency_loss: 0.00047095539048314095\n",
      "[Training] Epoch: 6 [==>            ] 15.9% Loss: 0.1275, Epoch 6, Batch 19, CE_loss: 0.08931673318147659, Dice_loss: 0.005224174354225397, Consistency_loss: 0.00033995704143308103\n",
      "[Training] Epoch: 6 [==>            ] 16.7% Loss: 0.1278, Epoch 6, Batch 20, CE_loss: 0.12367995083332062, Dice_loss: 0.010004586540162563, Consistency_loss: 0.00018243372323922813\n",
      "[Training] Epoch: 6 [==>            ] 17.5% Loss: 0.1270, Epoch 6, Batch 21, CE_loss: 0.10371540486812592, Dice_loss: 0.007220220752060413, Consistency_loss: 0.00021142866171430796\n",
      "[Training] Epoch: 6 [==>            ] 18.3% Loss: 0.1259, Epoch 6, Batch 22, CE_loss: 0.09427986294031143, Dice_loss: 0.005936310160905123, Consistency_loss: 0.00033435161458328366\n",
      "[Training] Epoch: 6 [==>            ] 19.0% Loss: 0.1254, Epoch 6, Batch 23, CE_loss: 0.10773533582687378, Dice_loss: 0.007607710547745228, Consistency_loss: 0.0002938601828645915\n",
      "[Training] Epoch: 6 [==>            ] 19.8% Loss: 0.1261, Epoch 6, Batch 24, CE_loss: 0.13042481243610382, Dice_loss: 0.010232601314783096, Consistency_loss: 0.00017366746033076197\n",
      "[Training] Epoch: 6 [===>           ] 20.6% Loss: 0.1261, Epoch 6, Batch 25, CE_loss: 0.11770296096801758, Dice_loss: 0.00913227815181017, Consistency_loss: 0.00016444751236122102\n",
      "[Training] Epoch: 6 [===>           ] 21.4% Loss: 0.1285, Epoch 6, Batch 26, CE_loss: 0.17381907999515533, Dice_loss: 0.015658602118492126, Consistency_loss: 0.00017300275794696063\n",
      "[Training] Epoch: 6 [===>           ] 22.2% Loss: 0.1293, Epoch 6, Batch 27, CE_loss: 0.1407199501991272, Dice_loss: 0.012007543817162514, Consistency_loss: 0.00018670606368687004\n",
      "[Training] Epoch: 6 [===>           ] 23.0% Loss: 0.1290, Epoch 6, Batch 28, CE_loss: 0.11214422434568405, Dice_loss: 0.008397737517952919, Consistency_loss: 0.0002243981434730813\n",
      "[Training] Epoch: 6 [===>           ] 23.8% Loss: 0.1304, Epoch 6, Batch 29, CE_loss: 0.1563093215227127, Dice_loss: 0.014231926761567593, Consistency_loss: 0.00029163373983465135\n",
      "[Training] Epoch: 6 [===>           ] 24.6% Loss: 0.1298, Epoch 6, Batch 30, CE_loss: 0.1036229282617569, Dice_loss: 0.007232720032334328, Consistency_loss: 0.00018203712534159422\n",
      "[Training] Epoch: 6 [===>           ] 25.4% Loss: 0.1297, Epoch 6, Batch 31, CE_loss: 0.11586135625839233, Dice_loss: 0.009186699986457825, Consistency_loss: 0.00023165189486462623\n",
      "[Training] Epoch: 6 [===>           ] 26.2% Loss: 0.1286, Epoch 6, Batch 32, CE_loss: 0.09028134495019913, Dice_loss: 0.005368244834244251, Consistency_loss: 0.0002529927296563983\n",
      "[Training] Epoch: 6 [====>          ] 27.0% Loss: 0.1283, Epoch 6, Batch 33, CE_loss: 0.10876993834972382, Dice_loss: 0.008123133331537247, Consistency_loss: 0.0004956793272867799\n",
      "[Training] Epoch: 6 [====>          ] 27.8% Loss: 0.1281, Epoch 6, Batch 34, CE_loss: 0.11213935911655426, Dice_loss: 0.008708382025361061, Consistency_loss: 2.7895035600522533e-05\n",
      "[Training] Epoch: 6 [====>          ] 28.6% Loss: 0.1274, Epoch 6, Batch 35, CE_loss: 0.0959385335445404, Dice_loss: 0.006267795339226723, Consistency_loss: 0.0002622953325044364\n",
      "[Training] Epoch: 6 [====>          ] 29.4% Loss: 0.1273, Epoch 6, Batch 36, CE_loss: 0.11651682108640671, Dice_loss: 0.009278986603021622, Consistency_loss: 0.00030987043282948434\n",
      "[Training] Epoch: 6 [====>          ] 30.2% Loss: 0.1284, Epoch 6, Batch 37, CE_loss: 0.15194113552570343, Dice_loss: 0.014325106516480446, Consistency_loss: 0.00034205769770778716\n",
      "[Training] Epoch: 6 [====>          ] 31.0% Loss: 0.1291, Epoch 6, Batch 38, CE_loss: 0.14497676491737366, Dice_loss: 0.013032648712396622, Consistency_loss: 0.00038476366898976266\n",
      "[Training] Epoch: 6 [====>          ] 31.7% Loss: 0.1289, Epoch 6, Batch 39, CE_loss: 0.11120177060365677, Dice_loss: 0.008592805825173855, Consistency_loss: 0.00039733489393256605\n",
      "[Training] Epoch: 6 [====>          ] 32.5% Loss: 0.1295, Epoch 6, Batch 40, CE_loss: 0.13965123891830444, Dice_loss: 0.012258839793503284, Consistency_loss: 0.0002803220704663545\n",
      "[Training] Epoch: 6 [=====>         ] 33.3% Loss: 0.1301, Epoch 6, Batch 41, CE_loss: 0.14184223115444183, Dice_loss: 0.012641099281609058, Consistency_loss: 0.0002596352424006909\n",
      "[Training] Epoch: 6 [=====>         ] 34.1% Loss: 0.1299, Epoch 6, Batch 42, CE_loss: 0.11200421303510666, Dice_loss: 0.008791557513177395, Consistency_loss: 0.0004611590411514044\n",
      "[Training] Epoch: 6 [=====>         ] 34.9% Loss: 0.1295, Epoch 6, Batch 43, CE_loss: 0.10626263171434402, Dice_loss: 0.007672325242310762, Consistency_loss: 0.00036454841028898954\n",
      "[Training] Epoch: 6 [=====>         ] 35.7% Loss: 0.1291, Epoch 6, Batch 44, CE_loss: 0.10377054661512375, Dice_loss: 0.007616615388542414, Consistency_loss: 0.0004393351264297962\n",
      "[Training] Epoch: 6 [=====>         ] 36.5% Loss: 0.1288, Epoch 6, Batch 45, CE_loss: 0.10661857575178146, Dice_loss: 0.008003845810890198, Consistency_loss: 0.0008170324726961553\n",
      "[Training] Epoch: 6 [=====>         ] 37.3% Loss: 0.1288, Epoch 6, Batch 46, CE_loss: 0.119160495698452, Dice_loss: 0.009441089816391468, Consistency_loss: 1.866144702944439e-05\n",
      "[Training] Epoch: 6 [=====>         ] 38.1% Loss: 0.1287, Epoch 6, Batch 47, CE_loss: 0.11536263674497604, Dice_loss: 0.009179869666695595, Consistency_loss: 1.524077288195258e-05\n",
      "[Training] Epoch: 6 [=====>         ] 38.9% Loss: 0.1282, Epoch 6, Batch 48, CE_loss: 0.09577654302120209, Dice_loss: 0.006473735440522432, Consistency_loss: 0.0004567577561829239\n",
      "[Training] Epoch: 6 [=====>         ] 39.7% Loss: 0.1280, Epoch 6, Batch 49, CE_loss: 0.10996925085783005, Dice_loss: 0.008521825075149536, Consistency_loss: 4.0730315959081054e-05\n",
      "[Training] Epoch: 6 [======>        ] 40.5% Loss: 0.1280, Epoch 6, Batch 50, CE_loss: 0.11776192486286163, Dice_loss: 0.008961841464042664, Consistency_loss: 0.0005673202103935182\n",
      "[Training] Epoch: 6 [======>        ] 41.3% Loss: 0.1280, Epoch 6, Batch 51, CE_loss: 0.11917737871408463, Dice_loss: 0.00966615416109562, Consistency_loss: 0.0005187019123695791\n",
      "[Training] Epoch: 6 [======>        ] 42.1% Loss: 0.1283, Epoch 6, Batch 52, CE_loss: 0.13243015110492706, Dice_loss: 0.011527061462402344, Consistency_loss: 0.0003295653441455215\n",
      "[Training] Epoch: 6 [======>        ] 42.9% Loss: 0.1282, Epoch 6, Batch 53, CE_loss: 0.11220386624336243, Dice_loss: 0.00874913390725851, Consistency_loss: 2.2366648408933543e-05\n",
      "[Training] Epoch: 6 [======>        ] 43.7% Loss: 0.1281, Epoch 6, Batch 54, CE_loss: 0.11203748732805252, Dice_loss: 0.008628040552139282, Consistency_loss: 0.00019287427130620927\n",
      "[Training] Epoch: 6 [======>        ] 44.4% Loss: 0.1278, Epoch 6, Batch 55, CE_loss: 0.10376788675785065, Dice_loss: 0.007597276940941811, Consistency_loss: 2.2110432837507688e-05\n",
      "[Training] Epoch: 6 [======>        ] 45.2% Loss: 0.1277, Epoch 6, Batch 56, CE_loss: 0.11441794037818909, Dice_loss: 0.009097713977098465, Consistency_loss: 0.00026213828823529184\n",
      "[Training] Epoch: 6 [======>        ] 46.0% Loss: 0.1278, Epoch 6, Batch 57, CE_loss: 0.12338005751371384, Dice_loss: 0.010426998138427734, Consistency_loss: 0.00023972235794644803\n",
      "[Training] Epoch: 6 [=======>       ] 46.8% Loss: 0.1279, Epoch 6, Batch 58, CE_loss: 0.12194884568452835, Dice_loss: 0.010091811418533325, Consistency_loss: 1.982148751267232e-05\n",
      "[Training] Epoch: 6 [=======>       ] 47.6% Loss: 0.1276, Epoch 6, Batch 59, CE_loss: 0.1040598601102829, Dice_loss: 0.007770958822220564, Consistency_loss: 0.0004181076365057379\n",
      "[Training] Epoch: 6 [=======>       ] 48.4% Loss: 0.1281, Epoch 6, Batch 60, CE_loss: 0.14400067925453186, Dice_loss: 0.012083486653864384, Consistency_loss: 1.613258064026013e-05\n",
      "[Training] Epoch: 6 [=======>       ] 49.2% Loss: 0.1295, Epoch 6, Batch 61, CE_loss: 0.19417501986026764, Dice_loss: 0.018775366246700287, Consistency_loss: 0.0004967442946508527\n",
      "[Training] Epoch: 6 [=======>       ] 50.0% Loss: 0.1292, Epoch 6, Batch 62, CE_loss: 0.10280968993902206, Dice_loss: 0.007546475622802973, Consistency_loss: 0.00033079259446822107\n",
      "[Training] Epoch: 6 [=======>       ] 50.8% Loss: 0.1291, Epoch 6, Batch 63, CE_loss: 0.11425396800041199, Dice_loss: 0.009090445004403591, Consistency_loss: 0.0003884677716996521\n",
      "[Training] Epoch: 6 [=======>       ] 51.6% Loss: 0.1289, Epoch 6, Batch 64, CE_loss: 0.10804283618927002, Dice_loss: 0.008383844047784805, Consistency_loss: 0.0005363651434890926\n",
      "[Training] Epoch: 6 [=======>       ] 52.4% Loss: 0.1290, Epoch 6, Batch 65, CE_loss: 0.12491407990455627, Dice_loss: 0.010717651806771755, Consistency_loss: 0.00047668657498434186\n",
      "[Training] Epoch: 6 [=======>       ] 53.2% Loss: 0.1287, Epoch 6, Batch 66, CE_loss: 0.09936916083097458, Dice_loss: 0.006769126746803522, Consistency_loss: 0.000300709274597466\n",
      "[Training] Epoch: 6 [========>      ] 54.0% Loss: 0.1284, Epoch 6, Batch 67, CE_loss: 0.104522205889225, Dice_loss: 0.007918042130768299, Consistency_loss: 0.00026002785307355225\n",
      "[Training] Epoch: 6 [========>      ] 54.8% Loss: 0.1283, Epoch 6, Batch 68, CE_loss: 0.11046963185071945, Dice_loss: 0.008687281981110573, Consistency_loss: 0.00022460150648839772\n",
      "[Training] Epoch: 6 [========>      ] 55.6% Loss: 0.1283, Epoch 6, Batch 69, CE_loss: 0.11966230720281601, Dice_loss: 0.010091614909470081, Consistency_loss: 0.00031361248693428934\n",
      "[Training] Epoch: 6 [========>      ] 56.3% Loss: 0.1279, Epoch 6, Batch 70, CE_loss: 0.09331026673316956, Dice_loss: 0.0060360971838235855, Consistency_loss: 0.0007888758555054665\n",
      "[Training] Epoch: 6 [========>      ] 57.1% Loss: 0.1280, Epoch 6, Batch 71, CE_loss: 0.12298877537250519, Dice_loss: 0.010532033629715443, Consistency_loss: 3.6666526284534484e-05\n",
      "[Training] Epoch: 6 [========>      ] 57.9% Loss: 0.1281, Epoch 6, Batch 72, CE_loss: 0.12107081711292267, Dice_loss: 0.009725555777549744, Consistency_loss: 0.00028144309180788696\n",
      "[Training] Epoch: 6 [========>      ] 58.7% Loss: 0.1282, Epoch 6, Batch 73, CE_loss: 0.12723107635974884, Dice_loss: 0.010890510864555836, Consistency_loss: 0.0002394510229350999\n",
      "[Training] Epoch: 6 [========>      ] 59.5% Loss: 0.1281, Epoch 6, Batch 74, CE_loss: 0.10928729921579361, Dice_loss: 0.008342985063791275, Consistency_loss: 0.0005799926584586501\n",
      "[Training] Epoch: 6 [=========>     ] 60.3% Loss: 0.1279, Epoch 6, Batch 75, CE_loss: 0.10800831019878387, Dice_loss: 0.008115989156067371, Consistency_loss: 0.0005085152806714177\n",
      "[Training] Epoch: 6 [=========>     ] 61.1% Loss: 0.1275, Epoch 6, Batch 76, CE_loss: 0.09071850031614304, Dice_loss: 0.006046879570931196, Consistency_loss: 0.0005379366921260953\n",
      "[Training] Epoch: 6 [=========>     ] 61.9% Loss: 0.1273, Epoch 6, Batch 77, CE_loss: 0.09995846450328827, Dice_loss: 0.007236546371132135, Consistency_loss: 2.0100551409996115e-05\n",
      "[Training] Epoch: 6 [=========>     ] 62.7% Loss: 0.1271, Epoch 6, Batch 78, CE_loss: 0.10769123584032059, Dice_loss: 0.008517659269273281, Consistency_loss: 0.00031523749930784106\n",
      "[Training] Epoch: 6 [=========>     ] 63.5% Loss: 0.1276, Epoch 6, Batch 79, CE_loss: 0.15562985837459564, Dice_loss: 0.014133516699075699, Consistency_loss: 0.00017847042181529105\n",
      "[Training] Epoch: 6 [=========>     ] 64.3% Loss: 0.1272, Epoch 6, Batch 80, CE_loss: 0.08775870501995087, Dice_loss: 0.005604172125458717, Consistency_loss: 0.0002963143342640251\n",
      "[Training] Epoch: 6 [=========>     ] 65.1% Loss: 0.1273, Epoch 6, Batch 81, CE_loss: 0.11907660216093063, Dice_loss: 0.009720727801322937, Consistency_loss: 0.0005147295305505395\n",
      "[Training] Epoch: 6 [=========>     ] 65.9% Loss: 0.1271, Epoch 6, Batch 82, CE_loss: 0.10542487353086472, Dice_loss: 0.008072367869317532, Consistency_loss: 0.0005203269538469613\n",
      "[Training] Epoch: 6 [==========>    ] 66.7% Loss: 0.1271, Epoch 6, Batch 83, CE_loss: 0.11482115834951401, Dice_loss: 0.008946910500526428, Consistency_loss: 0.00023257294378709048\n",
      "[Training] Epoch: 6 [==========>    ] 67.5% Loss: 0.1270, Epoch 6, Batch 84, CE_loss: 0.11317259818315506, Dice_loss: 0.008749822154641151, Consistency_loss: 0.0004444293736014515\n",
      "[Training] Epoch: 6 [==========>    ] 68.3% Loss: 0.1270, Epoch 6, Batch 85, CE_loss: 0.113807812333107, Dice_loss: 0.009416172280907631, Consistency_loss: 0.0006721442332491279\n",
      "[Training] Epoch: 6 [==========>    ] 69.0% Loss: 0.1270, Epoch 6, Batch 86, CE_loss: 0.1223175898194313, Dice_loss: 0.010610157623887062, Consistency_loss: 0.00037776786484755576\n",
      "[Training] Epoch: 6 [==========>    ] 69.8% Loss: 0.1269, Epoch 6, Batch 87, CE_loss: 0.10863517969846725, Dice_loss: 0.008541620336472988, Consistency_loss: 0.0004189822939224541\n",
      "[Training] Epoch: 6 [==========>    ] 70.6% Loss: 0.1268, Epoch 6, Batch 88, CE_loss: 0.10558632761240005, Dice_loss: 0.00812059361487627, Consistency_loss: 0.0004682325816247612\n",
      "[Training] Epoch: 6 [==========>    ] 71.4% Loss: 0.1268, Epoch 6, Batch 89, CE_loss: 0.11625798791646957, Dice_loss: 0.00927254930138588, Consistency_loss: 0.00041041281656362116\n",
      "[Training] Epoch: 6 [==========>    ] 72.2% Loss: 0.1266, Epoch 6, Batch 90, CE_loss: 0.10141220688819885, Dice_loss: 0.007447806186974049, Consistency_loss: 0.0005737110623158514\n",
      "[Training] Epoch: 6 [==========>    ] 73.0% Loss: 0.1265, Epoch 6, Batch 91, CE_loss: 0.10679629445075989, Dice_loss: 0.00845756009221077, Consistency_loss: 0.000443484605057165\n",
      "[Training] Epoch: 6 [===========>   ] 73.8% Loss: 0.1263, Epoch 6, Batch 92, CE_loss: 0.09979089349508286, Dice_loss: 0.007417407818138599, Consistency_loss: 2.035500256170053e-05\n",
      "[Training] Epoch: 6 [===========>   ] 74.6% Loss: 0.1261, Epoch 6, Batch 93, CE_loss: 0.10093022137880325, Dice_loss: 0.007666853256523609, Consistency_loss: 0.0003694233309943229\n",
      "[Training] Epoch: 6 [===========>   ] 75.4% Loss: 0.1258, Epoch 6, Batch 94, CE_loss: 0.09473767876625061, Dice_loss: 0.0067179324105381966, Consistency_loss: 0.0004951012087985873\n",
      "[Training] Epoch: 6 [===========>   ] 76.2% Loss: 0.1260, Epoch 6, Batch 95, CE_loss: 0.12912681698799133, Dice_loss: 0.011252546682953835, Consistency_loss: 0.0003654135507531464\n",
      "[Training] Epoch: 6 [===========>   ] 77.0% Loss: 0.1259, Epoch 6, Batch 96, CE_loss: 0.11125119030475616, Dice_loss: 0.009020027704536915, Consistency_loss: 0.00035336086875759065\n",
      "[Training] Epoch: 6 [===========>   ] 77.8% Loss: 0.1256, Epoch 6, Batch 97, CE_loss: 0.08812637627124786, Dice_loss: 0.005871820729225874, Consistency_loss: 0.0003359820111654699\n",
      "[Training] Epoch: 6 [===========>   ] 78.6% Loss: 0.1255, Epoch 6, Batch 98, CE_loss: 0.10823413729667664, Dice_loss: 0.008611715398728848, Consistency_loss: 2.099975972669199e-05\n",
      "[Training] Epoch: 6 [===========>   ] 79.4% Loss: 0.1253, Epoch 6, Batch 99, CE_loss: 0.09443448483943939, Dice_loss: 0.0068241748958826065, Consistency_loss: 0.00042987216147594154\n",
      "[Training] Epoch: 6 [============>  ] 80.2% Loss: 0.1251, Epoch 6, Batch 100, CE_loss: 0.1003798171877861, Dice_loss: 0.007290369365364313, Consistency_loss: 0.00037748223985545337\n",
      "[Training] Epoch: 6 [============>  ] 81.0% Loss: 0.1248, Epoch 6, Batch 101, CE_loss: 0.09004563093185425, Dice_loss: 0.006082150619477034, Consistency_loss: 0.000483266863739118\n",
      "[Training] Epoch: 6 [============>  ] 81.7% Loss: 0.1246, Epoch 6, Batch 102, CE_loss: 0.09216264635324478, Dice_loss: 0.006453860085457563, Consistency_loss: 0.0003896486305166036\n",
      "[Training] Epoch: 6 [============>  ] 82.5% Loss: 0.1249, Epoch 6, Batch 103, CE_loss: 0.14628969132900238, Dice_loss: 0.012579998932778835, Consistency_loss: 1.82769672392169e-05\n",
      "[Training] Epoch: 6 [============>  ] 83.3% Loss: 0.1248, Epoch 6, Batch 104, CE_loss: 0.10502293705940247, Dice_loss: 0.008204233832657337, Consistency_loss: 0.00045997623237781227\n",
      "[Training] Epoch: 6 [============>  ] 84.1% Loss: 0.1249, Epoch 6, Batch 105, CE_loss: 0.12036183476448059, Dice_loss: 0.010255837813019753, Consistency_loss: 0.00037775884266011417\n",
      "[Training] Epoch: 6 [============>  ] 84.9% Loss: 0.1247, Epoch 6, Batch 106, CE_loss: 0.10358186811208725, Dice_loss: 0.007776752579957247, Consistency_loss: 0.0006423336453735828\n",
      "[Training] Epoch: 6 [============>  ] 85.7% Loss: 0.1248, Epoch 6, Batch 107, CE_loss: 0.12269171327352524, Dice_loss: 0.010020786896348, Consistency_loss: 0.0005365565302781761\n",
      "[Training] Epoch: 6 [============>  ] 86.5% Loss: 0.1247, Epoch 6, Batch 108, CE_loss: 0.10570046305656433, Dice_loss: 0.007815367542207241, Consistency_loss: 0.00025872638798318803\n",
      "[Training] Epoch: 6 [=============> ] 87.3% Loss: 0.1246, Epoch 6, Batch 109, CE_loss: 0.10273256152868271, Dice_loss: 0.0077438149601221085, Consistency_loss: 0.0003058507281821221\n",
      "[Training] Epoch: 6 [=============> ] 88.1% Loss: 0.1244, Epoch 6, Batch 110, CE_loss: 0.10057798773050308, Dice_loss: 0.007521620485931635, Consistency_loss: 0.00021719241340178996\n",
      "[Training] Epoch: 6 [=============> ] 88.9% Loss: 0.1241, Epoch 6, Batch 111, CE_loss: 0.08230393379926682, Dice_loss: 0.005139452405273914, Consistency_loss: 0.0005196818965487182\n",
      "[Training] Epoch: 6 [=============> ] 89.7% Loss: 0.1241, Epoch 6, Batch 112, CE_loss: 0.11557351797819138, Dice_loss: 0.009594280272722244, Consistency_loss: 0.0005234159762039781\n",
      "[Training] Epoch: 6 [=============> ] 90.5% Loss: 0.1241, Epoch 6, Batch 113, CE_loss: 0.11364508420228958, Dice_loss: 0.009441528469324112, Consistency_loss: 0.0005058126407675445\n",
      "[Training] Epoch: 6 [=============> ] 91.3% Loss: 0.1242, Epoch 6, Batch 114, CE_loss: 0.12424151599407196, Dice_loss: 0.01060768123716116, Consistency_loss: 0.0003633450251072645\n",
      "[Training] Epoch: 6 [=============> ] 92.1% Loss: 0.1241, Epoch 6, Batch 115, CE_loss: 0.09655456990003586, Dice_loss: 0.00725157605484128, Consistency_loss: 0.0004199594259262085\n",
      "[Training] Epoch: 6 [=============> ] 92.9% Loss: 0.1238, Epoch 6, Batch 116, CE_loss: 0.08479554206132889, Dice_loss: 0.005495247431099415, Consistency_loss: 0.00024097179993987083\n",
      "[Training] Epoch: 6 [==============>] 93.7% Loss: 0.1238, Epoch 6, Batch 117, CE_loss: 0.12127009779214859, Dice_loss: 0.010594010353088379, Consistency_loss: 0.00016781078011263162\n",
      "[Training] Epoch: 6 [==============>] 94.4% Loss: 0.1239, Epoch 6, Batch 118, CE_loss: 0.12586060166358948, Dice_loss: 0.010743704624474049, Consistency_loss: 0.00025031596305780113\n",
      "[Training] Epoch: 6 [==============>] 95.2% Loss: 0.1237, Epoch 6, Batch 119, CE_loss: 0.09383045136928558, Dice_loss: 0.00666505703702569, Consistency_loss: 0.00021452261717058718\n",
      "[Training] Epoch: 6 [==============>] 96.0% Loss: 0.1235, Epoch 6, Batch 120, CE_loss: 0.09036502987146378, Dice_loss: 0.006166783161461353, Consistency_loss: 0.000245375296799466\n",
      "[Training] Epoch: 6 [==============>] 96.8% Loss: 0.1236, Epoch 6, Batch 121, CE_loss: 0.12205377966165543, Dice_loss: 0.0104934461414814, Consistency_loss: 0.00023020152002573013\n",
      "[Training] Epoch: 6 [==============>] 97.6% Loss: 0.1234, Epoch 6, Batch 122, CE_loss: 0.08938407152891159, Dice_loss: 0.006266060750931501, Consistency_loss: 0.00023177529510576278\n",
      "[Training] Epoch: 6 [==============>] 98.4% Loss: 0.1234, Epoch 6, Batch 123, CE_loss: 0.11180485785007477, Dice_loss: 0.00929307658225298, Consistency_loss: 0.0003025566984433681\n",
      "[Training] Epoch: 6 [==============>] 99.2% Loss: 0.1231, Epoch 6, Batch 124, CE_loss: 0.0879969671368599, Dice_loss: 0.006025788374245167, Consistency_loss: 0.0006498464499600232\n",
      "[Training] Epoch: 6 [DONE]                                 \n",
      "Epoch 6, Batch 125, CE_loss: 0.10873794555664062, Dice_loss: 0.0089308712631464, Consistency_loss: 5.867999789188616e-05\n",
      "Epoch 6, Batch 125, CE_loss: 0.10873794555664062, Dice_loss: 0.0089308712631464, Consistency_loss: 5.867999789188616e-05\n",
      "[Validation] Epoch: 6 [DONE]                                 \n",
      "[Epoch: 6, TrainLoss: 0.1231, TrainDice: 0.0089, ValLoss: 0.1677                                             \n",
      "Number of batches:  126\n",
      "[Training] Epoch: 7 [>              ] 0.8% Loss: 0.1282, Epoch 7, Batch 0, CE_loss: 0.11784472316503525, Dice_loss: 0.010092866607010365, Consistency_loss: 0.00022351845109369606\n",
      "[Training] Epoch: 7 [>              ] 1.6% Loss: 0.1445, Epoch 7, Batch 1, CE_loss: 0.14650283753871918, Dice_loss: 0.01412395853549242, Consistency_loss: 0.0002585287729743868\n",
      "[Training] Epoch: 7 [>              ] 2.4% Loss: 0.1245, Epoch 7, Batch 2, CE_loss: 0.07932469993829727, Dice_loss: 0.0048847319558262825, Consistency_loss: 0.00032242093584500253\n",
      "[Training] Epoch: 7 [>              ] 3.2% Loss: 0.1244, Epoch 7, Batch 3, CE_loss: 0.11431162804365158, Dice_loss: 0.009325951337814331, Consistency_loss: 0.0003771094197873026\n",
      "[Training] Epoch: 7 [>              ] 4.0% Loss: 0.1245, Epoch 7, Batch 4, CE_loss: 0.11473101377487183, Dice_loss: 0.00984503049403429, Consistency_loss: 0.0005657941801473498\n",
      "[Training] Epoch: 7 [>              ] 4.8% Loss: 0.1221, Epoch 7, Batch 5, CE_loss: 0.10179084539413452, Dice_loss: 0.007952597923576832, Consistency_loss: 2.550914723542519e-05\n",
      "[Training] Epoch: 7 [>              ] 5.6% Loss: 0.1192, Epoch 7, Batch 6, CE_loss: 0.09468257427215576, Dice_loss: 0.00711118895560503, Consistency_loss: 0.00037471731775440276\n",
      "[Training] Epoch: 7 [>              ] 6.3% Loss: 0.1193, Epoch 7, Batch 7, CE_loss: 0.10996582359075546, Dice_loss: 0.009025088511407375, Consistency_loss: 0.0003953602281399071\n",
      "[Training] Epoch: 7 [=>             ] 7.1% Loss: 0.1183, Epoch 7, Batch 8, CE_loss: 0.10272953659296036, Dice_loss: 0.008292470127344131, Consistency_loss: 4.121473102713935e-05\n",
      "[Training] Epoch: 7 [=>             ] 7.9% Loss: 0.1178, Epoch 7, Batch 9, CE_loss: 0.10439896583557129, Dice_loss: 0.007956407032907009, Consistency_loss: 0.00041873977170325816\n",
      "[Training] Epoch: 7 [=>             ] 8.7% Loss: 0.1197, Epoch 7, Batch 10, CE_loss: 0.1274861991405487, Dice_loss: 0.011069771833717823, Consistency_loss: 0.0005118165863677859\n",
      "[Training] Epoch: 7 [=>             ] 9.5% Loss: 0.1189, Epoch 7, Batch 11, CE_loss: 0.10149035602807999, Dice_loss: 0.007979062385857105, Consistency_loss: 0.0005154780810698867\n",
      "[Training] Epoch: 7 [=>             ] 10.3% Loss: 0.1197, Epoch 7, Batch 12, CE_loss: 0.1192220002412796, Dice_loss: 0.009921750985085964, Consistency_loss: 0.00042195283458568156\n",
      "[Training] Epoch: 7 [=>             ] 11.1% Loss: 0.1185, Epoch 7, Batch 13, CE_loss: 0.09501393884420395, Dice_loss: 0.007255008909851313, Consistency_loss: 0.00034444464836269617\n",
      "[Training] Epoch: 7 [=>             ] 11.9% Loss: 0.1182, Epoch 7, Batch 14, CE_loss: 0.10479208827018738, Dice_loss: 0.008483103476464748, Consistency_loss: 0.0004164033744018525\n",
      "[Training] Epoch: 7 [=>             ] 12.7% Loss: 0.1177, Epoch 7, Batch 15, CE_loss: 0.1022300198674202, Dice_loss: 0.008173209615051746, Consistency_loss: 0.00046650032163597643\n",
      "[Training] Epoch: 7 [==>            ] 13.5% Loss: 0.1180, Epoch 7, Batch 16, CE_loss: 0.11217691004276276, Dice_loss: 0.009547868743538857, Consistency_loss: 0.0003406933683436364\n",
      "[Training] Epoch: 7 [==>            ] 14.3% Loss: 0.1171, Epoch 7, Batch 17, CE_loss: 0.09416957199573517, Dice_loss: 0.0067560020834207535, Consistency_loss: 0.0004624366411007941\n",
      "[Training] Epoch: 7 [==>            ] 15.1% Loss: 0.1162, Epoch 7, Batch 18, CE_loss: 0.09415678679943085, Dice_loss: 0.00704674469307065, Consistency_loss: 2.980029421451036e-05\n",
      "[Training] Epoch: 7 [==>            ] 15.9% Loss: 0.1148, Epoch 7, Batch 19, CE_loss: 0.08167806267738342, Dice_loss: 0.00513170100748539, Consistency_loss: 0.000308122398564592\n",
      "[Training] Epoch: 7 [==>            ] 16.7% Loss: 0.1144, Epoch 7, Batch 20, CE_loss: 0.09807596355676651, Dice_loss: 0.007686916273087263, Consistency_loss: 0.0003239171055611223\n",
      "[Training] Epoch: 7 [==>            ] 17.5% Loss: 0.1146, Epoch 7, Batch 21, CE_loss: 0.1112443283200264, Dice_loss: 0.009066645056009293, Consistency_loss: 0.00025341505534015596\n",
      "[Training] Epoch: 7 [==>            ] 18.3% Loss: 0.1133, Epoch 7, Batch 22, CE_loss: 0.0789700448513031, Dice_loss: 0.0049974205903708935, Consistency_loss: 0.00019644781423266977\n",
      "[Training] Epoch: 7 [==>            ] 19.0% Loss: 0.1130, Epoch 7, Batch 23, CE_loss: 0.09731706976890564, Dice_loss: 0.007215088699012995, Consistency_loss: 0.0001555543130962178\n",
      "[Training] Epoch: 7 [==>            ] 19.8% Loss: 0.1136, Epoch 7, Batch 24, CE_loss: 0.11935118585824966, Dice_loss: 0.010332745499908924, Consistency_loss: 0.00016543529636692256\n",
      "[Training] Epoch: 7 [===>           ] 20.6% Loss: 0.1128, Epoch 7, Batch 25, CE_loss: 0.08554568886756897, Dice_loss: 0.0056922645308077335, Consistency_loss: 0.0002714875154197216\n",
      "[Training] Epoch: 7 [===>           ] 21.4% Loss: 0.1126, Epoch 7, Batch 26, CE_loss: 0.1006830632686615, Dice_loss: 0.007951203733682632, Consistency_loss: 0.00017269086674787104\n",
      "[Training] Epoch: 7 [===>           ] 22.2% Loss: 0.1121, Epoch 7, Batch 27, CE_loss: 0.09181757271289825, Dice_loss: 0.006783986464142799, Consistency_loss: 0.00015297600475605577\n",
      "[Training] Epoch: 7 [===>           ] 23.0% Loss: 0.1113, Epoch 7, Batch 28, CE_loss: 0.08218177407979965, Dice_loss: 0.005563330836594105, Consistency_loss: 0.00022998089843895286\n",
      "[Training] Epoch: 7 [===>           ] 23.8% Loss: 0.1104, Epoch 7, Batch 29, CE_loss: 0.08002970367670059, Dice_loss: 0.004830712452530861, Consistency_loss: 0.0004389990062918514\n",
      "[Training] Epoch: 7 [===>           ] 24.6% Loss: 0.1099, Epoch 7, Batch 30, CE_loss: 0.08576293289661407, Dice_loss: 0.006020987406373024, Consistency_loss: 0.0004800841852556914\n",
      "[Training] Epoch: 7 [===>           ] 25.4% Loss: 0.1101, Epoch 7, Batch 31, CE_loss: 0.10911936312913895, Dice_loss: 0.009366479702293873, Consistency_loss: 0.00023835919273551553\n",
      "[Training] Epoch: 7 [===>           ] 26.2% Loss: 0.1107, Epoch 7, Batch 32, CE_loss: 0.11826574057340622, Dice_loss: 0.00990570243448019, Consistency_loss: 0.000313695112708956\n",
      "[Training] Epoch: 7 [====>          ] 27.0% Loss: 0.1108, Epoch 7, Batch 33, CE_loss: 0.10467630624771118, Dice_loss: 0.008641371503472328, Consistency_loss: 0.0005680921021848917\n",
      "[Training] Epoch: 7 [====>          ] 27.8% Loss: 0.1101, Epoch 7, Batch 34, CE_loss: 0.08106507360935211, Dice_loss: 0.0054149329662323, Consistency_loss: 0.0006378897815011442\n",
      "[Training] Epoch: 7 [====>          ] 28.6% Loss: 0.1105, Epoch 7, Batch 35, CE_loss: 0.11482573300600052, Dice_loss: 0.009933525696396828, Consistency_loss: 0.00030505386530421674\n",
      "[Training] Epoch: 7 [====>          ] 29.4% Loss: 0.1110, Epoch 7, Batch 36, CE_loss: 0.11784981191158295, Dice_loss: 0.010374006815254688, Consistency_loss: 3.8605820009252056e-05\n",
      "[Training] Epoch: 7 [====>          ] 30.2% Loss: 0.1108, Epoch 7, Batch 37, CE_loss: 0.09503814578056335, Dice_loss: 0.007318452466279268, Consistency_loss: 0.000359151978045702\n",
      "[Training] Epoch: 7 [====>          ] 31.0% Loss: 0.1107, Epoch 7, Batch 38, CE_loss: 0.09928861260414124, Dice_loss: 0.007830683141946793, Consistency_loss: 1.487051667936612e-05\n",
      "[Training] Epoch: 7 [====>          ] 31.7% Loss: 0.1102, Epoch 7, Batch 39, CE_loss: 0.08529943972826004, Dice_loss: 0.0058125704526901245, Consistency_loss: 0.0005230228416621685\n",
      "[Training] Epoch: 7 [====>          ] 32.5% Loss: 0.1106, Epoch 7, Batch 40, CE_loss: 0.1138630136847496, Dice_loss: 0.009920114651322365, Consistency_loss: 0.0003219729114789516\n",
      "[Training] Epoch: 7 [=====>         ] 33.3% Loss: 0.1102, Epoch 7, Batch 41, CE_loss: 0.08976230770349503, Dice_loss: 0.006600746884942055, Consistency_loss: 0.0002594742109067738\n",
      "[Training] Epoch: 7 [=====>         ] 34.1% Loss: 0.1109, Epoch 7, Batch 42, CE_loss: 0.12833480536937714, Dice_loss: 0.011068090796470642, Consistency_loss: 1.692917794571258e-05\n",
      "[Training] Epoch: 7 [=====>         ] 34.9% Loss: 0.1111, Epoch 7, Batch 43, CE_loss: 0.1082807332277298, Dice_loss: 0.008963075466454029, Consistency_loss: 0.00047109415754675865\n",
      "[Training] Epoch: 7 [=====>         ] 35.7% Loss: 0.1106, Epoch 7, Batch 44, CE_loss: 0.08312593400478363, Dice_loss: 0.005281582474708557, Consistency_loss: 0.00047218697727657855\n",
      "[Training] Epoch: 7 [=====>         ] 36.5% Loss: 0.1104, Epoch 7, Batch 45, CE_loss: 0.0953332856297493, Dice_loss: 0.00751000689342618, Consistency_loss: 0.0005398492212407291\n",
      "[Training] Epoch: 7 [=====>         ] 37.3% Loss: 0.1104, Epoch 7, Batch 46, CE_loss: 0.10148525983095169, Dice_loss: 0.008133485913276672, Consistency_loss: 0.000386440078727901\n",
      "[Training] Epoch: 7 [=====>         ] 38.1% Loss: 0.1101, Epoch 7, Batch 47, CE_loss: 0.09037752449512482, Dice_loss: 0.0067155007272958755, Consistency_loss: 1.261204215552425e-05\n",
      "[Training] Epoch: 7 [=====>         ] 38.9% Loss: 0.1098, Epoch 7, Batch 48, CE_loss: 0.0880543440580368, Dice_loss: 0.006544965784996748, Consistency_loss: 0.00031138482154347\n",
      "[Training] Epoch: 7 [=====>         ] 39.7% Loss: 0.1099, Epoch 7, Batch 49, CE_loss: 0.10479626804590225, Dice_loss: 0.008509639650583267, Consistency_loss: 0.0004692533111665398\n",
      "[Training] Epoch: 7 [======>        ] 40.5% Loss: 0.1101, Epoch 7, Batch 50, CE_loss: 0.1107393205165863, Dice_loss: 0.00957740843296051, Consistency_loss: 0.0005502261919900775\n",
      "[Training] Epoch: 7 [======>        ] 41.3% Loss: 0.1099, Epoch 7, Batch 51, CE_loss: 0.09181492030620575, Dice_loss: 0.00676801847293973, Consistency_loss: 0.00047102916869334877\n",
      "[Training] Epoch: 7 [======>        ] 42.1% Loss: 0.1093, Epoch 7, Batch 52, CE_loss: 0.07299184054136276, Dice_loss: 0.004276174586266279, Consistency_loss: 0.0003393427177798003\n",
      "[Training] Epoch: 7 [======>        ] 42.9% Loss: 0.1099, Epoch 7, Batch 53, CE_loss: 0.13271594047546387, Dice_loss: 0.011893433518707752, Consistency_loss: 0.00021596942679025233\n",
      "[Training] Epoch: 7 [======>        ] 43.7% Loss: 0.1098, Epoch 7, Batch 54, CE_loss: 0.09248654544353485, Dice_loss: 0.007024133577942848, Consistency_loss: 0.00020463169494178146\n",
      "[Training] Epoch: 7 [======>        ] 44.4% Loss: 0.1096, Epoch 7, Batch 55, CE_loss: 0.09274748712778091, Dice_loss: 0.0071652536280453205, Consistency_loss: 0.0003632409207057208\n",
      "[Training] Epoch: 7 [======>        ] 45.2% Loss: 0.1096, Epoch 7, Batch 56, CE_loss: 0.10382964462041855, Dice_loss: 0.008456907235085964, Consistency_loss: 0.00027261965442448854\n",
      "[Training] Epoch: 7 [======>        ] 46.0% Loss: 0.1095, Epoch 7, Batch 57, CE_loss: 0.09441961348056793, Dice_loss: 0.007327830884605646, Consistency_loss: 0.00019730294297914952\n",
      "[Training] Epoch: 7 [=======>       ] 46.8% Loss: 0.1097, Epoch 7, Batch 58, CE_loss: 0.11331441253423691, Dice_loss: 0.009540144354104996, Consistency_loss: 0.00024155204300768673\n",
      "[Training] Epoch: 7 [=======>       ] 47.6% Loss: 0.1096, Epoch 7, Batch 59, CE_loss: 0.09170596301555634, Dice_loss: 0.006999144330620766, Consistency_loss: 0.0003442814340814948\n",
      "[Training] Epoch: 7 [=======>       ] 48.4% Loss: 0.1098, Epoch 7, Batch 60, CE_loss: 0.11351843923330307, Dice_loss: 0.010035905987024307, Consistency_loss: 0.0004316476115491241\n",
      "[Training] Epoch: 7 [=======>       ] 49.2% Loss: 0.1094, Epoch 7, Batch 61, CE_loss: 0.07820054888725281, Dice_loss: 0.00499326316639781, Consistency_loss: 0.0003947196528315544\n",
      "[Training] Epoch: 7 [=======>       ] 50.0% Loss: 0.1093, Epoch 7, Batch 62, CE_loss: 0.09473668038845062, Dice_loss: 0.007395511958748102, Consistency_loss: 0.0004675316740758717\n",
      "[Training] Epoch: 7 [=======>       ] 50.8% Loss: 0.1090, Epoch 7, Batch 63, CE_loss: 0.08640369027853012, Dice_loss: 0.006306723225861788, Consistency_loss: 0.0004237272369209677\n",
      "[Training] Epoch: 7 [=======>       ] 51.6% Loss: 0.1091, Epoch 7, Batch 64, CE_loss: 0.10357481986284256, Dice_loss: 0.008586627431213856, Consistency_loss: 0.0005659283488057554\n",
      "[Training] Epoch: 7 [=======>       ] 52.4% Loss: 0.1087, Epoch 7, Batch 65, CE_loss: 0.07877805829048157, Dice_loss: 0.005170217249542475, Consistency_loss: 0.0005173346144147217\n",
      "[Training] Epoch: 7 [=======>       ] 53.2% Loss: 0.1085, Epoch 7, Batch 66, CE_loss: 0.08743095397949219, Dice_loss: 0.006482273805886507, Consistency_loss: 0.0001763761683832854\n",
      "[Training] Epoch: 7 [========>      ] 54.0% Loss: 0.1083, Epoch 7, Batch 67, CE_loss: 0.09099940955638885, Dice_loss: 0.006836807820945978, Consistency_loss: 1.578739465912804e-05\n",
      "[Training] Epoch: 7 [========>      ] 54.8% Loss: 0.1082, Epoch 7, Batch 68, CE_loss: 0.0930568128824234, Dice_loss: 0.007222911808639765, Consistency_loss: 0.00030742998933419585\n",
      "[Training] Epoch: 7 [========>      ] 55.6% Loss: 0.1080, Epoch 7, Batch 69, CE_loss: 0.08531198650598526, Dice_loss: 0.006213069427758455, Consistency_loss: 0.00036185310455039144\n",
      "[Training] Epoch: 7 [========>      ] 56.3% Loss: 0.1080, Epoch 7, Batch 70, CE_loss: 0.10013452917337418, Dice_loss: 0.007792640011757612, Consistency_loss: 0.0010502320947125554\n",
      "[Training] Epoch: 7 [========>      ] 57.1% Loss: 0.1076, Epoch 7, Batch 71, CE_loss: 0.07395149022340775, Dice_loss: 0.004730898421257734, Consistency_loss: 0.0008858772343955934\n",
      "[Training] Epoch: 7 [========>      ] 57.9% Loss: 0.1077, Epoch 7, Batch 72, CE_loss: 0.10539379715919495, Dice_loss: 0.008552063256502151, Consistency_loss: 0.0007457408937625587\n",
      "[Training] Epoch: 7 [========>      ] 58.7% Loss: 0.1077, Epoch 7, Batch 73, CE_loss: 0.10226356238126755, Dice_loss: 0.008622434921562672, Consistency_loss: 0.000320849590934813\n",
      "[Training] Epoch: 7 [========>      ] 59.5% Loss: 0.1081, Epoch 7, Batch 74, CE_loss: 0.122314453125, Dice_loss: 0.010602799244225025, Consistency_loss: 0.0006057313876226544\n",
      "[Training] Epoch: 7 [=========>     ] 60.3% Loss: 0.1083, Epoch 7, Batch 75, CE_loss: 0.11163768172264099, Dice_loss: 0.009332273155450821, Consistency_loss: 0.0006949384114705026\n",
      "[Training] Epoch: 7 [=========>     ] 61.1% Loss: 0.1083, Epoch 7, Batch 76, CE_loss: 0.10440555959939957, Dice_loss: 0.008413500152528286, Consistency_loss: 0.0006166956154629588\n",
      "[Training] Epoch: 7 [=========>     ] 61.9% Loss: 0.1082, Epoch 7, Batch 77, CE_loss: 0.09444171190261841, Dice_loss: 0.007180121727287769, Consistency_loss: 0.00040642169187776744\n",
      "[Training] Epoch: 7 [=========>     ] 62.7% Loss: 0.1082, Epoch 7, Batch 78, CE_loss: 0.09768208116292953, Dice_loss: 0.00759844807907939, Consistency_loss: 0.0005890930769965053\n",
      "[Training] Epoch: 7 [=========>     ] 63.5% Loss: 0.1082, Epoch 7, Batch 79, CE_loss: 0.0987899899482727, Dice_loss: 0.008114675059914589, Consistency_loss: 0.00045753337326459587\n",
      "[Training] Epoch: 7 [=========>     ] 64.3% Loss: 0.1080, Epoch 7, Batch 80, CE_loss: 0.08812884986400604, Dice_loss: 0.0065423729829490185, Consistency_loss: 3.716148421517573e-05\n",
      "[Training] Epoch: 7 [=========>     ] 65.1% Loss: 0.1081, Epoch 7, Batch 81, CE_loss: 0.10158925503492355, Dice_loss: 0.008564580231904984, Consistency_loss: 0.0006966700893826783\n",
      "[Training] Epoch: 7 [=========>     ] 65.9% Loss: 0.1079, Epoch 7, Batch 82, CE_loss: 0.08700207620859146, Dice_loss: 0.006474754307419062, Consistency_loss: 0.0003529760579112917\n",
      "[Training] Epoch: 7 [==========>    ] 66.7% Loss: 0.1083, Epoch 7, Batch 83, CE_loss: 0.13029608130455017, Dice_loss: 0.011951753869652748, Consistency_loss: 0.0003143288486171514\n",
      "[Training] Epoch: 7 [==========>    ] 67.5% Loss: 0.1081, Epoch 7, Batch 84, CE_loss: 0.08591651171445847, Dice_loss: 0.006111860740929842, Consistency_loss: 0.00043231630115769804\n",
      "[Training] Epoch: 7 [==========>    ] 68.3% Loss: 0.1082, Epoch 7, Batch 85, CE_loss: 0.10808997601270676, Dice_loss: 0.009323484264314175, Consistency_loss: 3.1820596632314846e-05\n",
      "[Training] Epoch: 7 [==========>    ] 69.0% Loss: 0.1082, Epoch 7, Batch 86, CE_loss: 0.09989803284406662, Dice_loss: 0.008109454065561295, Consistency_loss: 0.0008312555146403611\n",
      "[Training] Epoch: 7 [==========>    ] 69.8% Loss: 0.1080, Epoch 7, Batch 87, CE_loss: 0.08342927694320679, Dice_loss: 0.005801189225167036, Consistency_loss: 0.0003253864706493914\n",
      "[Training] Epoch: 7 [==========>    ] 70.6% Loss: 0.1080, Epoch 7, Batch 88, CE_loss: 0.09966395050287247, Dice_loss: 0.008249197155237198, Consistency_loss: 6.355126242851838e-05\n",
      "[Training] Epoch: 7 [==========>    ] 71.4% Loss: 0.1081, Epoch 7, Batch 89, CE_loss: 0.10723519325256348, Dice_loss: 0.009180951863527298, Consistency_loss: 0.0003619114577304572\n",
      "[Training] Epoch: 7 [==========>    ] 72.2% Loss: 0.1079, Epoch 7, Batch 90, CE_loss: 0.08119657635688782, Dice_loss: 0.00583023764193058, Consistency_loss: 0.0003985115035902709\n",
      "[Training] Epoch: 7 [==========>    ] 73.0% Loss: 0.1081, Epoch 7, Batch 91, CE_loss: 0.11930610984563828, Dice_loss: 0.010728192515671253, Consistency_loss: 0.00042824522824957967\n",
      "[Training] Epoch: 7 [===========>   ] 73.8% Loss: 0.1084, Epoch 7, Batch 92, CE_loss: 0.11783357709646225, Dice_loss: 0.010731831192970276, Consistency_loss: 0.00047698267735540867\n",
      "[Training] Epoch: 7 [===========>   ] 74.6% Loss: 0.1083, Epoch 7, Batch 93, CE_loss: 0.08995799720287323, Dice_loss: 0.00680788466706872, Consistency_loss: 0.00042595123522914946\n",
      "[Training] Epoch: 7 [===========>   ] 75.4% Loss: 0.1081, Epoch 7, Batch 94, CE_loss: 0.08278514444828033, Dice_loss: 0.0060948822647333145, Consistency_loss: 0.0003279094526078552\n",
      "[Training] Epoch: 7 [===========>   ] 76.2% Loss: 0.1079, Epoch 7, Batch 95, CE_loss: 0.08476181328296661, Dice_loss: 0.005986538715660572, Consistency_loss: 0.0005759656778536737\n",
      "[Training] Epoch: 7 [===========>   ] 77.0% Loss: 0.1079, Epoch 7, Batch 96, CE_loss: 0.1056828573346138, Dice_loss: 0.00850446242839098, Consistency_loss: 0.00034150583087466657\n",
      "[Training] Epoch: 7 [===========>   ] 77.8% Loss: 0.1078, Epoch 7, Batch 97, CE_loss: 0.08760832250118256, Dice_loss: 0.006724709644913673, Consistency_loss: 0.00021852469944860786\n",
      "[Training] Epoch: 7 [===========>   ] 78.6% Loss: 0.1076, Epoch 7, Batch 98, CE_loss: 0.08147485554218292, Dice_loss: 0.0059067788533866405, Consistency_loss: 0.00022408294898923486\n",
      "[Training] Epoch: 7 [===========>   ] 79.4% Loss: 0.1073, Epoch 7, Batch 99, CE_loss: 0.07189696282148361, Dice_loss: 0.004421514458954334, Consistency_loss: 0.0004891221760772169\n",
      "[Training] Epoch: 7 [============>  ] 80.2% Loss: 0.1074, Epoch 7, Batch 100, CE_loss: 0.11138252168893814, Dice_loss: 0.009818932972848415, Consistency_loss: 0.000425548292696476\n",
      "[Training] Epoch: 7 [============>  ] 81.0% Loss: 0.1074, Epoch 7, Batch 101, CE_loss: 0.09220262616872787, Dice_loss: 0.007313454523682594, Consistency_loss: 0.00041861561476252973\n",
      "[Training] Epoch: 7 [============>  ] 81.7% Loss: 0.1072, Epoch 7, Batch 102, CE_loss: 0.0877154991030693, Dice_loss: 0.0067238155752420425, Consistency_loss: 0.00012710884038824588\n",
      "[Training] Epoch: 7 [============>  ] 82.5% Loss: 0.1070, Epoch 7, Batch 103, CE_loss: 0.07585114985704422, Dice_loss: 0.005033737514168024, Consistency_loss: 0.00041259839781560004\n",
      "[Training] Epoch: 7 [============>  ] 83.3% Loss: 0.1070, Epoch 7, Batch 104, CE_loss: 0.09816883504390717, Dice_loss: 0.007894644513726234, Consistency_loss: 0.00029442805680446327\n",
      "[Training] Epoch: 7 [============>  ] 84.1% Loss: 0.1069, Epoch 7, Batch 105, CE_loss: 0.09017500281333923, Dice_loss: 0.007140979636460543, Consistency_loss: 0.00044983052066527307\n",
      "[Training] Epoch: 7 [============>  ] 84.9% Loss: 0.1067, Epoch 7, Batch 106, CE_loss: 0.07597626745700836, Dice_loss: 0.004697719588875771, Consistency_loss: 0.0005627888604067266\n",
      "[Training] Epoch: 7 [============>  ] 85.7% Loss: 0.1067, Epoch 7, Batch 107, CE_loss: 0.0997391939163208, Dice_loss: 0.008367696776986122, Consistency_loss: 3.4445663914084435e-05\n",
      "[Training] Epoch: 7 [============>  ] 86.5% Loss: 0.1064, Epoch 7, Batch 108, CE_loss: 0.07583066076040268, Dice_loss: 0.005008524749428034, Consistency_loss: 0.00023481711104977876\n",
      "[Training] Epoch: 7 [=============> ] 87.3% Loss: 0.1064, Epoch 7, Batch 109, CE_loss: 0.09754917770624161, Dice_loss: 0.007796538062393665, Consistency_loss: 3.9071455830708146e-05\n",
      "[Training] Epoch: 7 [=============> ] 88.1% Loss: 0.1063, Epoch 7, Batch 110, CE_loss: 0.0872085765004158, Dice_loss: 0.006716475356370211, Consistency_loss: 0.0004962129751220345\n",
      "[Training] Epoch: 7 [=============> ] 88.9% Loss: 0.1063, Epoch 7, Batch 111, CE_loss: 0.09937980771064758, Dice_loss: 0.008314643055200577, Consistency_loss: 0.0003259573131799698\n",
      "[Training] Epoch: 7 [=============> ] 89.7% Loss: 0.1061, Epoch 7, Batch 112, CE_loss: 0.07316599041223526, Dice_loss: 0.004627731628715992, Consistency_loss: 0.0001683291484368965\n",
      "[Training] Epoch: 7 [=============> ] 90.5% Loss: 0.1061, Epoch 7, Batch 113, CE_loss: 0.10417257994413376, Dice_loss: 0.008543167263269424, Consistency_loss: 0.00018460757564753294\n",
      "[Training] Epoch: 7 [=============> ] 91.3% Loss: 0.1061, Epoch 7, Batch 114, CE_loss: 0.08932740241289139, Dice_loss: 0.006968450732529163, Consistency_loss: 0.00024248965200968087\n",
      "[Training] Epoch: 7 [=============> ] 92.1% Loss: 0.1060, Epoch 7, Batch 115, CE_loss: 0.09087121486663818, Dice_loss: 0.007005796302109957, Consistency_loss: 0.0002250867401016876\n",
      "[Training] Epoch: 7 [=============> ] 92.9% Loss: 0.1062, Epoch 7, Batch 116, CE_loss: 0.11912376433610916, Dice_loss: 0.009617114439606667, Consistency_loss: 0.00046368432231247425\n",
      "[Training] Epoch: 7 [==============>] 93.7% Loss: 0.1061, Epoch 7, Batch 117, CE_loss: 0.08331546187400818, Dice_loss: 0.0061735245399177074, Consistency_loss: 0.00024144451890606433\n",
      "[Training] Epoch: 7 [==============>] 94.4% Loss: 0.1060, Epoch 7, Batch 118, CE_loss: 0.09105505794286728, Dice_loss: 0.007122328970581293, Consistency_loss: 0.00029145946609787643\n",
      "[Training] Epoch: 7 [==============>] 95.2% Loss: 0.1059, Epoch 7, Batch 119, CE_loss: 0.08824418485164642, Dice_loss: 0.007009551394730806, Consistency_loss: 0.0001720815635053441\n",
      "[Training] Epoch: 7 [==============>] 96.0% Loss: 0.1058, Epoch 7, Batch 120, CE_loss: 0.09152515232563019, Dice_loss: 0.007248902693390846, Consistency_loss: 0.0002739615156315267\n",
      "[Training] Epoch: 7 [==============>] 96.8% Loss: 0.1058, Epoch 7, Batch 121, CE_loss: 0.09027740359306335, Dice_loss: 0.007107085082679987, Consistency_loss: 0.00023270995006896555\n",
      "[Training] Epoch: 7 [==============>] 97.6% Loss: 0.1057, Epoch 7, Batch 122, CE_loss: 0.0877249464392662, Dice_loss: 0.006964650936424732, Consistency_loss: 0.00022001040633767843\n",
      "[Training] Epoch: 7 [==============>] 98.4% Loss: 0.1055, Epoch 7, Batch 123, CE_loss: 0.07756071537733078, Dice_loss: 0.005288556218147278, Consistency_loss: 0.0004403824859764427\n",
      "[Training] Epoch: 7 [==============>] 99.2% Loss: 0.1054, Epoch 7, Batch 124, CE_loss: 0.08110476285219193, Dice_loss: 0.00580830592662096, Consistency_loss: 0.0006846353062428534\n",
      "[Training] Epoch: 7 [DONE]                                 \n",
      "Epoch 7, Batch 125, CE_loss: 0.08961860090494156, Dice_loss: 0.007271102163940668, Consistency_loss: 0.00033462673309259117\n",
      "Epoch 7, Batch 125, CE_loss: 0.08961860090494156, Dice_loss: 0.007271102163940668, Consistency_loss: 0.00033462673309259117\n",
      "[Validation] Epoch: 7 [DONE]                                 \n",
      "[Epoch: 7, TrainLoss: 0.1053, TrainDice: 0.0076, ValLoss: 0.1614                                             \n",
      "Number of batches:  126\n",
      "[Training] Epoch: 8 [>              ] 0.8% Loss: 0.0888, Epoch 8, Batch 0, CE_loss: 0.08231975138187408, Dice_loss: 0.006220266688615084, Consistency_loss: 0.0002642052713781595\n",
      "[Training] Epoch: 8 [>              ] 1.6% Loss: 0.0840, Epoch 8, Batch 1, CE_loss: 0.07430758327245712, Dice_loss: 0.004715654533356428, Consistency_loss: 0.00019676299416460097\n",
      "[Training] Epoch: 8 [>              ] 2.4% Loss: 0.0949, Epoch 8, Batch 2, CE_loss: 0.10667470097541809, Dice_loss: 0.009562558494508266, Consistency_loss: 0.0003701749083120376\n",
      "[Training] Epoch: 8 [>              ] 3.2% Loss: 0.0940, Epoch 8, Batch 3, CE_loss: 0.08485735952854156, Dice_loss: 0.006514862645417452, Consistency_loss: 1.9501398128340952e-05\n",
      "[Training] Epoch: 8 [>              ] 4.0% Loss: 0.0976, Epoch 8, Batch 4, CE_loss: 0.10360762476921082, Dice_loss: 0.008553779684007168, Consistency_loss: 1.9451479602139443e-05\n",
      "[Training] Epoch: 8 [>              ] 4.8% Loss: 0.0947, Epoch 8, Batch 5, CE_loss: 0.0746760219335556, Dice_loss: 0.005216208286583424, Consistency_loss: 3.966755321016535e-05\n",
      "[Training] Epoch: 8 [>              ] 5.6% Loss: 0.1046, Epoch 8, Batch 6, CE_loss: 0.15123705565929413, Dice_loss: 0.012888560071587563, Consistency_loss: 3.350311817484908e-05\n",
      "[Training] Epoch: 8 [>              ] 6.3% Loss: 0.1064, Epoch 8, Batch 7, CE_loss: 0.10910776257514954, Dice_loss: 0.009914258494973183, Consistency_loss: 2.813735045492649e-05\n",
      "[Training] Epoch: 8 [=>             ] 7.1% Loss: 0.1102, Epoch 8, Batch 8, CE_loss: 0.12820808589458466, Dice_loss: 0.011716622859239578, Consistency_loss: 0.00028249574825167656\n",
      "[Training] Epoch: 8 [=>             ] 7.9% Loss: 0.1112, Epoch 8, Batch 9, CE_loss: 0.11005985736846924, Dice_loss: 0.009973544627428055, Consistency_loss: 4.607306982506998e-05\n",
      "[Training] Epoch: 8 [=>             ] 8.7% Loss: 0.1111, Epoch 8, Batch 10, CE_loss: 0.1016332358121872, Dice_loss: 0.008783617988228798, Consistency_loss: 1.982277535717003e-05\n",
      "[Training] Epoch: 8 [=>             ] 9.5% Loss: 0.1098, Epoch 8, Batch 11, CE_loss: 0.087888702750206, Dice_loss: 0.00665258476510644, Consistency_loss: 0.0004930499126203358\n",
      "[Training] Epoch: 8 [=>             ] 10.3% Loss: 0.1081, Epoch 8, Batch 12, CE_loss: 0.08136634528636932, Dice_loss: 0.00617161113768816, Consistency_loss: 2.3425718609360047e-05\n",
      "[Training] Epoch: 8 [=>             ] 11.1% Loss: 0.1076, Epoch 8, Batch 13, CE_loss: 0.09358150511980057, Dice_loss: 0.007965347729623318, Consistency_loss: 0.0006678501376882195\n",
      "[Training] Epoch: 8 [=>             ] 11.9% Loss: 0.1078, Epoch 8, Batch 14, CE_loss: 0.10099653899669647, Dice_loss: 0.008482486009597778, Consistency_loss: 0.00044554268242791295\n",
      "[Training] Epoch: 8 [=>             ] 12.7% Loss: 0.1087, Epoch 8, Batch 15, CE_loss: 0.11159003525972366, Dice_loss: 0.0097902687266469, Consistency_loss: 0.00037559072370640934\n",
      "[Training] Epoch: 8 [==>            ] 13.5% Loss: 0.1090, Epoch 8, Batch 16, CE_loss: 0.10507630556821823, Dice_loss: 0.009440463967621326, Consistency_loss: 5.8234330936102197e-05\n",
      "[Training] Epoch: 8 [==>            ] 14.3% Loss: 0.1083, Epoch 8, Batch 17, CE_loss: 0.08886387199163437, Dice_loss: 0.007271307986229658, Consistency_loss: 0.0006217995542101562\n",
      "[Training] Epoch: 8 [==>            ] 15.1% Loss: 0.1082, Epoch 8, Batch 18, CE_loss: 0.09713249653577805, Dice_loss: 0.007823637686669827, Consistency_loss: 3.92648798879236e-05\n",
      "[Training] Epoch: 8 [==>            ] 15.9% Loss: 0.1076, Epoch 8, Batch 19, CE_loss: 0.08929356932640076, Dice_loss: 0.006798068061470985, Consistency_loss: 0.0002971497888211161\n",
      "[Training] Epoch: 8 [==>            ] 16.7% Loss: 0.1066, Epoch 8, Batch 20, CE_loss: 0.07998671382665634, Dice_loss: 0.006090161390602589, Consistency_loss: 0.00028212927281856537\n",
      "[Training] Epoch: 8 [==>            ] 17.5% Loss: 0.1059, Epoch 8, Batch 21, CE_loss: 0.0847509503364563, Dice_loss: 0.0063998582772910595, Consistency_loss: 0.0002966663450933993\n",
      "[Training] Epoch: 8 [==>            ] 18.3% Loss: 0.1051, Epoch 8, Batch 22, CE_loss: 0.08141718059778214, Dice_loss: 0.006214642897248268, Consistency_loss: 0.0003719947417266667\n",
      "[Training] Epoch: 8 [==>            ] 19.0% Loss: 0.1048, Epoch 8, Batch 23, CE_loss: 0.09052978456020355, Dice_loss: 0.007340383715927601, Consistency_loss: 0.00031306134769693017\n",
      "[Training] Epoch: 8 [==>            ] 19.8% Loss: 0.1046, Epoch 8, Batch 24, CE_loss: 0.0920426994562149, Dice_loss: 0.006819758098572493, Consistency_loss: 0.0002888251328840852\n",
      "[Training] Epoch: 8 [===>           ] 20.6% Loss: 0.1037, Epoch 8, Batch 25, CE_loss: 0.07687096297740936, Dice_loss: 0.005465975496917963, Consistency_loss: 0.00025752908550202847\n",
      "[Training] Epoch: 8 [===>           ] 21.4% Loss: 0.1035, Epoch 8, Batch 26, CE_loss: 0.09077610820531845, Dice_loss: 0.0072365556843578815, Consistency_loss: 0.00018871166685130447\n",
      "[Training] Epoch: 8 [===>           ] 22.2% Loss: 0.1023, Epoch 8, Batch 27, CE_loss: 0.06465812772512436, Dice_loss: 0.0039882659912109375, Consistency_loss: 0.00016208014858420938\n",
      "[Training] Epoch: 8 [===>           ] 23.0% Loss: 0.1020, Epoch 8, Batch 28, CE_loss: 0.08763835579156876, Dice_loss: 0.006795045919716358, Consistency_loss: 0.00019341408915352076\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter()\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(\"~~~~~~~~  Starting the training... ~~~~~~\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "num_classes = 4\n",
    "\n",
    "# Set device depending on the availability of GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "# elif torch.mps.is_available():  # Apple M-series of chips\n",
    "#     device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "print(\"~~~~~~~~~~~ Creating the UNet model ~~~~~~~~~~\")\n",
    "print(\" Model Name: {}\".format(modelName))\n",
    "\n",
    "## CREATION OF YOUR MODEL\n",
    "net = UNet(num_classes).to(device)\n",
    "\n",
    "print(\n",
    "    \"Total params: {0:,}\".format(\n",
    "        sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "    )\n",
    ")\n",
    "\n",
    "# DEFINE YOUR OUTPUT COMPONENTS (e.g., SOFTMAX, LOSS FUNCTION, ETC)\n",
    "softMax = torch.nn.Softmax(dim=1)\n",
    "CE_loss = torch.nn.CrossEntropyLoss()\n",
    "consistency_regularizer = ConsistencyRegularization(transformation_fn=random_transformation_fn)\n",
    "\n",
    "\n",
    "## PUT EVERYTHING IN GPU RESOURCES\n",
    "if torch.cuda.is_available():\n",
    "    net.cuda()\n",
    "    softMax.cuda()\n",
    "    CE_loss.cuda()\n",
    "\n",
    "## DEFINE YOUR OPTIMIZER\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "### To save statistics ####\n",
    "train_losses = []\n",
    "train_dc_losses = []\n",
    "val_losses = []\n",
    "val_dc_losses = []\n",
    "\n",
    "best_loss_val = 1000\n",
    "\n",
    "directory = \"Results/Statistics/\" + modelName\n",
    "\n",
    "print(\"~~~~~~~~~~~ Starting the training ~~~~~~~~~~\")\n",
    "if os.path.exists(directory) == False:\n",
    "    os.makedirs(directory)\n",
    "\n",
    "## START THE TRAINING\n",
    "\n",
    "## FOR EACH EPOCH\n",
    "for epoch in range(total_epochs):\n",
    "    net.train()\n",
    "    supervised_iter = iter(supervised_loader)\n",
    "    unsupervised_iter = iter(unsupervised_loader)\n",
    "    \n",
    "    num_batches = max(len(supervised_loader), len(unsupervised_loader))\n",
    "    print(\"Number of batches: \", num_batches)\n",
    "\n",
    "    running_train_loss = 0\n",
    "    running_dice_loss = 0\n",
    "\n",
    "    # Training loop\n",
    "    for idx in range(num_batches):\n",
    "        ### SUPERVISED BATCH\n",
    "        try :\n",
    "            supervised_data = next(supervised_iter)\n",
    "        except StopIteration:\n",
    "            supervised_iter = iter(supervised_loader)\n",
    "            supervised_data = next(supervised_iter)\n",
    "\n",
    "        ### Set to zero all the gradients\n",
    "        net.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        ## GET IMAGES, LABELS and IMG NAMES\n",
    "        images, labels, img_names = supervised_data\n",
    "\n",
    "        ### From numpy to torch variables\n",
    "        labels = utils.to_var(labels).to(device)\n",
    "        images = utils.to_var(images).to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        net_predictions = net(images)\n",
    "\n",
    "        # Get the segmentation classes\n",
    "        segmentation_classes = utils.getTargetSegmentation(labels)\n",
    "        # Modify segmentation classes to be one-hot encoded (shape [batch_size, num_classes, height, width])\n",
    "        dice_target = F.one_hot(segmentation_classes, num_classes = num_classes).permute(0,3,1,2).contiguous()\n",
    "\n",
    "        # Compute the loss\n",
    "        ce_loss = ce_loss_weight * CE_loss(net_predictions, segmentation_classes) \n",
    "        dice_loss = dice_loss_weight * DiceLoss()(net_predictions, dice_target)  \n",
    "        loss = ce_loss + dice_loss \n",
    "        running_train_loss += ce_loss.item() + dice_loss.item() \n",
    "        # dice_loss = dice_coefficient(net_predictions, labels)\n",
    "        # dice_loss = utils.compute_dsc(net_predictions, labels)\n",
    "        running_dice_loss += dice_loss\n",
    "\n",
    "        # Backprop\n",
    "        # loss.backward()\n",
    "        # optimizer.step()\n",
    "\n",
    "        ### UNSUPERVISED BATCH\n",
    "        try :\n",
    "            unsupervised_data = next(unsupervised_iter)\n",
    "        except StopIteration:\n",
    "            unsupervised_iter = iter(unsupervised_loader)\n",
    "            unsupervised_data = next(unsupervised_iter)\n",
    "        \n",
    "        unsupervised_images, _, __ = unsupervised_data\n",
    "        unsupervised_images = utils.to_var(unsupervised_images).to(device)\n",
    "\n",
    "        # net.zero_grad()\n",
    "        # optimizer.zero_grad()\n",
    "\n",
    "        consistency_loss = weight_TC * consistency_regularizer(net, unsupervised_images) \n",
    "        loss += consistency_loss\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_train_loss += consistency_loss.item()\n",
    "        running_dice_loss += 0\n",
    "\n",
    "        # Add the loss to the tensorboard every 5 batches\n",
    "        if idx % 10 == 0:\n",
    "            writer.add_scalar(\n",
    "                \"Loss/train\", running_train_loss / (idx + 1), epoch * len(supervised_loader) + idx\n",
    "            )\n",
    "            writer.add_scalar(\n",
    "                \"Dice/train\", running_dice_loss / (idx + 1), epoch * len(supervised_loader) + idx\n",
    "            )\n",
    "\n",
    "        if idx % 100 == 0:\n",
    "            # Also add visualizations of the images\n",
    "            probs = torch.softmax(net_predictions, dim=1)\n",
    "            y_pred = torch.argmax(probs, dim=1)\n",
    "            writer.add_figure('predictions vs. actuals',\n",
    "                        utils.plot_net_predictions(images, labels, y_pred, batch_size),\n",
    "                        global_step=epoch * len(supervised_loader) + idx)\n",
    "\n",
    "        # THIS IS JUST TO VISUALIZE THE TRAINING\n",
    "        printProgressBar(\n",
    "            idx + 1,\n",
    "            num_batches,\n",
    "            prefix=\"[Training] Epoch: {} \".format(epoch),\n",
    "            length=15,\n",
    "            suffix=\" Loss: {:.4f}, \".format(running_train_loss / (idx + 1)),\n",
    "        )\n",
    "        print(f\"Epoch {epoch}, Batch {idx}, CE_loss: {ce_loss.item()}, Dice_loss: {dice_loss.item()}, Consistency_loss: {consistency_loss.item()}\")\n",
    "\n",
    "    train_loss = running_train_loss / num_batches\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    train_dc_loss = running_dice_loss / num_batches\n",
    "    train_dc_losses.append(train_dc_loss)\n",
    "    # print(f\"Epoch {epoch}, Batch {idx}, CE_loss: {ce_loss.item()}, Dice_loss: {dice_loss.item()}, Consistency_loss: {consistency_loss.item()}\")\n",
    "    net.eval()\n",
    "    val_running_loss = 0\n",
    "    val_running_dc = 0\n",
    "\n",
    "    # Validation loop\n",
    "    with torch.no_grad():\n",
    "        for idx, data in enumerate(val_loader):\n",
    "            images, labels, img_names = data\n",
    "\n",
    "            labels = utils.to_var(labels).to(device)\n",
    "            images = utils.to_var(images).to(device)\n",
    "\n",
    "            net_predictions = net(images)\n",
    "\n",
    "            segmentation_classes = utils.getTargetSegmentation(labels)\n",
    "\n",
    "            loss = CE_loss(net_predictions, segmentation_classes) \n",
    "            val_running_loss += loss.item()\n",
    "\n",
    "            # dice_loss = dice_coefficient(net_predictions, labels)\n",
    "            dice_loss = utils.compute_dsc(net_predictions, labels)\n",
    "            val_running_dc += dice_loss\n",
    "\n",
    "            if idx % 10 == 0:\n",
    "                writer.add_scalar(\n",
    "                    \"Loss/val\",\n",
    "                    val_running_loss / (idx + 1),\n",
    "                    epoch * len(val_loader) + idx,\n",
    "                )\n",
    "                writer.add_scalar(\n",
    "                    \"Dice/val\",\n",
    "                    val_running_dc / (idx + 1),\n",
    "                    epoch * len(val_loader) + idx,\n",
    "                )\n",
    "\n",
    "            printProgressBar(\n",
    "                idx + 1,\n",
    "                len(val_loader),\n",
    "                prefix=\"[Validation] Epoch: {} \".format(epoch),\n",
    "                length=15,\n",
    "                suffix=\" Loss: {:.4f}, \".format(val_running_loss / (idx + 1)),\n",
    "            )\n",
    "\n",
    "    val_loss = val_running_loss / len(val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    dc_loss = val_running_dc / len(val_loader)\n",
    "    val_dc_losses.append(dc_loss)\n",
    "\n",
    "    # Check if model performed best and save it if true\n",
    "    if val_loss < best_loss_val:\n",
    "        best_loss_val = val_loss\n",
    "        if not os.path.exists(\"./models/\" + modelName):\n",
    "            os.makedirs(\"./models/\" + modelName)\n",
    "        torch.save(\n",
    "            net.state_dict(), \"./models/\" + modelName + \"/\" + str(epoch) + \"_Epoch\"\n",
    "        )\n",
    "\n",
    "    printProgressBar(\n",
    "        num_batches,\n",
    "        num_batches,\n",
    "        done=\"[Epoch: {}, TrainLoss: {:.4f}, TrainDice: {:.4f}, ValLoss: {:.4f}\".format(\n",
    "            epoch, train_loss, train_dc_loss, val_loss\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    np.save(os.path.join(directory, \"Losses.npy\"), train_losses)\n",
    "writer.flush()  # Flush the writer to ensure that all the data is written to disk\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd48e84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4172410f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
