{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f27e22b-c62f-4d9b-901a-64274891140c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runTraining(writer: SummaryWriter, loader, val_loader, modelName=\"Test_Model\", labeled_dataset_names=None):\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"~~~~~~~~  Starting the training for {modelName}... ~~~~~~\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    ## CREATION OF YOUR MODEL\n",
    "    print(f\" Model Name: {modelName}\")\n",
    "    net = UNet(num_classes).to(device)\n",
    "\n",
    "    print(\n",
    "        \"Total params: {0:,}\".format(\n",
    "            sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    softMax = torch.nn.Softmax(dim=1)\n",
    "    CE_loss = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "    train_losses = []\n",
    "    train_dc_losses = []\n",
    "    val_losses = []\n",
    "    val_dc_losses = []\n",
    "\n",
    "    best_loss_val = 1000\n",
    "\n",
    "    directory = f\"Results/Statistics/{modelName}\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    # START THE TRAINING\n",
    "    for epoch in range(total_epochs):\n",
    "        net.train()\n",
    "        num_batches = len(loader)\n",
    "        print(\"Number of batches: \", num_batches)\n",
    "\n",
    "        running_train_loss = 0\n",
    "        running_dice_loss = 0\n",
    "\n",
    "        for idx, data in enumerate(loader):\n",
    "            net.zero_grad()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            images, labels, img_names = data\n",
    "            labels = utils.to_var(labels).to(device)\n",
    "            images = utils.to_var(images).to(device)\n",
    "\n",
    "            net_predictions = net(images)\n",
    "\n",
    "            segmentation_classes = utils.getTargetSegmentation(labels)\n",
    "            loss = CE_loss(net_predictions, segmentation_classes)\n",
    "            running_train_loss += loss.item()\n",
    "            dice_loss = utils.compute_dsc(net_predictions, labels)\n",
    "            running_dice_loss += dice_loss\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if idx % 10 == 0:\n",
    "                writer.add_scalar(\n",
    "                    \"Loss/train\", running_train_loss / (idx + 1), epoch * len(loader) + idx\n",
    "                )\n",
    "                writer.add_scalar(\n",
    "                    \"Dice/train\", running_dice_loss / (idx + 1), epoch * len(loader) + idx\n",
    "                )\n",
    "\n",
    "            if idx % 100 == 0:\n",
    "                probs = torch.softmax(net_predictions, dim=1)\n",
    "                y_pred = torch.argmax(probs, dim=1)\n",
    "\n",
    "                annotated_img_names = [\n",
    "                    f\"{img} (Unlabeled)\" if labeled_dataset_names and img not in labeled_dataset_names else img\n",
    "                    for img in img_names\n",
    "                ]\n",
    "                writer.add_figure(\n",
    "                    \"predictions vs. actuals\",\n",
    "                    utils.plot_net_predictions(images, labels, y_pred, batch_size, annotated_img_names),\n",
    "                    global_step=epoch * len(loader) + idx,\n",
    "                )\n",
    "\n",
    "            printProgressBar(\n",
    "                idx + 1,\n",
    "                num_batches,\n",
    "                prefix=f\"[Training] Epoch: {epoch} \",\n",
    "                length=15,\n",
    "                suffix=f\" Loss: {running_train_loss / (idx + 1):.4f}, \",\n",
    "            )\n",
    "\n",
    "        train_loss = running_train_loss / num_batches\n",
    "        train_losses.append(train_loss)\n",
    "        train_dc_loss = running_dice_loss / num_batches\n",
    "        train_dc_losses.append(train_dc_loss)\n",
    "\n",
    "        # Validation\n",
    "        net.eval()\n",
    "        val_running_loss = 0\n",
    "        val_running_dc = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for idx, data in enumerate(val_loader):\n",
    "                images, labels, img_names = data\n",
    "                labels = utils.to_var(labels).to(device)\n",
    "                images = utils.to_var(images).to(device)\n",
    "\n",
    "                net_predictions = net(images)\n",
    "                segmentation_classes = utils.getTargetSegmentation(labels)\n",
    "                loss = CE_loss(net_predictions, segmentation_classes)\n",
    "                val_running_loss += loss.item()\n",
    "\n",
    "                dice_loss = utils.compute_dsc(net_predictions, labels)\n",
    "                val_running_dc += dice_loss\n",
    "\n",
    "                if idx % 10 == 0:\n",
    "                    writer.add_scalar(\n",
    "                        \"Loss/val\", val_running_loss / (idx + 1), epoch * len(val_loader) + idx\n",
    "                    )\n",
    "                    writer.add_scalar(\n",
    "                        \"Dice/val\", val_running_dc / (idx + 1), epoch * len(val_loader) + idx\n",
    "                    )\n",
    "\n",
    "                printProgressBar(\n",
    "                    idx + 1,\n",
    "                    len(val_loader),\n",
    "                    prefix=f\"[Validation] Epoch: {epoch} \",\n",
    "                    length=15,\n",
    "                    suffix=f\" Loss: {val_running_loss / (idx + 1):.4f}, \",\n",
    "                )\n",
    "\n",
    "        val_loss = val_running_loss / len(val_loader)\n",
    "        val_losses.append(val_loss)\n",
    "        dc_loss = val_running_dc / len(val_loader)\n",
    "        val_dc_losses.append(dc_loss)\n",
    "\n",
    "        if val_loss < best_loss_val:\n",
    "            best_loss_val = val_loss\n",
    "            if not os.path.exists(f\"./models/{modelName}\"):\n",
    "                os.makedirs(f\"./models/{modelName}\")\n",
    "            torch.save(\n",
    "                net.state_dict(), f\"./models/{modelName}/{epoch}_Epoch\"\n",
    "            )\n",
    "\n",
    "        printProgressBar(\n",
    "            num_batches,\n",
    "            num_batches,\n",
    "            done=f\"[Epoch: {epoch}, TrainLoss: {train_loss:.4f}, TrainDice: {train_dc_loss:.4f}, ValLoss: {val_loss:.4f}]\",\n",
    "        )\n",
    "\n",
    "        np.save(os.path.join(directory, \"Losses.npy\"), train_losses)\n",
    "    writer.flush()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
