{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b07cf2f-b81d-43ef-907a-c49fed2d95ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "from progressBar import printProgressBar\n",
    "\n",
    "import medicalDataLoader\n",
    "import argparse\n",
    "import utils\n",
    "from utils import inferenceTeacher\n",
    "\n",
    "\n",
    "from UNet_Base import *\n",
    "import random\n",
    "import torch\n",
    "import pdb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e976350-3fd5-4406-8511-86a06a9b4494",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fedb7747-3728-42ee-a895-d17dccae4fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!poetry shell\n",
    "#!poetry run tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54c80878",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = (\"background\", \"1–tbd\", \"2–tbd\", \"3–tbd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7464cf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspired by https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            classes[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            classes[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c636584b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coefficient(prediction, target, epsilon=1e-07): #compares this prediction model to validation model \n",
    "    prediction_copy = prediction.clone()\n",
    "\n",
    "    prediction_copy[prediction_copy < 0] = 0\n",
    "    prediction_copy[prediction_copy > 0] = 1\n",
    "\n",
    "    intersection = abs(torch.sum(prediction_copy * target))\n",
    "    union = abs(torch.sum(prediction_copy) + torch.sum(target))\n",
    "    dice = (2. * intersection + epsilon) / (union + epsilon)\n",
    "    \n",
    "    return dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d007e633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "batch_size = 8 #nb images processed at same time during training\n",
    "batch_size_val = 4 #nb images processed at same time during validation \n",
    "lr =  0.01   # Learning Rate\n",
    "total_epochs = 50  # Number of epochs (how many times the algorithm passes through training data)\n",
    "num_classes = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "789b9179-ead1-49f6-b00e-44ee5ddbcf5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Set device depending on the availability of GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.mps.is_available():  # Apple M-series of chips\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3566dc5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dataset: ./data/ \n"
     ]
    }
   ],
   "source": [
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "mask_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Define dataloaders\n",
    "root_dir = './data/'\n",
    "print(' Dataset: {} '.format(root_dir))\n",
    "\n",
    "train_set_full = medicalDataLoader.MedicalImageDataset('train',\n",
    "                                                    root_dir,\n",
    "                                                    transform=transform,\n",
    "                                                    mask_transform=mask_transform,\n",
    "                                                    augment=False,\n",
    "                                                    equalize=False)\n",
    "\n",
    "train_loader_full = DataLoader(train_set_full,\n",
    "                            batch_size=batch_size,\n",
    "                            worker_init_fn=np.random.seed(0),\n",
    "                            num_workers=0,\n",
    "                            shuffle=True)\n",
    "\n",
    "teacherTrain_set_full = medicalDataLoader.MedicalImageDataset('teacherTrain',\n",
    "                                                    root_dir,\n",
    "                                                    transform=transform,\n",
    "                                                    mask_transform=None,\n",
    "                                                    augment=False,\n",
    "                                                    equalize=False) #no transformation for now\n",
    "\n",
    "\n",
    "teacherTrain_loader_full = DataLoader(teacherTrain_set_full,\n",
    "                            batch_size=batch_size,\n",
    "                            worker_init_fn=np.random.seed(0),\n",
    "                            num_workers=0,\n",
    "                            shuffle=True)\n",
    "\n",
    "\n",
    "val_set = medicalDataLoader.MedicalImageDataset('val',\n",
    "                                                root_dir,\n",
    "                                                transform=transform,\n",
    "                                                mask_transform=mask_transform,\n",
    "                                                equalize=False)\n",
    "\n",
    "val_loader = DataLoader(val_set,\n",
    "                        batch_size=batch_size_val,\n",
    "                        worker_init_fn=np.random.seed(0),\n",
    "                        num_workers=0,\n",
    "                        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c2f9173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch dimensions:  torch.Size([8, 1, 256, 256])\n",
      "Mask batch dimensions:  torch.Size([8, 1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "for i, sample in enumerate(train_loader_full):\n",
    "    images, masks, _ = sample\n",
    "    print('Image batch dimensions: ', images.size()) #[batch_size, channels, height, width]\n",
    "    print('Mask batch dimensions: ', masks.size())\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20ac4eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runTraining(writer: SummaryWriter):\n",
    "    print(\"-\" * 40)\n",
    "    print(\"~~~~~~~~  Starting the training... ~~~~~~\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    print(\"~~~~~~~~~~~ Creating the UNet model ~~~~~~~~~~\")\n",
    "    modelName = \"Test_Model\"\n",
    "    print(\" Model Name: {}\".format(modelName))\n",
    "\n",
    "    ## CREATION OF YOUR MODEL\n",
    "    teacherNet = UNet(num_classes).to(device)\n",
    "\n",
    "    print(\n",
    "        \"Total params: {0:,}\".format(\n",
    "            sum(p.numel() for p in teacherNet.parameters() if p.requires_grad)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # DEFINE YOUR OUTPUT COMPONENTS (e.g., SOFTMAX, LOSS FUNCTION, ETC)\n",
    "    softMax = torch.nn.Softmax(dim=1)\n",
    "    CE_loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # # PUT EVERYTHING IN GPU RESOURCES\n",
    "    # if torch.cuda.is_available():\n",
    "    #     teacherNet.cuda()\n",
    "    #     softMax.cuda()\n",
    "    #     CE_loss.cuda()\n",
    "\n",
    "    ## DEFINE YOUR OPTIMIZER\n",
    "    optimizer = torch.optim.Adam(teacherNet.parameters(), lr=lr) #optimizer used (momentum +SGD)\n",
    "\n",
    "    ### To save statistics ####\n",
    "    train_losses = []\n",
    "    train_dc_losses = []\n",
    "    val_losses = []\n",
    "    val_dc_losses = []\n",
    "\n",
    "    best_loss_val = 1000\n",
    "\n",
    "    directory = \"Results/Statistics/\" + modelName\n",
    "\n",
    "    print(\"~~~~~~~~~~~ Starting the training ~~~~~~~~~~\")\n",
    "    if os.path.exists(directory) == False:\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    ## START THE TRAINING\n",
    "\n",
    "    ## FOR EACH EPOCH\n",
    "    for epoch in range(total_epochs):\n",
    "        teacherNet.train()\n",
    "\n",
    "        num_batches = len(train_loader_full) #26 batches of 8 images\n",
    "        print(\"Number of batches: \", num_batches)\n",
    "\n",
    "        running_train_loss = 0\n",
    "        running_dice_loss = 0\n",
    "\n",
    "        # Training loop\n",
    "        for idx, data in enumerate(train_loader_full): #idx : current batch number, data : images in that batch\n",
    "            ### Set to zero all the gradients\n",
    "            teacherNet.zero_grad()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            ## GET IMAGES, LABELS and IMG NAMES\n",
    "            images, labels, img_names = data #images with the corresponding label \n",
    "\n",
    "            ### From numpy to torch variables\n",
    "            labels = utils.to_var(labels).to(device)\n",
    "            images = utils.to_var(images).to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            teacherNet_predictions = teacherNet(images) #go through unet with images and get predictions (probabilities tensor)\n",
    "            #tensor of tables of predicted probabilities\n",
    "            \n",
    "\n",
    "            # Get the segmentation classes\n",
    "            segmentation_classes = utils.getTargetSegmentation(labels) #tensor of tables of 0(background), 1(1-tbd), 2(2-tbd), 3(3-tbd)\n",
    "\n",
    "            # Compute the loss\n",
    "            loss = CE_loss(teacherNet_predictions, segmentation_classes) #compare results and real segmentation\n",
    "            running_train_loss += loss.item()\n",
    "            # dice_loss = dice_coefficient(teacherNet_predictions, labels)\n",
    "            dice_loss = utils.compute_dsc(teacherNet_predictions, labels)\n",
    "            running_dice_loss += dice_loss\n",
    "\n",
    "            # Backprop\n",
    "            loss.backward() #calculates gradients from loss\n",
    "            optimizer.step() #use gradients just calculated to update weights of model \n",
    "\n",
    "            # Add the loss to the tensorboard every 5 batches\n",
    "            # if idx % 10 == 0:\n",
    "            #     writer.add_scalar(\n",
    "            #         \"Loss/train\", running_train_loss / (idx + 1), epoch * len(train_loader_full) + idx\n",
    "            #     )\n",
    "            #     writer.add_scalar(\n",
    "            #         \"Dice/train\", running_dice_loss / (idx + 1), epoch * len(train_loader_full) + idx\n",
    "            #     )\n",
    "\n",
    "            if idx % 100 == 0:\n",
    "                # Also add visualizations of the images\n",
    "                probs = torch.softmax(teacherNet_predictions, dim=1)\n",
    "                \n",
    "                \n",
    "                y_pred = torch.argmax(probs, dim=1)\n",
    "                print(\"Images min/max:\", images.min().item(), images.max().item())\n",
    "                print(\"Predictions min/max:\", y_pred.min().item(), y_pred.max().item())\n",
    "                #print(y_pred)\n",
    "                \n",
    "                # writer.add_figure('predictions vs. actuals',\n",
    "                #             utils.plot_net_predictions(images, labels, y_pred, batch_size),\n",
    "                #             global_step=epoch * len(train_loader_full) + idx)\n",
    "\n",
    "            # THIS IS JUST TO VISUALIZE THE TRAINING\n",
    "            printProgressBar(\n",
    "                idx + 1,\n",
    "                num_batches,\n",
    "                prefix=\"[Training] Epoch: {} \".format(epoch),\n",
    "                length=15,\n",
    "                suffix=\" Loss: {:.4f}, \".format(running_train_loss / (idx + 1)),\n",
    "            )\n",
    "\n",
    "        train_loss = running_train_loss / num_batches\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        train_dc_loss = running_dice_loss / num_batches\n",
    "        train_dc_losses.append(train_dc_loss)\n",
    "\n",
    "        teacherNet.eval()\n",
    "        val_running_loss = 0\n",
    "        val_running_dc = 0\n",
    "\n",
    "        # Validation loop\n",
    "        with torch.no_grad(): #validation made every time one epoch has finished being processed\n",
    "            for idx, data in enumerate(val_loader):\n",
    "                images, labels, img_names = data\n",
    "\n",
    "                labels = utils.to_var(labels).to(device)\n",
    "                images = utils.to_var(images).to(device)\n",
    "\n",
    "                teacherNet_predictions = teacherNet(images) #we try validation set in our model \n",
    "\n",
    "                segmentation_classes = utils.getTargetSegmentation(labels) #what should be predicted in a tensor\n",
    "\n",
    "                loss = CE_loss(teacherNet_predictions, segmentation_classes)\n",
    "                val_running_loss += loss.item()\n",
    "\n",
    "                # dice_loss = dice_coefficient(teacherNet_predictions, labels)\n",
    "                dice_loss = utils.compute_dsc(teacherNet_predictions, labels)\n",
    "                val_running_dc += dice_loss\n",
    "\n",
    "                # if idx % 10 == 0:\n",
    "                #     writer.add_scalar(\n",
    "                #         \"Loss/val\",\n",
    "                #         val_running_loss / (idx + 1),\n",
    "                #         epoch * len(val_loader) + idx,\n",
    "                #     )\n",
    "                #     writer.add_scalar(\n",
    "                #         \"Dice/val\",\n",
    "                #         val_running_dc / (idx + 1),\n",
    "                #         epoch * len(val_loader) + idx,\n",
    "                #     )\n",
    "\n",
    "                printProgressBar(\n",
    "                    idx + 1,\n",
    "                    len(val_loader),\n",
    "                    prefix=\"[Validation] Epoch: {} \".format(epoch),\n",
    "                    length=15,\n",
    "                    suffix=\" Loss: {:.4f}, \".format(val_running_loss / (idx + 1)),\n",
    "                )\n",
    "\n",
    "        val_loss = val_running_loss / len(val_loader)\n",
    "        val_losses.append(val_loss)\n",
    "        dc_loss = val_running_dc / len(val_loader)\n",
    "        val_dc_losses.append(dc_loss)\n",
    "\n",
    "        # Check if model performed best and save it if true\n",
    "        if val_loss < best_loss_val:\n",
    "            best_loss_val = val_loss\n",
    "            if not os.path.exists(\"./models/\" + modelName):\n",
    "                os.makedirs(\"./models/\" + modelName)\n",
    "            torch.save(\n",
    "                teacherNet.state_dict(), \"./models/\" + modelName + \"/\" + str(epoch) + \"_Epoch\"\n",
    "            )\n",
    "\n",
    "        printProgressBar(\n",
    "            num_batches,\n",
    "            num_batches,\n",
    "            done=\"[Epoch: {}, TrainLoss: {:.4f}, TrainDice: {:.4f}, ValLoss: {:.4f}\".format(\n",
    "                epoch, train_loss, train_dc_loss, val_loss\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        np.save(os.path.join(directory, \"Losses.npy\"), train_losses)\n",
    "    writer.flush()  # Flush the writer to ensure that all the data is written to disk\n",
    "    return teacherNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20c64dea-42e1-406b-8da3-c004b9d7cf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selfTrain with unlabeled images\n",
    "def runSelfTraining(teacherModel, writer: SummaryWriter): #garder writer: SummaryWriter ? \n",
    "    teacherModel.eval()\n",
    "    print(\"-\" * 40)\n",
    "    print(\"~~~~~~~~  Starting the self training... ~~~~~~\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    num_images = len(selftrain_loader_full.dataset)\n",
    "    print(\"num images fourni : \", num_images)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, data in enumerate(selftrain_loader_full):\n",
    "            images, img_names = data\n",
    "            \n",
    "            images = utils.to_var(images).to(device)\n",
    "\n",
    "            studentNet_predictions = teacherModel(images)\n",
    "            \n",
    "\n",
    "\n",
    "            if idx % 100 == 0:\n",
    "                # Also add visualizations of the images\n",
    "                probs = torch.softmax(studentNet_predictions, dim=1)\n",
    "                y_pred = torch.argmax(probs, dim=1)\n",
    "\n",
    "                \n",
    "                \n",
    "                writer.add_figure('predictions on unlabeled',\n",
    "                            utils.plot_net_predictions_without_ground_truth(images, y_pred, img_names, batch_size)                            )\n",
    "    print(\"hellooo\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "67f81713-4c18-4dd3-bc72-35dd8f30a339",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "~~~~~~~~  Starting the training... ~~~~~~\n",
      "----------------------------------------\n",
      "~~~~~~~~~~~ Creating the UNet model ~~~~~~~~~~\n",
      " Model Name: Test_Model\n",
      "Total params: 60,664\n",
      "~~~~~~~~~~~ Starting the training ~~~~~~~~~~\n",
      "Number of batches:  26\n",
      "Images min/max: 0.0 1.0\n",
      "Predictions min/max: 0 1\n",
      "[Training] Epoch: 0 [====>          ] 26.9% Loss: 1.2420, "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m writer \u001b[38;5;241m=\u001b[39m SummaryWriter()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#training du teacher\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m teacherNet \u001b[38;5;241m=\u001b[39m \u001b[43mrunTraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m writer\u001b[38;5;241m.\u001b[39mclose()\n",
      "Cell \u001b[1;32mIn[21], line 87\u001b[0m, in \u001b[0;36mrunTraining\u001b[1;34m(writer)\u001b[0m\n\u001b[0;32m     84\u001b[0m running_dice_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m dice_loss\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# Backprop\u001b[39;00m\n\u001b[1;32m---> 87\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#calculates gradients from loss\u001b[39;00m\n\u001b[0;32m     88\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep() \u001b[38;5;66;03m#use gradients just calculated to update weights of model \u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# Add the loss to the tensorboard every 5 batches\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;66;03m# if idx % 10 == 0:\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m#     writer.add_scalar(\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;66;03m#         \"Dice/train\", running_dice_loss / (idx + 1), epoch * len(train_loader_full) + idx\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m#     )\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\mti865_projet-KgCgpAUh-py3.12\\Lib\\site-packages\\torch\\_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\mti865_projet-KgCgpAUh-py3.12\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\mti865_projet-KgCgpAUh-py3.12\\Lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Set up Tensorboard writer\n",
    "writer = SummaryWriter()\n",
    "#training du teacher\n",
    "teacherNet = runTraining(writer)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a71d581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import inference\n",
    "\n",
    "epoch_to_load = 41 #num du modele à charger\n",
    "model = UNet(4)\n",
    "model.load_state_dict(torch.load(f\"./models/Test_Model/{epoch_to_load}_Epoch\")) #charge le fichiers des poids\n",
    "#inf_losses = inference(model, val_loader, \"Student\", epoch_to_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7c8651-2031-440c-842f-0ab1b03f7d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img batch :  126\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter()\n",
    "\n",
    "#predictions on unlabeled images\n",
    "#teacherNet = UNet(num_classes).to(device)\n",
    "# epoch = 41\n",
    "# checkpoint_path = \"./models/\" + \"Test_Model\" + \"/\" + str(epoch) + \"_Epoch\"\n",
    "#teacherNet.load_state_dict(torch.load(checkpoint_path))\n",
    "# model.eval()\n",
    "# runSelfTraining(model, writer)\n",
    "\n",
    "\n",
    "epoch_to_load = 28 #num du modele à charger\n",
    "model = UNet(4)\n",
    "model.load_state_dict(torch.load(f\"./models/Test_Model/{epoch_to_load}_Epoch\")) #charge le fichiers des poids\n",
    "inferenceTeacher(model, teacherTrain_loader_full, 'TeacherUnlabeledPredictions', epoch_to_load, device)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a88d3b9-fd40-4d8a-9dad-d68b1b2bb101",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Poetry (mti865_projet)",
   "language": "python",
   "name": "mti865_projet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
