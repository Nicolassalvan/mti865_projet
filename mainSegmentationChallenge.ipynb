{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6b07cf2f-b81d-43ef-907a-c49fed2d95ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "import medicalDataLoader\n",
    "import argparse\n",
    "import utils\n",
    "from utils import inferenceTeacher\n",
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "\n",
    "from UNet_Base import *\n",
    "import random\n",
    "import torch\n",
    "import pdb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8e976350-3fd5-4406-8511-86a06a9b4494",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "54c80878",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = (\"background\", \"1–tbd\", \"2–tbd\", \"3–tbd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7464cf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspired by https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            classes[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            classes[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c636584b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coefficient(prediction, target, epsilon=1e-07): #compares this prediction model to validation model \n",
    "    prediction_copy = prediction.clone()\n",
    "\n",
    "    prediction_copy[prediction_copy < 0] = 0\n",
    "    prediction_copy[prediction_copy > 0] = 1\n",
    "\n",
    "    intersection = abs(torch.sum(prediction_copy * target))\n",
    "    union = abs(torch.sum(prediction_copy) + torch.sum(target))\n",
    "    dice = (2. * intersection + epsilon) / (union + epsilon)\n",
    "    \n",
    "    return dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d007e633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "batch_size = 8 #nb images processed at same time during training\n",
    "batch_size_val = 4 #nb images processed at same time during validation \n",
    "lr =  0.01   # Learning Rate\n",
    "total_epochs = 50  # Number of epochs (how many times the algorithm passes through training data)\n",
    "num_classes = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "789b9179-ead1-49f6-b00e-44ee5ddbcf5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Set device depending on the availability of GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.mps.is_available():  # Apple M-series of chips\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3566dc5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dataset: ./data/ \n"
     ]
    }
   ],
   "source": [
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "mask_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Define dataloaders\n",
    "root_dir = './data/'\n",
    "print(' Dataset: {} '.format(root_dir))\n",
    "\n",
    "train_set_full = medicalDataLoader.MedicalImageDataset('train',\n",
    "                                                    root_dir,\n",
    "                                                    transform=transform,\n",
    "                                                    mask_transform=mask_transform,\n",
    "                                                    augment=False,\n",
    "                                                    equalize=False)\n",
    "\n",
    "train_loader_full = DataLoader(train_set_full,\n",
    "                            batch_size=batch_size,\n",
    "                            worker_init_fn=np.random.seed(0),\n",
    "                            num_workers=0,\n",
    "                            shuffle=True)\n",
    "\n",
    "#unlabeled data used to make predictions by teacher\n",
    "unlabeledEval_set_full = medicalDataLoader.MedicalImageDataset('unlabeledEval',\n",
    "                                                    root_dir,\n",
    "                                                    transform=transform,\n",
    "                                                    mask_transform=None,\n",
    "                                                    augment=False,\n",
    "                                                    equalize=False) #no transformation for now\n",
    "\n",
    "\n",
    "unlabeledEval_loader_full = DataLoader(unlabeledEval_set_full,\n",
    "                            batch_size=batch_size,\n",
    "                            worker_init_fn=np.random.seed(0),\n",
    "                            num_workers=0,\n",
    "                            shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "val_set = medicalDataLoader.MedicalImageDataset('val',\n",
    "                                                root_dir,\n",
    "                                                transform=transform,\n",
    "                                                mask_transform=mask_transform,\n",
    "                                                equalize=False)\n",
    "\n",
    "val_loader = DataLoader(val_set,\n",
    "                        batch_size=batch_size_val,\n",
    "                        worker_init_fn=np.random.seed(0),\n",
    "                        num_workers=0,\n",
    "                        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3c2f9173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch dimensions:  torch.Size([8, 1, 256, 256])\n",
      "Mask batch dimensions:  torch.Size([8, 1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "for i, sample in enumerate(train_loader_full):\n",
    "    images, masks, _ = sample\n",
    "    print('Image batch dimensions: ', images.size()) #[batch_size, channels, height, width]\n",
    "    print('Mask batch dimensions: ', masks.size())\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "20ac4eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runTraining(writer: SummaryWriter, loader, model_type=\"Teacher\", model = None ):\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"~~~~~~~~  Starting the training for {model_type}... ~~~~~~\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    print(f\"~~~~~~~~~~~ Creating the UNet model for {model_type} ~~~~~~~~~~\")\n",
    "    modelName = f\"{model_type}_Model\"\n",
    "    print(\" Model Name: {}\".format(modelName))\n",
    "\n",
    "    ## CREATION OF YOUR MODEL\n",
    "    if model == None : \n",
    "        net = UNet(num_classes).to(device)\n",
    "    else :\n",
    "        net = model\n",
    "\n",
    "    print(\n",
    "        \"Total params: {0:,}\".format(\n",
    "            sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # DEFINE YOUR OUTPUT COMPONENTS (e.g., SOFTMAX, LOSS FUNCTION, ETC)\n",
    "    softMax = torch.nn.Softmax(dim=1)\n",
    "    CE_loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # # PUT EVERYTHING IN GPU RESOURCES\n",
    "    # if torch.cuda.is_available():\n",
    "    #     net.cuda()\n",
    "    #     softMax.cuda()\n",
    "    #     CE_loss.cuda()\n",
    "\n",
    "    ## DEFINE YOUR OPTIMIZER\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr) #optimizer used (momentum +SGD)\n",
    "\n",
    "    ### To save statistics ####\n",
    "    train_losses = []\n",
    "    train_dc_losses = []\n",
    "    val_losses = []\n",
    "    val_dc_losses = []\n",
    "\n",
    "    best_loss_val = 1000\n",
    "\n",
    "    directory = f\"Results/Statistics/{model_type}/\" + modelName\n",
    "    print(f\"~~~~~~~~~~~ Saving results in: {directory} ~~~~~~~~~~\")\n",
    "\n",
    "    print(\"~~~~~~~~~~~ Starting the training ~~~~~~~~~~\")\n",
    "    if os.path.exists(directory) == False:\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    ## START THE TRAINING\n",
    "\n",
    "    ## FOR EACH EPOCH\n",
    "    for epoch in range(total_epochs):\n",
    "        net.train()\n",
    "\n",
    "        num_batches = len(loader) #26 batches of 8 images\n",
    "        print(\"Number of batches: \", num_batches)\n",
    "\n",
    "        running_train_loss = 0\n",
    "        running_dice_loss = 0\n",
    "\n",
    "        # Training loop\n",
    "        for idx, data in enumerate(loader): #idx : current batch number, data : images in that batch\n",
    "            ### Set to zero all the gradients\n",
    "            net.zero_grad()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            ## GET IMAGES, LABELS and IMG NAMES\n",
    "            images, labels, img_names = data #images with the corresponding label \n",
    "\n",
    "            ### From numpy to torch variables\n",
    "            labels = utils.to_var(labels).to(device)\n",
    "            images = utils.to_var(images).to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            net_predictions = net(images) #go through unet with images and get predictions (probabilities tensor)\n",
    "            #tensor of tables of predicted probabilities\n",
    "            \n",
    "\n",
    "            # Get the segmentation classes\n",
    "            segmentation_classes = utils.getTargetSegmentation(labels) #tensor of tables of 0(background), 1(1-tbd), 2(2-tbd), 3(3-tbd)\n",
    "\n",
    "            # Compute the loss\n",
    "            loss = CE_loss(net_predictions, segmentation_classes) #compare results and real segmentation\n",
    "            running_train_loss += loss.item()\n",
    "            # dice_loss = dice_coefficient(net_predictions, labels)\n",
    "            dice_loss = utils.compute_dsc(net_predictions, labels)\n",
    "            running_dice_loss += dice_loss\n",
    "\n",
    "            # Backprop\n",
    "            loss.backward() #calculates gradients from loss\n",
    "            optimizer.step() #use gradients just calculated to update weights of model \n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            # Add the loss to the tensorboard every 5 batches\n",
    "            if idx % 10 == 0:\n",
    "                writer.add_scalar(\n",
    "                    f\"Loss/train/{model_type}\", running_train_loss / (idx + 1), epoch * len(loader) + idx\n",
    "                )\n",
    "                writer.add_scalar(\n",
    "                    f\"Dice/train/{model_type}\", running_dice_loss / (idx + 1), epoch * len(loader) + idx\n",
    "                )\n",
    "\n",
    "            if idx % 100 == 0:\n",
    "                # Also add visualizations of the images\n",
    "                probs = torch.softmax(net_predictions, dim=1)\n",
    "                \n",
    "                \n",
    "                y_pred = torch.argmax(probs, dim=1)\n",
    "                print(\"Images min/max:\", images.min().item(), images.max().item())\n",
    "                print(\"Predictions min/max:\", y_pred.min().item(), y_pred.max().item())\n",
    "                \n",
    "                writer.add_figure('predictions vs. actuals',\n",
    "                            utils.plot_net_predictions(images, labels, y_pred, batch_size),\n",
    "                            global_step=epoch * len(loader) + idx)\n",
    "\n",
    "\n",
    "            # THIS IS JUST TO VISUALIZE THE TRAINING\n",
    "            printProgressBar(\n",
    "                idx + 1,\n",
    "                num_batches,\n",
    "                prefix=\"[Training] Epoch: {} \".format(epoch),\n",
    "                length=15,\n",
    "                suffix=\" Loss: {:.4f}, \".format(running_train_loss / (idx + 1)),\n",
    "            )\n",
    "\n",
    "        train_loss = running_train_loss / num_batches\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        train_dc_loss = running_dice_loss / num_batches\n",
    "        train_dc_losses.append(train_dc_loss)\n",
    "\n",
    "        net.eval()\n",
    "        val_running_loss = 0\n",
    "        val_running_dc = 0\n",
    "\n",
    "        # Validation loop\n",
    "        with torch.no_grad(): #validation made every time one epoch has finished being processed\n",
    "            for idx, data in enumerate(val_loader):\n",
    "                images, labels, img_names = data\n",
    "\n",
    "                labels = utils.to_var(labels).to(device)\n",
    "                images = utils.to_var(images).to(device)\n",
    "\n",
    "                net_predictions = net(images) #we try validation set in our model \n",
    "\n",
    "                segmentation_classes = utils.getTargetSegmentation(labels) #what should be predicted in a tensor\n",
    "\n",
    "                loss = CE_loss(net_predictions, segmentation_classes)\n",
    "                val_running_loss += loss.item()\n",
    "\n",
    "                # dice_loss = dice_coefficient(net_predictions, labels)\n",
    "                dice_loss = utils.compute_dsc(net_predictions, labels)\n",
    "                val_running_dc += dice_loss\n",
    "\n",
    "                if idx % 10 == 0:\n",
    "                    writer.add_scalar(\n",
    "                        f\"Loss/val/{model_type}\",\n",
    "                        val_running_loss / (idx + 1),\n",
    "                        epoch * len(val_loader) + idx,\n",
    "                    )\n",
    "                    writer.add_scalar(\n",
    "                        f\"Dice/val/{model_type}\",\n",
    "                        val_running_dc / (idx + 1),\n",
    "                        epoch * len(val_loader) + idx,\n",
    "                    )\n",
    "\n",
    "                printProgressBar(\n",
    "                    idx + 1,\n",
    "                    len(val_loader),\n",
    "                    prefix=\"[Validation] Epoch: {} \".format(epoch),\n",
    "                    length=15,\n",
    "                    suffix=\" Loss: {:.4f}, \".format(val_running_loss / (idx + 1)),\n",
    "                )\n",
    "\n",
    "        val_loss = val_running_loss / len(val_loader)\n",
    "        val_losses.append(val_loss)\n",
    "        dc_loss = val_running_dc / len(val_loader)\n",
    "        val_dc_losses.append(dc_loss)\n",
    "\n",
    "        # Check if model performed best and save it if true\n",
    "        if val_loss < best_loss_val:\n",
    "            best_loss_val = val_loss\n",
    "            if not os.path.exists(f\"./models/{model_type}\"):\n",
    "                os.makedirs(f\"./models/{model_type}\")\n",
    "                \n",
    "            torch.save(\n",
    "                net.state_dict(), f\"./models/{model_type}\" + \"/\" + str(epoch) + \"_Epoch\"\n",
    "            )\n",
    "\n",
    "        printProgressBar(\n",
    "            num_batches,\n",
    "            num_batches,\n",
    "            done=\"[Epoch: {}, TrainLoss: {:.4f}, TrainDice: {:.4f}, ValLoss: {:.4f}\".format(\n",
    "                epoch, train_loss, train_dc_loss, val_loss\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        np.save(os.path.join(directory, \"Losses.npy\"), train_losses)\n",
    "    writer.flush()  # Flush the writer to ensure that all the data is written to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "20c64dea-42e1-406b-8da3-c004b9d7cf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to delete\n",
    "def runSelfTraining(model, writer: SummaryWriter): #garder writer: SummaryWriter ? \n",
    "    model.eval()\n",
    "    print(\"-\" * 40)\n",
    "    print(\"~~~~~~~~  Starting the self training... ~~~~~~\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    num_images = len(loader.dataset)\n",
    "    print(\"num images fourni : \", num_images)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, data in enumerate(loader):\n",
    "            images, img_names = data\n",
    "            \n",
    "            images = utils.to_var(images).to(device)\n",
    "\n",
    "            studentNet_predictions = model(images)\n",
    "            \n",
    "\n",
    "\n",
    "            if idx % 100 == 0:\n",
    "                # Also add visualizations of the images\n",
    "                probs = torch.softmax(studentNet_predictions, dim=1)\n",
    "                y_pred = torch.argmax(probs, dim=1)\n",
    "\n",
    "                \n",
    "                \n",
    "                writer.add_figure('predictions on unlabeled',\n",
    "                            utils.plot_net_predictions_without_ground_truth(images, y_pred, img_names, batch_size)                            )\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "67f81713-4c18-4dd3-bc72-35dd8f30a339",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "~~~~~~~~  Starting the training for Teacher... ~~~~~~\n",
      "----------------------------------------\n",
      "~~~~~~~~~~~ Creating the UNet model for Teacher ~~~~~~~~~~\n",
      " Model Name: Teacher_Model\n",
      "Total params: 60,664\n",
      "~~~~~~~~~~~ Saving results in: Results/Statistics/Teacher/Teacher_Model ~~~~~~~~~~\n",
      "~~~~~~~~~~~ Starting the training ~~~~~~~~~~\n",
      "Number of batches:  26\n",
      "Images min/max: 0.0 1.0\n",
      "Predictions min/max: 0 3\n",
      "[Training] Epoch: 0 [DONE]                                 \n",
      "[Validation] Epoch: 0 [DONE]                                 \n",
      "[Epoch: 0, TrainLoss: 1.2214, TrainDice: 0.0546, ValLoss: 0.8701                                             \n",
      "Number of batches:  26\n",
      "Images min/max: 0.0 1.0\n",
      "Predictions min/max: 0 3\n",
      "[Training] Epoch: 1 [==>            ] 19.2% Loss: 0.7516, "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Code de base\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Set up Tensorboard writer\u001b[39;00m\n\u001b[0;32m      3\u001b[0m writer \u001b[38;5;241m=\u001b[39m SummaryWriter()\n\u001b[1;32m----> 5\u001b[0m \u001b[43mrunTraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader_full\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m writer\u001b[38;5;241m.\u001b[39mclose()\n",
      "Cell \u001b[1;32mIn[40], line 91\u001b[0m, in \u001b[0;36mrunTraining\u001b[1;34m(writer, loader, model_type, model)\u001b[0m\n\u001b[0;32m     88\u001b[0m running_dice_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m dice_loss\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# Backprop\u001b[39;00m\n\u001b[1;32m---> 91\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#calculates gradients from loss\u001b[39;00m\n\u001b[0;32m     92\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep() \u001b[38;5;66;03m#use gradients just calculated to update weights of model \u001b[39;00m\n\u001b[0;32m     93\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\mti865_projet-KgCgpAUh-py3.12\\Lib\\site-packages\\torch\\_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\mti865_projet-KgCgpAUh-py3.12\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\mti865_projet-KgCgpAUh-py3.12\\Lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Code de base\n",
    "# Set up Tensorboard writer\n",
    "writer = SummaryWriter()\n",
    "\n",
    "runTraining(writer, train_loader_full)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9a71d581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#do delete\n",
    "\n",
    "epoch_to_load = 41 #num du modele à charger\n",
    "model = UNet(num_classes).to(device)\n",
    "model.load_state_dict(torch.load(f\"./models/Test_Model/{epoch_to_load}_Epoch\")) #charge le fichiers des poids\n",
    "#inf_losses = inference(model, val_loader, \"Test\", epoch_to_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7c8651-2031-440c-842f-0ab1b03f7d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#on utilise modele Teacher (n°28 ici) pour générer prédictions sur unlabeled\n",
    "\n",
    "#Teacher predictions on unlabeled (attention les teachers sont placés dans le dossier models/Teacher)!\n",
    "epoch_to_load = 28 #num du modele à charger\n",
    "model = UNet(4)\n",
    "model.load_state_dict(torch.load(f\"./models/Teacher/{epoch_to_load}_Epoch\")) #charge le fichiers des poids du Teacher\n",
    "inferenceTeacher(model, unlabeledEval_loader_full, 'TeacherUnlabeledPredictions', epoch_to_load, device) #predictions sur les unlabeled\n",
    "#predictions enregistrees dans Results/Images/TeacherUnlabeledPredictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a88d3b9-fd40-4d8a-9dad-d68b1b2bb101",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Student predictions on labeled + unlabeled (!cette query doit rester ici car il faut d'abord que le teacher ait travaillé avant de récupérer ses prédictions)\n",
    "writer = SummaryWriter()\n",
    "unlabeledTrain_set_full = medicalDataLoader.MedicalImageDataset('unlabeledTrain',\n",
    "                                                    root_dir,\n",
    "                                                    transform=transform,\n",
    "                                                    mask_transform=mask_transform,\n",
    "                                                    augment=False,\n",
    "                                                    equalize=False) #no transformation for now\n",
    "\n",
    "\n",
    "unlabeledTrain_loader_full = DataLoader(unlabeledTrain_set_full,\n",
    "                            batch_size=batch_size,\n",
    "                            worker_init_fn=np.random.seed(0),\n",
    "                            num_workers=0,\n",
    "                            shuffle=True)\n",
    "\n",
    "#le student se base sur les unlabeled et les labeled\n",
    "studentTrain_set_full = ConcatDataset([train_set_full, unlabeledTrain_set_full])\n",
    "\n",
    "studentTrain_loader_full = DataLoader(studentTrain_set_full,\n",
    "                             batch_size=batch_size,\n",
    "                             worker_init_fn=np.random.seed(0),\n",
    "                             num_workers=0,\n",
    "                             shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "epoch_to_load = 28  # numéro teacher dont on charge les poids pour le student\n",
    "teacher_model_path = f\"./models/Teacher/{epoch_to_load}_Epoch\"\n",
    "\n",
    "\n",
    "student_model = UNet(num_classes).to(device)\n",
    "\n",
    "# # charger les poids du teacher dans le student\n",
    "try:\n",
    "    student_model.load_state_dict(torch.load(teacher_model_path))\n",
    "    print(f\"Les poids du modèle Teacher (époque {epoch_to_load}) ont été chargés avec succès dans le modèle Student.\")\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors du chargement des poids : {e}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "runTraining(writer, studentTrain_loader_full, 'Student', student_model)\n",
    "\n",
    "\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd0881a-1c1d-4c8e-8625-9a97ef83e4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss qui compare les prédictions du student avec celles du softmax\n",
    "\n",
    "def distillation_loss(y_pred_student, y_pred_teacher, temperature=2.0) :\n",
    "    soft_y_pred_teacher = torch.softmax(y_pred_teacher / temperature, dim=1)\n",
    "    soft_y_pred_student = torch.softmax(y_pred_student / temperature, dim=1)\n",
    "    \n",
    "    loss = nn.KLDivLoss(reduction='batchmean')(torch.log(soft_y_pred_student), soft_y_pred_teacher)\n",
    "    \n",
    "    return loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Poetry (mti865_projet)",
   "language": "python",
   "name": "mti865_projet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
