{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c6e025f",
   "metadata": {},
   "source": [
    "# Project MTI865 - Heart segmentation using UNet \n",
    "\n",
    "---\n",
    "\n",
    "# Model training "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31b841f",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b07cf2f-b81d-43ef-907a-c49fed2d95ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.transforms import v2\n",
    "from progressBar import printProgressBar\n",
    "\n",
    "import medicalDataLoader\n",
    "import argparse\n",
    "import utils\n",
    "from utils import *\n",
    "\n",
    "from UNet_Base import *\n",
    "import random\n",
    "import torch\n",
    "import pdb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e976350-3fd5-4406-8511-86a06a9b4494",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6136411",
   "metadata": {},
   "source": [
    "## Loading data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19e19f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "batch_size_val = 4\n",
    "batch_size_unlabel = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37a65765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image and mask transformations\n",
    "transform = v2.Compose([\n",
    "    v2.ToTensor()\n",
    "])\n",
    "\n",
    "mask_transform = v2.Compose([\n",
    "    v2.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "029239f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    imgs = []\n",
    "    masks = []\n",
    "    img_paths = []\n",
    "\n",
    "    for item in batch:\n",
    "        img, mask, img_path = item[0], item[1], item[2]\n",
    "        imgs.append(img)\n",
    "        img_paths.append(img_path)\n",
    "        \n",
    "        # Si le masque est None, ajouter un tenseur de zéros correspondant à sa taille\n",
    "        if mask is not None:\n",
    "            masks.append(mask)\n",
    "        else:\n",
    "            masks.append(torch.zeros_like(img[0, :, :]))  # Même taille que le canal de l'image (assumant CxHxW)\n",
    "\n",
    "    # Stack les images et les masques\n",
    "    imgs_tensor = torch.stack(imgs)  # Tensor de forme (B, C, H, W)\n",
    "    masks_tensor = torch.stack(masks)  # Tensor de forme (B, H, W)\n",
    "\n",
    "    return imgs_tensor, masks_tensor, img_paths\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3566dc5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dataset: ./data/ \n",
      "Found 204 items in train\n",
      "First item:  ('./data/train\\\\Img\\\\patient006_01_1.png', './data/train\\\\GT\\\\patient006_01_1.png')\n",
      "Found 74 items in val\n",
      "First item:  ('./data/val\\\\Img\\\\patient001_01_1.png', './data/val\\\\GT\\\\patient001_01_1.png')\n",
      "Found 1004 items in train-unlabelled\n",
      "First item:  ('./data/train\\\\Img-Unlabeled\\\\patient007_01_1.png', None)\n",
      "Found 1004 items in train-unlabelled\n",
      "First item:  ('./data/train\\\\Img-Unlabeled\\\\patient007_01_1.png', None)\n",
      "Train set:  204\n",
      "Validation set:  74\n",
      "Image shape:  torch.Size([1, 256, 256])\n",
      "Mask shape:  torch.Size([1, 256, 256])\n",
      "Number of batches:  102\n",
      "Image shape:  torch.Size([1, 256, 256])\n",
      "Mask shape:  torch.Size([1, 256, 256])\n",
      "Number of batches:  19\n",
      "Image shape:  torch.Size([1, 256, 256])\n",
      "Mask shape:  torch.Size([1, 256, 256])\n",
      "Number of batches:  126\n",
      "First of the supervised set\n",
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n",
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n",
      "./data/train\\Img\\patient006_01_1.png\n",
      "First of the unsupervised set\n",
      "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]])\n",
      "None\n",
      "./data/train\\Img-Unlabeled\\patient007_01_1.png\n"
     ]
    }
   ],
   "source": [
    "# Define dataloaders\n",
    "root_dir = './data/'\n",
    "print(' Dataset: {} '.format(root_dir))\n",
    "\n",
    "supervised_set = medicalDataLoader.MedicalImageDataset('train',\n",
    "                                                    root_dir,\n",
    "                                                    transform=transform,\n",
    "                                                    mask_transform=mask_transform,\n",
    "                                                    augment=True,\n",
    "                                                    equalize=False)\n",
    "\n",
    "\n",
    "supervised_loader = DataLoader(\n",
    "    supervised_set,\n",
    "    batch_size=batch_size,\n",
    "    worker_init_fn=np.random.seed(0),\n",
    "    num_workers=0,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "val_set = medicalDataLoader.MedicalImageDataset('val',\n",
    "                                                root_dir,\n",
    "                                                transform=transform,\n",
    "                                                mask_transform=mask_transform,\n",
    "                                                equalize=False)\n",
    "\n",
    "val_loader = DataLoader(val_set,\n",
    "                        batch_size=batch_size_val,\n",
    "                        worker_init_fn=np.random.seed(0),\n",
    "                        num_workers=0,\n",
    "                        shuffle=False)\n",
    "\n",
    "unsupervised_set = medicalDataLoader.MedicalImageDataset('train-unlabelled',\n",
    "                                                            root_dir,\n",
    "                                                            transform=transform,\n",
    "                                                            mask_transform=mask_transform,\n",
    "                                                            augment=False,\n",
    "                                                            equalize=False,\n",
    "                                                            )\n",
    "# print(train_unlabelled_set.imgs)\n",
    "# train_unlabelled_set = [(img) for img, mask in train_unlabelled_set]\n",
    "unsupervised_loader = DataLoader(unsupervised_set,\n",
    "                                    batch_size=batch_size_unlabel,\n",
    "                                    worker_init_fn=np.random.seed(0),\n",
    "                                    num_workers=0,\n",
    "                                    shuffle=False,\n",
    "                                    collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "unlabeledEval_set_full = medicalDataLoader.MedicalImageDataset('train-unlabelled',\n",
    "                                                            root_dir,\n",
    "                                                            transform=transform,\n",
    "                                                            mask_transform=None,\n",
    "                                                            augment=False,\n",
    "                                                            equalize=False,\n",
    "                                                            method='method2') #no transformation\n",
    "\n",
    "unlabeledEval_loader_full = DataLoader(unlabeledEval_set_full,\n",
    "                                    batch_size=batch_size_unlabel,\n",
    "                                    worker_init_fn=np.random.seed(0),\n",
    "                                    num_workers=0,\n",
    "                                    shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('Train set: ', len(supervised_set))\n",
    "print('Validation set: ', len(val_set))\n",
    "\n",
    "n_train_label = len(supervised_set)\n",
    "n_train_unlabel = len(unsupervised_set)\n",
    "\n",
    "# shape of the image a  nd mask\n",
    "img, mask, _ = supervised_set[0]\n",
    "print('Image shape: ', img.shape)\n",
    "print('Mask shape: ', mask.shape)\n",
    "print('Number of batches: ', len(supervised_loader))\n",
    "\n",
    "img, mask, _ = val_set[0]\n",
    "print('Image shape: ', img.shape)\n",
    "print('Mask shape: ', mask.shape)\n",
    "print('Number of batches: ', len(val_loader))\n",
    "\n",
    "img, _, __ = unsupervised_set[0]\n",
    "print('Image shape: ', img.shape)\n",
    "print('Mask shape: ', mask.shape)\n",
    "print('Number of batches: ', len(unsupervised_loader))\n",
    "\n",
    "\n",
    "print('First of the supervised set')\n",
    "img, mask, path_tuple = supervised_set[0]\n",
    "print(img)\n",
    "print(mask)\n",
    "print(path_tuple)\n",
    "\n",
    "print('First of the unsupervised set')\n",
    "img, mask, path_tuple = unsupervised_set[0]\n",
    "print(img)\n",
    "print(mask)\n",
    "print(path_tuple)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c2f9173",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), ['./data/train\\\\Img\\\\patient033_01_8.png', './data/train\\\\Img\\\\patient035_11_9.png'])\n",
      "Image batch dimensions:  torch.Size([2, 1, 256, 256])\n",
      "Mask batch dimensions:  torch.Size([2, 1, 256, 256])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for sample in supervised_loader:\n",
    "    images, masks, _ = sample\n",
    "    print(sample)\n",
    "    print('Image batch dimensions: ', images.size())\n",
    "    print('Mask batch dimensions: ', masks.size())\n",
    "    \n",
    "    # Show first image and mask\n",
    "    plt.figure()\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(images[0,0,:,:], cmap='gray')\n",
    "    plt.title('Image')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(masks[0,0,:,:], cmap='gray')\n",
    "    plt.title('Mask')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    break\n",
    "print('Done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c8b3ec8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]]), ['./data/train\\\\Img-Unlabeled\\\\patient007_01_1.png', './data/train\\\\Img-Unlabeled\\\\patient007_01_10.png', './data/train\\\\Img-Unlabeled\\\\patient007_01_2.png', './data/train\\\\Img-Unlabeled\\\\patient007_01_3.png', './data/train\\\\Img-Unlabeled\\\\patient007_01_4.png', './data/train\\\\Img-Unlabeled\\\\patient007_01_5.png', './data/train\\\\Img-Unlabeled\\\\patient007_01_6.png', './data/train\\\\Img-Unlabeled\\\\patient007_01_7.png'])\n",
      "Image batch dimensions:  torch.Size([8, 1, 256, 256])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for i, sample in enumerate(unsupervised_loader):\n",
    "    print(sample)\n",
    "    images, maskNone, _ = sample\n",
    "    print('Image batch dimensions: ', images.size())\n",
    "    # print('Mask batch dimensions: ', masks.size())\n",
    "    \n",
    "    # Show first image and mask        \n",
    "    plt.figure()\n",
    "    plt.imshow(images[0,0,:,:], cmap='gray')\n",
    "    plt.title('Image')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    break\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468c777e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54151507",
   "metadata": {},
   "source": [
    "## Modèle basique : Entraînement avec les GT uniquement "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cdab0d",
   "metadata": {},
   "source": [
    "### Paramètres de l'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53295490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "\n",
    "lr =  0.001    # Learning Rate\n",
    "total_epochs = 100  # Number of epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95462f91",
   "metadata": {},
   "source": [
    "### Entraînement du modèle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b4c3b0a-7c64-40ba-8f6b-dc585a1851de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device depending on the availability of GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "# elif torch.mps.is_available():  # Apple M-series of chips\n",
    "#     device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20ac4eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runTraining(writer: SummaryWriter):\n",
    "    print(\"-\" * 40)\n",
    "    print(\"~~~~~~~~  Starting the training... ~~~~~~\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    num_classes = 4\n",
    "\n",
    "    # Set device depending on the availability of GPU\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "    # elif torch.mps.is_available():  # Apple M-series of chips\n",
    "    #     device = torch.device(\"mps\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    print(\"~~~~~~~~~~~ Creating the UNet model ~~~~~~~~~~\")\n",
    "    modelName = \"Test_Model\"\n",
    "    print(\" Model Name: {}\".format(modelName))\n",
    "\n",
    "    # Create the model\n",
    "    net = UNet(num_classes).to(device)\n",
    "\n",
    "    print(\n",
    "        \"Total params: {0:,}\".format(\n",
    "            sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Define the loss function\n",
    "    softMax = torch.nn.Softmax(dim=1)\n",
    "    CE_loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    ## PUT EVERYTHING IN GPU RESOURCES\n",
    "    # if torch.cuda.is_available():\n",
    "    #     net.cuda()\n",
    "    #     softMax.cuda()\n",
    "    #     CE_loss.cuda()\n",
    "\n",
    "    ## OPTIMIZER\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr, weight_decay=1e-5)\n",
    "\n",
    "    ### To save statistics ####\n",
    "    train_losses = []\n",
    "    train_dc_losses = []\n",
    "    val_losses = []\n",
    "    val_dc_losses = []\n",
    "\n",
    "    best_loss_val = 1000\n",
    "\n",
    "    directory = \"Results/Statistics/\" + modelName\n",
    "\n",
    "    print(\"~~~~~~~~~~~ Starting the training ~~~~~~~~~~\")\n",
    "    if os.path.exists(directory) == False:\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    ## START THE TRAINING\n",
    "\n",
    "    ## FOR EACH EPOCH\n",
    "    for epoch in range(total_epochs):\n",
    "        net.train()\n",
    "\n",
    "        num_batches = len(supervised_loader)\n",
    "        print(\"Number of batches: \", num_batches)\n",
    "\n",
    "        running_train_loss = 0\n",
    "        running_dice_loss = 0\n",
    "\n",
    "        # Training loop\n",
    "        for idx, data in enumerate(supervised_loader):\n",
    "            ### Set to zero all the gradients\n",
    "            net.zero_grad()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            ## GET IMAGES, LABELS and IMG NAMES\n",
    "            images, labels, img_names = data\n",
    "            # print(\"Type of labels before to_var:\", type(labels))\n",
    "            ### From numpy to torch variables\n",
    "            labels = utils.to_var(labels).to(device)\n",
    "            images = utils.to_var(images).to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            net_predictions = net(images)\n",
    "\n",
    "            # Get the segmentation classes\n",
    "            segmentation_classes = utils.getTargetSegmentation(labels)\n",
    "\n",
    "            # Compute the loss\n",
    "            loss = CE_loss(net_predictions, segmentation_classes)\n",
    "            running_train_loss += loss.detach().item()\n",
    "            # dice_loss = dice_coefficient(net_predictions, labels)\n",
    "            dice_loss = utils.compute_dsc(net_predictions, labels)\n",
    "            running_dice_loss += dice_loss\n",
    "\n",
    "            # Backprop\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Add the loss to the tensorboard every 5 batches\n",
    "            if idx % 10 == 0:\n",
    "                writer.add_scalar(\n",
    "                    \"Loss/train\", running_train_loss / (idx + 1), epoch * len(supervised_loader) + idx\n",
    "                )\n",
    "                writer.add_scalar(\n",
    "                    \"Dice/train\", running_dice_loss / (idx + 1), epoch * len(supervised_loader) + idx\n",
    "                )\n",
    "\n",
    "            if idx % 100 == 0:\n",
    "                # Also add visualizations of the images\n",
    "                probs = torch.softmax(net_predictions, dim=1)\n",
    "                y_pred = torch.argmax(probs, dim=1)\n",
    "                writer.add_figure('predictions vs. actuals',\n",
    "                            utils.plot_net_predictions(images, labels, y_pred, batch_size),\n",
    "                            global_step=epoch * len(supervised_loader) + idx)\n",
    "\n",
    "            # THIS IS JUST TO VISUALIZE THE TRAINING\n",
    "            printProgressBar(\n",
    "                idx + 1,\n",
    "                num_batches,\n",
    "                prefix=\"[Training] Epoch: {} \".format(epoch),\n",
    "                length=15,\n",
    "                suffix=\" Loss: {:.4f}, \".format(running_train_loss / (idx + 1)),\n",
    "            )\n",
    "\n",
    "        train_loss = running_train_loss / num_batches\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        train_dc_loss = running_dice_loss / num_batches\n",
    "        train_dc_losses.append(train_dc_loss)\n",
    "\n",
    "        net.eval()\n",
    "        val_running_loss = 0\n",
    "        val_running_dc = 0\n",
    "\n",
    "        # Validation loop\n",
    "        with torch.no_grad():\n",
    "            for idx, data in enumerate(val_loader):\n",
    "                images, labels, img_names = data\n",
    "\n",
    "                labels = utils.to_var(labels).to(device)\n",
    "                images = utils.to_var(images).to(device)\n",
    "\n",
    "                net_predictions = net(images)\n",
    "\n",
    "                segmentation_classes = utils.getTargetSegmentation(labels)\n",
    "\n",
    "                loss = CE_loss(net_predictions, segmentation_classes) \n",
    "                val_running_loss += loss.item()\n",
    "\n",
    "                # dice_loss = dice_coefficient(net_predictions, labels)\n",
    "                dice_loss = utils.compute_dsc(net_predictions, labels)\n",
    "                val_running_dc += dice_loss\n",
    "\n",
    "                if idx % 10 == 0:\n",
    "                    writer.add_scalar(\n",
    "                        \"Loss/val\",\n",
    "                        val_running_loss / (idx + 1),\n",
    "                        epoch * len(val_loader) + idx,\n",
    "                    )\n",
    "                    writer.add_scalar(\n",
    "                        \"Dice/val\",\n",
    "                        val_running_dc / (idx + 1),\n",
    "                        epoch * len(val_loader) + idx,\n",
    "                    )\n",
    "\n",
    "                printProgressBar(\n",
    "                    idx + 1,\n",
    "                    len(val_loader),\n",
    "                    prefix=\"[Validation] Epoch: {} \".format(epoch),\n",
    "                    length=15,\n",
    "                    suffix=\" Loss: {:.4f}, \".format(val_running_loss / (idx + 1)),\n",
    "                )\n",
    "\n",
    "        val_loss = val_running_loss / len(val_loader)\n",
    "        val_losses.append(val_loss)\n",
    "        dc_loss = val_running_dc / len(val_loader)\n",
    "        val_dc_losses.append(dc_loss)\n",
    "\n",
    "        # Check if model performed best and save it if true\n",
    "        if val_loss < best_loss_val:\n",
    "            best_loss_val = val_loss\n",
    "            if not os.path.exists(\"./models/\" + modelName):\n",
    "                os.makedirs(\"./models/\" + modelName)\n",
    "            torch.save(\n",
    "                net.state_dict(), \"./models/\" + modelName + \"/\" + str(epoch) + \"_Epoch\"\n",
    "            )\n",
    "\n",
    "        printProgressBar(\n",
    "            num_batches,\n",
    "            num_batches,\n",
    "            done=\"[Epoch: {}, TrainLoss: {:.4f}, TrainDice: {:.4f}, ValLoss: {:.4f}\".format(\n",
    "                epoch, train_loss, train_dc_loss, val_loss\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        np.save(os.path.join(directory, \"Losses.npy\"), train_losses)\n",
    "    writer.flush()  # Flush the writer to ensure that all the data is written to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67f81713-4c18-4dd3-bc72-35dd8f30a339",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up Tensorboard writer\n",
    "# writer = SummaryWriter()\n",
    "# runTraining(writer)\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fff2d34",
   "metadata": {},
   "source": [
    "### Tests (validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f80703",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85e0e07c",
   "metadata": {},
   "source": [
    "### Sauvegarde du modèle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fe086af-2395-4758-99db-7b6917d6abeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import inference\n",
    "\n",
    "epoch_to_load = 72\n",
    "num_epoch_teacher= epoch_to_load\n",
    "model = UNet(4)\n",
    "model.load_state_dict(torch.load(f\"./models/Test_Model/{epoch_to_load}_Epoch\"))\n",
    "#inf_losses = inference(model, val_loader, \"test\", epoch_to_load)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef7c545",
   "metadata": {},
   "source": [
    "## Model using both labeled and unlabeled data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db31076c",
   "metadata": {},
   "source": [
    "### Hyperparameters of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "369d8a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "\n",
    "lr =  0.005    # Learning Rate\n",
    "total_epochs = 100  # Number of epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c94cc8",
   "metadata": {},
   "source": [
    "### Example of loop\n",
    "\n",
    "In this exemple, we modified the structure of the code to use iterators instead. In each epoch, we see the whole range of supervised data and one time each unsupervised data. We can also try to see once the supervised data and to see random images of unsupervised data, which could mean we would not be able to see it all. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e05de59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# supervised_iter = iter(supervised_loader)\n",
    "# unsupervised_iter = iter(unsupervised_loader)\n",
    "\n",
    "# for epoch in range(total_epochs):\n",
    "#     num_batches = max(len(supervised_loader), len(unsupervised_loader))\n",
    "#     for idx in range(num_batches):\n",
    "#         try :\n",
    "#             supervised_data = next(supervised_iter)\n",
    "#         except StopIteration:\n",
    "#             supervised_iter = iter(supervised_loader)\n",
    "#             supervised_data= next(supervised_iter)\n",
    "\n",
    "#         print(supervised_data)\n",
    "#         print('Supervised batch')   \n",
    "#         try :\n",
    "#             unsupervised_data = next(unsupervised_iter)\n",
    "#         except StopIteration:\n",
    "#             unsupervised_iter = iter(unsupervised_loader)\n",
    "#             unsupervised_data = next(unsupervised_iter)\n",
    "        \n",
    "#         print(unsupervised_data)\n",
    "#         print('Unsupervised batch')\n",
    "#         break\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cf0784",
   "metadata": {},
   "source": [
    "### Transformation consistency regularisation\n",
    "\n",
    "The transformation consistency consists in the principle that transformation T suchs as rotation and flipping should affect the mask f(y) only by the same rotation, which means that f and T should be symetrical. In this implementation, we used the 2-norm to measure the difference, and we included it in the optimisation problem.  $\\mathcal{L}_{TC}(y_u) = \\|f(T(y_u))-T(F(y))\\|_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16443fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "class ConsistencyRegularization(nn.Module):\n",
    "    def __init__(self, transformation_fn, loss_fn=nn.MSELoss()):\n",
    "        \"\"\"\n",
    "        Régularisation basée sur la consistance à la transformation.\n",
    "\n",
    "        Args:\n",
    "            transformation_fn (callable): Fonction d'augmentation/transformation appliquée aux images.\n",
    "            loss_fn (callable): Fonction de perte utilisée pour comparer les prédictions (par défaut MSELoss).\n",
    "        \"\"\"\n",
    "        super(ConsistencyRegularization, self).__init__()\n",
    "        self.transformation_fn = transformation_fn\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def forward(self, model, images):\n",
    "        \"\"\"\n",
    "        Calcule la perte de consistance.\n",
    "\n",
    "        Args:\n",
    "            model (torch.nn.Module): Le modèle de segmentation.\n",
    "            images (torch.Tensor): Batch d'images d'entrée.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: La perte de consistance.\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            # Prédictions de base\n",
    "            original_predictions = F.softmax(model(images), dim=1)\n",
    "\n",
    "        # Augmenter les images\n",
    "        augmented_images = self.transformation_fn(images)\n",
    "\n",
    "        # Prédictions pour les images augmentées\n",
    "        augmented_predictions = F.softmax(model(augmented_images), dim=1)\n",
    "\n",
    "        # Calcul de la perte de consistance\n",
    "        consistency_loss = self.loss_fn(original_predictions, augmented_predictions)\n",
    "\n",
    "        return consistency_loss\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f5c928",
   "metadata": {},
   "source": [
    "### Training of the model \n",
    "\n",
    "At each epoch, the model sees once every exemple of unlabeled data, and sees several time the labeled data. We first train it with the labeled data, and then we train it on the unsupervised data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "186cae12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "~~~~~~~~  Starting the training... ~~~~~~\n",
      "----------------------------------------\n",
      "Using device: cpu\n",
      "~~~~~~~~~~~ Creating the UNet model ~~~~~~~~~~\n",
      " Model Name: SemiSupervised-TransformConsistency\n",
      "Total params: 60,664\n",
      "~~~~~~~~~~~ Starting the training ~~~~~~~~~~\n",
      "Number of batches:  126\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "The shape of the mask [256, 256] at index 0 does not match the shape of the indexed tensor [4, 256, 256] at index 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 150\u001b[0m\n\u001b[0;32m    147\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m    149\u001b[0m \u001b[38;5;66;03m#on recupere les distributions de proba du teacher pour les unlabeled\u001b[39;00m\n\u001b[1;32m--> 150\u001b[0m segmentation_class_teacher \u001b[38;5;241m=\u001b[39m \u001b[43mget_teacher_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epoch_teacher\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;66;03m#predictions sur unlabeled\u001b[39;00m\n\u001b[0;32m    152\u001b[0m teacher_net_predictions \u001b[38;5;241m=\u001b[39m teacher_net(images)\n",
      "File \u001b[1;32m~\\DDCANADA1\\MTI865\\mti865_projet\\utils.py:278\u001b[0m, in \u001b[0;36mget_teacher_proba\u001b[1;34m(num_epoch_teacher, img_names, device)\u001b[0m\n\u001b[0;32m    276\u001b[0m max_probs, _ \u001b[38;5;241m=\u001b[39m teacher_probs\u001b[38;5;241m.\u001b[39mmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# on recuperre la proba des classes predites\u001b[39;00m\n\u001b[0;32m    277\u001b[0m low_confidence_mask \u001b[38;5;241m=\u001b[39m max_probs \u001b[38;5;241m<\u001b[39m confidence_threshold\n\u001b[1;32m--> 278\u001b[0m \u001b[43mteacher_probs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlow_confidence_mask\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.00001\u001b[39m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;66;03m# on doit charger la distribution de probas et la convertir en tenseur pytorch\u001b[39;00m\n\u001b[0;32m    282\u001b[0m batch_teacher_probs\u001b[38;5;241m.\u001b[39mappend(teacher_probs)\n",
      "\u001b[1;31mIndexError\u001b[0m: The shape of the mask [256, 256] at index 0 does not match the shape of the indexed tensor [4, 256, 256] at index 0"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter()\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(\"~~~~~~~~  Starting the training... ~~~~~~\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# num_classes = 4\n",
    "alpha = 0.1\n",
    "\n",
    "# Set device depending on the availability of GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "# elif torch.mps.is_available():  # Apple M-series of chips\n",
    "#     device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "print(\"~~~~~~~~~~~ Creating the UNet model ~~~~~~~~~~\")\n",
    "modelName = \"SemiSupervised-TransformConsistency\"\n",
    "print(\" Model Name: {}\".format(modelName))\n",
    "\n",
    "## CREATION OF YOUR MODEL\n",
    "teacher_net = UNet(num_classes).to(device)\n",
    "\n",
    "print(\n",
    "    \"Total params: {0:,}\".format(\n",
    "        sum(p.numel() for p in teacher_net.parameters() if p.requires_grad)\n",
    "    )\n",
    ")\n",
    "\n",
    "# DEFINE YOUR OUTPUT COMPONENTS (e.g., SOFTMAX, LOSS FUNCTION, ETC)\n",
    "softMax = torch.nn.Softmax(dim=1)\n",
    "CE_loss = torch.nn.CrossEntropyLoss()\n",
    "consistency_regularizer = ConsistencyRegularization(transformation_fn=transforms.RandomHorizontalFlip()) #!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "\n",
    "## PUT EVERYTHING IN GPU RESOURCES\n",
    "# if torch.cuda.is_available():\n",
    "#     teacher_net.cuda()\n",
    "#     softMax.cuda()\n",
    "#     CE_loss.cuda()\n",
    "\n",
    "## DEFINE YOUR OPTIMIZER\n",
    "optimizer = torch.optim.Adam(teacher_net.parameters(), lr=lr)\n",
    "\n",
    "### To save statistics ####\n",
    "train_losses = []\n",
    "train_dc_losses = []\n",
    "val_losses = []\n",
    "val_dc_losses = []\n",
    "\n",
    "best_loss_val = 1000\n",
    "\n",
    "directory = \"Results/Statistics/\" + modelName\n",
    "\n",
    "print(\"~~~~~~~~~~~ Starting the training ~~~~~~~~~~\")\n",
    "if os.path.exists(directory) == False:\n",
    "    os.makedirs(directory)\n",
    "\n",
    "## START THE TRAINING\n",
    "\n",
    "## FOR EACH EPOCH\n",
    "for epoch in range(total_epochs):\n",
    "    teacher_net.train()\n",
    "    supervised_iter = iter(supervised_loader)\n",
    "    unsupervised_iter = iter(unsupervised_loader)\n",
    "    unlabeled_iter = iter(unlabeledEval_loader_full)\n",
    "    \n",
    "    num_batches = max(len(supervised_loader), len(unsupervised_loader))\n",
    "    print(\"Number of batches: \", num_batches)\n",
    "\n",
    "    running_train_loss = 0\n",
    "    running_dice_loss = 0\n",
    "\n",
    "    # Training loop\n",
    "    for idx in range(num_batches):\n",
    "        ### SUPERVISED BATCH\n",
    "        try :\n",
    "            supervised_data = next(supervised_iter)\n",
    "        except StopIteration:\n",
    "            supervised_iter = iter(supervised_loader)\n",
    "            supervised_data = next(supervised_iter)\n",
    "\n",
    "        ### Set to zero all the gradients\n",
    "        teacher_net.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        ## GET IMAGES, LABELS and IMG NAMES\n",
    "        images, labels, img_names = supervised_data\n",
    "\n",
    "        ### From numpy to torch variables\n",
    "        labels = utils.to_var(labels).to(device)\n",
    "        images = utils.to_var(images).to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        teacher_net_predictions = teacher_net(images)\n",
    "\n",
    "        # Get the segmentation classes\n",
    "        segmentation_classes = utils.getTargetSegmentation(labels)\n",
    "\n",
    "        # Compute the loss\n",
    "        ce_loss = CE_loss(teacher_net_predictions, segmentation_classes)\n",
    "        running_train_loss += ce_loss.item()\n",
    "        # dice_loss = dice_coefficient(teacher_net_predictions, labels)\n",
    "        dice_loss = utils.compute_dsc(teacher_net_predictions, labels)\n",
    "        running_dice_loss += dice_loss\n",
    "\n",
    "        # Backprop\n",
    "        ce_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "        # ### UNSUPERVISED BATCH (consistency regularization)\n",
    "        # try :\n",
    "        #     unsupervised_data = next(unsupervised_iter)\n",
    "        # except StopIteration:\n",
    "        #     unsupervised_iter = iter(unsupervised_loader)\n",
    "        #     unsupervised_data = next(unsupervised_iter)\n",
    "        \n",
    "        # unsupervised_images, _, _ = unsupervised_data\n",
    "        # unsupervised_images = utils.to_var(unsupervised_images).to(device)\n",
    "\n",
    "        # teacher_net.zero_grad()\n",
    "        # optimizer.zero_grad()\n",
    "        \n",
    "        # consistency_loss = consistency_regularizer(teacher_net, unsupervised_images)\n",
    "        # (alpha * consistency_loss).backward()\n",
    "        # optimizer.step()\n",
    "\n",
    "        # running_train_loss += consistency_loss.item()\n",
    "        # running_dice_loss += 0\n",
    "\n",
    "\n",
    "        ### SEMI-SUPERVISED BATCH (pseudo labels made by Teacher)\n",
    "        try :\n",
    "            unlabeled_data = next(unlabeled_iter)\n",
    "        except StopIteration:\n",
    "            unlabeled_iter = iter(unlabeledEval_loader_full)\n",
    "            unlabeled_data = next(unlabeled_iter)\n",
    "\n",
    "        images, img_names = unlabeled_data\n",
    "        images = utils.to_var(images).to(device)\n",
    "\n",
    "        teacher_net.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #on recupere les distributions de proba du teacher pour les unlabeled\n",
    "        segmentation_class_teacher = get_teacher_proba(num_epoch_teacher, img_names, device)\n",
    "        #predictions sur unlabeled\n",
    "        teacher_net_predictions = teacher_net(images)\n",
    "        KLdivLoss = distillation_loss(teacher_net_predictions, segmentation_class_teacher)\n",
    "        print(f\"KLdivLOSS epoch {epoch}\")\n",
    "        (alpha * KLdivLoss).backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_train_loss += KLdivLoss.item()\n",
    "        running_dice_loss += 0\n",
    "\n",
    "        \n",
    "        # Add the loss to the tensorboard every 5 batches\n",
    "        if idx % 10 == 0:\n",
    "            writer.add_scalar(\n",
    "                \"Loss/train\", running_train_loss / (idx + 1), epoch * len(supervised_loader) + idx\n",
    "            )\n",
    "            writer.add_scalar(\n",
    "                \"Dice/train\", running_dice_loss / (idx + 1), epoch * len(supervised_loader) + idx\n",
    "            )\n",
    "\n",
    "        if idx % 100 == 0:\n",
    "            # Also add visualizations of the images\n",
    "            probs = torch.softmax(teacher_net_predictions, dim=1)\n",
    "            y_pred = torch.argmax(probs, dim=1)\n",
    "            writer.add_figure('predictions vs. actuals',\n",
    "                        utils.plot_net_predictions(images, labels, y_pred, batch_size),\n",
    "                        global_step=epoch * len(supervised_loader) + idx)\n",
    "\n",
    "        # THIS IS JUST TO VISUALIZE THE TRAINING\n",
    "        printProgressBar(\n",
    "            idx + 1,\n",
    "            num_batches,\n",
    "            prefix=\"[Training] Epoch: {} \".format(epoch),\n",
    "            length=15,\n",
    "            suffix=\" Loss: {:.4f}, \".format(running_train_loss / (idx + 1)),\n",
    "        )\n",
    "\n",
    "    train_loss = running_train_loss / num_batches\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    train_dc_loss = running_dice_loss / num_batches\n",
    "    train_dc_losses.append(train_dc_loss)\n",
    "\n",
    "    teacher_net.eval()\n",
    "    val_running_loss = 0\n",
    "    val_running_dc = 0\n",
    "\n",
    "    # Validation loop\n",
    "    with torch.no_grad():\n",
    "        for idx, data in enumerate(val_loader):\n",
    "            images, labels, img_names = data\n",
    "\n",
    "            labels = utils.to_var(labels).to(device)\n",
    "            images = utils.to_var(images).to(device)\n",
    "\n",
    "            teacher_net_predictions = teacher_net(images)\n",
    "\n",
    "            segmentation_classes = utils.getTargetSegmentation(labels)\n",
    "\n",
    "            loss = CE_loss(teacher_net_predictions, segmentation_classes) \n",
    "            val_running_loss += loss.item()\n",
    "\n",
    "            # dice_loss = dice_coefficient(teacher_net_predictions, labels)\n",
    "            dice_loss = utils.compute_dsc(teacher_net_predictions, labels)\n",
    "            val_running_dc += dice_loss\n",
    "\n",
    "            if idx % 10 == 0:\n",
    "                writer.add_scalar(\n",
    "                    \"Loss/val\",\n",
    "                    val_running_loss / (idx + 1),\n",
    "                    epoch * len(val_loader) + idx,\n",
    "                )\n",
    "                writer.add_scalar(\n",
    "                    \"Dice/val\",\n",
    "                    val_running_dc / (idx + 1),\n",
    "                    epoch * len(val_loader) + idx,\n",
    "                )\n",
    "\n",
    "            printProgressBar(\n",
    "                idx + 1,\n",
    "                len(val_loader),\n",
    "                prefix=\"[Validation] Epoch: {} \".format(epoch),\n",
    "                length=15,\n",
    "                suffix=\" Loss: {:.4f}, \".format(val_running_loss / (idx + 1)),\n",
    "            )\n",
    "\n",
    "    val_loss = val_running_loss / len(val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    dc_loss = val_running_dc / len(val_loader)\n",
    "    val_dc_losses.append(dc_loss)\n",
    "\n",
    "    # Check if model performed best and save it if true\n",
    "    if val_loss < best_loss_val:\n",
    "        best_loss_val = val_loss\n",
    "        if not os.path.exists(\"./models/\" + modelName):\n",
    "            os.makedirs(\"./models/\" + modelName)\n",
    "        torch.save(\n",
    "            teacher_net.state_dict(), \"./models/\" + modelName + \"/\" + str(epoch) + \"_Epoch\"\n",
    "        )\n",
    "\n",
    "    printProgressBar(\n",
    "        num_batches,\n",
    "        num_batches,\n",
    "        done=\"[Epoch: {}, TrainLoss: {:.4f}, TrainDice: {:.4f}, ValLoss: {:.4f}\".format(\n",
    "            epoch, train_loss, train_dc_loss, val_loss\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    np.save(os.path.join(directory, \"Losses.npy\"), train_losses)\n",
    "writer.flush()  # Flush the writer to ensure that all the data is written to disk\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "871e0829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils import inference\n",
    "# # C:\\Users\\nicos\\OneDrive\\Bureau\\ETS - 2024 - 2025\\MTI865-ApprentissageProfondVision\\mti865_projet\\models\\SemiSupervised-TransformConsistency\n",
    "# epoch_to_load = 76\n",
    "# model = UNet(4)\n",
    "# model.load_state_dict(torch.load(f\"./models/SemiSupervised-TransformConsistency/{epoch_to_load}_Epoch\"))\n",
    "# inf_losses = inference(model, val_loader, \"test\", epoch_to_load)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a371d466-76ab-449a-9b76-79fdd1d2a738",
   "metadata": {},
   "source": [
    "### Generate pseudo labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9afe7ad9-62e2-4be9-b65d-e5b4d35d3c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len image batch :  126\n",
      "[Inference] Teacher Inference Done !                                                                         \n"
     ]
    }
   ],
   "source": [
    " inferenceTeacher(teacher_net, unlabeledEval_loader_full, 74, device) #predictions sur les unlabeled\n",
    "#predictions enregistrees dans Data/train/Img-UnlabeledPredictions/{numEpoch}\n",
    "#probabilités de predictions enregistrées dans Data/train/Img-UnlabeledProbabilities/{numEpoch}\n",
    "#comparaison image d'entrée/prédiction enregistrée dans Results/Images/TeacherUnlabeledPredictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df73346d-dda6-460b-a270-94f4eb503f11",
   "metadata": {},
   "source": [
    "### Student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d948eabb-1657-4aa7-9c83-ef010d50ffa4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "~~~~~~~~  Starting the training of the student... ~~~~~~\n",
      "----------------------------------------\n",
      "Using device: cpu\n",
      "~~~~~~~~~~~ Creating the UNet model ~~~~~~~~~~\n",
      " Model Name: SemiSupervised-TransformConsistency\n",
      "Les poids du modèle Teacher (époque 74) ont été chargés avec succès dans le modèle Student.\n",
      "Total params: 60,664\n",
      "~~~~~~~~~~~ Starting the training ~~~~~~~~~~\n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.029475480318069458 et loss avant de l'appliquer = 0.047923943027853966\n",
      "KLdivLoss = 0.02735413983464241 et loss avant de l'appliquer = 0.9588698968291283\n",
      "KLdivLoss = 0.025657566264271736 et loss avant de l'appliquer = 1.850233979523182\n",
      "KLdivLoss = 0.024796538054943085 et loss avant de l'appliquer = 2.6993032451719046\n",
      "KLdivLoss = 0.02383602038025856 et loss avant de l'appliquer = 3.446049453690648\n",
      "KLdivLoss = 0.022614916786551476 et loss avant de l'appliquer = 4.327939715236425\n",
      "KLdivLoss = 0.021987000480294228 et loss avant de l'appliquer = 5.1009624395519495\n",
      "KLdivLoss = 0.021552275866270065 et loss avant de l'appliquer = 5.723172536119819\n",
      "KLdivLoss = 0.021275322884321213 et loss avant de l'appliquer = 6.380378130823374\n",
      "KLdivLoss = 0.021232517436146736 et loss avant de l'appliquer = 7.046648403629661\n",
      "KLdivLoss = 0.020968176424503326 et loss avant de l'appliquer = 7.711375176906586\n",
      "KLdivLoss = 0.020261965692043304 et loss avant de l'appliquer = 8.291178843937814\n",
      "KLdivLoss = 0.01996772177517414 et loss avant de l'appliquer = 8.792961618863046\n",
      "[Validation] Epoch: 0 [DONE]                                 \n",
      "[Epoch: 0, TrainLoss: 0.0720, TrainDice: 0.0535, ValLoss: 0.2184                                             \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.019891800358891487 et loss avant de l'appliquer = 0.04247144050896168\n",
      "KLdivLoss = 0.019811293110251427 et loss avant de l'appliquer = 0.5858240928500891\n",
      "KLdivLoss = 0.019159266725182533 et loss avant de l'appliquer = 1.1870605647563934\n",
      "KLdivLoss = 0.018047653138637543 et loss avant de l'appliquer = 2.092377606779337\n",
      "KLdivLoss = 0.016765035688877106 et loss avant de l'appliquer = 2.910117944702506\n",
      "KLdivLoss = 0.016184614971280098 et loss avant de l'appliquer = 3.6051684636622667\n",
      "KLdivLoss = 0.01486656628549099 et loss avant de l'appliquer = 4.3293251087889075\n",
      "KLdivLoss = 0.014097150415182114 et loss avant de l'appliquer = 5.065770950168371\n",
      "KLdivLoss = 0.014715239405632019 et loss avant de l'appliquer = 5.568265524692833\n",
      "KLdivLoss = 0.01455525029450655 et loss avant de l'appliquer = 6.112393626943231\n",
      "KLdivLoss = 0.014537759125232697 et loss avant de l'appliquer = 6.619949926622212\n",
      "KLdivLoss = 0.014341242611408234 et loss avant de l'appliquer = 7.1537041598930955\n",
      "KLdivLoss = 0.014164545573294163 et loss avant de l'appliquer = 7.660541485995054\n",
      "[Validation] Epoch: 1 [DONE]                                 \n",
      "[Epoch: 1, TrainLoss: 0.0633, TrainDice: 0.0556, ValLoss: 0.0569                                             \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.013965526595711708 et loss avant de l'appliquer = 0.059063924476504326\n",
      "KLdivLoss = 0.013561848551034927 et loss avant de l'appliquer = 0.6461143055930734\n",
      "KLdivLoss = 0.013663647696375847 et loss avant de l'appliquer = 1.1546002635732293\n",
      "KLdivLoss = 0.013693749904632568 et loss avant de l'appliquer = 1.6970046339556575\n",
      "KLdivLoss = 0.013884473592042923 et loss avant de l'appliquer = 2.2580531844869256\n",
      "KLdivLoss = 0.01394926942884922 et loss avant de l'appliquer = 2.7610018253326416\n",
      "KLdivLoss = 0.013564439490437508 et loss avant de l'appliquer = 3.2749901516363025\n",
      "KLdivLoss = 0.01321360282599926 et loss avant de l'appliquer = 3.799343070946634\n",
      "KLdivLoss = 0.012921560555696487 et loss avant de l'appliquer = 4.3280757972970605\n",
      "KLdivLoss = 0.012487975880503654 et loss avant de l'appliquer = 4.867688511498272\n",
      "KLdivLoss = 0.011964013800024986 et loss avant de l'appliquer = 5.3830811008811\n",
      "KLdivLoss = 0.011599970050156116 et loss avant de l'appliquer = 5.888504451140761\n",
      "KLdivLoss = 0.011298551224172115 et loss avant de l'appliquer = 6.393132284283638\n",
      "[Validation] Epoch: 2 [DONE]                                 \n",
      "[Epoch: 2, TrainLoss: 0.0524, TrainDice: 0.0552, ValLoss: 0.1478                                             \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.011355225928127766 et loss avant de l'appliquer = 0.04967669490724802\n",
      "KLdivLoss = 0.011054079048335552 et loss avant de l'appliquer = 0.5447158422321081\n",
      "KLdivLoss = 0.011131254956126213 et loss avant de l'appliquer = 0.9998824698850513\n",
      "KLdivLoss = 0.010697610676288605 et loss avant de l'appliquer = 1.5889269802719355\n",
      "KLdivLoss = 0.009860868565738201 et loss avant de l'appliquer = 2.2719750087708235\n",
      "KLdivLoss = 0.009810327552258968 et loss avant de l'appliquer = 2.906801937147975\n",
      "KLdivLoss = 0.009361420758068562 et loss avant de l'appliquer = 3.378885142505169\n",
      "KLdivLoss = 0.009435519576072693 et loss avant de l'appliquer = 3.8468910343945026\n",
      "KLdivLoss = 0.009289812296628952 et loss avant de l'appliquer = 4.322810407727957\n",
      "KLdivLoss = 0.009529663249850273 et loss avant de l'appliquer = 4.749891269952059\n",
      "KLdivLoss = 0.009175064973533154 et loss avant de l'appliquer = 5.389460160396993\n",
      "KLdivLoss = 0.008812673389911652 et loss avant de l'appliquer = 5.8738954877480865\n",
      "KLdivLoss = 0.008848918601870537 et loss avant de l'appliquer = 6.435018234886229\n",
      "[Validation] Epoch: 3 [DONE]                                 \n",
      "[Epoch: 3, TrainLoss: 0.0530, TrainDice: 0.0552, ValLoss: 0.0584                                             \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.008467565290629864 et loss avant de l'appliquer = 0.05398878734558821\n",
      "KLdivLoss = 0.008686733432114124 et loss avant de l'appliquer = 0.5615080334246159\n",
      "KLdivLoss = 0.008394859731197357 et loss avant de l'appliquer = 1.1354725807905197\n",
      "KLdivLoss = 0.008318847976624966 et loss avant de l'appliquer = 1.6192863574251533\n",
      "KLdivLoss = 0.008346304297447205 et loss avant de l'appliquer = 2.073583325371146\n",
      "KLdivLoss = 0.00844251736998558 et loss avant de l'appliquer = 2.522319655865431\n",
      "KLdivLoss = 0.008140604943037033 et loss avant de l'appliquer = 3.0250909943133593\n",
      "KLdivLoss = 0.008154972456395626 et loss avant de l'appliquer = 3.5080037405714393\n",
      "KLdivLoss = 0.007988948374986649 et loss avant de l'appliquer = 4.000672494061291\n",
      "KLdivLoss = 0.00849102158099413 et loss avant de l'appliquer = 4.437177233397961\n",
      "KLdivLoss = 0.008757561445236206 et loss avant de l'appliquer = 4.891316080465913\n",
      "KLdivLoss = 0.008408114314079285 et loss avant de l'appliquer = 5.319978568702936\n",
      "KLdivLoss = 0.008374068886041641 et loss avant de l'appliquer = 5.756117522716522\n",
      "[Validation] Epoch: 4 [DONE]                                 \n",
      "[Epoch: 4, TrainLoss: 0.0474, TrainDice: 0.0555, ValLoss: 0.0456                                             \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.00854191742837429 et loss avant de l'appliquer = 0.03069467283785343\n",
      "KLdivLoss = 0.009045611135661602 et loss avant de l'appliquer = 0.41527413949370384\n",
      "KLdivLoss = 0.008956804871559143 et loss avant de l'appliquer = 0.8226515995338559\n",
      "KLdivLoss = 0.0090511254966259 et loss avant de l'appliquer = 1.2505093459039927\n",
      "KLdivLoss = 0.009138568304479122 et loss avant de l'appliquer = 1.6287676487118006\n",
      "KLdivLoss = 0.008957617916166782 et loss avant de l'appliquer = 2.090567409992218\n",
      "KLdivLoss = 0.00937340036034584 et loss avant de l'appliquer = 2.527508563362062\n",
      "KLdivLoss = 0.009125743992626667 et loss avant de l'appliquer = 3.030150732025504\n",
      "KLdivLoss = 0.009124375879764557 et loss avant de l'appliquer = 3.472432001493871\n",
      "KLdivLoss = 0.008967527188360691 et loss avant de l'appliquer = 3.9272541981190443\n",
      "KLdivLoss = 0.00888076052069664 et loss avant de l'appliquer = 4.44745188113302\n",
      "KLdivLoss = 0.00884917937219143 et loss avant de l'appliquer = 4.934292796999216\n",
      "KLdivLoss = 0.00907215103507042 et loss avant de l'appliquer = 5.356152115389705\n",
      "[Validation] Epoch: 5 [DONE]                                 \n",
      "[Epoch: 5, TrainLoss: 0.0445, TrainDice: 0.0550, ValLoss: 0.0561                                             \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.009024637751281261 et loss avant de l'appliquer = 0.05991966184228659\n",
      "KLdivLoss = 0.008803388103842735 et loss avant de l'appliquer = 0.5494113396853209\n",
      "KLdivLoss = 0.008589067496359348 et loss avant de l'appliquer = 1.1061957348138094\n",
      "KLdivLoss = 0.008693143725395203 et loss avant de l'appliquer = 1.5283646015450358\n",
      "KLdivLoss = 0.008636869490146637 et loss avant de l'appliquer = 1.9809534819796681\n",
      "KLdivLoss = 0.008425012230873108 et loss avant de l'appliquer = 2.4188791951164603\n",
      "KLdivLoss = 0.008578156121075153 et loss avant de l'appliquer = 2.8706406373530626\n",
      "KLdivLoss = 0.00841443706303835 et loss avant de l'appliquer = 3.330750096589327\n",
      "KLdivLoss = 0.008462482132017612 et loss avant de l'appliquer = 3.728745313361287\n",
      "KLdivLoss = 0.008428500033915043 et loss avant de l'appliquer = 4.157928095199168\n",
      "KLdivLoss = 0.008297843858599663 et loss avant de l'appliquer = 4.614729351364076\n",
      "KLdivLoss = 0.008120235055685043 et loss avant de l'appliquer = 5.0424268851056695\n",
      "KLdivLoss = 0.00818906631320715 et loss avant de l'appliquer = 5.393922366667539\n",
      "[Validation] Epoch: 6 [DONE]                                 \n",
      "[Epoch: 6, TrainLoss: 0.0443, TrainDice: 0.0534, ValLoss: 0.0901                                             \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.008306264877319336 et loss avant de l'appliquer = 0.03798830509185791\n",
      "KLdivLoss = 0.008217970840632915 et loss avant de l'appliquer = 0.4458653638139367\n",
      "KLdivLoss = 0.008478379808366299 et loss avant de l'appliquer = 0.8377972319722176\n",
      "KLdivLoss = 0.00780320493504405 et loss avant de l'appliquer = 1.4300358202308416\n",
      "KLdivLoss = 0.006948353722691536 et loss avant de l'appliquer = 2.1163104153238237\n",
      "KLdivLoss = 0.006611252203583717 et loss avant de l'appliquer = 2.6513879001140594\n",
      "KLdivLoss = 0.0067443642765283585 et loss avant de l'appliquer = 3.1705116499215364\n",
      "KLdivLoss = 0.006482004653662443 et loss avant de l'appliquer = 3.63893849728629\n",
      "KLdivLoss = 0.0071484921500086784 et loss avant de l'appliquer = 4.060222170781344\n",
      "KLdivLoss = 0.00755001325160265 et loss avant de l'appliquer = 4.456782488152385\n",
      "KLdivLoss = 0.007286662235856056 et loss avant de l'appliquer = 4.943533168174326\n",
      "KLdivLoss = 0.00746953533962369 et loss avant de l'appliquer = 5.319245094433427\n",
      "KLdivLoss = 0.00767638860270381 et loss avant de l'appliquer = 5.7421607044525445\n",
      "[Validation] Epoch: 7 [DONE]                                 \n",
      "[Epoch: 7, TrainLoss: 0.0475, TrainDice: 0.0543, ValLoss: 0.0794                                             \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.007454578764736652 et loss avant de l'appliquer = 0.06691711489111185\n",
      "KLdivLoss = 0.007379451766610146 et loss avant de l'appliquer = 0.45642324537038803\n",
      "KLdivLoss = 0.00753313722088933 et loss avant de l'appliquer = 0.8671636623330414\n",
      "KLdivLoss = 0.007473577745258808 et loss avant de l'appliquer = 1.262364611029625\n",
      "KLdivLoss = 0.00750490790233016 et loss avant de l'appliquer = 1.639260210096836\n",
      "KLdivLoss = 0.007456839084625244 et loss avant de l'appliquer = 2.0499643818475306\n",
      "KLdivLoss = 0.007934262044727802 et loss avant de l'appliquer = 2.42463947692886\n",
      "KLdivLoss = 0.007836597040295601 et loss avant de l'appliquer = 2.807159486692399\n",
      "KLdivLoss = 0.007975157350301743 et loss avant de l'appliquer = 3.181951919104904\n",
      "KLdivLoss = 0.007997697219252586 et loss avant de l'appliquer = 3.5413622627966106\n",
      "KLdivLoss = 0.008056926541030407 et loss avant de l'appliquer = 3.9977312884293497\n",
      "KLdivLoss = 0.008384335786104202 et loss avant de l'appliquer = 4.35326759936288\n",
      "KLdivLoss = 0.00843135453760624 et loss avant de l'appliquer = 4.721194782759994\n",
      "[Validation] Epoch: 8 [DONE]                                 \n",
      "[Epoch: 8, TrainLoss: 0.0390, TrainDice: 0.0544, ValLoss: 0.0584                                             \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.008353574201464653 et loss avant de l'appliquer = 0.048237716779112816\n",
      "KLdivLoss = 0.008340314961969852 et loss avant de l'appliquer = 0.43327831849455833\n",
      "KLdivLoss = 0.008611719124019146 et loss avant de l'appliquer = 0.7825953019782901\n",
      "KLdivLoss = 0.008003056049346924 et loss avant de l'appliquer = 1.2598989270627499\n",
      "KLdivLoss = 0.007546905428171158 et loss avant de l'appliquer = 1.737434033304453\n",
      "KLdivLoss = 0.007908634841442108 et loss avant de l'appliquer = 2.102182135451585\n",
      "KLdivLoss = 0.007902843877673149 et loss avant de l'appliquer = 2.4613016708754003\n",
      "KLdivLoss = 0.008124567568302155 et loss avant de l'appliquer = 2.9053971651010215\n",
      "KLdivLoss = 0.008050724864006042 et loss avant de l'appliquer = 3.2934326552785933\n",
      "KLdivLoss = 0.008115527220070362 et loss avant de l'appliquer = 3.780843992251903\n",
      "KLdivLoss = 0.007833462208509445 et loss avant de l'appliquer = 4.240805987734348\n",
      "KLdivLoss = 0.007991109043359756 et loss avant de l'appliquer = 4.624021803494543\n",
      "KLdivLoss = 0.00814136303961277 et loss avant de l'appliquer = 4.968971702735871\n",
      "[Validation] Epoch: 9 [DONE]                                 \n",
      "[Epoch: 9, TrainLoss: 0.0409, TrainDice: 0.0551, ValLoss: 0.0560                                             \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.00819411687552929 et loss avant de l'appliquer = 0.0480108093470335\n",
      "KLdivLoss = 0.008470854721963406 et loss avant de l'appliquer = 0.42211440671235323\n",
      "KLdivLoss = 0.008694465272128582 et loss avant de l'appliquer = 0.7928490843623877\n",
      "KLdivLoss = 0.008339287713170052 et loss avant de l'appliquer = 1.1729439999908209\n",
      "KLdivLoss = 0.00876691285520792 et loss avant de l'appliquer = 1.5263132089748979\n",
      "KLdivLoss = 0.008607364259660244 et loss avant de l'appliquer = 1.8570978678762913\n",
      "KLdivLoss = 0.008545396849513054 et loss avant de l'appliquer = 2.22093204036355\n",
      "KLdivLoss = 0.008783837780356407 et loss avant de l'appliquer = 2.634485762566328\n",
      "KLdivLoss = 0.008309255354106426 et loss avant de l'appliquer = 3.1087185917422175\n",
      "KLdivLoss = 0.008266373537480831 et loss avant de l'appliquer = 3.609068175777793\n",
      "KLdivLoss = 0.008300530724227428 et loss avant de l'appliquer = 4.036443273536861\n",
      "KLdivLoss = 0.008153916336596012 et loss avant de l'appliquer = 4.439813897013664\n",
      "KLdivLoss = 0.008071565069258213 et loss avant de l'appliquer = 4.801031980663538\n",
      "[Validation] Epoch: 10 [DONE]                                 \n",
      "[Epoch: 10, TrainLoss: 0.0395, TrainDice: 0.0537, ValLoss: 0.0463                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.008452189154922962 et loss avant de l'appliquer = 0.05202305782586336\n",
      "KLdivLoss = 0.008457834832370281 et loss avant de l'appliquer = 0.44020643923431635\n",
      "KLdivLoss = 0.00834065955132246 et loss avant de l'appliquer = 0.7405349668115377\n",
      "KLdivLoss = 0.008393284864723682 et loss avant de l'appliquer = 1.1099120089784265\n",
      "KLdivLoss = 0.008344680070877075 et loss avant de l'appliquer = 1.5164368385449052\n",
      "KLdivLoss = 0.008135505020618439 et loss avant de l'appliquer = 1.9009895585477352\n",
      "KLdivLoss = 0.00821035634726286 et loss avant de l'appliquer = 2.2807000717148185\n",
      "KLdivLoss = 0.007956034503877163 et loss avant de l'appliquer = 2.7715966291725636\n",
      "KLdivLoss = 0.00778516661375761 et loss avant de l'appliquer = 3.2278634281829\n",
      "KLdivLoss = 0.007867366075515747 et loss avant de l'appliquer = 3.7347770873457193\n",
      "KLdivLoss = 0.007442684844136238 et loss avant de l'appliquer = 4.153865123633295\n",
      "KLdivLoss = 0.0068516237661242485 et loss avant de l'appliquer = 4.682643810752779\n",
      "KLdivLoss = 0.0069623482413589954 et loss avant de l'appliquer = 5.0893361498601735\n",
      "[Validation] Epoch: 11 [DONE]                                 \n",
      "[Epoch: 11, TrainLoss: 0.0417, TrainDice: 0.0537, ValLoss: 0.0405                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.007114107720553875 et loss avant de l'appliquer = 0.04106700699776411\n",
      "KLdivLoss = 0.00726154912263155 et loss avant de l'appliquer = 0.42966578993946314\n",
      "KLdivLoss = 0.007223369553685188 et loss avant de l'appliquer = 0.8145204996690154\n",
      "KLdivLoss = 0.0077939522452652454 et loss avant de l'appliquer = 1.2344687622971833\n",
      "KLdivLoss = 0.006877382751554251 et loss avant de l'appliquer = 1.7570074936375022\n",
      "KLdivLoss = 0.0070254188030958176 et loss avant de l'appliquer = 2.1694838008843362\n",
      "KLdivLoss = 0.006834941916167736 et loss avant de l'appliquer = 2.601061396766454\n",
      "KLdivLoss = 0.007171100936830044 et loss avant de l'appliquer = 2.9218726828694344\n",
      "KLdivLoss = 0.007569741457700729 et loss avant de l'appliquer = 3.285934208892286\n",
      "KLdivLoss = 0.007655667141079903 et loss avant de l'appliquer = 3.7178496280685067\n",
      "KLdivLoss = 0.007693951949477196 et loss avant de l'appliquer = 4.157346254214644\n",
      "KLdivLoss = 0.007352401968091726 et loss avant de l'appliquer = 4.586523028090596\n",
      "KLdivLoss = 0.007699854671955109 et loss avant de l'appliquer = 4.964797925204039\n",
      "[Validation] Epoch: 12 [DONE]                                 \n",
      "[Epoch: 12, TrainLoss: 0.0413, TrainDice: 0.0550, ValLoss: 0.0691                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.007536110933870077 et loss avant de l'appliquer = 0.02836764184758067\n",
      "KLdivLoss = 0.007652446627616882 et loss avant de l'appliquer = 0.42784610018134117\n",
      "KLdivLoss = 0.008005045354366302 et loss avant de l'appliquer = 0.7908156281337142\n",
      "KLdivLoss = 0.007924259640276432 et loss avant de l'appliquer = 1.261892497073859\n",
      "KLdivLoss = 0.00839140173047781 et loss avant de l'appliquer = 1.6591412401758134\n",
      "KLdivLoss = 0.008465849794447422 et loss avant de l'appliquer = 2.0013833926059306\n",
      "KLdivLoss = 0.008601083420217037 et loss avant de l'appliquer = 2.324843403417617\n",
      "KLdivLoss = 0.008052155375480652 et loss avant de l'appliquer = 2.7712998096831143\n",
      "KLdivLoss = 0.007901578210294247 et loss avant de l'appliquer = 3.194972275290638\n",
      "KLdivLoss = 0.007922501303255558 et loss avant de l'appliquer = 3.5602439693175256\n",
      "KLdivLoss = 0.007963094860315323 et loss avant de l'appliquer = 3.888398255687207\n",
      "KLdivLoss = 0.00802585855126381 et loss avant de l'appliquer = 4.303757736925036\n",
      "KLdivLoss = 0.008417513221502304 et loss avant de l'appliquer = 4.621067754458636\n",
      "[Validation] Epoch: 13 [DONE]                                 \n",
      "[Epoch: 13, TrainLoss: 0.0379, TrainDice: 0.0545, ValLoss: 0.0722                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.0083443783223629 et loss avant de l'appliquer = 0.05111997574567795\n",
      "KLdivLoss = 0.008823882788419724 et loss avant de l'appliquer = 0.42170507833361626\n",
      "KLdivLoss = 0.009010512381792068 et loss avant de l'appliquer = 0.7854983946308494\n",
      "KLdivLoss = 0.008707772009074688 et loss avant de l'appliquer = 1.2684488147497177\n",
      "KLdivLoss = 0.008570192381739616 et loss avant de l'appliquer = 1.7042732313275337\n",
      "KLdivLoss = 0.008154988288879395 et loss avant de l'appliquer = 2.180991441011429\n",
      "KLdivLoss = 0.007768991868942976 et loss avant de l'appliquer = 2.6137579907663167\n",
      "KLdivLoss = 0.007817203179001808 et loss avant de l'appliquer = 2.9871547198854387\n",
      "KLdivLoss = 0.007611372508108616 et loss avant de l'appliquer = 3.3942585517652333\n",
      "KLdivLoss = 0.008016539737582207 et loss avant de l'appliquer = 3.7566023473627865\n",
      "KLdivLoss = 0.008160891011357307 et loss avant de l'appliquer = 4.093052097130567\n",
      "KLdivLoss = 0.008207384496927261 et loss avant de l'appliquer = 4.409304243978113\n",
      "KLdivLoss = 0.008508925326168537 et loss avant de l'appliquer = 4.757111644838005\n",
      "[Validation] Epoch: 14 [DONE]                                 \n",
      "[Epoch: 14, TrainLoss: 0.0391, TrainDice: 0.0544, ValLoss: 0.0905                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.008363449946045876 et loss avant de l'appliquer = 0.04926030524075031\n",
      "KLdivLoss = 0.008672451600432396 et loss avant de l'appliquer = 0.42852785903960466\n",
      "KLdivLoss = 0.008618175983428955 et loss avant de l'appliquer = 0.8189821671694517\n",
      "KLdivLoss = 0.008527986705303192 et loss avant de l'appliquer = 1.182628732174635\n",
      "KLdivLoss = 0.00843813456594944 et loss avant de l'appliquer = 1.5393616808578372\n",
      "KLdivLoss = 0.008816924877464771 et loss avant de l'appliquer = 1.8550570206716657\n",
      "KLdivLoss = 0.008468138054013252 et loss avant de l'appliquer = 2.262752078473568\n",
      "KLdivLoss = 0.008632604964077473 et loss avant de l'appliquer = 2.6260176822543144\n",
      "KLdivLoss = 0.008639147505164146 et loss avant de l'appliquer = 2.999206985346973\n",
      "KLdivLoss = 0.008557465858757496 et loss avant de l'appliquer = 3.369991316460073\n",
      "KLdivLoss = 0.008607348427176476 et loss avant de l'appliquer = 3.7139448262751102\n",
      "KLdivLoss = 0.007414363324642181 et loss avant de l'appliquer = 4.313996953889728\n",
      "KLdivLoss = 0.007036254275590181 et loss avant de l'appliquer = 4.9470410933718085\n",
      "[Validation] Epoch: 15 [DONE]                                 \n",
      "[Epoch: 15, TrainLoss: 0.0419, TrainDice: 0.0552, ValLoss: 0.0906                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.007100088521838188 et loss avant de l'appliquer = 0.08148658834397793\n",
      "KLdivLoss = 0.006665405351668596 et loss avant de l'appliquer = 0.5503484583459795\n",
      "KLdivLoss = 0.006342694163322449 et loss avant de l'appliquer = 0.9929809859022498\n",
      "KLdivLoss = 0.0066155362874269485 et loss avant de l'appliquer = 1.401801013853401\n",
      "KLdivLoss = 0.006810842547565699 et loss avant de l'appliquer = 1.810827531851828\n",
      "KLdivLoss = 0.006816376466304064 et loss avant de l'appliquer = 2.192852135747671\n",
      "KLdivLoss = 0.007300542201846838 et loss avant de l'appliquer = 2.5621085818856955\n",
      "KLdivLoss = 0.007693729363381863 et loss avant de l'appliquer = 2.8699519862420857\n",
      "KLdivLoss = 0.0075032892636954784 et loss avant de l'appliquer = 3.3441817234270275\n",
      "KLdivLoss = 0.007420815527439117 et loss avant de l'appliquer = 3.729399736505002\n",
      "KLdivLoss = 0.0075169820338487625 et loss avant de l'appliquer = 4.207566061522812\n",
      "KLdivLoss = 0.007228546775877476 et loss avant de l'appliquer = 4.603025396820158\n",
      "KLdivLoss = 0.007362198084592819 et loss avant de l'appliquer = 4.926472160499543\n",
      "[Validation] Epoch: 16 [DONE]                                 \n",
      "[Epoch: 16, TrainLoss: 0.0403, TrainDice: 0.0548, ValLoss: 0.0400                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.007613907568156719 et loss avant de l'appliquer = 0.028258432634174824\n",
      "KLdivLoss = 0.00779144698753953 et loss avant de l'appliquer = 0.4045648262836039\n",
      "KLdivLoss = 0.00803618784993887 et loss avant de l'appliquer = 0.8657490978948772\n",
      "KLdivLoss = 0.008146763779222965 et loss avant de l'appliquer = 1.3227426442317665\n",
      "KLdivLoss = 0.008067911490797997 et loss avant de l'appliquer = 1.6949633522890508\n",
      "KLdivLoss = 0.008182957768440247 et loss avant de l'appliquer = 2.0214751274324954\n",
      "KLdivLoss = 0.008181840181350708 et loss avant de l'appliquer = 2.43909601168707\n",
      "KLdivLoss = 0.00781673938035965 et loss avant de l'appliquer = 2.8417121139355004\n",
      "KLdivLoss = 0.007859672419726849 et loss avant de l'appliquer = 3.3190310546196997\n",
      "KLdivLoss = 0.007652364205569029 et loss avant de l'appliquer = 3.7287039454095066\n",
      "KLdivLoss = 0.007549452595412731 et loss avant de l'appliquer = 4.0784960351884365\n",
      "KLdivLoss = 0.008023712784051895 et loss avant de l'appliquer = 4.409357200842351\n",
      "KLdivLoss = 0.007679381873458624 et loss avant de l'appliquer = 4.8755767294205725\n",
      "[Validation] Epoch: 17 [DONE]                                 \n",
      "[Epoch: 17, TrainLoss: 0.0399, TrainDice: 0.0539, ValLoss: 0.0495                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.007724200375378132 et loss avant de l'appliquer = 0.03064688201993704\n",
      "KLdivLoss = 0.007865424267947674 et loss avant de l'appliquer = 0.4204252031631768\n",
      "KLdivLoss = 0.008289051242172718 et loss avant de l'appliquer = 0.7802616409026086\n",
      "KLdivLoss = 0.008242548443377018 et loss avant de l'appliquer = 1.1327092205174267\n",
      "KLdivLoss = 0.00842892937362194 et loss avant de l'appliquer = 1.4557845699600875\n",
      "KLdivLoss = 0.008725220337510109 et loss avant de l'appliquer = 1.8429818176664412\n",
      "KLdivLoss = 0.008803033269941807 et loss avant de l'appliquer = 2.168201749678701\n",
      "KLdivLoss = 0.009013038128614426 et loss avant de l'appliquer = 2.447158257011324\n",
      "KLdivLoss = 0.009120622649788857 et loss avant de l'appliquer = 2.78415608080104\n",
      "KLdivLoss = 0.008876211941242218 et loss avant de l'appliquer = 3.1952899801544845\n",
      "KLdivLoss = 0.008936304599046707 et loss avant de l'appliquer = 3.530307804699987\n",
      "KLdivLoss = 0.008788901381194592 et loss avant de l'appliquer = 3.8684986135922372\n",
      "KLdivLoss = 0.008777191862463951 et loss avant de l'appliquer = 4.203363286796957\n",
      "[Validation] Epoch: 18 [DONE]                                 \n",
      "[Epoch: 18, TrainLoss: 0.0345, TrainDice: 0.0541, ValLoss: 0.0857                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.008923976682126522 et loss avant de l'appliquer = 0.026708525605499744\n",
      "KLdivLoss = 0.008822830393910408 et loss avant de l'appliquer = 0.3616019506007433\n",
      "KLdivLoss = 0.00884314812719822 et loss avant de l'appliquer = 0.6604459742084146\n",
      "KLdivLoss = 0.008830126374959946 et loss avant de l'appliquer = 1.0501428274437785\n",
      "KLdivLoss = 0.008065875619649887 et loss avant de l'appliquer = 1.4952639564871788\n",
      "KLdivLoss = 0.007994811050593853 et loss avant de l'appliquer = 1.9257924119010568\n",
      "KLdivLoss = 0.008406378328800201 et loss avant de l'appliquer = 2.2864969531074166\n",
      "KLdivLoss = 0.008222105912864208 et loss avant de l'appliquer = 2.6581907272338867\n",
      "KLdivLoss = 0.00792337954044342 et loss avant de l'appliquer = 3.0958403646945953\n",
      "KLdivLoss = 0.008225906640291214 et loss avant de l'appliquer = 3.446706634014845\n",
      "KLdivLoss = 0.008120258338749409 et loss avant de l'appliquer = 3.854053219780326\n",
      "KLdivLoss = 0.008144203573465347 et loss avant de l'appliquer = 4.2051780838519335\n",
      "KLdivLoss = 0.00819015596061945 et loss avant de l'appliquer = 4.509499811567366\n",
      "[Validation] Epoch: 19 [DONE]                                 \n",
      "[Epoch: 19, TrainLoss: 0.0371, TrainDice: 0.0553, ValLoss: 0.0572                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.008140797726809978 et loss avant de l'appliquer = 0.028227909468114376\n",
      "KLdivLoss = 0.00831380020827055 et loss avant de l'appliquer = 0.3555274438112974\n",
      "KLdivLoss = 0.008435957133769989 et loss avant de l'appliquer = 0.6497201882302761\n",
      "KLdivLoss = 0.00854554120451212 et loss avant de l'appliquer = 1.0488508753478527\n",
      "KLdivLoss = 0.008738074451684952 et loss avant de l'appliquer = 1.3479803139343858\n",
      "KLdivLoss = 0.008694305084645748 et loss avant de l'appliquer = 1.7192293424159288\n",
      "KLdivLoss = 0.008821235038340092 et loss avant de l'appliquer = 2.020423835143447\n",
      "KLdivLoss = 0.00832633301615715 et loss avant de l'appliquer = 2.4187227934598923\n",
      "KLdivLoss = 0.008337371051311493 et loss avant de l'appliquer = 2.7967322655022144\n",
      "KLdivLoss = 0.008389935828745365 et loss avant de l'appliquer = 3.0930573269724846\n",
      "KLdivLoss = 0.008327747695147991 et loss avant de l'appliquer = 3.402863275259733\n",
      "KLdivLoss = 0.008334575220942497 et loss avant de l'appliquer = 3.7257568780332804\n",
      "KLdivLoss = 0.008334075100719929 et loss avant de l'appliquer = 4.0466619515791535\n",
      "[Validation] Epoch: 20 [DONE]                                 \n",
      "[Epoch: 20, TrainLoss: 0.0339, TrainDice: 0.0538, ValLoss: 0.1357                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.00825356412678957 et loss avant de l'appliquer = 0.0366424610838294\n",
      "KLdivLoss = 0.00782847311347723 et loss avant de l'appliquer = 0.4389820471405983\n",
      "KLdivLoss = 0.00815097987651825 et loss avant de l'appliquer = 0.82108367793262\n",
      "KLdivLoss = 0.007884187623858452 et loss avant de l'appliquer = 1.2382212523370981\n",
      "KLdivLoss = 0.007702450267970562 et loss avant de l'appliquer = 1.6310295732691884\n",
      "KLdivLoss = 0.008039392530918121 et loss avant de l'appliquer = 1.9674691027030349\n",
      "KLdivLoss = 0.007785503286868334 et loss avant de l'appliquer = 2.3544865110889077\n",
      "KLdivLoss = 0.008179329335689545 et loss avant de l'appliquer = 2.713411293923855\n",
      "KLdivLoss = 0.007990924641489983 et loss avant de l'appliquer = 3.0756323095411062\n",
      "KLdivLoss = 0.008186696097254753 et loss avant de l'appliquer = 3.4462463511154056\n",
      "KLdivLoss = 0.008065177127718925 et loss avant de l'appliquer = 3.8096596328541636\n",
      "KLdivLoss = 0.008167991414666176 et loss avant de l'appliquer = 4.127202291041613\n",
      "KLdivLoss = 0.008032196201384068 et loss avant de l'appliquer = 4.509381291456521\n",
      "[Validation] Epoch: 21 [DONE]                                 \n",
      "[Epoch: 21, TrainLoss: 0.0371, TrainDice: 0.0548, ValLoss: 0.0459                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.008035967126488686 et loss avant de l'appliquer = 0.051036762073636055\n",
      "KLdivLoss = 0.008171545341610909 et loss avant de l'appliquer = 0.41032352950423956\n",
      "KLdivLoss = 0.008408762514591217 et loss avant de l'appliquer = 0.7606347752735019\n",
      "KLdivLoss = 0.00805296003818512 et loss avant de l'appliquer = 1.1423967275768518\n",
      "KLdivLoss = 0.008234626613557339 et loss avant de l'appliquer = 1.4858412528410554\n",
      "KLdivLoss = 0.007748287171125412 et loss avant de l'appliquer = 1.8875203933566809\n",
      "KLdivLoss = 0.008094306103885174 et loss avant de l'appliquer = 2.208899355493486\n",
      "KLdivLoss = 0.008282981812953949 et loss avant de l'appliquer = 2.557395468465984\n",
      "KLdivLoss = 0.008302907459437847 et loss avant de l'appliquer = 2.9463274478912354\n",
      "KLdivLoss = 0.008544107899069786 et loss avant de l'appliquer = 3.352849637158215\n",
      "KLdivLoss = 0.008470190688967705 et loss avant de l'appliquer = 3.765703648328781\n",
      "KLdivLoss = 0.008342553861439228 et loss avant de l'appliquer = 4.174633945338428\n",
      "KLdivLoss = 0.00886104628443718 et loss avant de l'appliquer = 4.481321315281093\n",
      "[Validation] Epoch: 22 [DONE]                                 \n",
      "[Epoch: 22, TrainLoss: 0.0368, TrainDice: 0.0545, ValLoss: 0.0927                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.008914807811379433 et loss avant de l'appliquer = 0.02951313741505146\n",
      "KLdivLoss = 0.008434305898845196 et loss avant de l'appliquer = 0.4067059215158224\n",
      "KLdivLoss = 0.008204273879528046 et loss avant de l'appliquer = 0.8059129621833563\n",
      "KLdivLoss = 0.008383374661207199 et loss avant de l'appliquer = 1.1346185095608234\n",
      "KLdivLoss = 0.00859213899821043 et loss avant de l'appliquer = 1.4511345028877258\n",
      "KLdivLoss = 0.008591589517891407 et loss avant de l'appliquer = 1.7480606995522976\n",
      "KLdivLoss = 0.00873552355915308 et loss avant de l'appliquer = 2.0942662516608834\n",
      "KLdivLoss = 0.008428528904914856 et loss avant de l'appliquer = 2.5086040357127786\n",
      "KLdivLoss = 0.008319756016135216 et loss avant de l'appliquer = 2.8543524239212275\n",
      "KLdivLoss = 0.008373521268367767 et loss avant de l'appliquer = 3.139934027567506\n",
      "KLdivLoss = 0.008495733141899109 et loss avant de l'appliquer = 3.4700001450255513\n",
      "KLdivLoss = 0.008526329882442951 et loss avant de l'appliquer = 3.789791302755475\n",
      "KLdivLoss = 0.008531685918569565 et loss avant de l'appliquer = 4.141306763514876\n",
      "[Validation] Epoch: 23 [DONE]                                 \n",
      "[Epoch: 23, TrainLoss: 0.0340, TrainDice: 0.0545, ValLoss: 0.0353                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.008417528122663498 et loss avant de l'appliquer = 0.03348187543451786\n",
      "KLdivLoss = 0.008090156130492687 et loss avant de l'appliquer = 0.3700633039698005\n",
      "KLdivLoss = 0.008522496558725834 et loss avant de l'appliquer = 0.7011545328423381\n",
      "KLdivLoss = 0.008542094379663467 et loss avant de l'appliquer = 0.9945199554786086\n",
      "KLdivLoss = 0.008563971146941185 et loss avant de l'appliquer = 1.2891106074675918\n",
      "KLdivLoss = 0.008798539638519287 et loss avant de l'appliquer = 1.6376220686361194\n",
      "KLdivLoss = 0.00816488079726696 et loss avant de l'appliquer = 2.0863581905141473\n",
      "KLdivLoss = 0.00814819522202015 et loss avant de l'appliquer = 2.4395491974428296\n",
      "KLdivLoss = 0.008253782987594604 et loss avant de l'appliquer = 2.78699286095798\n",
      "KLdivLoss = 0.008231643587350845 et loss avant de l'appliquer = 3.1536113880574703\n",
      "KLdivLoss = 0.007948191836476326 et loss avant de l'appliquer = 3.4804921047762036\n",
      "KLdivLoss = 0.008367582224309444 et loss avant de l'appliquer = 3.838208549655974\n",
      "KLdivLoss = 0.007218595594167709 et loss avant de l'appliquer = 4.414836946874857\n",
      "[Validation] Epoch: 24 [DONE]                                 \n",
      "[Epoch: 24, TrainLoss: 0.0370, TrainDice: 0.0537, ValLoss: 0.1248                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.007119669578969479 et loss avant de l'appliquer = 0.06225986313074827\n",
      "KLdivLoss = 0.006907985545694828 et loss avant de l'appliquer = 0.5175224328413606\n",
      "KLdivLoss = 0.00674704322591424 et loss avant de l'appliquer = 0.8804537202231586\n",
      "KLdivLoss = 0.00677755381911993 et loss avant de l'appliquer = 1.3153671408072114\n",
      "KLdivLoss = 0.007040940225124359 et loss avant de l'appliquer = 1.6692959922365844\n",
      "KLdivLoss = 0.007338728755712509 et loss avant de l'appliquer = 1.969870156608522\n",
      "KLdivLoss = 0.007289404980838299 et loss avant de l'appliquer = 2.3533401847817004\n",
      "KLdivLoss = 0.007429106160998344 et loss avant de l'appliquer = 2.7299891831353307\n",
      "KLdivLoss = 0.007450132630765438 et loss avant de l'appliquer = 3.1007809974253178\n",
      "KLdivLoss = 0.007646031677722931 et loss avant de l'appliquer = 3.4501298046670854\n",
      "KLdivLoss = 0.00794227235019207 et loss avant de l'appliquer = 3.7934846966527402\n",
      "KLdivLoss = 0.007828029803931713 et loss avant de l'appliquer = 4.161811899859458\n",
      "KLdivLoss = 0.008167722262442112 et loss avant de l'appliquer = 4.4674837864004076\n",
      "[Validation] Epoch: 25 [DONE]                                 \n",
      "[Epoch: 25, TrainLoss: 0.0367, TrainDice: 0.0546, ValLoss: 0.0492                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.008214185014367104 et loss avant de l'appliquer = 0.05652819387614727\n",
      "KLdivLoss = 0.008399724960327148 et loss avant de l'appliquer = 0.36103477887809277\n",
      "KLdivLoss = 0.008436865173280239 et loss avant de l'appliquer = 0.7328585451468825\n",
      "KLdivLoss = 0.0084369583055377 et loss avant de l'appliquer = 1.0700975013896823\n",
      "KLdivLoss = 0.008188626728951931 et loss avant de l'appliquer = 1.4076429717242718\n",
      "KLdivLoss = 0.008415520191192627 et loss avant de l'appliquer = 1.7114456621930003\n",
      "KLdivLoss = 0.008515270426869392 et loss avant de l'appliquer = 2.0663366494700313\n",
      "KLdivLoss = 0.008590305224061012 et loss avant de l'appliquer = 2.3675622288137674\n",
      "KLdivLoss = 0.00847602915018797 et loss avant de l'appliquer = 2.7821277203038335\n",
      "KLdivLoss = 0.008074341341853142 et loss avant de l'appliquer = 3.1697184666991234\n",
      "KLdivLoss = 0.008156104013323784 et loss avant de l'appliquer = 3.512534228153527\n",
      "KLdivLoss = 0.008042529225349426 et loss avant de l'appliquer = 3.8568196278065443\n",
      "KLdivLoss = 0.0076865884475409985 et loss avant de l'appliquer = 4.27326676202938\n",
      "[Validation] Epoch: 26 [DONE]                                 \n",
      "[Epoch: 26, TrainLoss: 0.0359, TrainDice: 0.0548, ValLoss: 0.0482                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.007311882451176643 et loss avant de l'appliquer = 0.1014633197337389\n",
      "KLdivLoss = 0.00750493910163641 et loss avant de l'appliquer = 0.4258489031344652\n",
      "KLdivLoss = 0.007720872759819031 et loss avant de l'appliquer = 0.8150413460098207\n",
      "KLdivLoss = 0.007705245167016983 et loss avant de l'appliquer = 1.1981844021938741\n",
      "KLdivLoss = 0.007321102079004049 et loss avant de l'appliquer = 1.6230106125585735\n",
      "KLdivLoss = 0.007029369007796049 et loss avant de l'appliquer = 1.9938749130815268\n",
      "KLdivLoss = 0.006996812764555216 et loss avant de l'appliquer = 2.293724136427045\n",
      "KLdivLoss = 0.007146188989281654 et loss avant de l'appliquer = 2.6217005169019103\n",
      "KLdivLoss = 0.007279125042259693 et loss avant de l'appliquer = 2.9416366750374436\n",
      "KLdivLoss = 0.007426661904901266 et loss avant de l'appliquer = 3.276662290096283\n",
      "KLdivLoss = 0.007561397273093462 et loss avant de l'appliquer = 3.582021434325725\n",
      "KLdivLoss = 0.007748045492917299 et loss avant de l'appliquer = 3.881086296867579\n",
      "KLdivLoss = 0.00816765334457159 et loss avant de l'appliquer = 4.169922449160367\n",
      "[Validation] Epoch: 27 [DONE]                                 \n",
      "[Epoch: 27, TrainLoss: 0.0341, TrainDice: 0.0531, ValLoss: 0.0466                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.008203096687793732 et loss avant de l'appliquer = 0.0189219294115901\n",
      "KLdivLoss = 0.007989170961081982 et loss avant de l'appliquer = 0.3454293590039015\n",
      "KLdivLoss = 0.008025476709008217 et loss avant de l'appliquer = 0.6539392462000251\n",
      "KLdivLoss = 0.008111068978905678 et loss avant de l'appliquer = 0.980887658894062\n",
      "KLdivLoss = 0.008245831355452538 et loss avant de l'appliquer = 1.3447100967168808\n",
      "KLdivLoss = 0.00813252106308937 et loss avant de l'appliquer = 1.666686980985105\n",
      "KLdivLoss = 0.00842265598475933 et loss avant de l'appliquer = 2.0182423954829574\n",
      "KLdivLoss = 0.008335592225193977 et loss avant de l'appliquer = 2.356745382770896\n",
      "KLdivLoss = 0.008299325592815876 et loss avant de l'appliquer = 2.6781885344535112\n",
      "KLdivLoss = 0.00841496605426073 et loss avant de l'appliquer = 3.0057461000978947\n",
      "KLdivLoss = 0.008543863892555237 et loss avant de l'appliquer = 3.3450164422392845\n",
      "KLdivLoss = 0.008530966006219387 et loss avant de l'appliquer = 3.667361297644675\n",
      "KLdivLoss = 0.008478871546685696 et loss avant de l'appliquer = 3.9918277403339744\n",
      "[Validation] Epoch: 28 [DONE]                                 \n",
      "[Epoch: 28, TrainLoss: 0.0328, TrainDice: 0.0548, ValLoss: 0.0352                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.008577028289437294 et loss avant de l'appliquer = 0.03024972230195999\n",
      "KLdivLoss = 0.008371444419026375 et loss avant de l'appliquer = 0.354627694003284\n",
      "KLdivLoss = 0.008875428698956966 et loss avant de l'appliquer = 0.6586910597980022\n",
      "KLdivLoss = 0.008715236559510231 et loss avant de l'appliquer = 0.9403642741963267\n",
      "KLdivLoss = 0.00886455737054348 et loss avant de l'appliquer = 1.2429232308641076\n",
      "KLdivLoss = 0.008781183511018753 et loss avant de l'appliquer = 1.6205493174493313\n",
      "KLdivLoss = 0.008850683458149433 et loss avant de l'appliquer = 1.9529887391254306\n",
      "KLdivLoss = 0.008881278336048126 et loss avant de l'appliquer = 2.297762374393642\n",
      "KLdivLoss = 0.008437469601631165 et loss avant de l'appliquer = 2.630461709573865\n",
      "KLdivLoss = 0.008464683778584003 et loss avant de l'appliquer = 3.013071209192276\n",
      "KLdivLoss = 0.0084922406822443 et loss avant de l'appliquer = 3.410993100143969\n",
      "KLdivLoss = 0.008140185847878456 et loss avant de l'appliquer = 3.7227927334606647\n",
      "KLdivLoss = 0.008176552131772041 et loss avant de l'appliquer = 4.13223085924983\n",
      "[Validation] Epoch: 29 [DONE]                                 \n",
      "[Epoch: 29, TrainLoss: 0.0344, TrainDice: 0.0541, ValLoss: 0.0420                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.008116298355162144 et loss avant de l'appliquer = 0.040587455965578556\n",
      "KLdivLoss = 0.008319913409650326 et loss avant de l'appliquer = 0.3690188452601433\n",
      "KLdivLoss = 0.008414641954004765 et loss avant de l'appliquer = 0.6646526586264372\n",
      "KLdivLoss = 0.008246894925832748 et loss avant de l'appliquer = 1.0863108318299055\n",
      "KLdivLoss = 0.007956935092806816 et loss avant de l'appliquer = 1.4631064515560865\n",
      "KLdivLoss = 0.008193379268050194 et loss avant de l'appliquer = 1.899966855533421\n",
      "KLdivLoss = 0.008354413323104382 et loss avant de l'appliquer = 2.2572656320407987\n",
      "KLdivLoss = 0.008037621155381203 et loss avant de l'appliquer = 2.57124578114599\n",
      "KLdivLoss = 0.007939092814922333 et loss avant de l'appliquer = 2.9362861439585686\n",
      "KLdivLoss = 0.008310658857226372 et loss avant de l'appliquer = 3.214065265841782\n",
      "KLdivLoss = 0.008211513049900532 et loss avant de l'appliquer = 3.544931411743164\n",
      "KLdivLoss = 0.008367445319890976 et loss avant de l'appliquer = 3.8537625428289175\n",
      "KLdivLoss = 0.00837994646281004 et loss avant de l'appliquer = 4.160232303664088\n",
      "[Validation] Epoch: 30 [DONE]                                 \n",
      "[Epoch: 30, TrainLoss: 0.0342, TrainDice: 0.0535, ValLoss: 0.0680                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.008344685658812523 et loss avant de l'appliquer = 0.029164530336856842\n",
      "KLdivLoss = 0.008683367632329464 et loss avant de l'appliquer = 0.32425166573375463\n",
      "KLdivLoss = 0.00819868128746748 et loss avant de l'appliquer = 0.6008991170674562\n",
      "KLdivLoss = 0.008212094195187092 et loss avant de l'appliquer = 0.9757828395813704\n",
      "KLdivLoss = 0.008193422108888626 et loss avant de l'appliquer = 1.325344080105424\n",
      "KLdivLoss = 0.007930281572043896 et loss avant de l'appliquer = 1.6620406014844775\n",
      "KLdivLoss = 0.008001726120710373 et loss avant de l'appliquer = 2.042366597801447\n",
      "KLdivLoss = 0.008292563259601593 et loss avant de l'appliquer = 2.4215214867144823\n",
      "KLdivLoss = 0.008070794865489006 et loss avant de l'appliquer = 2.7171152206137776\n",
      "KLdivLoss = 0.0077980440109968185 et loss avant de l'appliquer = 3.048275876790285\n",
      "KLdivLoss = 0.007975748740136623 et loss avant de l'appliquer = 3.3659882098436356\n",
      "KLdivLoss = 0.007880758494138718 et loss avant de l'appliquer = 3.7248798087239265\n",
      "KLdivLoss = 0.008081402629613876 et loss avant de l'appliquer = 4.0511890556663275\n",
      "[Validation] Epoch: 31 [DONE]                                 \n",
      "[Epoch: 31, TrainLoss: 0.0333, TrainDice: 0.0542, ValLoss: 0.0455                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.00801123958081007 et loss avant de l'appliquer = 0.031530546955764294\n",
      "KLdivLoss = 0.00815199501812458 et loss avant de l'appliquer = 0.3160868640989065\n",
      "KLdivLoss = 0.008457887917757034 et loss avant de l'appliquer = 0.6053117979317904\n",
      "KLdivLoss = 0.008464264683425426 et loss avant de l'appliquer = 0.9071490745991468\n",
      "KLdivLoss = 0.008603336289525032 et loss avant de l'appliquer = 1.250967557542026\n",
      "KLdivLoss = 0.008660372346639633 et loss avant de l'appliquer = 1.5447488259524107\n",
      "KLdivLoss = 0.008987804874777794 et loss avant de l'appliquer = 1.8946471717208624\n",
      "KLdivLoss = 0.008554923348128796 et loss avant de l'appliquer = 2.2496974198147655\n",
      "KLdivLoss = 0.008458324708044529 et loss avant de l'appliquer = 2.617298270575702\n",
      "KLdivLoss = 0.00841798447072506 et loss avant de l'appliquer = 2.993670583702624\n",
      "KLdivLoss = 0.00851544737815857 et loss avant de l'appliquer = 3.3400945449247956\n",
      "KLdivLoss = 0.008588844910264015 et loss avant de l'appliquer = 3.616887872107327\n",
      "KLdivLoss = 0.008666635490953922 et loss avant de l'appliquer = 3.9524806533008814\n",
      "[Validation] Epoch: 32 [DONE]                                 \n",
      "[Epoch: 32, TrainLoss: 0.0326, TrainDice: 0.0547, ValLoss: 0.0353                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.008760549128055573 et loss avant de l'appliquer = 0.026812557131052017\n",
      "KLdivLoss = 0.008591227233409882 et loss avant de l'appliquer = 0.35384510550647974\n",
      "KLdivLoss = 0.008866227231919765 et loss avant de l'appliquer = 0.6063978588208556\n",
      "KLdivLoss = 0.009122490882873535 et loss avant de l'appliquer = 0.9168869126588106\n",
      "KLdivLoss = 0.008952369913458824 et loss avant de l'appliquer = 1.2713420689105988\n",
      "KLdivLoss = 0.008568784222006798 et loss avant de l'appliquer = 1.6558229168877006\n",
      "KLdivLoss = 0.008905060589313507 et loss avant de l'appliquer = 1.9361996920779347\n",
      "KLdivLoss = 0.00882252212613821 et loss avant de l'appliquer = 2.2709023552015424\n",
      "KLdivLoss = 0.008873376995325089 et loss avant de l'appliquer = 2.6266934033483267\n",
      "KLdivLoss = 0.008769710548222065 et loss avant de l'appliquer = 2.964081116952002\n",
      "KLdivLoss = 0.008326897397637367 et loss avant de l'appliquer = 3.2700035041198134\n",
      "KLdivLoss = 0.00834156759083271 et loss avant de l'appliquer = 3.568377759307623\n",
      "KLdivLoss = 0.008407103829085827 et loss avant de l'appliquer = 3.8748572263866663\n",
      "[Validation] Epoch: 33 [DONE]                                 \n",
      "[Epoch: 33, TrainLoss: 0.0321, TrainDice: 0.0552, ValLoss: 0.0482                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.00834723748266697 et loss avant de l'appliquer = 0.03200119733810425\n",
      "KLdivLoss = 0.008396136574447155 et loss avant de l'appliquer = 0.34860494220629334\n",
      "KLdivLoss = 0.008302142843604088 et loss avant de l'appliquer = 0.6875268300063908\n",
      "KLdivLoss = 0.008464363403618336 et loss avant de l'appliquer = 1.0097203752957284\n",
      "KLdivLoss = 0.008369946852326393 et loss avant de l'appliquer = 1.3460784307681024\n",
      "KLdivLoss = 0.008211585693061352 et loss avant de l'appliquer = 1.6821017353795469\n",
      "KLdivLoss = 0.008262327872216702 et loss avant de l'appliquer = 1.9756112839095294\n",
      "KLdivLoss = 0.008448569104075432 et loss avant de l'appliquer = 2.2530316640622914\n",
      "KLdivLoss = 0.008177907206118107 et loss avant de l'appliquer = 2.564721802715212\n",
      "KLdivLoss = 0.008429929614067078 et loss avant de l'appliquer = 2.905102164018899\n",
      "KLdivLoss = 0.007929477840662003 et loss avant de l'appliquer = 3.1982943541370332\n",
      "KLdivLoss = 0.007968448102474213 et loss avant de l'appliquer = 3.5147274644114077\n",
      "KLdivLoss = 0.007417032495141029 et loss avant de l'appliquer = 3.877587514463812\n",
      "[Validation] Epoch: 34 [DONE]                                 \n",
      "[Epoch: 34, TrainLoss: 0.0322, TrainDice: 0.0548, ValLoss: 0.0411                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.007374580018222332 et loss avant de l'appliquer = 0.02846155595034361\n",
      "KLdivLoss = 0.007676140870898962 et loss avant de l'appliquer = 0.4116741372272372\n",
      "KLdivLoss = 0.0075033362954854965 et loss avant de l'appliquer = 0.7629346870817244\n",
      "KLdivLoss = 0.007637906353920698 et loss avant de l'appliquer = 1.0854741083458066\n",
      "KLdivLoss = 0.007704614661633968 et loss avant de l'appliquer = 1.3914403091184795\n",
      "KLdivLoss = 0.007705984637141228 et loss avant de l'appliquer = 1.7116861920803785\n",
      "KLdivLoss = 0.0075586759485304356 et loss avant de l'appliquer = 2.1346399784088135\n",
      "KLdivLoss = 0.007728684227913618 et loss avant de l'appliquer = 2.4230408063158393\n",
      "KLdivLoss = 0.007869898341596127 et loss avant de l'appliquer = 2.805548201315105\n",
      "KLdivLoss = 0.00727203069254756 et loss avant de l'appliquer = 3.118875971529633\n",
      "KLdivLoss = 0.007389682345092297 et loss avant de l'appliquer = 3.482152461539954\n",
      "KLdivLoss = 0.007638863753527403 et loss avant de l'appliquer = 3.762996857985854\n",
      "KLdivLoss = 0.00770682143047452 et loss avant de l'appliquer = 4.0879959487356246\n",
      "[Validation] Epoch: 35 [DONE]                                 \n",
      "[Epoch: 35, TrainLoss: 0.0334, TrainDice: 0.0560, ValLoss: 0.0308                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.007898950017988682 et loss avant de l'appliquer = 0.030164730735123158\n",
      "KLdivLoss = 0.008001119829714298 et loss avant de l'appliquer = 0.3132447940297425\n",
      "KLdivLoss = 0.008191267028450966 et loss avant de l'appliquer = 0.5927995429374278\n",
      "KLdivLoss = 0.008314413949847221 et loss avant de l'appliquer = 0.9669816293753684\n",
      "KLdivLoss = 0.007903845980763435 et loss avant de l'appliquer = 1.2752500069327652\n",
      "KLdivLoss = 0.008125178515911102 et loss avant de l'appliquer = 1.595436958130449\n",
      "KLdivLoss = 0.008128205314278603 et loss avant de l'appliquer = 1.9093834641389549\n",
      "KLdivLoss = 0.00805443525314331 et loss avant de l'appliquer = 2.2141107548959553\n",
      "KLdivLoss = 0.008194619789719582 et loss avant de l'appliquer = 2.5062189721502364\n",
      "KLdivLoss = 0.00843023881316185 et loss avant de l'appliquer = 2.803067168686539\n",
      "KLdivLoss = 0.008564730174839497 et loss avant de l'appliquer = 3.1124124550260603\n",
      "KLdivLoss = 0.008184931240975857 et loss avant de l'appliquer = 3.4373957398347557\n",
      "KLdivLoss = 0.008263830095529556 et loss avant de l'appliquer = 3.7775876983068883\n",
      "[Validation] Epoch: 36 [DONE]                                 \n",
      "[Epoch: 36, TrainLoss: 0.0311, TrainDice: 0.0542, ValLoss: 0.0789                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.008317411877214909 et loss avant de l'appliquer = 0.03394314553588629\n",
      "KLdivLoss = 0.00813700258731842 et loss avant de l'appliquer = 0.3085526963695884\n",
      "KLdivLoss = 0.00838933140039444 et loss avant de l'appliquer = 0.6149215577170253\n",
      "KLdivLoss = 0.008166717365384102 et loss avant de l'appliquer = 0.9537032451480627\n",
      "KLdivLoss = 0.008310009725391865 et loss avant de l'appliquer = 1.2764601772651076\n",
      "KLdivLoss = 0.008359077386558056 et loss avant de l'appliquer = 1.5736079490743577\n",
      "KLdivLoss = 0.00840043369680643 et loss avant de l'appliquer = 1.8704564939253032\n",
      "KLdivLoss = 0.008458397351205349 et loss avant de l'appliquer = 2.1988549646921456\n",
      "KLdivLoss = 0.008307046256959438 et loss avant de l'appliquer = 2.6188770956359804\n",
      "KLdivLoss = 0.008627766743302345 et loss avant de l'appliquer = 2.9185201642103493\n",
      "KLdivLoss = 0.00882838387042284 et loss avant de l'appliquer = 3.2321690968237817\n",
      "KLdivLoss = 0.008770043961703777 et loss avant de l'appliquer = 3.5218834285624325\n",
      "KLdivLoss = 0.008243555203080177 et loss avant de l'appliquer = 3.919404395390302\n",
      "[Validation] Epoch: 37 [DONE]                                 \n",
      "[Epoch: 37, TrainLoss: 0.0324, TrainDice: 0.0547, ValLoss: 0.0483                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.007918107323348522 et loss avant de l'appliquer = 0.031186905689537525\n",
      "KLdivLoss = 0.007930620573461056 et loss avant de l'appliquer = 0.3340774071402848\n",
      "KLdivLoss = 0.007793389726430178 et loss avant de l'appliquer = 0.7261243294924498\n",
      "KLdivLoss = 0.007823251187801361 et loss avant de l'appliquer = 1.0549538037739694\n",
      "KLdivLoss = 0.007983271032571793 et loss avant de l'appliquer = 1.3265315634198487\n",
      "KLdivLoss = 0.008366298861801624 et loss avant de l'appliquer = 1.6421378864906728\n",
      "KLdivLoss = 0.007645111996680498 et loss avant de l'appliquer = 2.0669128661975265\n",
      "KLdivLoss = 0.007185027934610844 et loss avant de l'appliquer = 2.4306999291293323\n",
      "KLdivLoss = 0.007207226939499378 et loss avant de l'appliquer = 2.7110341731458902\n",
      "KLdivLoss = 0.007395426742732525 et loss avant de l'appliquer = 2.9953921269625425\n",
      "KLdivLoss = 0.007698815315961838 et loss avant de l'appliquer = 3.3176108305342495\n",
      "KLdivLoss = 0.007832834497094154 et loss avant de l'appliquer = 3.61267078993842\n",
      "KLdivLoss = 0.007979764603078365 et loss avant de l'appliquer = 3.892241731286049\n",
      "[Validation] Epoch: 38 [DONE]                                 \n",
      "[Epoch: 38, TrainLoss: 0.0320, TrainDice: 0.0525, ValLoss: 0.0474                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.007728755474090576 et loss avant de l'appliquer = 0.024267653003335\n",
      "KLdivLoss = 0.007820439524948597 et loss avant de l'appliquer = 0.3338628448545933\n",
      "KLdivLoss = 0.007842142134904861 et loss avant de l'appliquer = 0.6674994742497802\n",
      "KLdivLoss = 0.007782781962305307 et loss avant de l'appliquer = 0.9796125972643495\n",
      "KLdivLoss = 0.0076522743329405785 et loss avant de l'appliquer = 1.2769250678829849\n",
      "KLdivLoss = 0.007836434990167618 et loss avant de l'appliquer = 1.5575495837256312\n",
      "KLdivLoss = 0.007593152113258839 et loss avant de l'appliquer = 2.012131465598941\n",
      "KLdivLoss = 0.0075219785794615746 et loss avant de l'appliquer = 2.3439750582911074\n",
      "KLdivLoss = 0.0075523629784584045 et loss avant de l'appliquer = 2.6844762028194964\n",
      "KLdivLoss = 0.007603503298014402 et loss avant de l'appliquer = 3.060988459736109\n",
      "KLdivLoss = 0.007271600887179375 et loss avant de l'appliquer = 3.416720915120095\n",
      "KLdivLoss = 0.007512202952057123 et loss avant de l'appliquer = 3.7183853522874415\n",
      "KLdivLoss = 0.007980912923812866 et loss avant de l'appliquer = 4.058943986427039\n",
      "[Validation] Epoch: 39 [DONE]                                 \n",
      "[Epoch: 39, TrainLoss: 0.0335, TrainDice: 0.0541, ValLoss: 0.0372                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.007835260592401028 et loss avant de l'appliquer = 0.046422588638961315\n",
      "KLdivLoss = 0.008021059446036816 et loss avant de l'appliquer = 0.3825691770762205\n",
      "KLdivLoss = 0.007976826280355453 et loss avant de l'appliquer = 0.679991764947772\n",
      "KLdivLoss = 0.008362186141312122 et loss avant de l'appliquer = 0.9659597449935973\n",
      "KLdivLoss = 0.008540901355445385 et loss avant de l'appliquer = 1.2491746447049081\n",
      "KLdivLoss = 0.008485602214932442 et loss avant de l'appliquer = 1.5367912710644305\n",
      "KLdivLoss = 0.00854433886706829 et loss avant de l'appliquer = 1.810859841760248\n",
      "KLdivLoss = 0.007994391955435276 et loss avant de l'appliquer = 2.1975654060952365\n",
      "KLdivLoss = 0.008122812025249004 et loss avant de l'appliquer = 2.5690357256680727\n",
      "KLdivLoss = 0.007712224498391151 et loss avant de l'appliquer = 2.9556155120953918\n",
      "KLdivLoss = 0.007896259427070618 et loss avant de l'appliquer = 3.2511595636606216\n",
      "KLdivLoss = 0.007861578837037086 et loss avant de l'appliquer = 3.5715081919915974\n",
      "KLdivLoss = 0.00797174870967865 et loss avant de l'appliquer = 3.8395634260959923\n",
      "[Validation] Epoch: 40 [DONE]                                 \n",
      "[Epoch: 40, TrainLoss: 0.0322, TrainDice: 0.0546, ValLoss: 0.0364                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.007767993491142988 et loss avant de l'appliquer = 0.029521651100367308\n",
      "KLdivLoss = 0.007889553904533386 et loss avant de l'appliquer = 0.33588077081367373\n",
      "KLdivLoss = 0.008055479265749454 et loss avant de l'appliquer = 0.6438296171836555\n",
      "KLdivLoss = 0.008018230088055134 et loss avant de l'appliquer = 0.943237813655287\n",
      "KLdivLoss = 0.00803991500288248 et loss avant de l'appliquer = 1.298332994338125\n",
      "KLdivLoss = 0.007608980406075716 et loss avant de l'appliquer = 1.5985626932233572\n",
      "KLdivLoss = 0.007326651364564896 et loss avant de l'appliquer = 2.006864215247333\n",
      "KLdivLoss = 0.007707719225436449 et loss avant de l'appliquer = 2.325677442830056\n",
      "KLdivLoss = 0.007887165993452072 et loss avant de l'appliquer = 2.5864588380791247\n",
      "KLdivLoss = 0.00797191634774208 et loss avant de l'appliquer = 2.8566337670199573\n",
      "KLdivLoss = 0.007843347266316414 et loss avant de l'appliquer = 3.1236477587372065\n",
      "KLdivLoss = 0.008080631494522095 et loss avant de l'appliquer = 3.4060451071709394\n",
      "KLdivLoss = 0.00832687970250845 et loss avant de l'appliquer = 3.6560407178476453\n",
      "[Validation] Epoch: 41 [DONE]                                 \n",
      "[Epoch: 41, TrainLoss: 0.0302, TrainDice: 0.0543, ValLoss: 0.0319                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.008430923335254192 et loss avant de l'appliquer = 0.023434069007635117\n",
      "KLdivLoss = 0.008409117348492146 et loss avant de l'appliquer = 0.31998838391155005\n",
      "KLdivLoss = 0.008385065011680126 et loss avant de l'appliquer = 0.5955104827880859\n",
      "KLdivLoss = 0.008532287552952766 et loss avant de l'appliquer = 0.8671744987368584\n",
      "KLdivLoss = 0.008875466883182526 et loss avant de l'appliquer = 1.1549745881929994\n",
      "KLdivLoss = 0.00878879800438881 et loss avant de l'appliquer = 1.4710559463128448\n",
      "KLdivLoss = 0.00865237694233656 et loss avant de l'appliquer = 1.770965414121747\n",
      "KLdivLoss = 0.00897275935858488 et loss avant de l'appliquer = 2.0796090634539723\n",
      "KLdivLoss = 0.008633323945105076 et loss avant de l'appliquer = 2.4136801911517978\n",
      "KLdivLoss = 0.008374870754778385 et loss avant de l'appliquer = 2.7620946019887924\n",
      "KLdivLoss = 0.008501953445374966 et loss avant de l'appliquer = 3.035180374979973\n",
      "KLdivLoss = 0.008633226156234741 et loss avant de l'appliquer = 3.295705030672252\n",
      "KLdivLoss = 0.00882739294320345 et loss avant de l'appliquer = 3.6089265160262585\n",
      "[Validation] Epoch: 42 [DONE]                                 \n",
      "[Epoch: 42, TrainLoss: 0.0298, TrainDice: 0.0539, ValLoss: 0.0605                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.008584477007389069 et loss avant de l'appliquer = 0.040126968175172806\n",
      "KLdivLoss = 0.00838647224009037 et loss avant de l'appliquer = 0.34788287710398436\n",
      "KLdivLoss = 0.008668223395943642 et loss avant de l'appliquer = 0.659653932787478\n",
      "KLdivLoss = 0.008382710628211498 et loss avant de l'appliquer = 0.9446123735979199\n",
      "KLdivLoss = 0.008608479052782059 et loss avant de l'appliquer = 1.2817033734172583\n",
      "KLdivLoss = 0.008372217416763306 et loss avant de l'appliquer = 1.5576449865475297\n",
      "KLdivLoss = 0.008189253509044647 et loss avant de l'appliquer = 1.848880309611559\n",
      "KLdivLoss = 0.008771315217018127 et loss avant de l'appliquer = 2.102600233629346\n",
      "KLdivLoss = 0.00888898316770792 et loss avant de l'appliquer = 2.4011645689606667\n",
      "KLdivLoss = 0.008817937225103378 et loss avant de l'appliquer = 2.6816533263772726\n",
      "KLdivLoss = 0.00870555266737938 et loss avant de l'appliquer = 2.9633294474333525\n",
      "KLdivLoss = 0.00876137986779213 et loss avant de l'appliquer = 3.244705860503018\n",
      "KLdivLoss = 0.008210863918066025 et loss avant de l'appliquer = 3.5456239636987448\n",
      "[Validation] Epoch: 43 [DONE]                                 \n",
      "[Epoch: 43, TrainLoss: 0.0293, TrainDice: 0.0540, ValLoss: 0.0379                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.00821854267269373 et loss avant de l'appliquer = 0.024130542762577534\n",
      "KLdivLoss = 0.008042899891734123 et loss avant de l'appliquer = 0.34966934844851494\n",
      "KLdivLoss = 0.008303950540721416 et loss avant de l'appliquer = 0.6591996876522899\n",
      "KLdivLoss = 0.008481264114379883 et loss avant de l'appliquer = 0.9743289025500417\n",
      "KLdivLoss = 0.008752426132559776 et loss avant de l'appliquer = 1.2794895516708493\n",
      "KLdivLoss = 0.008318711072206497 et loss avant de l'appliquer = 1.6069517461583018\n",
      "KLdivLoss = 0.008100313134491444 et loss avant de l'appliquer = 1.833766994997859\n",
      "KLdivLoss = 0.008011897094547749 et loss avant de l'appliquer = 2.100128590129316\n",
      "KLdivLoss = 0.008108299225568771 et loss avant de l'appliquer = 2.3882924085482955\n",
      "KLdivLoss = 0.008000500500202179 et loss avant de l'appliquer = 2.71958839148283\n",
      "KLdivLoss = 0.007800049148499966 et loss avant de l'appliquer = 3.008013972081244\n",
      "KLdivLoss = 0.008147272281348705 et loss avant de l'appliquer = 3.292688736692071\n",
      "KLdivLoss = 0.008320508524775505 et loss avant de l'appliquer = 3.5714472951367497\n",
      "[Validation] Epoch: 44 [DONE]                                 \n",
      "[Epoch: 44, TrainLoss: 0.0293, TrainDice: 0.0535, ValLoss: 0.0599                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.008328212425112724 et loss avant de l'appliquer = 0.028746066614985466\n",
      "KLdivLoss = 0.00840330682694912 et loss avant de l'appliquer = 0.3431558357551694\n",
      "KLdivLoss = 0.008357677608728409 et loss avant de l'appliquer = 0.6678161611780524\n",
      "KLdivLoss = 0.008661746978759766 et loss avant de l'appliquer = 0.9224463170394301\n",
      "KLdivLoss = 0.008561083115637302 et loss avant de l'appliquer = 1.2379308072850108\n",
      "KLdivLoss = 0.008612046018242836 et loss avant de l'appliquer = 1.4881624775007367\n",
      "KLdivLoss = 0.008635837584733963 et loss avant de l'appliquer = 1.7952009215950966\n",
      "KLdivLoss = 0.008400670252740383 et loss avant de l'appliquer = 2.0908963149413466\n",
      "KLdivLoss = 0.00824098289012909 et loss avant de l'appliquer = 2.3933037258684635\n",
      "KLdivLoss = 0.00845953170210123 et loss avant de l'appliquer = 2.7022260199300945\n",
      "KLdivLoss = 0.008533349260687828 et loss avant de l'appliquer = 2.9521772577427328\n",
      "KLdivLoss = 0.0084951501339674 et loss avant de l'appliquer = 3.30049290927127\n",
      "KLdivLoss = 0.008391127921640873 et loss avant de l'appliquer = 3.5883042770437896\n",
      "[Validation] Epoch: 45 [DONE]                                 \n",
      "[Epoch: 45, TrainLoss: 0.0296, TrainDice: 0.0543, ValLoss: 0.0791                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.008395246230065823 et loss avant de l'appliquer = 0.03943133819848299\n",
      "KLdivLoss = 0.008244537748396397 et loss avant de l'appliquer = 0.35936280619353056\n",
      "KLdivLoss = 0.008681394159793854 et loss avant de l'appliquer = 0.6175172887742519\n",
      "KLdivLoss = 0.008416939526796341 et loss avant de l'appliquer = 0.9395177848637104\n",
      "KLdivLoss = 0.007774951867759228 et loss avant de l'appliquer = 1.2657331298105419\n",
      "KLdivLoss = 0.007705265190452337 et loss avant de l'appliquer = 1.606041747611016\n",
      "KLdivLoss = 0.008141390979290009 et loss avant de l'appliquer = 1.9607032593339682\n",
      "KLdivLoss = 0.0079313013702631 et loss avant de l'appliquer = 2.285335815977305\n",
      "KLdivLoss = 0.007808635011315346 et loss avant de l'appliquer = 2.5703889266587794\n",
      "KLdivLoss = 0.007815465331077576 et loss avant de l'appliquer = 2.8701397483237088\n",
      "KLdivLoss = 0.007729837205260992 et loss avant de l'appliquer = 3.225727125070989\n",
      "KLdivLoss = 0.007617116905748844 et loss avant de l'appliquer = 3.527441711165011\n",
      "KLdivLoss = 0.0080142542719841 et loss avant de l'appliquer = 3.7721846271306276\n",
      "[Validation] Epoch: 46 [DONE]                                 \n",
      "[Epoch: 46, TrainLoss: 0.0310, TrainDice: 0.0525, ValLoss: 0.0576                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.007885938510298729 et loss avant de l'appliquer = 0.021892918273806572\n",
      "KLdivLoss = 0.007974500767886639 et loss avant de l'appliquer = 0.34595697559416294\n",
      "KLdivLoss = 0.007869187742471695 et loss avant de l'appliquer = 0.6105909519828856\n",
      "KLdivLoss = 0.007762099616229534 et loss avant de l'appliquer = 0.8950514593161643\n",
      "KLdivLoss = 0.008155912160873413 et loss avant de l'appliquer = 1.1539074103347957\n",
      "KLdivLoss = 0.008084980770945549 et loss avant de l'appliquer = 1.4479434578679502\n",
      "KLdivLoss = 0.008129888214170933 et loss avant de l'appliquer = 1.818840351421386\n",
      "KLdivLoss = 0.008287984877824783 et loss avant de l'appliquer = 2.1593758654780686\n",
      "KLdivLoss = 0.00815722905099392 et loss avant de l'appliquer = 2.4369836286641657\n",
      "KLdivLoss = 0.00766843743622303 et loss avant de l'appliquer = 2.783985325600952\n",
      "KLdivLoss = 0.007639374118298292 et loss avant de l'appliquer = 3.1284802216105163\n",
      "KLdivLoss = 0.007748677395284176 et loss avant de l'appliquer = 3.4477828997187316\n",
      "KLdivLoss = 0.008037672378122807 et loss avant de l'appliquer = 3.7727131568826735\n",
      "[Validation] Epoch: 47 [DONE]                                 \n",
      "[Epoch: 47, TrainLoss: 0.0312, TrainDice: 0.0543, ValLoss: 0.1107                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.00808239821344614 et loss avant de l'appliquer = 0.0343581372871995\n",
      "KLdivLoss = 0.008015250787138939 et loss avant de l'appliquer = 0.32697110529989004\n",
      "KLdivLoss = 0.008166952058672905 et loss avant de l'appliquer = 0.6233170982450247\n",
      "KLdivLoss = 0.008026298135519028 et loss avant de l'appliquer = 0.9600767018273473\n",
      "KLdivLoss = 0.007925251498818398 et loss avant de l'appliquer = 1.249012442305684\n",
      "KLdivLoss = 0.008266777731478214 et loss avant de l'appliquer = 1.4918890791013837\n",
      "KLdivLoss = 0.008375689387321472 et loss avant de l'appliquer = 1.731576256453991\n",
      "KLdivLoss = 0.008440762758255005 et loss avant de l'appliquer = 1.9976991824805737\n",
      "KLdivLoss = 0.008413147181272507 et loss avant de l'appliquer = 2.2909834943711758\n",
      "KLdivLoss = 0.008429763838648796 et loss avant de l'appliquer = 2.6346314568072557\n",
      "KLdivLoss = 0.008413171395659447 et loss avant de l'appliquer = 2.9908365132287145\n",
      "KLdivLoss = 0.008256034925580025 et loss avant de l'appliquer = 3.3067204784601927\n",
      "KLdivLoss = 0.007994082756340504 et loss avant de l'appliquer = 3.5929902475327253\n",
      "[Validation] Epoch: 48 [DONE]                                 \n",
      "[Epoch: 48, TrainLoss: 0.0297, TrainDice: 0.0552, ValLoss: 0.0388                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.00798504427075386 et loss avant de l'appliquer = 0.03411417081952095\n",
      "KLdivLoss = 0.007919332943856716 et loss avant de l'appliquer = 0.3427479472011328\n",
      "KLdivLoss = 0.008129461668431759 et loss avant de l'appliquer = 0.5793536119163036\n",
      "KLdivLoss = 0.008358960971236229 et loss avant de l'appliquer = 0.8281940454617143\n",
      "KLdivLoss = 0.008254324086010456 et loss avant de l'appliquer = 1.1840710435062647\n",
      "KLdivLoss = 0.008364803157746792 et loss avant de l'appliquer = 1.4537244429811835\n",
      "KLdivLoss = 0.008681157603859901 et loss avant de l'appliquer = 1.7117327926680446\n",
      "KLdivLoss = 0.0084155835211277 et loss avant de l'appliquer = 1.9538200441747904\n",
      "KLdivLoss = 0.008227146230638027 et loss avant de l'appliquer = 2.2493526972830296\n",
      "KLdivLoss = 0.00807725079357624 et loss avant de l'appliquer = 2.6085107270628214\n",
      "KLdivLoss = 0.0076783038675785065 et loss avant de l'appliquer = 2.9889217959716916\n",
      "KLdivLoss = 0.00728096067905426 et loss avant de l'appliquer = 3.2757567847147584\n",
      "KLdivLoss = 0.007997032254934311 et loss avant de l'appliquer = 3.5662671397440135\n",
      "[Validation] Epoch: 49 [DONE]                                 \n",
      "[Epoch: 49, TrainLoss: 0.0295, TrainDice: 0.0551, ValLoss: 0.0594                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.007929505780339241 et loss avant de l'appliquer = 0.028106030076742172\n",
      "KLdivLoss = 0.008180768229067326 et loss avant de l'appliquer = 0.3160145077854395\n",
      "KLdivLoss = 0.007970215752720833 et loss avant de l'appliquer = 0.6556860785931349\n",
      "KLdivLoss = 0.007915889844298363 et loss avant de l'appliquer = 0.939266019500792\n",
      "KLdivLoss = 0.00806518830358982 et loss avant de l'appliquer = 1.217778841033578\n",
      "KLdivLoss = 0.00817465502768755 et loss avant de l'appliquer = 1.5921669006347656\n",
      "KLdivLoss = 0.007841158658266068 et loss avant de l'appliquer = 1.9412159780040383\n",
      "KLdivLoss = 0.007472156547009945 et loss avant de l'appliquer = 2.2586245769634843\n",
      "KLdivLoss = 0.007767109200358391 et loss avant de l'appliquer = 2.5484577235765755\n",
      "KLdivLoss = 0.00812542624771595 et loss avant de l'appliquer = 2.8362020030617714\n",
      "KLdivLoss = 0.008209658786654472 et loss avant de l'appliquer = 3.088356918655336\n",
      "KLdivLoss = 0.00838427059352398 et loss avant de l'appliquer = 3.3569443551823497\n",
      "KLdivLoss = 0.008267007768154144 et loss avant de l'appliquer = 3.6565505722537637\n",
      "[Validation] Epoch: 50 [DONE]                                 \n",
      "[Epoch: 50, TrainLoss: 0.0301, TrainDice: 0.0535, ValLoss: 0.0473                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.00820956937968731 et loss avant de l'appliquer = 0.041440753266215324\n",
      "KLdivLoss = 0.00811771024018526 et loss avant de l'appliquer = 0.32827097550034523\n",
      "KLdivLoss = 0.008355406112968922 et loss avant de l'appliquer = 0.5960178934037685\n",
      "KLdivLoss = 0.008133307099342346 et loss avant de l'appliquer = 0.8570207478478551\n",
      "KLdivLoss = 0.008182293735444546 et loss avant de l'appliquer = 1.1373927760869265\n",
      "KLdivLoss = 0.007921828888356686 et loss avant de l'appliquer = 1.490742715075612\n",
      "KLdivLoss = 0.007818339392542839 et loss avant de l'appliquer = 1.7978134867735207\n",
      "KLdivLoss = 0.007932983338832855 et loss avant de l'appliquer = 2.090343649033457\n",
      "KLdivLoss = 0.008030354045331478 et loss avant de l'appliquer = 2.4200500673614442\n",
      "KLdivLoss = 0.008022950030863285 et loss avant de l'appliquer = 2.6964202472008765\n",
      "KLdivLoss = 0.007552762981504202 et loss avant de l'appliquer = 2.9962994856759906\n",
      "KLdivLoss = 0.0073019759729504585 et loss avant de l'appliquer = 3.335511154960841\n",
      "KLdivLoss = 0.00767421443015337 et loss avant de l'appliquer = 3.6783417188562453\n",
      "[Validation] Epoch: 51 [DONE]                                 \n",
      "[Epoch: 51, TrainLoss: 0.0303, TrainDice: 0.0544, ValLoss: 0.0759                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.007871539331972599 et loss avant de l'appliquer = 0.0193941006436944\n",
      "KLdivLoss = 0.007627418730407953 et loss avant de l'appliquer = 0.32239831797778606\n",
      "KLdivLoss = 0.00764508219435811 et loss avant de l'appliquer = 0.5969163235276937\n",
      "KLdivLoss = 0.007969293743371964 et loss avant de l'appliquer = 0.8959113503806293\n",
      "KLdivLoss = 0.00809136126190424 et loss avant de l'appliquer = 1.1730763246305287\n",
      "KLdivLoss = 0.007894332520663738 et loss avant de l'appliquer = 1.484549708198756\n",
      "KLdivLoss = 0.007863491773605347 et loss avant de l'appliquer = 1.7629167754203081\n",
      "KLdivLoss = 0.008066424168646336 et loss avant de l'appliquer = 2.084326973184943\n",
      "KLdivLoss = 0.00783951673656702 et loss avant de l'appliquer = 2.368858590722084\n",
      "KLdivLoss = 0.007792588323354721 et loss avant de l'appliquer = 2.6488239029422402\n",
      "KLdivLoss = 0.007752252742648125 et loss avant de l'appliquer = 2.9673164347186685\n",
      "KLdivLoss = 0.007618035189807415 et loss avant de l'appliquer = 3.24871116457507\n",
      "KLdivLoss = 0.007835716009140015 et loss avant de l'appliquer = 3.562441194895655\n",
      "[Validation] Epoch: 52 [DONE]                                 \n",
      "[Epoch: 52, TrainLoss: 0.0300, TrainDice: 0.0540, ValLoss: 0.0401                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.00720525998622179 et loss avant de l'appliquer = 0.028108629398047924\n",
      "KLdivLoss = 0.007490600924938917 et loss avant de l'appliquer = 0.3648705552332103\n",
      "KLdivLoss = 0.007461784407496452 et loss avant de l'appliquer = 0.6438495884649456\n",
      "KLdivLoss = 0.007478020619601011 et loss avant de l'appliquer = 0.9283850118517876\n",
      "KLdivLoss = 0.0076566776260733604 et loss avant de l'appliquer = 1.2229495239444077\n",
      "KLdivLoss = 0.007723900489509106 et loss avant de l'appliquer = 1.4979000543244183\n",
      "KLdivLoss = 0.007723377086222172 et loss avant de l'appliquer = 1.7820694125257432\n",
      "KLdivLoss = 0.007821504957973957 et loss avant de l'appliquer = 2.0554732102900743\n",
      "KLdivLoss = 0.007969117723405361 et loss avant de l'appliquer = 2.3119127391837537\n",
      "KLdivLoss = 0.00805746205151081 et loss avant de l'appliquer = 2.579375569242984\n",
      "KLdivLoss = 0.008192792534828186 et loss avant de l'appliquer = 2.936055234167725\n",
      "KLdivLoss = 0.007679876871407032 et loss avant de l'appliquer = 3.1823188508860767\n",
      "KLdivLoss = 0.007957331836223602 et loss avant de l'appliquer = 3.460317440330982\n",
      "[Validation] Epoch: 53 [DONE]                                 \n",
      "[Epoch: 53, TrainLoss: 0.0287, TrainDice: 0.0542, ValLoss: 0.0564                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.008111715316772461 et loss avant de l'appliquer = 0.02241420093923807\n",
      "KLdivLoss = 0.007807913236320019 et loss avant de l'appliquer = 0.2890632664784789\n",
      "KLdivLoss = 0.007881415076553822 et loss avant de l'appliquer = 0.5237766611389816\n",
      "KLdivLoss = 0.008119429461658001 et loss avant de l'appliquer = 0.7667310307733715\n",
      "KLdivLoss = 0.008085628971457481 et loss avant de l'appliquer = 1.0641619735397398\n",
      "KLdivLoss = 0.008457286283373833 et loss avant de l'appliquer = 1.3290397529490292\n",
      "KLdivLoss = 0.00804960262030363 et loss avant de l'appliquer = 1.6857119486667216\n",
      "KLdivLoss = 0.007699849549680948 et loss avant de l'appliquer = 1.939717025961727\n",
      "KLdivLoss = 0.007503167260438204 et loss avant de l'appliquer = 2.236738600768149\n",
      "KLdivLoss = 0.007694991305470467 et loss avant de l'appliquer = 2.5958538348786533\n",
      "KLdivLoss = 0.007602171041071415 et loss avant de l'appliquer = 2.883339030202478\n",
      "KLdivLoss = 0.007627600338310003 et loss avant de l'appliquer = 3.1588922305963933\n",
      "KLdivLoss = 0.007847916334867477 et loss avant de l'appliquer = 3.433849500492215\n",
      "[Validation] Epoch: 54 [DONE]                                 \n",
      "[Epoch: 54, TrainLoss: 0.0283, TrainDice: 0.0547, ValLoss: 0.0426                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.007801639847457409 et loss avant de l'appliquer = 0.027163119055330753\n",
      "KLdivLoss = 0.007825104519724846 et loss avant de l'appliquer = 0.2764479937031865\n",
      "KLdivLoss = 0.00813177041709423 et loss avant de l'appliquer = 0.5620706956833601\n",
      "KLdivLoss = 0.008201616816222668 et loss avant de l'appliquer = 0.8454233063384891\n",
      "KLdivLoss = 0.007797500118613243 et loss avant de l'appliquer = 1.186387650668621\n",
      "KLdivLoss = 0.00748969754204154 et loss avant de l'appliquer = 1.5388232618570328\n",
      "KLdivLoss = 0.00744617311283946 et loss avant de l'appliquer = 1.8610084988176823\n",
      "KLdivLoss = 0.0073427376337349415 et loss avant de l'appliquer = 2.164105888456106\n",
      "KLdivLoss = 0.007594567257910967 et loss avant de l'appliquer = 2.4600014109164476\n",
      "KLdivLoss = 0.007875829003751278 et loss avant de l'appliquer = 2.717905154917389\n",
      "KLdivLoss = 0.008261219598352909 et loss avant de l'appliquer = 2.9897321863099933\n",
      "KLdivLoss = 0.007918240502476692 et loss avant de l'appliquer = 3.277815537992865\n",
      "KLdivLoss = 0.007597477175295353 et loss avant de l'appliquer = 3.5938760680146515\n",
      "[Validation] Epoch: 55 [DONE]                                 \n",
      "[Epoch: 55, TrainLoss: 0.0296, TrainDice: 0.0559, ValLoss: 0.0617                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.008021733723580837 et loss avant de l'appliquer = 0.02313256449997425\n",
      "KLdivLoss = 0.007654111832380295 et loss avant de l'appliquer = 0.32232434395700693\n",
      "KLdivLoss = 0.007787001319229603 et loss avant de l'appliquer = 0.6457419833168387\n",
      "KLdivLoss = 0.008031237870454788 et loss avant de l'appliquer = 0.904151692520827\n",
      "KLdivLoss = 0.008089213632047176 et loss avant de l'appliquer = 1.184670573566109\n",
      "KLdivLoss = 0.00804681796580553 et loss avant de l'appliquer = 1.4282938153482974\n",
      "KLdivLoss = 0.007613353431224823 et loss avant de l'appliquer = 1.7306006331928074\n",
      "KLdivLoss = 0.007742076646536589 et loss avant de l'appliquer = 2.012041201815009\n",
      "KLdivLoss = 0.007461360655725002 et loss avant de l'appliquer = 2.3228387720882893\n",
      "KLdivLoss = 0.007512250915169716 et loss avant de l'appliquer = 2.669586810283363\n",
      "KLdivLoss = 0.007311539724469185 et loss avant de l'appliquer = 2.9624103624373674\n",
      "KLdivLoss = 0.0072656297124922276 et loss avant de l'appliquer = 3.315229231491685\n",
      "KLdivLoss = 0.007359358016401529 et loss avant de l'appliquer = 3.592599226627499\n",
      "[Validation] Epoch: 56 [DONE]                                 \n",
      "[Epoch: 56, TrainLoss: 0.0294, TrainDice: 0.0542, ValLoss: 0.0598                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.007597623858600855 et loss avant de l'appliquer = 0.034454450476914644\n",
      "KLdivLoss = 0.007852859795093536 et loss avant de l'appliquer = 0.3246679613366723\n",
      "KLdivLoss = 0.007280237041413784 et loss avant de l'appliquer = 0.6821788549423218\n",
      "KLdivLoss = 0.007466341368854046 et loss avant de l'appliquer = 0.9155018585734069\n",
      "KLdivLoss = 0.007297402713447809 et loss avant de l'appliquer = 1.164828130044043\n",
      "KLdivLoss = 0.007377226836979389 et loss avant de l'appliquer = 1.4333036202006042\n",
      "KLdivLoss = 0.00755006680265069 et loss avant de l'appliquer = 1.6930117406882346\n",
      "KLdivLoss = 0.007924934849143028 et loss avant de l'appliquer = 1.9789628367871046\n",
      "KLdivLoss = 0.00781482644379139 et loss avant de l'appliquer = 2.2406684635207057\n",
      "KLdivLoss = 0.008041942492127419 et loss avant de l'appliquer = 2.481211822014302\n",
      "KLdivLoss = 0.007507599424570799 et loss avant de l'appliquer = 2.75884559052065\n",
      "KLdivLoss = 0.007909051142632961 et loss avant de l'appliquer = 3.0057062567211688\n",
      "KLdivLoss = 0.007987606339156628 et loss avant de l'appliquer = 3.2857298706658185\n",
      "[Validation] Epoch: 57 [DONE]                                 \n",
      "[Epoch: 57, TrainLoss: 0.0271, TrainDice: 0.0547, ValLoss: 0.0481                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.007981347851455212 et loss avant de l'appliquer = 0.02218230441212654\n",
      "KLdivLoss = 0.008108431473374367 et loss avant de l'appliquer = 0.28441085759550333\n",
      "KLdivLoss = 0.008013393729925156 et loss avant de l'appliquer = 0.5238997340202332\n",
      "KLdivLoss = 0.008331541903316975 et loss avant de l'appliquer = 0.801309903152287\n",
      "KLdivLoss = 0.00799312349408865 et loss avant de l'appliquer = 1.1153370579704642\n",
      "KLdivLoss = 0.007736944127827883 et loss avant de l'appliquer = 1.4092053263448179\n",
      "KLdivLoss = 0.008146117441356182 et loss avant de l'appliquer = 1.6473116758279502\n",
      "KLdivLoss = 0.008146940730512142 et loss avant de l'appliquer = 1.8921473729424179\n",
      "KLdivLoss = 0.00807371735572815 et loss avant de l'appliquer = 2.206289651338011\n",
      "KLdivLoss = 0.007936165668070316 et loss avant de l'appliquer = 2.4925797670148313\n",
      "KLdivLoss = 0.007875626906752586 et loss avant de l'appliquer = 2.779910733923316\n",
      "KLdivLoss = 0.007871349342167377 et loss avant de l'appliquer = 3.0588956251740456\n",
      "KLdivLoss = 0.0078078219667077065 et loss avant de l'appliquer = 3.367050691973418\n",
      "[Validation] Epoch: 58 [DONE]                                 \n",
      "[Epoch: 58, TrainLoss: 0.0278, TrainDice: 0.0559, ValLoss: 0.0410                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.007833819836378098 et loss avant de l'appliquer = 0.028571123257279396\n",
      "KLdivLoss = 0.007751100696623325 et loss avant de l'appliquer = 0.3889641920104623\n",
      "KLdivLoss = 0.007593968883156776 et loss avant de l'appliquer = 0.673155824188143\n",
      "KLdivLoss = 0.007489074487239122 et loss avant de l'appliquer = 0.9449568497948349\n",
      "KLdivLoss = 0.007461783476173878 et loss avant de l'appliquer = 1.191016829572618\n",
      "KLdivLoss = 0.007849558256566525 et loss avant de l'appliquer = 1.4371355716139078\n",
      "KLdivLoss = 0.008012287318706512 et loss avant de l'appliquer = 1.7313227830454707\n",
      "KLdivLoss = 0.008173331618309021 et loss avant de l'appliquer = 2.037292579188943\n",
      "KLdivLoss = 0.007375261280685663 et loss avant de l'appliquer = 2.4006289304234087\n",
      "KLdivLoss = 0.007183777168393135 et loss avant de l'appliquer = 2.6755711217410862\n",
      "KLdivLoss = 0.007378233131021261 et loss avant de l'appliquer = 2.9524130634963512\n",
      "KLdivLoss = 0.007291585206985474 et loss avant de l'appliquer = 3.211791919544339\n",
      "KLdivLoss = 0.007376924157142639 et loss avant de l'appliquer = 3.466147326864302\n",
      "[Validation] Epoch: 59 [DONE]                                 \n",
      "[Epoch: 59, TrainLoss: 0.0285, TrainDice: 0.0541, ValLoss: 0.0506                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.007820449769496918 et loss avant de l'appliquer = 0.028308138251304626\n",
      "KLdivLoss = 0.007635145448148251 et loss avant de l'appliquer = 0.3147384952753782\n",
      "KLdivLoss = 0.007842157036066055 et loss avant de l'appliquer = 0.5993015924468637\n",
      "KLdivLoss = 0.007737844716757536 et loss avant de l'appliquer = 0.8693649657070637\n",
      "KLdivLoss = 0.007639630697667599 et loss avant de l'appliquer = 1.1536463778465986\n",
      "KLdivLoss = 0.00783347524702549 et loss avant de l'appliquer = 1.396480888593942\n",
      "KLdivLoss = 0.007754993159323931 et loss avant de l'appliquer = 1.662460501305759\n",
      "KLdivLoss = 0.007692771032452583 et loss avant de l'appliquer = 1.8847410716116428\n",
      "KLdivLoss = 0.007667462341487408 et loss avant de l'appliquer = 2.1551537099294364\n",
      "KLdivLoss = 0.00788837019354105 et loss avant de l'appliquer = 2.4510110868141055\n",
      "KLdivLoss = 0.007985957898199558 et loss avant de l'appliquer = 2.6929542678408325\n",
      "KLdivLoss = 0.00799998827278614 et loss avant de l'appliquer = 2.9839929970912635\n",
      "KLdivLoss = 0.007938524708151817 et loss avant de l'appliquer = 3.2473260588012636\n",
      "[Validation] Epoch: 60 [DONE]                                 \n",
      "[Epoch: 60, TrainLoss: 0.0269, TrainDice: 0.0545, ValLoss: 0.0539                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.008039177395403385 et loss avant de l'appliquer = 0.023578503169119358\n",
      "KLdivLoss = 0.007946118712425232 et loss avant de l'appliquer = 0.279621260240674\n",
      "KLdivLoss = 0.008093759417533875 et loss avant de l'appliquer = 0.5501575255766511\n",
      "KLdivLoss = 0.008032312616705894 et loss avant de l'appliquer = 0.8240877445787191\n",
      "KLdivLoss = 0.007764376699924469 et loss avant de l'appliquer = 1.0972774624824524\n",
      "KLdivLoss = 0.008066813461482525 et loss avant de l'appliquer = 1.379514027852565\n",
      "KLdivLoss = 0.00830688513815403 et loss avant de l'appliquer = 1.6576325609348714\n",
      "KLdivLoss = 0.008204995654523373 et loss avant de l'appliquer = 1.9319118093699217\n",
      "KLdivLoss = 0.008014397695660591 et loss avant de l'appliquer = 2.226141798309982\n",
      "KLdivLoss = 0.007561160251498222 et loss avant de l'appliquer = 2.5133500206284225\n",
      "KLdivLoss = 0.007605583406984806 et loss avant de l'appliquer = 2.8183625051751733\n",
      "KLdivLoss = 0.007706495001912117 et loss avant de l'appliquer = 3.0666230437345803\n",
      "KLdivLoss = 0.007482169196009636 et loss avant de l'appliquer = 3.3530236054211855\n",
      "[Validation] Epoch: 61 [DONE]                                 \n",
      "[Epoch: 61, TrainLoss: 0.0276, TrainDice: 0.0544, ValLoss: 0.0486                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.007584321312606335 et loss avant de l'appliquer = 0.026087802834808826\n",
      "KLdivLoss = 0.007891533896327019 et loss avant de l'appliquer = 0.3135182564146817\n",
      "KLdivLoss = 0.007847711443901062 et loss avant de l'appliquer = 0.6014222861267626\n",
      "KLdivLoss = 0.00812496617436409 et loss avant de l'appliquer = 0.8813100620172918\n",
      "KLdivLoss = 0.007862684316933155 et loss avant de l'appliquer = 1.1667446834035218\n",
      "KLdivLoss = 0.00756723340600729 et loss avant de l'appliquer = 1.5071780299767852\n",
      "KLdivLoss = 0.006639786995947361 et loss avant de l'appliquer = 1.7817212147638202\n",
      "KLdivLoss = 0.0071647497825324535 et loss avant de l'appliquer = 2.0850344030186534\n",
      "KLdivLoss = 0.007138022221624851 et loss avant de l'appliquer = 2.3544618817977607\n",
      "KLdivLoss = 0.007095766719430685 et loss avant de l'appliquer = 2.6270513804629445\n",
      "KLdivLoss = 0.007051579654216766 et loss avant de l'appliquer = 2.894177807494998\n",
      "KLdivLoss = 0.007314360700547695 et loss avant de l'appliquer = 3.141123631503433\n",
      "KLdivLoss = 0.007423672825098038 et loss avant de l'appliquer = 3.4705860023386776\n",
      "[Validation] Epoch: 62 [DONE]                                 \n",
      "[Epoch: 62, TrainLoss: 0.0288, TrainDice: 0.0551, ValLoss: 0.0479                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.007176319137215614 et loss avant de l'appliquer = 0.025717122480273247\n",
      "KLdivLoss = 0.007509977091103792 et loss avant de l'appliquer = 0.28448685351759195\n",
      "KLdivLoss = 0.00753235025331378 et loss avant de l'appliquer = 0.5433812704868615\n",
      "KLdivLoss = 0.00766871590167284 et loss avant de l'appliquer = 0.8200224316678941\n",
      "KLdivLoss = 0.007788807153701782 et loss avant de l'appliquer = 1.055066124536097\n",
      "KLdivLoss = 0.007672653533518314 et loss avant de l'appliquer = 1.2878752620890737\n",
      "KLdivLoss = 0.007872344925999641 et loss avant de l'appliquer = 1.5450303708203137\n",
      "KLdivLoss = 0.0079681146889925 et loss avant de l'appliquer = 1.7818553615361452\n",
      "KLdivLoss = 0.007758751045912504 et loss avant de l'appliquer = 2.0607581115327775\n",
      "KLdivLoss = 0.007555101066827774 et loss avant de l'appliquer = 2.3522550873458385\n",
      "KLdivLoss = 0.0075891511514782906 et loss avant de l'appliquer = 2.660773803014308\n",
      "KLdivLoss = 0.007721866015344858 et loss avant de l'appliquer = 2.8938342132605612\n",
      "KLdivLoss = 0.007843971252441406 et loss avant de l'appliquer = 3.1430427017621696\n",
      "[Validation] Epoch: 63 [DONE]                                 \n",
      "[Epoch: 63, TrainLoss: 0.0262, TrainDice: 0.0546, ValLoss: 0.0332                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.00783407874405384 et loss avant de l'appliquer = 0.044492656365036964\n",
      "KLdivLoss = 0.007703763898462057 et loss avant de l'appliquer = 0.29262129962444305\n",
      "KLdivLoss = 0.0075839790515601635 et loss avant de l'appliquer = 0.583448326215148\n",
      "KLdivLoss = 0.007549520116299391 et loss avant de l'appliquer = 0.8323385273106396\n",
      "KLdivLoss = 0.007733052596449852 et loss avant de l'appliquer = 1.0664735799655318\n",
      "KLdivLoss = 0.007965343073010445 et loss avant de l'appliquer = 1.3258841265924275\n",
      "KLdivLoss = 0.007834836840629578 et loss avant de l'appliquer = 1.6232937276363373\n",
      "KLdivLoss = 0.007629981264472008 et loss avant de l'appliquer = 1.9273762195371091\n",
      "KLdivLoss = 0.0073805805295705795 et loss avant de l'appliquer = 2.259988757316023\n",
      "KLdivLoss = 0.007410699501633644 et loss avant de l'appliquer = 2.510515860747546\n",
      "KLdivLoss = 0.007286428473889828 et loss avant de l'appliquer = 2.7834169915877283\n",
      "KLdivLoss = 0.007749889977276325 et loss avant de l'appliquer = 3.040547217708081\n",
      "KLdivLoss = 0.007494754623621702 et loss avant de l'appliquer = 3.274829641915858\n",
      "[Validation] Epoch: 64 [DONE]                                 \n",
      "[Epoch: 64, TrainLoss: 0.0270, TrainDice: 0.0536, ValLoss: 0.0462                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.007660524919629097 et loss avant de l'appliquer = 0.031513506546616554\n",
      "KLdivLoss = 0.007450300734490156 et loss avant de l'appliquer = 0.2803289503790438\n",
      "KLdivLoss = 0.007669404614716768 et loss avant de l'appliquer = 0.5245296899229288\n",
      "KLdivLoss = 0.007190775126218796 et loss avant de l'appliquer = 0.8124901209957898\n",
      "KLdivLoss = 0.007388733327388763 et loss avant de l'appliquer = 1.086323875002563\n",
      "KLdivLoss = 0.007340016774833202 et loss avant de l'appliquer = 1.3592982511036098\n",
      "KLdivLoss = 0.007450491655617952 et loss avant de l'appliquer = 1.6308874618262053\n",
      "KLdivLoss = 0.007592474110424519 et loss avant de l'appliquer = 1.9184938161633909\n",
      "KLdivLoss = 0.00763861695304513 et loss avant de l'appliquer = 2.2018393860198557\n",
      "KLdivLoss = 0.007907690480351448 et loss avant de l'appliquer = 2.429020266979933\n",
      "KLdivLoss = 0.00816759467124939 et loss avant de l'appliquer = 2.7105127898976207\n",
      "KLdivLoss = 0.0077582718804478645 et loss avant de l'appliquer = 3.067704583518207\n",
      "KLdivLoss = 0.007634217385202646 et loss avant de l'appliquer = 3.3727068658918142\n",
      "[Validation] Epoch: 65 [DONE]                                 \n",
      "[Epoch: 65, TrainLoss: 0.0279, TrainDice: 0.0553, ValLoss: 0.0355                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.007279910147190094 et loss avant de l'appliquer = 0.030981209129095078\n",
      "KLdivLoss = 0.007482364308089018 et loss avant de l'appliquer = 0.27148916758596897\n",
      "KLdivLoss = 0.007833028212189674 et loss avant de l'appliquer = 0.5174416289664805\n",
      "KLdivLoss = 0.007837573066353798 et loss avant de l'appliquer = 0.7683713822625577\n",
      "KLdivLoss = 0.007660615257918835 et loss avant de l'appliquer = 1.0596821531653404\n",
      "KLdivLoss = 0.0076867081224918365 et loss avant de l'appliquer = 1.2898661084473133\n",
      "KLdivLoss = 0.007697367575019598 et loss avant de l'appliquer = 1.5104819210246205\n",
      "KLdivLoss = 0.007744709029793739 et loss avant de l'appliquer = 1.7545971884392202\n",
      "KLdivLoss = 0.007952645421028137 et loss avant de l'appliquer = 2.0702567230910063\n",
      "KLdivLoss = 0.007601059041917324 et loss avant de l'appliquer = 2.417394222225994\n",
      "KLdivLoss = 0.007581096142530441 et loss avant de l'appliquer = 2.730130275245756\n",
      "KLdivLoss = 0.007551753893494606 et loss avant de l'appliquer = 2.99209301546216\n",
      "KLdivLoss = 0.007545183412730694 et loss avant de l'appliquer = 3.2710320097394288\n",
      "[Validation] Epoch: 66 [DONE]                                 \n",
      "[Epoch: 66, TrainLoss: 0.0268, TrainDice: 0.0550, ValLoss: 0.0416                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.007630013860762119 et loss avant de l'appliquer = 0.03596383985131979\n",
      "KLdivLoss = 0.007726634386926889 et loss avant de l'appliquer = 0.26764029916375875\n",
      "KLdivLoss = 0.007359858602285385 et loss avant de l'appliquer = 0.5853643449954689\n",
      "KLdivLoss = 0.007488911040127277 et loss avant de l'appliquer = 0.8294877400621772\n",
      "KLdivLoss = 0.007867328822612762 et loss avant de l'appliquer = 1.0583880781196058\n",
      "KLdivLoss = 0.007761047221720219 et loss avant de l'appliquer = 1.3692973642610013\n",
      "KLdivLoss = 0.007739998400211334 et loss avant de l'appliquer = 1.6329667111858726\n",
      "KLdivLoss = 0.007984822615981102 et loss avant de l'appliquer = 1.8551697595976293\n",
      "KLdivLoss = 0.0078744450584054 et loss avant de l'appliquer = 2.1489255581982434\n",
      "KLdivLoss = 0.007939770817756653 et loss avant de l'appliquer = 2.442996497731656\n",
      "KLdivLoss = 0.007933753542602062 et loss avant de l'appliquer = 2.705664331559092\n",
      "KLdivLoss = 0.007955661043524742 et loss avant de l'appliquer = 2.981485248077661\n",
      "KLdivLoss = 0.007655702531337738 et loss avant de l'appliquer = 3.2473475099541247\n",
      "[Validation] Epoch: 67 [DONE]                                 \n",
      "[Epoch: 67, TrainLoss: 0.0268, TrainDice: 0.0549, ValLoss: 0.0336                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.007446672767400742 et loss avant de l'appliquer = 0.044286470860242844\n",
      "KLdivLoss = 0.007774225901812315 et loss avant de l'appliquer = 0.3040478974580765\n",
      "KLdivLoss = 0.007588244043290615 et loss avant de l'appliquer = 0.5603907792828977\n",
      "KLdivLoss = 0.007347257807850838 et loss avant de l'appliquer = 0.828389560803771\n",
      "KLdivLoss = 0.006974400486797094 et loss avant de l'appliquer = 1.1622171765193343\n",
      "KLdivLoss = 0.00744547788053751 et loss avant de l'appliquer = 1.4200908252969384\n",
      "KLdivLoss = 0.007607918232679367 et loss avant de l'appliquer = 1.6758907549083233\n",
      "KLdivLoss = 0.007482483983039856 et loss avant de l'appliquer = 1.9426462198607624\n",
      "KLdivLoss = 0.007478831335902214 et loss avant de l'appliquer = 2.1949995616450906\n",
      "KLdivLoss = 0.0075187780894339085 et loss avant de l'appliquer = 2.4604316842742264\n",
      "KLdivLoss = 0.007763075176626444 et loss avant de l'appliquer = 2.7095045163296163\n",
      "KLdivLoss = 0.007574510760605335 et loss avant de l'appliquer = 3.0412036068737507\n",
      "KLdivLoss = 0.007306256797164679 et loss avant de l'appliquer = 3.355435356963426\n",
      "[Validation] Epoch: 68 [DONE]                                 \n",
      "[Epoch: 68, TrainLoss: 0.0279, TrainDice: 0.0551, ValLoss: 0.0491                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.007078126072883606 et loss avant de l'appliquer = 0.03327837213873863\n",
      "KLdivLoss = 0.0071058678440749645 et loss avant de l'appliquer = 0.29691334813833237\n",
      "KLdivLoss = 0.007087815552949905 et loss avant de l'appliquer = 0.5615804702974856\n",
      "KLdivLoss = 0.0073051913641393185 et loss avant de l'appliquer = 0.8358628540299833\n",
      "KLdivLoss = 0.007165746297687292 et loss avant de l'appliquer = 1.063105508685112\n",
      "KLdivLoss = 0.007744260132312775 et loss avant de l'appliquer = 1.3078891444019973\n",
      "KLdivLoss = 0.007907561957836151 et loss avant de l'appliquer = 1.558479976374656\n",
      "KLdivLoss = 0.007813184522092342 et loss avant de l'appliquer = 1.7817326062358916\n",
      "KLdivLoss = 0.007469148375093937 et loss avant de l'appliquer = 2.0648969309404492\n",
      "KLdivLoss = 0.00732595007866621 et loss avant de l'appliquer = 2.3657724228687584\n",
      "KLdivLoss = 0.007237364538013935 et loss avant de l'appliquer = 2.642638338729739\n",
      "KLdivLoss = 0.007427618373185396 et loss avant de l'appliquer = 2.9181090760976076\n",
      "KLdivLoss = 0.007648622151464224 et loss avant de l'appliquer = 3.1808641497045755\n",
      "[Validation] Epoch: 69 [DONE]                                 \n",
      "[Epoch: 69, TrainLoss: 0.0262, TrainDice: 0.0544, ValLoss: 0.0378                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.007558385841548443 et loss avant de l'appliquer = 0.022502733394503593\n",
      "KLdivLoss = 0.007701993919909 et loss avant de l'appliquer = 0.27544538443908095\n",
      "KLdivLoss = 0.008017022162675858 et loss avant de l'appliquer = 0.4894280470907688\n",
      "KLdivLoss = 0.007776749320328236 et loss avant de l'appliquer = 0.7869992488995194\n",
      "KLdivLoss = 0.007738862186670303 et loss avant de l'appliquer = 1.040381696075201\n",
      "KLdivLoss = 0.007943112403154373 et loss avant de l'appliquer = 1.2835422535426915\n",
      "KLdivLoss = 0.0074366675689816475 et loss avant de l'appliquer = 1.6057807100005448\n",
      "KLdivLoss = 0.007257427088916302 et loss avant de l'appliquer = 1.8918552002869546\n",
      "KLdivLoss = 0.007144314236938953 et loss avant de l'appliquer = 2.1468944316729903\n",
      "KLdivLoss = 0.0074391793459653854 et loss avant de l'appliquer = 2.4187362203374505\n",
      "KLdivLoss = 0.007706460542976856 et loss avant de l'appliquer = 2.6673967130482197\n",
      "KLdivLoss = 0.007792143151164055 et loss avant de l'appliquer = 2.940546026919037\n",
      "KLdivLoss = 0.007639696355909109 et loss avant de l'appliquer = 3.200664671137929\n",
      "[Validation] Epoch: 70 [DONE]                                 \n",
      "[Epoch: 70, TrainLoss: 0.0265, TrainDice: 0.0546, ValLoss: 0.0530                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.007621836848556995 et loss avant de l'appliquer = 0.02279416099190712\n",
      "KLdivLoss = 0.00768512487411499 et loss avant de l'appliquer = 0.2755780639126897\n",
      "KLdivLoss = 0.007666055113077164 et loss avant de l'appliquer = 0.5547121968120337\n",
      "KLdivLoss = 0.0074500772170722485 et loss avant de l'appliquer = 0.7813552971929312\n",
      "KLdivLoss = 0.007708680350333452 et loss avant de l'appliquer = 1.045887636486441\n",
      "KLdivLoss = 0.007204548921436071 et loss avant de l'appliquer = 1.34531689574942\n",
      "KLdivLoss = 0.007349886931478977 et loss avant de l'appliquer = 1.624782316852361\n",
      "KLdivLoss = 0.0077804881148040295 et loss avant de l'appliquer = 1.880039440933615\n",
      "KLdivLoss = 0.00785360299050808 et loss avant de l'appliquer = 2.17182571394369\n",
      "KLdivLoss = 0.007282615173608065 et loss avant de l'appliquer = 2.4399966173805296\n",
      "KLdivLoss = 0.007475333288311958 et loss avant de l'appliquer = 2.77503132307902\n",
      "KLdivLoss = 0.0071932049468159676 et loss avant de l'appliquer = 3.049194497987628\n",
      "KLdivLoss = 0.007256650365889072 et loss avant de l'appliquer = 3.280222141649574\n",
      "[Validation] Epoch: 71 [DONE]                                 \n",
      "[Epoch: 71, TrainLoss: 0.0269, TrainDice: 0.0542, ValLoss: 0.0566                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.007390214130282402 et loss avant de l'appliquer = 0.020064109936356544\n",
      "KLdivLoss = 0.007152947131544352 et loss avant de l'appliquer = 0.2639941186644137\n",
      "KLdivLoss = 0.0074256183579564095 et loss avant de l'appliquer = 0.5027031530626118\n",
      "KLdivLoss = 0.007172143552452326 et loss avant de l'appliquer = 0.8016091561876237\n",
      "KLdivLoss = 0.007558056153357029 et loss avant de l'appliquer = 1.0595445996150374\n",
      "KLdivLoss = 0.007282980717718601 et loss avant de l'appliquer = 1.3260976667515934\n",
      "KLdivLoss = 0.007242853753268719 et loss avant de l'appliquer = 1.601806410588324\n",
      "KLdivLoss = 0.007279281038790941 et loss avant de l'appliquer = 1.8431030679494143\n",
      "KLdivLoss = 0.007477864157408476 et loss avant de l'appliquer = 2.0971942939795554\n",
      "KLdivLoss = 0.007593340706080198 et loss avant de l'appliquer = 2.349183574318886\n",
      "KLdivLoss = 0.007626643404364586 et loss avant de l'appliquer = 2.599303630646318\n",
      "KLdivLoss = 0.007464137859642506 et loss avant de l'appliquer = 2.8231481234543025\n",
      "KLdivLoss = 0.007632019463926554 et loss avant de l'appliquer = 3.0648002685047686\n",
      "[Validation] Epoch: 72 [DONE]                                 \n",
      "[Epoch: 72, TrainLoss: 0.0252, TrainDice: 0.0546, ValLoss: 0.0486                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.007414344698190689 et loss avant de l'appliquer = 0.13405278697609901\n",
      "KLdivLoss = 0.006797599606215954 et loss avant de l'appliquer = 0.4752295045182109\n",
      "KLdivLoss = 0.006925706751644611 et loss avant de l'appliquer = 0.7196175381541252\n",
      "KLdivLoss = 0.0068779606372118 et loss avant de l'appliquer = 1.0002879798412323\n",
      "KLdivLoss = 0.0065779718570411205 et loss avant de l'appliquer = 1.2755499258637428\n",
      "KLdivLoss = 0.006369556300342083 et loss avant de l'appliquer = 1.5752405608072877\n",
      "KLdivLoss = 0.006401566322892904 et loss avant de l'appliquer = 1.8498265412636101\n",
      "KLdivLoss = 0.006949153728783131 et loss avant de l'appliquer = 2.0939085371792316\n",
      "KLdivLoss = 0.006860741414129734 et loss avant de l'appliquer = 2.3465279662050307\n",
      "KLdivLoss = 0.007143807597458363 et loss avant de l'appliquer = 2.6080939122475684\n",
      "KLdivLoss = 0.007577010430395603 et loss avant de l'appliquer = 2.864764683879912\n",
      "KLdivLoss = 0.007485415320843458 et loss avant de l'appliquer = 3.1307703917846084\n",
      "KLdivLoss = 0.007640731055289507 et loss avant de l'appliquer = 3.370055108331144\n",
      "[Validation] Epoch: 73 [DONE]                                 \n",
      "[Epoch: 73, TrainLoss: 0.0281, TrainDice: 0.0547, ValLoss: 0.0365                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.00739702396094799 et loss avant de l'appliquer = 0.02636202797293663\n",
      "KLdivLoss = 0.007452270947396755 et loss avant de l'appliquer = 0.27159644663333893\n",
      "KLdivLoss = 0.007512882351875305 et loss avant de l'appliquer = 0.5425916179083288\n",
      "KLdivLoss = 0.007110139355063438 et loss avant de l'appliquer = 0.820430678781122\n",
      "KLdivLoss = 0.007153148762881756 et loss avant de l'appliquer = 1.1145492275245488\n",
      "KLdivLoss = 0.0070792087353765965 et loss avant de l'appliquer = 1.4248835467733443\n",
      "KLdivLoss = 0.007259234320372343 et loss avant de l'appliquer = 1.7268580263480544\n",
      "KLdivLoss = 0.007352665066719055 et loss avant de l'appliquer = 1.994166573509574\n",
      "KLdivLoss = 0.007635538931936026 et loss avant de l'appliquer = 2.2385260723531246\n",
      "KLdivLoss = 0.007596252486109734 et loss avant de l'appliquer = 2.508126539643854\n",
      "KLdivLoss = 0.007682040333747864 et loss avant de l'appliquer = 2.7460980219766498\n",
      "KLdivLoss = 0.007592438720166683 et loss avant de l'appliquer = 3.0698743178509176\n",
      "KLdivLoss = 0.007547726389020681 et loss avant de l'appliquer = 3.364783121738583\n",
      "[Validation] Epoch: 74 [DONE]                                 \n",
      "[Epoch: 74, TrainLoss: 0.0277, TrainDice: 0.0551, ValLoss: 0.0348                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.007521235849708319 et loss avant de l'appliquer = 0.019576796796172857\n",
      "KLdivLoss = 0.007429731078445911 et loss avant de l'appliquer = 0.29526433628052473\n",
      "KLdivLoss = 0.007164979353547096 et loss avant de l'appliquer = 0.5349516803398728\n",
      "KLdivLoss = 0.007482662331312895 et loss avant de l'appliquer = 0.7775870417244732\n",
      "KLdivLoss = 0.007371569983661175 et loss avant de l'appliquer = 1.0386129207909107\n",
      "KLdivLoss = 0.0071735987439751625 et loss avant de l'appliquer = 1.2955239471048117\n",
      "KLdivLoss = 0.0075193410739302635 et loss avant de l'appliquer = 1.5421141078695655\n",
      "KLdivLoss = 0.007630335167050362 et loss avant de l'appliquer = 1.792124196421355\n",
      "KLdivLoss = 0.007464269176125526 et loss avant de l'appliquer = 2.031964620575309\n",
      "KLdivLoss = 0.007866892963647842 et loss avant de l'appliquer = 2.326443162281066\n",
      "KLdivLoss = 0.007456041872501373 et loss avant de l'appliquer = 2.6145262817153707\n",
      "KLdivLoss = 0.007408409379422665 et loss avant de l'appliquer = 2.865190179203637\n",
      "KLdivLoss = 0.006999148055911064 et loss avant de l'appliquer = 3.1603057618485764\n",
      "[Validation] Epoch: 75 [DONE]                                 \n",
      "[Epoch: 75, TrainLoss: 0.0259, TrainDice: 0.0535, ValLoss: 0.0387                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.007057523354887962 et loss avant de l'appliquer = 0.016154221259057522\n",
      "KLdivLoss = 0.0070003485307097435 et loss avant de l'appliquer = 0.29383359057828784\n",
      "KLdivLoss = 0.00718242023140192 et loss avant de l'appliquer = 0.5536137344315648\n",
      "KLdivLoss = 0.007024078629910946 et loss avant de l'appliquer = 0.8471019128337502\n",
      "KLdivLoss = 0.0073623680509626865 et loss avant de l'appliquer = 1.1611707718111575\n",
      "KLdivLoss = 0.006919471081346273 et loss avant de l'appliquer = 1.4310201779007912\n",
      "KLdivLoss = 0.0071471938863396645 et loss avant de l'appliquer = 1.6855696006678045\n",
      "KLdivLoss = 0.006936781108379364 et loss avant de l'appliquer = 1.9843719354830682\n",
      "KLdivLoss = 0.006808452308177948 et loss avant de l'appliquer = 2.242704117204994\n",
      "KLdivLoss = 0.007301740348339081 et loss avant de l'appliquer = 2.4925242802128196\n",
      "KLdivLoss = 0.007225315552204847 et loss avant de l'appliquer = 2.7332924944348633\n",
      "KLdivLoss = 0.007242441643029451 et loss avant de l'appliquer = 2.9694344252347946\n",
      "KLdivLoss = 0.00735665624961257 et loss avant de l'appliquer = 3.2127655460499227\n",
      "[Validation] Epoch: 76 [DONE]                                 \n",
      "[Epoch: 76, TrainLoss: 0.0265, TrainDice: 0.0539, ValLoss: 0.0498                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.007333758287131786 et loss avant de l'appliquer = 0.026463300921022892\n",
      "KLdivLoss = 0.007656888570636511 et loss avant de l'appliquer = 0.26483682775869966\n",
      "KLdivLoss = 0.00780522171407938 et loss avant de l'appliquer = 0.5105575360357761\n",
      "KLdivLoss = 0.007741741836071014 et loss avant de l'appliquer = 0.8029558174312115\n",
      "KLdivLoss = 0.007396589033305645 et loss avant de l'appliquer = 1.0926285446621478\n",
      "KLdivLoss = 0.006862428039312363 et loss avant de l'appliquer = 1.3780778939835727\n",
      "KLdivLoss = 0.006674491800367832 et loss avant de l'appliquer = 1.675430558156222\n",
      "KLdivLoss = 0.006801071111112833 et loss avant de l'appliquer = 1.9219679776579142\n",
      "KLdivLoss = 0.007004348561167717 et loss avant de l'appliquer = 2.1678227419033647\n",
      "KLdivLoss = 0.00699757132679224 et loss avant de l'appliquer = 2.416649664286524\n",
      "KLdivLoss = 0.006880213972181082 et loss avant de l'appliquer = 2.6650105523876846\n",
      "KLdivLoss = 0.0073493774980306625 et loss avant de l'appliquer = 2.8833436239510775\n",
      "KLdivLoss = 0.0072164274752140045 et loss avant de l'appliquer = 3.115487657021731\n",
      "[Validation] Epoch: 77 [DONE]                                 \n",
      "[Epoch: 77, TrainLoss: 0.0258, TrainDice: 0.0539, ValLoss: 0.0520                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.007446888368576765 et loss avant de l'appliquer = 0.01963392784819007\n",
      "KLdivLoss = 0.007364844437688589 et loss avant de l'appliquer = 0.22487002611160278\n",
      "KLdivLoss = 0.0073549142107367516 et loss avant de l'appliquer = 0.44356895331293344\n",
      "KLdivLoss = 0.007291329093277454 et loss avant de l'appliquer = 0.7118291123770177\n",
      "KLdivLoss = 0.00724234851077199 et loss avant de l'appliquer = 0.9305592146702111\n",
      "KLdivLoss = 0.007520277984440327 et loss avant de l'appliquer = 1.1819856483489275\n",
      "KLdivLoss = 0.007422053255140781 et loss avant de l'appliquer = 1.4524180558510125\n",
      "KLdivLoss = 0.00745042460039258 et loss avant de l'appliquer = 1.688953261822462\n",
      "KLdivLoss = 0.007289930712431669 et loss avant de l'appliquer = 1.9580097389407456\n",
      "KLdivLoss = 0.007050388492643833 et loss avant de l'appliquer = 2.234743171837181\n",
      "KLdivLoss = 0.006721071433275938 et loss avant de l'appliquer = 2.475104875396937\n",
      "KLdivLoss = 0.006856426130980253 et loss avant de l'appliquer = 2.711812132038176\n",
      "KLdivLoss = 0.0070083122700452805 et loss avant de l'appliquer = 2.9239448155276477\n",
      "[Validation] Epoch: 78 [DONE]                                 \n",
      "[Epoch: 78, TrainLoss: 0.0243, TrainDice: 0.0544, ValLoss: 0.0483                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.007138720713555813 et loss avant de l'appliquer = 0.02364653628319502\n",
      "KLdivLoss = 0.006901686079800129 et loss avant de l'appliquer = 0.32435061829164624\n",
      "KLdivLoss = 0.007268077228218317 et loss avant de l'appliquer = 0.5723533187992871\n",
      "KLdivLoss = 0.006761122960597277 et loss avant de l'appliquer = 0.8175389729440212\n",
      "KLdivLoss = 0.006819544825702906 et loss avant de l'appliquer = 1.1128121917136014\n",
      "KLdivLoss = 0.00718219019472599 et loss avant de l'appliquer = 1.3521098583005369\n",
      "KLdivLoss = 0.007221216335892677 et loss avant de l'appliquer = 1.5759012738708407\n",
      "KLdivLoss = 0.007312145084142685 et loss avant de l'appliquer = 1.849800256313756\n",
      "KLdivLoss = 0.007619211450219154 et loss avant de l'appliquer = 2.084044076735154\n",
      "KLdivLoss = 0.007425128482282162 et loss avant de l'appliquer = 2.346615442307666\n",
      "KLdivLoss = 0.00708780437707901 et loss avant de l'appliquer = 2.6027044870425016\n",
      "KLdivLoss = 0.006965802516788244 et loss avant de l'appliquer = 2.8083836452569813\n",
      "KLdivLoss = 0.007026832550764084 et loss avant de l'appliquer = 3.0540446408558637\n",
      "[Validation] Epoch: 79 [DONE]                                 \n",
      "[Epoch: 79, TrainLoss: 0.0252, TrainDice: 0.0546, ValLoss: 0.0376                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.007068153470754623 et loss avant de l'appliquer = 0.014062395319342613\n",
      "KLdivLoss = 0.0074940943159163 et loss avant de l'appliquer = 0.26778834080323577\n",
      "KLdivLoss = 0.007489197887480259 et loss avant de l'appliquer = 0.5138203073292971\n",
      "KLdivLoss = 0.007468517869710922 et loss avant de l'appliquer = 0.7984704403206706\n",
      "KLdivLoss = 0.0075498721562325954 et loss avant de l'appliquer = 1.0741727813147008\n",
      "KLdivLoss = 0.007142568472772837 et loss avant de l'appliquer = 1.3273641518317163\n",
      "KLdivLoss = 0.007088520564138889 et loss avant de l'appliquer = 1.5505534000694752\n",
      "KLdivLoss = 0.007055268157273531 et loss avant de l'appliquer = 1.8178379130549729\n",
      "KLdivLoss = 0.007181988097727299 et loss avant de l'appliquer = 2.0520854722708464\n",
      "KLdivLoss = 0.007278153672814369 et loss avant de l'appliquer = 2.3033323385752738\n",
      "KLdivLoss = 0.0074250660836696625 et loss avant de l'appliquer = 2.551052608527243\n",
      "KLdivLoss = 0.007324595004320145 et loss avant de l'appliquer = 2.7994846128858626\n",
      "KLdivLoss = 0.007855184376239777 et loss avant de l'appliquer = 3.0021545724011958\n",
      "[Validation] Epoch: 80 [DONE]                                 \n",
      "[Epoch: 80, TrainLoss: 0.0251, TrainDice: 0.0547, ValLoss: 0.0359                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.007225720211863518 et loss avant de l'appliquer = 0.024039974436163902\n",
      "KLdivLoss = 0.0074398755095899105 et loss avant de l'appliquer = 0.30335692036896944\n",
      "KLdivLoss = 0.007331031374633312 et loss avant de l'appliquer = 0.5572616145946085\n",
      "KLdivLoss = 0.007478583604097366 et loss avant de l'appliquer = 0.8328795777633786\n",
      "KLdivLoss = 0.007677770685404539 et loss avant de l'appliquer = 1.0705681471154094\n",
      "KLdivLoss = 0.007565585896372795 et loss avant de l'appliquer = 1.3075842335820198\n",
      "KLdivLoss = 0.007496756501495838 et loss avant de l'appliquer = 1.5444230856373906\n",
      "KLdivLoss = 0.0074111586436629295 et loss avant de l'appliquer = 1.7910726885311306\n",
      "KLdivLoss = 0.007978643290698528 et loss avant de l'appliquer = 2.0066560083068907\n",
      "KLdivLoss = 0.007935170084238052 et loss avant de l'appliquer = 2.2379687298089266\n",
      "KLdivLoss = 0.007840536534786224 et loss avant de l'appliquer = 2.520215732511133\n",
      "KLdivLoss = 0.007535743527114391 et loss avant de l'appliquer = 2.7365159397013485\n",
      "KLdivLoss = 0.007823885418474674 et loss avant de l'appliquer = 2.956586865708232\n",
      "[Validation] Epoch: 81 [DONE]                                 \n",
      "[Epoch: 81, TrainLoss: 0.0248, TrainDice: 0.0543, ValLoss: 0.0468                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.007280576042830944 et loss avant de l'appliquer = 0.028285537846386433\n",
      "KLdivLoss = 0.007340884767472744 et loss avant de l'appliquer = 0.2589674983173609\n",
      "KLdivLoss = 0.007621965371072292 et loss avant de l'appliquer = 0.5163211338222027\n",
      "KLdivLoss = 0.0073698172345757484 et loss avant de l'appliquer = 0.7725915689952672\n",
      "KLdivLoss = 0.007281736470758915 et loss avant de l'appliquer = 1.0351292015984654\n",
      "KLdivLoss = 0.007277999073266983 et loss avant de l'appliquer = 1.2841616859659553\n",
      "KLdivLoss = 0.007351428736001253 et loss avant de l'appliquer = 1.5229706838726997\n",
      "KLdivLoss = 0.007187001872807741 et loss avant de l'appliquer = 1.773580321110785\n",
      "KLdivLoss = 0.007045392878353596 et loss avant de l'appliquer = 2.0237077684141695\n",
      "KLdivLoss = 0.006869914475828409 et loss avant de l'appliquer = 2.2205047586467117\n",
      "KLdivLoss = 0.006515935063362122 et loss avant de l'appliquer = 2.5819884503725916\n",
      "KLdivLoss = 0.00678443256765604 et loss avant de l'appliquer = 2.860651611117646\n",
      "KLdivLoss = 0.006454769521951675 et loss avant de l'appliquer = 3.106873356504366\n",
      "[Validation] Epoch: 82 [DONE]                                 \n",
      "[Epoch: 82, TrainLoss: 0.0257, TrainDice: 0.0546, ValLoss: 0.0292                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.006551668047904968 et loss avant de l'appliquer = 0.02209575567394495\n",
      "KLdivLoss = 0.006652725860476494 et loss avant de l'appliquer = 0.24091000156477094\n",
      "KLdivLoss = 0.00685298815369606 et loss avant de l'appliquer = 0.49691899958997965\n",
      "KLdivLoss = 0.006843867711722851 et loss avant de l'appliquer = 0.782397982198745\n",
      "KLdivLoss = 0.006522023119032383 et loss avant de l'appliquer = 1.0523583334870636\n",
      "KLdivLoss = 0.006708240136504173 et loss avant de l'appliquer = 1.2741562272422016\n",
      "KLdivLoss = 0.006879501976072788 et loss avant de l'appliquer = 1.52526690158993\n",
      "KLdivLoss = 0.006890472024679184 et loss avant de l'appliquer = 1.782407799270004\n",
      "KLdivLoss = 0.007046540733426809 et loss avant de l'appliquer = 2.0216958574019372\n",
      "KLdivLoss = 0.007036962080746889 et loss avant de l'appliquer = 2.2747997264377773\n",
      "KLdivLoss = 0.006863046437501907 et loss avant de l'appliquer = 2.570147325284779\n",
      "KLdivLoss = 0.006688176654279232 et loss avant de l'appliquer = 2.80356119107455\n",
      "KLdivLoss = 0.006733625195920467 et loss avant de l'appliquer = 3.086644608527422\n",
      "[Validation] Epoch: 83 [DONE]                                 \n",
      "[Epoch: 83, TrainLoss: 0.0255, TrainDice: 0.0542, ValLoss: 0.0458                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.007217245176434517 et loss avant de l'appliquer = 0.051333775743842125\n",
      "KLdivLoss = 0.007240918930619955 et loss avant de l'appliquer = 0.28231571475043893\n",
      "KLdivLoss = 0.007546728011220694 et loss avant de l'appliquer = 0.5041085937991738\n",
      "KLdivLoss = 0.00720218475908041 et loss avant de l'appliquer = 0.738288922701031\n",
      "KLdivLoss = 0.00774935819208622 et loss avant de l'appliquer = 0.972148488741368\n",
      "KLdivLoss = 0.0073159001767635345 et loss avant de l'appliquer = 1.2408901480957866\n",
      "KLdivLoss = 0.007083086296916008 et loss avant de l'appliquer = 1.4989356556907296\n",
      "KLdivLoss = 0.007071535103023052 et loss avant de l'appliquer = 1.7671796749345958\n",
      "KLdivLoss = 0.006834575906395912 et loss avant de l'appliquer = 1.9714137082919478\n",
      "KLdivLoss = 0.007388944737613201 et loss avant de l'appliquer = 2.2153562759049237\n",
      "KLdivLoss = 0.0071337223052978516 et loss avant de l'appliquer = 2.522513591684401\n",
      "KLdivLoss = 0.006863947957754135 et loss avant de l'appliquer = 2.772545370273292\n",
      "KLdivLoss = 0.0069085825234651566 et loss avant de l'appliquer = 3.051396115683019\n",
      "[Validation] Epoch: 84 [DONE]                                 \n",
      "[Epoch: 84, TrainLoss: 0.0252, TrainDice: 0.0556, ValLoss: 0.0339                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.0065976642072200775 et loss avant de l'appliquer = 0.02249748259782791\n",
      "KLdivLoss = 0.006943300366401672 et loss avant de l'appliquer = 0.2306816461496055\n",
      "KLdivLoss = 0.00677516870200634 et loss avant de l'appliquer = 0.49780246149748564\n",
      "KLdivLoss = 0.006920774467289448 et loss avant de l'appliquer = 0.7486256826668978\n",
      "KLdivLoss = 0.006955244578421116 et loss avant de l'appliquer = 1.0168761815875769\n",
      "KLdivLoss = 0.006854829378426075 et loss avant de l'appliquer = 1.242240042425692\n",
      "KLdivLoss = 0.006983887404203415 et loss avant de l'appliquer = 1.4635551953688264\n",
      "KLdivLoss = 0.006877346895635128 et loss avant de l'appliquer = 1.713341711089015\n",
      "KLdivLoss = 0.006929575931280851 et loss avant de l'appliquer = 1.9452010728418827\n",
      "KLdivLoss = 0.0072618830017745495 et loss avant de l'appliquer = 2.2075245771557093\n",
      "KLdivLoss = 0.00713768508285284 et loss avant de l'appliquer = 2.4881263631395996\n",
      "KLdivLoss = 0.007085815537720919 et loss avant de l'appliquer = 2.736639599315822\n",
      "KLdivLoss = 0.0072818296030163765 et loss avant de l'appliquer = 2.956748491153121\n",
      "[Validation] Epoch: 85 [DONE]                                 \n",
      "[Epoch: 85, TrainLoss: 0.0245, TrainDice: 0.0558, ValLoss: 0.0499                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.007435408420860767 et loss avant de l'appliquer = 0.040914286859333515\n",
      "KLdivLoss = 0.0073560504242777824 et loss avant de l'appliquer = 0.272731623146683\n",
      "KLdivLoss = 0.007325757294893265 et loss avant de l'appliquer = 0.5199328912422061\n",
      "KLdivLoss = 0.007393393665552139 et loss avant de l'appliquer = 0.7652060608379543\n",
      "KLdivLoss = 0.007424947340041399 et loss avant de l'appliquer = 1.007853265851736\n",
      "KLdivLoss = 0.007409559562802315 et loss avant de l'appliquer = 1.2307972367852926\n",
      "KLdivLoss = 0.007529814727604389 et loss avant de l'appliquer = 1.4595191706903279\n",
      "KLdivLoss = 0.007364304736256599 et loss avant de l'appliquer = 1.7344414796680212\n",
      "KLdivLoss = 0.006986815482378006 et loss avant de l'appliquer = 1.985046733636409\n",
      "KLdivLoss = 0.007306048646569252 et loss avant de l'appliquer = 2.2286274884827435\n",
      "KLdivLoss = 0.006529334932565689 et loss avant de l'appliquer = 2.5610795747488737\n",
      "KLdivLoss = 0.006322375498712063 et loss avant de l'appliquer = 2.8607875523157418\n",
      "KLdivLoss = 0.006363732274621725 et loss avant de l'appliquer = 3.1089264918118715\n",
      "[Validation] Epoch: 86 [DONE]                                 \n",
      "[Epoch: 86, TrainLoss: 0.0256, TrainDice: 0.0553, ValLoss: 0.0396                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.006641731597483158 et loss avant de l'appliquer = 0.021834456361830235\n",
      "KLdivLoss = 0.0067903101444244385 et loss avant de l'appliquer = 0.27046531764790416\n",
      "KLdivLoss = 0.006948457099497318 et loss avant de l'appliquer = 0.47779565351083875\n",
      "KLdivLoss = 0.007056220434606075 et loss avant de l'appliquer = 0.7101618591696024\n",
      "KLdivLoss = 0.007543914020061493 et loss avant de l'appliquer = 0.9255416379310191\n",
      "KLdivLoss = 0.006671784911304712 et loss avant de l'appliquer = 1.222226019948721\n",
      "KLdivLoss = 0.006744748912751675 et loss avant de l'appliquer = 1.456600639037788\n",
      "KLdivLoss = 0.006805200595408678 et loss avant de l'appliquer = 1.7343306760303676\n",
      "KLdivLoss = 0.006934190168976784 et loss avant de l'appliquer = 1.9812651961110532\n",
      "KLdivLoss = 0.007236441597342491 et loss avant de l'appliquer = 2.2146184938028455\n",
      "KLdivLoss = 0.007078263908624649 et loss avant de l'appliquer = 2.5214227247051895\n",
      "KLdivLoss = 0.007124269846826792 et loss avant de l'appliquer = 2.8157058912329376\n",
      "KLdivLoss = 0.006739001255482435 et loss avant de l'appliquer = 3.056816519703716\n",
      "[Validation] Epoch: 87 [DONE]                                 \n",
      "[Epoch: 87, TrainLoss: 0.0256, TrainDice: 0.0555, ValLoss: 0.0399                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.006791681982576847 et loss avant de l'appliquer = 0.025284147821366787\n",
      "KLdivLoss = 0.006999279372394085 et loss avant de l'appliquer = 0.2584943282417953\n",
      "KLdivLoss = 0.007207207381725311 et loss avant de l'appliquer = 0.5210550404153764\n",
      "KLdivLoss = 0.007167945150285959 et loss avant de l'appliquer = 0.7583042294718325\n",
      "KLdivLoss = 0.00718862097710371 et loss avant de l'appliquer = 0.9862771285697818\n",
      "KLdivLoss = 0.006885576993227005 et loss avant de l'appliquer = 1.2218504059128463\n",
      "KLdivLoss = 0.007688239216804504 et loss avant de l'appliquer = 1.463227683212608\n",
      "KLdivLoss = 0.007416206412017345 et loss avant de l'appliquer = 1.717345470096916\n",
      "KLdivLoss = 0.007048607338219881 et loss avant de l'appliquer = 2.024109990336001\n",
      "KLdivLoss = 0.007222007028758526 et loss avant de l'appliquer = 2.310923090670258\n",
      "KLdivLoss = 0.007058344781398773 et loss avant de l'appliquer = 2.563944541849196\n",
      "KLdivLoss = 0.007291579619050026 et loss avant de l'appliquer = 2.8082024534232914\n",
      "KLdivLoss = 0.007295348681509495 et loss avant de l'appliquer = 3.056924934964627\n",
      "[Validation] Epoch: 88 [DONE]                                 \n",
      "[Epoch: 88, TrainLoss: 0.0254, TrainDice: 0.0546, ValLoss: 0.0483                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.007320248521864414 et loss avant de l'appliquer = 0.026108057238161564\n",
      "KLdivLoss = 0.0069807590916752815 et loss avant de l'appliquer = 0.32501279655843973\n",
      "KLdivLoss = 0.0071313465014100075 et loss avant de l'appliquer = 0.5689595728181303\n",
      "KLdivLoss = 0.007176581770181656 et loss avant de l'appliquer = 0.8367323135025799\n",
      "KLdivLoss = 0.0072071850299835205 et loss avant de l'appliquer = 1.0485980436205864\n",
      "KLdivLoss = 0.007241434417665005 et loss avant de l'appliquer = 1.3478755336254835\n",
      "KLdivLoss = 0.007340513169765472 et loss avant de l'appliquer = 1.5715362187474966\n",
      "KLdivLoss = 0.007712497841566801 et loss avant de l'appliquer = 1.836363854818046\n",
      "KLdivLoss = 0.007603936363011599 et loss avant de l'appliquer = 2.0618012393824756\n",
      "KLdivLoss = 0.007540533319115639 et loss avant de l'appliquer = 2.284405583050102\n",
      "KLdivLoss = 0.007397057954221964 et loss avant de l'appliquer = 2.509628533385694\n",
      "KLdivLoss = 0.007318473886698484 et loss avant de l'appliquer = 2.7365107177756727\n",
      "KLdivLoss = 0.007345241494476795 et loss avant de l'appliquer = 2.9801323153078556\n",
      "[Validation] Epoch: 89 [DONE]                                 \n",
      "[Epoch: 89, TrainLoss: 0.0249, TrainDice: 0.0559, ValLoss: 0.0570                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.00721741421148181 et loss avant de l'appliquer = 0.02165668411180377\n",
      "KLdivLoss = 0.007484199944883585 et loss avant de l'appliquer = 0.2594105158932507\n",
      "KLdivLoss = 0.006884820759296417 et loss avant de l'appliquer = 0.49023404298350215\n",
      "KLdivLoss = 0.007172807119786739 et loss avant de l'appliquer = 0.7139500146731734\n",
      "KLdivLoss = 0.007413045037537813 et loss avant de l'appliquer = 0.9859911669045687\n",
      "KLdivLoss = 0.006832808256149292 et loss avant de l'appliquer = 1.2624553362838924\n",
      "KLdivLoss = 0.007127529941499233 et loss avant de l'appliquer = 1.5328948576934636\n",
      "KLdivLoss = 0.0071969544515013695 et loss avant de l'appliquer = 1.7770203808322549\n",
      "KLdivLoss = 0.007263328414410353 et loss avant de l'appliquer = 2.00189613038674\n",
      "KLdivLoss = 0.007152372505515814 et loss avant de l'appliquer = 2.243629472795874\n",
      "KLdivLoss = 0.006715327501296997 et loss avant de l'appliquer = 2.5928426613099873\n",
      "KLdivLoss = 0.006338893435895443 et loss avant de l'appliquer = 2.8914944315329194\n",
      "KLdivLoss = 0.006385748274624348 et loss avant de l'appliquer = 3.1529777315445244\n",
      "[Validation] Epoch: 90 [DONE]                                 \n",
      "[Epoch: 90, TrainLoss: 0.0261, TrainDice: 0.0548, ValLoss: 0.0547                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.0064436993561685085 et loss avant de l'appliquer = 0.024156599771231413\n",
      "KLdivLoss = 0.006306897848844528 et loss avant de l'appliquer = 0.2986642448231578\n",
      "KLdivLoss = 0.006528997328132391 et loss avant de l'appliquer = 0.5197038385085762\n",
      "KLdivLoss = 0.006738633383065462 et loss avant de l'appliquer = 0.7871423331089318\n",
      "KLdivLoss = 0.006981616374105215 et loss avant de l'appliquer = 1.0082572563551366\n",
      "KLdivLoss = 0.006971597205847502 et loss avant de l'appliquer = 1.2443785783834755\n",
      "KLdivLoss = 0.0072392988950014114 et loss avant de l'appliquer = 1.4570842650718987\n",
      "KLdivLoss = 0.006993873510509729 et loss avant de l'appliquer = 1.704369951505214\n",
      "KLdivLoss = 0.0070898085832595825 et loss avant de l'appliquer = 1.9394302060827613\n",
      "KLdivLoss = 0.007241036742925644 et loss avant de l'appliquer = 2.1732779848389328\n",
      "KLdivLoss = 0.007132973056286573 et loss avant de l'appliquer = 2.4699883619323373\n",
      "KLdivLoss = 0.006613682955503464 et loss avant de l'appliquer = 2.748089086264372\n",
      "KLdivLoss = 0.006827682256698608 et loss avant de l'appliquer = 2.995892869774252\n",
      "[Validation] Epoch: 91 [DONE]                                 \n",
      "[Epoch: 91, TrainLoss: 0.0247, TrainDice: 0.0551, ValLoss: 0.0555                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.006942600477486849 et loss avant de l'appliquer = 0.02517767297104001\n",
      "KLdivLoss = 0.006966807879507542 et loss avant de l'appliquer = 0.2742260526865721\n",
      "KLdivLoss = 0.007047709077596664 et loss avant de l'appliquer = 0.5298564392141998\n",
      "KLdivLoss = 0.00735938036814332 et loss avant de l'appliquer = 0.8746850178577006\n",
      "KLdivLoss = 0.006868366617709398 et loss avant de l'appliquer = 1.1594329290091991\n",
      "KLdivLoss = 0.00688500190153718 et loss avant de l'appliquer = 1.4088111026212573\n",
      "KLdivLoss = 0.007261019665747881 et loss avant de l'appliquer = 1.603904280345887\n",
      "KLdivLoss = 0.007487081456929445 et loss avant de l'appliquer = 1.8182147955521941\n",
      "KLdivLoss = 0.007172213401645422 et loss avant de l'appliquer = 2.073987439274788\n",
      "KLdivLoss = 0.00713819544762373 et loss avant de l'appliquer = 2.3270806716755033\n",
      "KLdivLoss = 0.006990581750869751 et loss avant de l'appliquer = 2.5803348175249994\n",
      "KLdivLoss = 0.0069459532387554646 et loss avant de l'appliquer = 2.846446681767702\n",
      "KLdivLoss = 0.007039780728518963 et loss avant de l'appliquer = 3.061939811334014\n",
      "[Validation] Epoch: 92 [DONE]                                 \n",
      "[Epoch: 92, TrainLoss: 0.0252, TrainDice: 0.0544, ValLoss: 0.0369                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.007088432088494301 et loss avant de l'appliquer = 0.02615942619740963\n",
      "KLdivLoss = 0.007457003928720951 et loss avant de l'appliquer = 0.2667269487865269\n",
      "KLdivLoss = 0.007145486772060394 et loss avant de l'appliquer = 0.5205496246926486\n",
      "KLdivLoss = 0.006765466183423996 et loss avant de l'appliquer = 0.7613116465508938\n",
      "KLdivLoss = 0.006825787015259266 et loss avant de l'appliquer = 1.0099485353566706\n",
      "KLdivLoss = 0.006844282150268555 et loss avant de l'appliquer = 1.2393358242698014\n",
      "KLdivLoss = 0.007045620121061802 et loss avant de l'appliquer = 1.4569012192077935\n",
      "KLdivLoss = 0.00692384596914053 et loss avant de l'appliquer = 1.6879444369114935\n",
      "KLdivLoss = 0.007234203163534403 et loss avant de l'appliquer = 1.938423302024603\n",
      "KLdivLoss = 0.006755887996405363 et loss avant de l'appliquer = 2.238045539241284\n",
      "KLdivLoss = 0.006571155972778797 et loss avant de l'appliquer = 2.528927471023053\n",
      "KLdivLoss = 0.007176097948104143 et loss avant de l'appliquer = 2.7904858104884624\n",
      "KLdivLoss = 0.0075291600078344345 et loss avant de l'appliquer = 3.0692687379196286\n",
      "[Validation] Epoch: 93 [DONE]                                 \n",
      "[Epoch: 93, TrainLoss: 0.0257, TrainDice: 0.0545, ValLoss: 0.0317                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.006760653108358383 et loss avant de l'appliquer = 0.028282340615987778\n",
      "KLdivLoss = 0.007004688959568739 et loss avant de l'appliquer = 0.3050574064254761\n",
      "KLdivLoss = 0.006808815058320761 et loss avant de l'appliquer = 0.574311485979706\n",
      "KLdivLoss = 0.006887773983180523 et loss avant de l'appliquer = 0.8837855961173773\n",
      "KLdivLoss = 0.007132794242352247 et loss avant de l'appliquer = 1.1269520963542163\n",
      "KLdivLoss = 0.007061675190925598 et loss avant de l'appliquer = 1.3760620816610754\n",
      "KLdivLoss = 0.007224413100630045 et loss avant de l'appliquer = 1.6001071999780834\n",
      "KLdivLoss = 0.007179141975939274 et loss avant de l'appliquer = 1.8159002857282758\n",
      "KLdivLoss = 0.007148011587560177 et loss avant de l'appliquer = 2.042152302339673\n",
      "KLdivLoss = 0.007047630846500397 et loss avant de l'appliquer = 2.2642880836501718\n",
      "KLdivLoss = 0.007197327446192503 et loss avant de l'appliquer = 2.5069642630405724\n",
      "KLdivLoss = 0.007507650181651115 et loss avant de l'appliquer = 2.7464607185684144\n",
      "KLdivLoss = 0.007262845989316702 et loss avant de l'appliquer = 2.9915814963169396\n",
      "[Validation] Epoch: 94 [DONE]                                 \n",
      "[Epoch: 94, TrainLoss: 0.0247, TrainDice: 0.0544, ValLoss: 0.0418                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.007043578661978245 et loss avant de l'appliquer = 0.0330091817304492\n",
      "KLdivLoss = 0.0071460651233792305 et loss avant de l'appliquer = 0.27174851344898343\n",
      "KLdivLoss = 0.007266372907906771 et loss avant de l'appliquer = 0.5308035351336002\n",
      "KLdivLoss = 0.006934435106813908 et loss avant de l'appliquer = 0.805657995864749\n",
      "KLdivLoss = 0.00690213730558753 et loss avant de l'appliquer = 1.0351252602413297\n",
      "KLdivLoss = 0.007214919198304415 et loss avant de l'appliquer = 1.2446157112717628\n",
      "KLdivLoss = 0.007058070041239262 et loss avant de l'appliquer = 1.4827448856085539\n",
      "KLdivLoss = 0.00715728010982275 et loss avant de l'appliquer = 1.6842752122320235\n",
      "KLdivLoss = 0.007321217563003302 et loss avant de l'appliquer = 1.8989700856618583\n",
      "KLdivLoss = 0.006989989895373583 et loss avant de l'appliquer = 2.1336250314489007\n",
      "KLdivLoss = 0.006925866939127445 et loss avant de l'appliquer = 2.4103748127818108\n",
      "KLdivLoss = 0.006676019169390202 et loss avant de l'appliquer = 2.657967289444059\n",
      "KLdivLoss = 0.006652705371379852 et loss avant de l'appliquer = 2.882950637023896\n",
      "[Validation] Epoch: 95 [DONE]                                 \n",
      "[Epoch: 95, TrainLoss: 0.0238, TrainDice: 0.0554, ValLoss: 0.0285                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.006910144817084074 et loss avant de l'appliquer = 0.023204404395073652\n",
      "KLdivLoss = 0.007274056784808636 et loss avant de l'appliquer = 0.23378764977678657\n",
      "KLdivLoss = 0.007181434892117977 et loss avant de l'appliquer = 0.48217435367405415\n",
      "KLdivLoss = 0.007135650143027306 et loss avant de l'appliquer = 0.7516763741150498\n",
      "KLdivLoss = 0.0070190271362662315 et loss avant de l'appliquer = 0.9599202354438603\n",
      "KLdivLoss = 0.0071594323962926865 et loss avant de l'appliquer = 1.1792264939285815\n",
      "KLdivLoss = 0.007155375089496374 et loss avant de l'appliquer = 1.4188142544589937\n",
      "KLdivLoss = 0.007256811019033194 et loss avant de l'appliquer = 1.6621443778276443\n",
      "KLdivLoss = 0.00744832307100296 et loss avant de l'appliquer = 1.8999068420380354\n",
      "KLdivLoss = 0.00737705547362566 et loss avant de l'appliquer = 2.1158316573128104\n",
      "KLdivLoss = 0.007619822397828102 et loss avant de l'appliquer = 2.3460876955650747\n",
      "KLdivLoss = 0.007571028545498848 et loss avant de l'appliquer = 2.571576352696866\n",
      "KLdivLoss = 0.007222365587949753 et loss avant de l'appliquer = 2.851290450897068\n",
      "[Validation] Epoch: 96 [DONE]                                 \n",
      "[Epoch: 96, TrainLoss: 0.0235, TrainDice: 0.0536, ValLoss: 0.0433                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.007366166450083256 et loss avant de l'appliquer = 0.02365512866526842\n",
      "KLdivLoss = 0.007107695564627647 et loss avant de l'appliquer = 0.27884566411376\n",
      "KLdivLoss = 0.007099306210875511 et loss avant de l'appliquer = 0.5092385429888964\n",
      "KLdivLoss = 0.007086069323122501 et loss avant de l'appliquer = 0.760584844276309\n",
      "KLdivLoss = 0.007526272442191839 et loss avant de l'appliquer = 1.0279951211996377\n",
      "KLdivLoss = 0.007691148668527603 et loss avant de l'appliquer = 1.2649480970576406\n",
      "KLdivLoss = 0.007319761905819178 et loss avant de l'appliquer = 1.4976405324414372\n",
      "KLdivLoss = 0.00744161382317543 et loss avant de l'appliquer = 1.7404630328528583\n",
      "KLdivLoss = 0.007156413048505783 et loss avant de l'appliquer = 1.9482388966716826\n",
      "KLdivLoss = 0.0071611241437494755 et loss avant de l'appliquer = 2.1860926910303533\n",
      "KLdivLoss = 0.0071458593010902405 et loss avant de l'appliquer = 2.4494048240594566\n",
      "KLdivLoss = 0.007196936756372452 et loss avant de l'appliquer = 2.656028216239065\n",
      "KLdivLoss = 0.007142098620533943 et loss avant de l'appliquer = 2.896773303858936\n",
      "[Validation] Epoch: 97 [DONE]                                 \n",
      "[Epoch: 97, TrainLoss: 0.0239, TrainDice: 0.0543, ValLoss: 0.0422                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.007274973671883345 et loss avant de l'appliquer = 0.024174341466277838\n",
      "KLdivLoss = 0.007379551883786917 et loss avant de l'appliquer = 0.2592362961731851\n",
      "KLdivLoss = 0.007221597712486982 et loss avant de l'appliquer = 0.4618058023042977\n",
      "KLdivLoss = 0.007196974474936724 et loss avant de l'appliquer = 0.7091928427107632\n",
      "KLdivLoss = 0.00704683642834425 et loss avant de l'appliquer = 0.9671531924977899\n",
      "KLdivLoss = 0.0068598343059420586 et loss avant de l'appliquer = 1.2010502396151423\n",
      "KLdivLoss = 0.00717241782695055 et loss avant de l'appliquer = 1.4313502586446702\n",
      "KLdivLoss = 0.007377334404736757 et loss avant de l'appliquer = 1.663462990662083\n",
      "KLdivLoss = 0.007446398958563805 et loss avant de l'appliquer = 1.8955092926044017\n",
      "KLdivLoss = 0.00745650939643383 et loss avant de l'appliquer = 2.130375822307542\n",
      "KLdivLoss = 0.007248635403811932 et loss avant de l'appliquer = 2.3734528466593474\n",
      "KLdivLoss = 0.0073916055262088776 et loss avant de l'appliquer = 2.628632117761299\n",
      "KLdivLoss = 0.007317179813981056 et loss avant de l'appliquer = 2.8724955890793353\n",
      "[Validation] Epoch: 98 [DONE]                                 \n",
      "[Epoch: 98, TrainLoss: 0.0238, TrainDice: 0.0550, ValLoss: 0.0323                                            \n",
      "Number of batches:  126\n",
      "KLdivLoss = 0.007300953380763531 et loss avant de l'appliquer = 0.024693037383258343\n",
      "KLdivLoss = 0.007267402950674295 et loss avant de l'appliquer = 0.24551214464008808\n",
      "KLdivLoss = 0.007344772573560476 et loss avant de l'appliquer = 0.49126141611486673\n",
      "KLdivLoss = 0.0072907255962491035 et loss avant de l'appliquer = 0.7431161534041166\n",
      "KLdivLoss = 0.0066708349622786045 et loss avant de l'appliquer = 1.0166288642212749\n",
      "KLdivLoss = 0.007039823569357395 et loss avant de l'appliquer = 1.2775722197256982\n",
      "KLdivLoss = 0.007061947137117386 et loss avant de l'appliquer = 1.4935237052850425\n",
      "KLdivLoss = 0.007347873877733946 et loss avant de l'appliquer = 1.7397405235096812\n",
      "KLdivLoss = 0.0071064140647649765 et loss avant de l'appliquer = 1.9695292939431965\n",
      "KLdivLoss = 0.007435355335474014 et loss avant de l'appliquer = 2.219271897803992\n",
      "KLdivLoss = 0.007556837052106857 et loss avant de l'appliquer = 2.439819465856999\n",
      "KLdivLoss = 0.006992388516664505 et loss avant de l'appliquer = 2.702778108883649\n",
      "KLdivLoss = 0.006741862744092941 et loss avant de l'appliquer = 2.989162483252585\n",
      "[Validation] Epoch: 99 [DONE]                                 \n",
      "[Epoch: 99, TrainLoss: 0.0246, TrainDice: 0.0545, ValLoss: 0.0450                                            \n"
     ]
    }
   ],
   "source": [
    "#on considère que précédemment c'était le Teacher \n",
    "#maintenant on fait le student \n",
    "\n",
    "writer = SummaryWriter()\n",
    "num_epoch_teacher = 74\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(\"~~~~~~~~  Starting the training of the student... ~~~~~~\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "num_classes = 4\n",
    "alpha = 0.1\n",
    "\n",
    "# Set device depending on the availability of GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "print(\"~~~~~~~~~~~ Creating the UNet model ~~~~~~~~~~\")\n",
    "modelName = \"SemiSupervised-TransformConsistency\"\n",
    "print(\" Model Name: {}\".format(modelName))\n",
    "\n",
    "## CREATION OF YOUR MODEL\n",
    "student_net = UNet(num_classes).to(device)\n",
    "epoch_to_load = 74\n",
    "teacher_model_path = f\"./models/SemiSupervised-TransformConsistency/{epoch_to_load}_Epoch\"\n",
    "#charger les poids du teacher dans le student\n",
    "try:\n",
    "    student_net.load_state_dict(torch.load(teacher_model_path))\n",
    "    print(f\"Les poids du modèle Teacher (époque {epoch_to_load}) ont été chargés avec succès dans le modèle Student.\")\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors du chargement des poids : {e}\")\n",
    "\n",
    "print(\n",
    "    \"Total params: {0:,}\".format(\n",
    "        sum(p.numel() for p in student_net.parameters() if p.requires_grad)\n",
    "    )\n",
    ")\n",
    "\n",
    "# DEFINE YOUR OUTPUT COMPONENTS (e.g., SOFTMAX, LOSS FUNCTION, ETC)\n",
    "softMax = torch.nn.Softmax(dim=1)\n",
    "CE_loss = torch.nn.CrossEntropyLoss()\n",
    "consistency_regularizer = ConsistencyRegularization(transformation_fn=transforms.RandomHorizontalFlip()) #!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "\n",
    "## PUT EVERYTHING IN GPU RESOURCES\n",
    "# if torch.cuda.is_available():\n",
    "#     student_net.cuda()\n",
    "#     softMax.cuda()\n",
    "#     CE_loss.cuda()\n",
    "\n",
    "## DEFINE YOUR OPTIMIZER\n",
    "optimizer = torch.optim.Adam(student_net.parameters(), lr=lr)\n",
    "\n",
    "### To save statistics ####\n",
    "train_losses = []\n",
    "train_dc_losses = []\n",
    "val_losses = []\n",
    "val_dc_losses = []\n",
    "\n",
    "best_loss_val = 1000\n",
    "\n",
    "directory = \"Results/Statistics/\" + modelName\n",
    "\n",
    "print(\"~~~~~~~~~~~ Starting the training ~~~~~~~~~~\")\n",
    "if os.path.exists(directory) == False:\n",
    "    os.makedirs(directory)\n",
    "\n",
    "## START THE TRAINING\n",
    "\n",
    "## FOR EACH EPOCH\n",
    "for epoch in range(total_epochs):\n",
    "    student_net.train()\n",
    "    supervised_iter = iter(supervised_loader)\n",
    "    unsupervised_iter = iter(unsupervised_loader)\n",
    "    unlabeled_iter = iter(unlabeledEval_loader_full)\n",
    "    \n",
    "    num_batches = max(len(supervised_loader), len(unsupervised_loader))\n",
    "    print(\"Number of batches: \", num_batches)\n",
    "\n",
    "    running_train_loss = 0\n",
    "    running_dice_loss = 0\n",
    "\n",
    "    # Training loop\n",
    "    for idx in range(num_batches):\n",
    "        ### SUPERVISED BATCH\n",
    "        try :\n",
    "            supervised_data = next(supervised_iter)\n",
    "        except StopIteration:\n",
    "            supervised_iter = iter(supervised_loader)\n",
    "            supervised_data = next(supervised_iter)\n",
    "\n",
    "        ### Set to zero all the gradients\n",
    "        student_net.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        ## GET IMAGES, LABELS and IMG NAMES\n",
    "        images, labels, img_names = supervised_data\n",
    "\n",
    "        ### From numpy to torch variables\n",
    "        labels = utils.to_var(labels).to(device)\n",
    "        images = utils.to_var(images).to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        net_predictions = student_net(images)\n",
    "\n",
    "        # Get the segmentation classes\n",
    "        segmentation_classes = utils.getTargetSegmentation(labels)\n",
    "\n",
    "        # Compute the loss\n",
    "        ce_loss = CE_loss(net_predictions, segmentation_classes)\n",
    "        running_train_loss += ce_loss.item()\n",
    "        # dice_loss = dice_coefficient(net_predictions, labels)\n",
    "        dice_loss = utils.compute_dsc(net_predictions, labels)\n",
    "        running_dice_loss += dice_loss\n",
    "\n",
    "        # Backprop\n",
    "        ce_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "        # ### UNSUPERVISED BATCH (consistency regularization)\n",
    "        # try :\n",
    "        #     unsupervised_data = next(unsupervised_iter)\n",
    "        # except StopIteration:\n",
    "        #     unsupervised_iter = iter(unsupervised_loader)\n",
    "        #     unsupervised_data = next(unsupervised_iter)\n",
    "        \n",
    "        # unsupervised_images, _, _ = unsupervised_data\n",
    "        # unsupervised_images = utils.to_var(unsupervised_images).to(device)\n",
    "\n",
    "        # student_net.zero_grad()\n",
    "        # optimizer.zero_grad()\n",
    "        \n",
    "        # consistency_loss = consistency_regularizer(student_net, unsupervised_images)\n",
    "        # (alpha * consistency_loss).backward()\n",
    "        # optimizer.step()\n",
    "\n",
    "        # running_train_loss += consistency_loss.item()\n",
    "        # running_dice_loss += 0\n",
    "\n",
    "\n",
    "        ### SEMI-SUPERVISED BATCH (pseudo labels made by Teacher)\n",
    "        try :\n",
    "            unlabeled_data = next(unlabeled_iter)\n",
    "        except StopIteration:\n",
    "            unlabeled_iter = iter(unlabeledEval_loader_full)\n",
    "            unlabeled_data = next(unlabeled_iter)\n",
    "\n",
    "        images, img_names = unlabeled_data\n",
    "        images = utils.to_var(images).to(device)\n",
    "\n",
    "        student_net.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #on recupere les distributions de proba du teacher pour les unlabeled\n",
    "        segmentation_class_teacher = get_teacher_proba(num_epoch_teacher, img_names, device)\n",
    "        #predictions sur unlabeled\n",
    "        net_predictions = student_net(images)\n",
    "        KLdivLoss = dynamic_weight_kl_div(net_predictions, segmentation_class_teacher)\n",
    "\n",
    "        (alpha * KLdivLoss).backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "\n",
    "        running_train_loss += KLdivLoss.item()\n",
    "       \n",
    "        running_dice_loss += 0\n",
    "\n",
    "        \n",
    "        # Add the loss to the tensorboard every 5 batches\n",
    "        if idx % 10 == 0:\n",
    "            writer.add_scalar(\n",
    "                \"Loss/train\", running_train_loss / (idx + 1), epoch * len(supervised_loader) + idx\n",
    "            )\n",
    "            writer.add_scalar(\n",
    "                \"Dice/train\", running_dice_loss / (idx + 1), epoch * len(supervised_loader) + idx\n",
    "            )\n",
    "            print(f\"KLdivLoss = {KLdivLoss} et loss avant de l'appliquer = {running_train_loss}\")\n",
    "\n",
    "        # if idx % 100 == 0:\n",
    "        #     # Also add visualizations of the images\n",
    "        #     probs = torch.softmax(net_predictions, dim=1)\n",
    "        #     y_pred = torch.argmax(probs, dim=1)\n",
    "        #     writer.add_figure('predictions vs. actuals',\n",
    "        #                 utils.plot_net_predictions(images, labels, y_pred, batch_size),\n",
    "        #                 global_step=epoch * len(supervised_loader) + idx)\n",
    "\n",
    "        # # THIS IS JUST TO VISUALIZE THE TRAINING\n",
    "        # printProgressBar(\n",
    "        #     idx + 1,\n",
    "        #     num_batches,\n",
    "        #     prefix=\"[Training] Epoch: {} \".format(epoch),\n",
    "        #     length=15,\n",
    "        #     suffix=\" Loss: {:.4f}, \".format(running_train_loss / (idx + 1)),\n",
    "        # )\n",
    "\n",
    "    train_loss = running_train_loss / num_batches\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    train_dc_loss = running_dice_loss / num_batches\n",
    "    train_dc_losses.append(train_dc_loss)\n",
    "\n",
    "    student_net.eval()\n",
    "    val_running_loss = 0\n",
    "    val_running_dc = 0\n",
    "\n",
    "    # Validation loop\n",
    "    with torch.no_grad():\n",
    "        for idx, data in enumerate(val_loader):\n",
    "            images, labels, img_names = data\n",
    "\n",
    "            labels = utils.to_var(labels).to(device)\n",
    "            images = utils.to_var(images).to(device)\n",
    "\n",
    "            net_predictions = student_net(images)\n",
    "\n",
    "            segmentation_classes = utils.getTargetSegmentation(labels)\n",
    "\n",
    "            loss = CE_loss(net_predictions, segmentation_classes) \n",
    "            val_running_loss += loss.item()\n",
    "\n",
    "            # dice_loss = dice_coefficient(net_predictions, labels)\n",
    "            dice_loss = utils.compute_dsc(net_predictions, labels)\n",
    "            val_running_dc += dice_loss\n",
    "\n",
    "            if idx % 10 == 0:\n",
    "                writer.add_scalar(\n",
    "                    \"Loss/val\",\n",
    "                    val_running_loss / (idx + 1),\n",
    "                    epoch * len(val_loader) + idx,\n",
    "                )\n",
    "                writer.add_scalar(\n",
    "                    \"Dice/val\",\n",
    "                    val_running_dc / (idx + 1),\n",
    "                    epoch * len(val_loader) + idx,\n",
    "                )\n",
    "\n",
    "            printProgressBar(\n",
    "                idx + 1,\n",
    "                len(val_loader),\n",
    "                prefix=\"[Validation] Epoch: {} \".format(epoch),\n",
    "                length=15,\n",
    "                suffix=\" Loss: {:.4f}, \".format(val_running_loss / (idx + 1)),\n",
    "            )\n",
    "\n",
    "    val_loss = val_running_loss / len(val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    dc_loss = val_running_dc / len(val_loader)\n",
    "    val_dc_losses.append(dc_loss)\n",
    "\n",
    "    # Check if model performed best and save it if true\n",
    "    if val_loss < best_loss_val:\n",
    "        best_loss_val = val_loss\n",
    "        if not os.path.exists(\"./models/\" + modelName):\n",
    "            os.makedirs(\"./models/\" + modelName)\n",
    "        torch.save(\n",
    "            student_net.state_dict(), \"./models/TESTSTUDENT\" + \"/AvecPseudo\" + str(epoch) + \"_Epoch\"\n",
    "        )\n",
    "\n",
    "    printProgressBar(\n",
    "        num_batches,\n",
    "        num_batches,\n",
    "        done=\"[Epoch: {}, TrainLoss: {:.4f}, TrainDice: {:.4f}, ValLoss: {:.4f}\".format(\n",
    "            epoch, train_loss, train_dc_loss, val_loss\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    np.save(os.path.join(directory, \"Losses.npy\"), train_losses)\n",
    "writer.flush()  # Flush the writer to ensure that all the data is written to disk\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c5516a",
   "metadata": {},
   "source": [
    "### Test with validation set "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2c3351",
   "metadata": {},
   "source": [
    "IoU, Dice Coefficient, Precision and Recall, F1 Score, MAE, MSE, Hausdorff Distance, Pixel accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2cbbfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f1(preds, labels):\n",
    "    \"\"\"\n",
    "    Compute the F1 score given the predictions and the labels.\n",
    "\n",
    "    Args:\n",
    "        preds (torch.Tensor): Predictions from the model.\n",
    "        labels (torch.Tensor): Ground truth labels.\n",
    "\n",
    "    Returns:\n",
    "        float: The F1 score.\n",
    "    \"\"\"\n",
    "    # print(\"Computing F1 score...\")\n",
    "    # print('Preds:', preds.shape) # (B, C, H, W)\n",
    "    # print('Labels:', labels.shape) # (B, 1, H, W)\n",
    "\n",
    "    tp = torch.sum(preds * labels).float()\n",
    "    fp = torch.sum(preds * (1 - labels)).float()\n",
    "    fn = torch.sum((1 - preds) * labels).float()\n",
    "\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "    return f1.item()\n",
    "\n",
    "\n",
    "def compute_precision(preds, labels):\n",
    "    \"\"\"\n",
    "    Compute the precision score given the predictions and the labels.\n",
    "\n",
    "    Args:\n",
    "        preds (torch.Tensor): Predictions from the model.\n",
    "        labels (torch.Tensor): Ground truth labels.\n",
    "\n",
    "    Returns:\n",
    "        float: The precision score.\n",
    "    \"\"\"\n",
    "    # print(\"Computing precision...\")\n",
    "    tp = torch.sum(preds * labels).float()\n",
    "    fp = torch.sum(preds * (1 - labels)).float()\n",
    "\n",
    "    precision = tp / (tp + fp)\n",
    "\n",
    "    return precision.item()\n",
    "\n",
    "def compute_recall(preds, labels):\n",
    "    \"\"\"\n",
    "    Compute the recall score given the predictions and the labels.\n",
    "\n",
    "    Args:\n",
    "        preds (torch.Tensor): Predictions from the model.\n",
    "        labels (torch.Tensor): Ground truth labels.\n",
    "\n",
    "    Returns:\n",
    "        float: The recall score.\n",
    "    \"\"\"\n",
    "    # print(\"Computing recall...\")\n",
    "    tp = torch.sum(preds * labels).float()\n",
    "    fn = torch.sum((1 - preds) * labels).float()\n",
    "\n",
    "    recall = tp / (tp + fn)\n",
    "\n",
    "    return recall.item()\n",
    "\n",
    "def compute_iou(preds, labels):\n",
    "    \"\"\"\n",
    "    Compute the Intersection over Union (IoU) score given the predictions and the labels.\n",
    "\n",
    "    Args:\n",
    "        preds (torch.Tensor): Predictions from the model.\n",
    "        labels (torch.Tensor): Ground truth labels.\n",
    "\n",
    "    Returns:\n",
    "        float: The IoU score.\n",
    "    \"\"\"\n",
    "    # print(\"Computing IoU...\")\n",
    "    intersection = torch.sum(preds * labels).float()\n",
    "    union = torch.sum((preds + labels) > 0).float()\n",
    "\n",
    "    iou = intersection / union\n",
    "\n",
    "    return iou.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ce99b5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape:  torch.Size([4, 1, 256, 256])\n",
      "Predictions shape:  torch.Size([4, 4, 256, 256])\n",
      "GT shape:  torch.Size([4, 1, 256, 256])\n",
      "Image shape:  torch.Size([4, 1, 256, 256])\n",
      "Predictions shape:  torch.Size([4, 4, 256, 256])\n",
      "GT shape:  torch.Size([4, 1, 256, 256])\n",
      "Image shape:  torch.Size([4, 1, 256, 256])\n",
      "Predictions shape:  torch.Size([4, 4, 256, 256])\n",
      "GT shape:  torch.Size([4, 1, 256, 256])\n",
      "Image shape:  torch.Size([4, 1, 256, 256])\n",
      "Predictions shape:  torch.Size([4, 4, 256, 256])\n",
      "GT shape:  torch.Size([4, 1, 256, 256])\n",
      "Image shape:  torch.Size([4, 1, 256, 256])\n",
      "Predictions shape:  torch.Size([4, 4, 256, 256])\n",
      "GT shape:  torch.Size([4, 1, 256, 256])\n",
      "Image shape:  torch.Size([4, 1, 256, 256])\n",
      "Predictions shape:  torch.Size([4, 4, 256, 256])\n",
      "GT shape:  torch.Size([4, 1, 256, 256])\n",
      "Image shape:  torch.Size([4, 1, 256, 256])\n",
      "Predictions shape:  torch.Size([4, 4, 256, 256])\n",
      "GT shape:  torch.Size([4, 1, 256, 256])\n",
      "Image shape:  torch.Size([4, 1, 256, 256])\n",
      "Predictions shape:  torch.Size([4, 4, 256, 256])\n",
      "GT shape:  torch.Size([4, 1, 256, 256])\n",
      "Image shape:  torch.Size([4, 1, 256, 256])\n",
      "Predictions shape:  torch.Size([4, 4, 256, 256])\n",
      "GT shape:  torch.Size([4, 1, 256, 256])\n",
      "Image shape:  torch.Size([4, 1, 256, 256])\n",
      "Predictions shape:  torch.Size([4, 4, 256, 256])\n",
      "GT shape:  torch.Size([4, 1, 256, 256])\n",
      "Image shape:  torch.Size([4, 1, 256, 256])\n",
      "Predictions shape:  torch.Size([4, 4, 256, 256])\n",
      "GT shape:  torch.Size([4, 1, 256, 256])\n",
      "Image shape:  torch.Size([4, 1, 256, 256])\n",
      "Predictions shape:  torch.Size([4, 4, 256, 256])\n",
      "GT shape:  torch.Size([4, 1, 256, 256])\n",
      "Image shape:  torch.Size([4, 1, 256, 256])\n",
      "Predictions shape:  torch.Size([4, 4, 256, 256])\n",
      "GT shape:  torch.Size([4, 1, 256, 256])\n",
      "Image shape:  torch.Size([4, 1, 256, 256])\n",
      "Predictions shape:  torch.Size([4, 4, 256, 256])\n",
      "GT shape:  torch.Size([4, 1, 256, 256])\n",
      "Image shape:  torch.Size([4, 1, 256, 256])\n",
      "Predictions shape:  torch.Size([4, 4, 256, 256])\n",
      "GT shape:  torch.Size([4, 1, 256, 256])\n",
      "Image shape:  torch.Size([4, 1, 256, 256])\n",
      "Predictions shape:  torch.Size([4, 4, 256, 256])\n",
      "GT shape:  torch.Size([4, 1, 256, 256])\n",
      "Image shape:  torch.Size([4, 1, 256, 256])\n",
      "Predictions shape:  torch.Size([4, 4, 256, 256])\n",
      "GT shape:  torch.Size([4, 1, 256, 256])\n",
      "Image shape:  torch.Size([4, 1, 256, 256])\n",
      "Predictions shape:  torch.Size([4, 4, 256, 256])\n",
      "GT shape:  torch.Size([4, 1, 256, 256])\n",
      "Image shape:  torch.Size([2, 1, 256, 256])\n",
      "Predictions shape:  torch.Size([2, 4, 256, 256])\n",
      "GT shape:  torch.Size([2, 1, 256, 256])\n",
      "Dice Score: 1.1322805661876258\n",
      "F1 Score: 1.6536682187579572\n",
      "Precision: 0.8164518107660115\n",
      "Recall: -75.963383436203\n",
      "IoU: -6.937036756426096\n"
     ]
    }
   ],
   "source": [
    "net = UNet(4)\n",
    "epoch_to_load = 95\n",
    "\n",
    "net.load_state_dict(torch.load(f\"./models/TESTSTUDENT/AvecPseudo{epoch_to_load}_Epoch\"))\n",
    "\n",
    "DiceScore = 0.0\n",
    "F1Score = 0.0\n",
    "Precision = 0.0\n",
    "\n",
    "Recall = 0.0\n",
    "IoU = 0.0\n",
    "for idx, data in enumerate(val_loader):\n",
    "    images, labels, img_names = data\n",
    "\n",
    "    labels = utils.to_var(labels).to(device)\n",
    "    images = utils.to_var(images).to(device)\n",
    "\n",
    "    print('Image shape: ', images.shape)\n",
    "    net_predictions = net(images)\n",
    "    print('Predictions shape: ', net_predictions.shape)\n",
    "    print('GT shape: ', labels.shape)\n",
    "    segmentation_classes = utils.getTargetSegmentation(labels)\n",
    "    try :\n",
    "        DiceScore += utils.compute_dsc(net_predictions, labels) \n",
    "    except NameError:\n",
    "        DiceScore = utils.compute_dsc(net_predictions, labels)\n",
    "\n",
    "    # other metrics \n",
    "    try : \n",
    "        F1Score += compute_f1(net_predictions, labels)\n",
    "    except NameError:\n",
    "        F1Score = compute_f1(net_predictions, labels)\n",
    "\n",
    "    try :\n",
    "        Precision += compute_precision(net_predictions, labels)\n",
    "    except NameError:\n",
    "        Precision = compute_precision(net_predictions, labels)\n",
    "\n",
    "    try :\n",
    "        Recall += compute_recall(net_predictions, labels)\n",
    "    except NameError:\n",
    "        Recall = compute_recall(net_predictions, labels)\n",
    "\n",
    "    try :\n",
    "        IoU += compute_iou(net_predictions, labels)\n",
    "    except NameError:\n",
    "        IoU = compute_iou(net_predictions, labels)\n",
    "\n",
    "print('Dice Score:', DiceScore)\n",
    "print('F1 Score:', F1Score)\n",
    "print('Precision:', Precision)\n",
    "print('Recall:', Recall)\n",
    "print('IoU:', IoU)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f8ea2214-9051-45e5-9c6f-e099ff29134b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #test \n",
    "# import torch\n",
    "# tensor = [[[0.1, 0.2, 0.3, 0.3, 0.1],\n",
    "#          [0.4, 0.0, 0.3, 0.3, 0.4],\n",
    "#          [0.2, 0.2, 0.2, 0.1, 0.4]],\n",
    "          \n",
    "#            [[0.2, 0.1, 0.1, 0.1, 0.1],\n",
    "#           [0.1, 0.1, 0.1, 0.2, 0.1],\n",
    "#           [0.1, 0.2, 0.1, 0.0, 0.2]],\n",
    "\n",
    "#           [[0.2, 0.2, 0.1, 0.1, 0.2],\n",
    "#           [0.1, 0.1, 0.3, 0.2, 0.3],\n",
    "#           [0.6, 0.2, 0.4, 0.5, 0.1]],\n",
    "\n",
    "#           [[0.1, 0.3, 0.1, 0.2, 0.2],\n",
    "#           [0.0, 0.7, 0.3, 0.2, 0.2],\n",
    "#           [0.0, 0.3, 0.2, 0.2, 0.1]],\n",
    "\n",
    "\n",
    "#           [[0.4, 0.2, 0.4, 0.3, 0.4],\n",
    "#           [0.4, 0.1, 0.0, 0.1, 0.0],\n",
    "#           [0.1, 0.1, 0.1, 0.2, 0.2]]]\n",
    "\n",
    "# teacher_probs = torch.tensor(tensor)\n",
    "# max_probs, _ = teacher_probs.max(dim=0)\n",
    "# print(max_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0046d5cc-d803-4f49-8842-c2b9feb6230d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Poetry (mti865_projet)",
   "language": "python",
   "name": "mti865_projet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
