{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b07cf2f-b81d-43ef-907a-c49fed2d95ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "from progressBar import printProgressBar\n",
    "\n",
    "import medicalDataLoader\n",
    "import argparse\n",
    "import utils\n",
    "from utils import inferenceTeacher\n",
    "\n",
    "\n",
    "from UNet_Base import *\n",
    "import random\n",
    "import torch\n",
    "import pdb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e976350-3fd5-4406-8511-86a06a9b4494",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fedb7747-3728-42ee-a895-d17dccae4fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!poetry shell\n",
    "#!poetry run tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54c80878",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = (\"background\", \"1–tbd\", \"2–tbd\", \"3–tbd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7464cf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspired by https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 48))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            classes[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            classes[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c636584b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coefficient(prediction, target, epsilon=1e-07): #compares this prediction model to validation model \n",
    "    prediction_copy = prediction.clone()\n",
    "\n",
    "    prediction_copy[prediction_copy < 0] = 0\n",
    "    prediction_copy[prediction_copy > 0] = 1\n",
    "\n",
    "    intersection = abs(torch.sum(prediction_copy * target))\n",
    "    union = abs(torch.sum(prediction_copy) + torch.sum(target))\n",
    "    dice = (2. * intersection + epsilon) / (union + epsilon)\n",
    "    \n",
    "    return dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d007e633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "batch_size = 8 #nb images processed at same time during training\n",
    "batch_size_val = 4 #nb images processed at same time during validation \n",
    "lr =  0.01   # Learning Rate\n",
    "total_epochs = 50  # Number of epochs (how many times the algorithm passes through training data)\n",
    "num_classes = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "789b9179-ead1-49f6-b00e-44ee5ddbcf5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Set device depending on the availability of GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.mps.is_available():  # Apple M-series of chips\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3566dc5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dataset: ./data/ \n"
     ]
    }
   ],
   "source": [
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "mask_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Define dataloaders\n",
    "root_dir = './data/'\n",
    "print(' Dataset: {} '.format(root_dir))\n",
    "\n",
    "train_set_full = medicalDataLoader.MedicalImageDataset('train',\n",
    "                                                    root_dir,\n",
    "                                                    transform=transform,\n",
    "                                                    mask_transform=mask_transform,\n",
    "                                                    augment=False,\n",
    "                                                    equalize=False)\n",
    "\n",
    "train_loader_full = DataLoader(train_set_full,\n",
    "                            batch_size=batch_size,\n",
    "                            worker_init_fn=np.random.seed(0),\n",
    "                            num_workers=0,\n",
    "                            shuffle=True)\n",
    "\n",
    "selftrain_set_full = medicalDataLoader.MedicalImageDataset('selfTrain',\n",
    "                                                    root_dir,\n",
    "                                                    transform=transform,\n",
    "                                                    mask_transform=None,\n",
    "                                                    augment=False,\n",
    "                                                    equalize=False) #no transformation for now\n",
    "\n",
    "\n",
    "selftrain_loader_full = DataLoader(selftrain_set_full,\n",
    "                            batch_size=batch_size,\n",
    "                            worker_init_fn=np.random.seed(0),\n",
    "                            num_workers=0,\n",
    "                            shuffle=True)\n",
    "\n",
    "\n",
    "val_set = medicalDataLoader.MedicalImageDataset('val',\n",
    "                                                root_dir,\n",
    "                                                transform=transform,\n",
    "                                                mask_transform=mask_transform,\n",
    "                                                equalize=False)\n",
    "\n",
    "val_loader = DataLoader(val_set,\n",
    "                        batch_size=batch_size_val,\n",
    "                        worker_init_fn=np.random.seed(0),\n",
    "                        num_workers=0,\n",
    "                        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c2f9173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch dimensions:  torch.Size([8, 1, 256, 256])\n",
      "Mask batch dimensions:  torch.Size([8, 1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "for i, sample in enumerate(train_loader_full):\n",
    "    images, masks, _ = sample\n",
    "    print('Image batch dimensions: ', images.size()) #[batch_size, channels, height, width]\n",
    "    print('Mask batch dimensions: ', masks.size())\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20ac4eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runTraining(writer: SummaryWriter):\n",
    "    print(\"-\" * 40)\n",
    "    print(\"~~~~~~~~  Starting the training... ~~~~~~\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    print(\"~~~~~~~~~~~ Creating the UNet model ~~~~~~~~~~\")\n",
    "    modelName = \"Test_Model\"\n",
    "    print(\" Model Name: {}\".format(modelName))\n",
    "\n",
    "    ## CREATION OF YOUR MODEL\n",
    "    teacherNet = UNet(num_classes).to(device)\n",
    "\n",
    "    print(\n",
    "        \"Total params: {0:,}\".format(\n",
    "            sum(p.numel() for p in teacherNet.parameters() if p.requires_grad)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # DEFINE YOUR OUTPUT COMPONENTS (e.g., SOFTMAX, LOSS FUNCTION, ETC)\n",
    "    softMax = torch.nn.Softmax(dim=1)\n",
    "    CE_loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # # PUT EVERYTHING IN GPU RESOURCES\n",
    "    # if torch.cuda.is_available():\n",
    "    #     teacherNet.cuda()\n",
    "    #     softMax.cuda()\n",
    "    #     CE_loss.cuda()\n",
    "\n",
    "    ## DEFINE YOUR OPTIMIZER\n",
    "    optimizer = torch.optim.Adam(teacherNet.parameters(), lr=lr) #optimizer used (momentum +SGD)\n",
    "\n",
    "    ### To save statistics ####\n",
    "    train_losses = []\n",
    "    train_dc_losses = []\n",
    "    val_losses = []\n",
    "    val_dc_losses = []\n",
    "\n",
    "    best_loss_val = 1000\n",
    "\n",
    "    directory = \"Results/Statistics/\" + modelName\n",
    "\n",
    "    print(\"~~~~~~~~~~~ Starting the training ~~~~~~~~~~\")\n",
    "    if os.path.exists(directory) == False:\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    ## START THE TRAINING\n",
    "\n",
    "    ## FOR EACH EPOCH\n",
    "    for epoch in range(total_epochs):\n",
    "        teacherNet.train()\n",
    "\n",
    "        num_batches = len(train_loader_full) #26 batches of 8 images\n",
    "        print(\"Number of batches: \", num_batches)\n",
    "\n",
    "        running_train_loss = 0\n",
    "        running_dice_loss = 0\n",
    "\n",
    "        # Training loop\n",
    "        for idx, data in enumerate(train_loader_full): #idx : current batch number, data : images in that batch\n",
    "            ### Set to zero all the gradients\n",
    "            teacherNet.zero_grad()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            ## GET IMAGES, LABELS and IMG NAMES\n",
    "            images, labels, img_names = data #images with the corresponding label \n",
    "\n",
    "            ### From numpy to torch variables\n",
    "            labels = utils.to_var(labels).to(device)\n",
    "            images = utils.to_var(images).to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            teacherNet_predictions = teacherNet(images) #go through unet with images and get predictions (probabilities tensor)\n",
    "            #tensor of tables of predicted probabilities\n",
    "            \n",
    "\n",
    "            # Get the segmentation classes\n",
    "            segmentation_classes = utils.getTargetSegmentation(labels) #tensor of tables of 0(background), 1(1-tbd), 2(2-tbd), 3(3-tbd)\n",
    "\n",
    "            # Compute the loss\n",
    "            loss = CE_loss(teacherNet_predictions, segmentation_classes) #compare results and real segmentation\n",
    "            running_train_loss += loss.item()\n",
    "            # dice_loss = dice_coefficient(teacherNet_predictions, labels)\n",
    "            dice_loss = utils.compute_dsc(teacherNet_predictions, labels)\n",
    "            running_dice_loss += dice_loss\n",
    "\n",
    "            # Backprop\n",
    "            loss.backward() #calculates gradients from loss\n",
    "            optimizer.step() #use gradients just calculated to update weights of model \n",
    "\n",
    "            # Add the loss to the tensorboard every 5 batches\n",
    "            # if idx % 10 == 0:\n",
    "            #     writer.add_scalar(\n",
    "            #         \"Loss/train\", running_train_loss / (idx + 1), epoch * len(train_loader_full) + idx\n",
    "            #     )\n",
    "            #     writer.add_scalar(\n",
    "            #         \"Dice/train\", running_dice_loss / (idx + 1), epoch * len(train_loader_full) + idx\n",
    "            #     )\n",
    "\n",
    "            if idx % 100 == 0:\n",
    "                # Also add visualizations of the images\n",
    "                probs = torch.softmax(teacherNet_predictions, dim=1)\n",
    "                \n",
    "                \n",
    "                y_pred = torch.argmax(probs, dim=1)\n",
    "                print(\"Images min/max:\", images.min().item(), images.max().item())\n",
    "                print(\"Predictions min/max:\", y_pred.min().item(), y_pred.max().item())\n",
    "                #print(y_pred)\n",
    "                \n",
    "                # writer.add_figure('predictions vs. actuals',\n",
    "                #             utils.plot_net_predictions(images, labels, y_pred, batch_size),\n",
    "                #             global_step=epoch * len(train_loader_full) + idx)\n",
    "\n",
    "            # THIS IS JUST TO VISUALIZE THE TRAINING\n",
    "            printProgressBar(\n",
    "                idx + 1,\n",
    "                num_batches,\n",
    "                prefix=\"[Training] Epoch: {} \".format(epoch),\n",
    "                length=15,\n",
    "                suffix=\" Loss: {:.4f}, \".format(running_train_loss / (idx + 1)),\n",
    "            )\n",
    "\n",
    "        train_loss = running_train_loss / num_batches\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        train_dc_loss = running_dice_loss / num_batches\n",
    "        train_dc_losses.append(train_dc_loss)\n",
    "\n",
    "        teacherNet.eval()\n",
    "        val_running_loss = 0\n",
    "        val_running_dc = 0\n",
    "\n",
    "        # Validation loop\n",
    "        with torch.no_grad(): #validation made every time one epoch has finished being processed\n",
    "            for idx, data in enumerate(val_loader):\n",
    "                images, labels, img_names = data\n",
    "\n",
    "                labels = utils.to_var(labels).to(device)\n",
    "                images = utils.to_var(images).to(device)\n",
    "\n",
    "                teacherNet_predictions = teacherNet(images) #we try validation set in our model \n",
    "\n",
    "                segmentation_classes = utils.getTargetSegmentation(labels) #what should be predicted in a tensor\n",
    "\n",
    "                loss = CE_loss(teacherNet_predictions, segmentation_classes)\n",
    "                val_running_loss += loss.item()\n",
    "\n",
    "                # dice_loss = dice_coefficient(teacherNet_predictions, labels)\n",
    "                dice_loss = utils.compute_dsc(teacherNet_predictions, labels)\n",
    "                val_running_dc += dice_loss\n",
    "\n",
    "                # if idx % 10 == 0:\n",
    "                #     writer.add_scalar(\n",
    "                #         \"Loss/val\",\n",
    "                #         val_running_loss / (idx + 1),\n",
    "                #         epoch * len(val_loader) + idx,\n",
    "                #     )\n",
    "                #     writer.add_scalar(\n",
    "                #         \"Dice/val\",\n",
    "                #         val_running_dc / (idx + 1),\n",
    "                #         epoch * len(val_loader) + idx,\n",
    "                #     )\n",
    "\n",
    "                printProgressBar(\n",
    "                    idx + 1,\n",
    "                    len(val_loader),\n",
    "                    prefix=\"[Validation] Epoch: {} \".format(epoch),\n",
    "                    length=15,\n",
    "                    suffix=\" Loss: {:.4f}, \".format(val_running_loss / (idx + 1)),\n",
    "                )\n",
    "\n",
    "        val_loss = val_running_loss / len(val_loader)\n",
    "        val_losses.append(val_loss)\n",
    "        dc_loss = val_running_dc / len(val_loader)\n",
    "        val_dc_losses.append(dc_loss)\n",
    "\n",
    "        # Check if model performed best and save it if true\n",
    "        if val_loss < best_loss_val:\n",
    "            best_loss_val = val_loss\n",
    "            if not os.path.exists(\"./models/\" + modelName):\n",
    "                os.makedirs(\"./models/\" + modelName)\n",
    "            torch.save(\n",
    "                teacherNet.state_dict(), \"./models/\" + modelName + \"/\" + str(epoch) + \"_Epoch\"\n",
    "            )\n",
    "\n",
    "        printProgressBar(\n",
    "            num_batches,\n",
    "            num_batches,\n",
    "            done=\"[Epoch: {}, TrainLoss: {:.4f}, TrainDice: {:.4f}, ValLoss: {:.4f}\".format(\n",
    "                epoch, train_loss, train_dc_loss, val_loss\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        np.save(os.path.join(directory, \"Losses.npy\"), train_losses)\n",
    "    writer.flush()  # Flush the writer to ensure that all the data is written to disk\n",
    "    return teacherNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20c64dea-42e1-406b-8da3-c004b9d7cf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selfTrain with unlabeled images\n",
    "def runSelfTraining(teacherModel, writer: SummaryWriter): #garder writer: SummaryWriter ? \n",
    "    teacherModel.eval()\n",
    "    print(\"-\" * 40)\n",
    "    print(\"~~~~~~~~  Starting the self training... ~~~~~~\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    num_images = len(selftrain_loader_full.dataset)\n",
    "    print(\"num images fourni : \", num_images)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, data in enumerate(selftrain_loader_full):\n",
    "            images, img_names = data\n",
    "            \n",
    "            images = utils.to_var(images).to(device)\n",
    "\n",
    "            studentNet_predictions = teacherModel(images)\n",
    "            \n",
    "\n",
    "\n",
    "            if idx % 100 == 0:\n",
    "                # Also add visualizations of the images\n",
    "                probs = torch.softmax(studentNet_predictions, dim=1)\n",
    "                y_pred = torch.argmax(probs, dim=1)\n",
    "\n",
    "                \n",
    "                \n",
    "                writer.add_figure('predictions on unlabeled',\n",
    "                            utils.plot_net_predictions_without_ground_truth(images, y_pred, img_names, batch_size)                            )\n",
    "    print(\"hellooo\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f81713-4c18-4dd3-bc72-35dd8f30a339",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up Tensorboard writer\n",
    "writer = SummaryWriter()\n",
    "#training du teacher\n",
    "teacherNet = runTraining(writer)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a71d581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import inference\n",
    "\n",
    "epoch_to_load = 41 #num du modele à charger\n",
    "model = UNet(4)\n",
    "model.load_state_dict(torch.load(f\"./models/Test_Model/{epoch_to_load}_Epoch\")) #charge le fichiers des poids\n",
    "#inf_losses = inference(model, val_loader, \"Student\", epoch_to_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a7c8651-2031-440c-842f-0ab1b03f7d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb images à traiter  126\n",
      "[Inference] Segmentation Done !                                                                              \n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter()\n",
    "\n",
    "#predictions on unlabeled images\n",
    "#teacherNet = UNet(num_classes).to(device)\n",
    "# epoch = 41\n",
    "# checkpoint_path = \"./models/\" + \"Test_Model\" + \"/\" + str(epoch) + \"_Epoch\"\n",
    "#teacherNet.load_state_dict(torch.load(checkpoint_path))\n",
    "# model.eval()\n",
    "# runSelfTraining(model, writer)\n",
    "\n",
    "\n",
    "epoch_to_load = 41 #num du modele à charger\n",
    "model = UNet(4)\n",
    "inferenceTeacher(model, selftrain_loader_full, 'TeacherUnlabeledPredictions', epoch_to_load, device)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a88d3b9-fd40-4d8a-9dad-d68b1b2bb101",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Poetry (mti865_projet)",
   "language": "python",
   "name": "mti865_projet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
