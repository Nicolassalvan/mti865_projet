{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c6e025f",
   "metadata": {},
   "source": [
    "# Project MTI865 - Heart segmentation using UNet \n",
    "\n",
    "---\n",
    "\n",
    "# Model training - Transformation consistency with L2 penality \n",
    "\n",
    "$$\n",
    "\\mathcal{L} = \\frac{1}{n_{l}} \\mathcal{L}_{CE} + \\frac{\\alpha_{TC}}{n_{u}} \\mathcal{L}_{TC-MSE}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31b841f",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739d9ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding .. to path \n",
    "import sys \n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b07cf2f-b81d-43ef-907a-c49fed2d95ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.transforms import v2\n",
    "from progressBar import printProgressBar\n",
    "\n",
    "import medicalDataLoader\n",
    "import argparse\n",
    "import utils\n",
    "\n",
    "from UNet_Base import *\n",
    "import random\n",
    "import torch\n",
    "import pdb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e976350-3fd5-4406-8511-86a06a9b4494",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6136411",
   "metadata": {},
   "source": [
    "## Loading data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19e19f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "batch_size_val = 4\n",
    "batch_size_unlabel = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37a65765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image and mask transformations\n",
    "transform = v2.Compose([\n",
    "    v2.ToTensor()\n",
    "])\n",
    "\n",
    "mask_transform = v2.Compose([\n",
    "    v2.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "029239f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Fonction de regroupement pour le DataLoader.\n",
    "\n",
    "    Args:\n",
    "    -----\n",
    "        batch (list): Liste de tuples (image, masque, chemin de l'image).\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "        imgs_tensor (torch.Tensor): Batch d'images.\n",
    "        masks_tensor (torch.Tensor): Batch de masques.\n",
    "        img_paths (list): Liste des chemins des images.\n",
    "    \"\"\"\n",
    "    imgs = []\n",
    "    masks = []\n",
    "    img_paths = []\n",
    "\n",
    "    for item in batch:\n",
    "        img, mask, img_path = item[0], item[1], item[2]\n",
    "        imgs.append(img)\n",
    "        img_paths.append(img_path)\n",
    "        \n",
    "        # Si le masque est None, ajouter un tenseur de zéros correspondant à sa taille\n",
    "        if mask is not None:\n",
    "            masks.append(mask)\n",
    "        else:\n",
    "            masks.append(torch.zeros_like(img[0, :, :]))  # Même taille que le canal de l'image (assumant CxHxW)\n",
    "\n",
    "    # Stack les images et les masques\n",
    "    imgs_tensor = torch.stack(imgs)  # Tensor de forme (B, C, H, W)\n",
    "    masks_tensor = torch.stack(masks)  # Tensor de forme (B, H, W)\n",
    "\n",
    "    return imgs_tensor, masks_tensor, img_paths\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3566dc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataloaders\n",
    "root_dir = '../data/'\n",
    "print(' Dataset: {} '.format(root_dir))\n",
    "\n",
    "supervised_set = medicalDataLoader.MedicalImageDataset(\n",
    "    'train',\n",
    "    root_dir,\n",
    "    transform=transform,\n",
    "    mask_transform=mask_transform,\n",
    "    augment=True,\n",
    "    equalize=False)\n",
    "\n",
    "\n",
    "supervised_loader = DataLoader(\n",
    "    supervised_set,\n",
    "    batch_size=batch_size,\n",
    "    worker_init_fn=np.random.seed(0),\n",
    "    num_workers=0,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "val_set = medicalDataLoader.MedicalImageDataset(\n",
    "    'val',  \n",
    "    root_dir,\n",
    "    transform=transform,\n",
    "    mask_transform=mask_transform,\n",
    "    equalize=False)\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_set,\n",
    "    batch_size=batch_size_val,\n",
    "    worker_init_fn=np.random.seed(0),\n",
    "    num_workers=0,\n",
    "    shuffle=False)\n",
    "\n",
    "unsupervised_set = medicalDataLoader.MedicalImageDataset(\n",
    "    'train-unlabelled',\n",
    "    root_dir,\n",
    "    transform=transform,\n",
    "    mask_transform=mask_transform,\n",
    "    augment=False,\n",
    "    equalize=False)\n",
    "\n",
    "unsupervised_loader = DataLoader(\n",
    "    unsupervised_set,\n",
    "    batch_size=batch_size_unlabel,\n",
    "    worker_init_fn=np.random.seed(0),\n",
    "    num_workers=0,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "\n",
    "print('Train set: ', len(supervised_set))\n",
    "print('Validation set: ', len(val_set))\n",
    "\n",
    "n_train_label = len(supervised_set)\n",
    "n_train_unlabel = len(unsupervised_set)\n",
    "\n",
    "# shape of the image a  nd mask\n",
    "img, mask, _ = supervised_set[0]\n",
    "print('Image shape: ', img.shape)\n",
    "print('Mask shape: ', mask.shape)\n",
    "print('Number of batches: ', len(supervised_loader))\n",
    "\n",
    "img, mask, _ = val_set[0]\n",
    "print('Image shape: ', img.shape)\n",
    "print('Mask shape: ', mask.shape)\n",
    "print('Number of batches: ', len(val_loader))\n",
    "\n",
    "img, _, __ = unsupervised_set[0]\n",
    "print('Image shape: ', img.shape)\n",
    "print('Mask shape: ', mask.shape)\n",
    "print('Number of batches: ', len(unsupervised_loader))\n",
    "\n",
    "\n",
    "# print('First of the supervised set')\n",
    "# img, mask, path_tuple = supervised_set[0]\n",
    "# print(img)\n",
    "# print(mask)\n",
    "# print(path_tuple)\n",
    "\n",
    "# print('First of the unsupervised set')\n",
    "# img, mask, path_tuple = unsupervised_set[0]\n",
    "# print(img)\n",
    "# print(mask)\n",
    "# print(path_tuple)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef7c545",
   "metadata": {},
   "source": [
    "## Model using both labeled and unlabeled data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db31076c",
   "metadata": {},
   "source": [
    "### Hyperparameters of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "369d8a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters \n",
    "lr =  0.001    # Learning Rate\n",
    "total_epochs = 150  # Number of epochs\n",
    "alpha_TC = 0.1 # Alpha parameter for the consistency loss term \n",
    "weight_decay = 1e-5  # Weight decay\n",
    "modelName = f\"TransformationConsistencyL2Model-{total_epochs}epochs{lr}lr{alpha_TC}alphaTC{weight_decay}wd\"\n",
    "\n",
    "\n",
    "# save parameters\n",
    "param_dict = {\n",
    "    'lr': lr,\n",
    "    'total_epochs': total_epochs,\n",
    "    'alpha_TC': alpha_TC,\n",
    "    'weight_decay': weight_decay,\n",
    "    'batch_size': batch_size,\n",
    "    'batch_size_val': batch_size_val,\n",
    "    'batch_size_unlabel': batch_size_unlabel,\n",
    "    'consistency_criterion': 'L2'\n",
    "}\n",
    "model_dir = f\"models/{modelName}\"\n",
    "# write params in a file \n",
    "\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "with open(f\"{model_dir}/params.txt\", 'w') as f:\n",
    "    print(param_dict, file=f)\n",
    "\n",
    "print(f\"Parameters saved to {model_dir}/params.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c94cc8",
   "metadata": {},
   "source": [
    "### Example of loop\n",
    "\n",
    "In this exemple, we modified the structure of the code to use iterators instead. In each epoch, we see the whole range of supervised data and one time each unsupervised data. We can also try to see once the supervised data and to see random images of unsupervised data, which could mean we would not be able to see it all. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e05de59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# supervised_iter = iter(supervised_loader)\n",
    "# unsupervised_iter = iter(unsupervised_loader)\n",
    "\n",
    "# for epoch in range(total_epochs):\n",
    "#     num_batches = max(len(supervised_loader), len(unsupervised_loader))\n",
    "#     for idx in range(num_batches):\n",
    "#         try :\n",
    "#             supervised_data = next(supervised_iter)\n",
    "#         except StopIteration:\n",
    "#             supervised_iter = iter(supervised_loader)\n",
    "#             supervised_data= next(supervised_iter)\n",
    "\n",
    "#         print(supervised_data)\n",
    "#         print('Supervised batch')   \n",
    "#         try :\n",
    "#             unsupervised_data = next(unsupervised_iter)\n",
    "#         except StopIteration:\n",
    "#             unsupervised_iter = iter(unsupervised_loader)\n",
    "#             unsupervised_data = next(unsupervised_iter)\n",
    "        \n",
    "#         print(unsupervised_data)\n",
    "#         print('Unsupervised batch')\n",
    "#         break\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cf0784",
   "metadata": {},
   "source": [
    "### Transformation consistency regularisation\n",
    "\n",
    "The transformation consistency consists in the principle that transformation T suchs as rotation and flipping should affect the mask f(y) only by the same rotation, which means that f and T should be symetrical. In this implementation, we used the 2-norm to measure the difference, and we included it in the optimisation problem.  $\\mathcal{L}_{TC}(y_u) = \\|f(T(y_u))-T(F(y))\\|_2$. \n",
    "Il est aussi possible de faire une régularisation avec la CE : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16443fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "class ConsistencyRegularization(nn.Module):\n",
    "    def __init__(self, transformation_fn, loss_fn=nn.MSELoss()):\n",
    "        \"\"\"\n",
    "        Régularisation basée sur la consistance à la transformation.\n",
    "\n",
    "        Args:\n",
    "        -----\n",
    "            transformation_fn (callable): Fonction d'augmentation/transformation appliquée aux images.\n",
    "            loss_fn (callable): Fonction de perte utilisée pour comparer les prédictions (par défaut MSELoss). Aussi possible d'utiliser \n",
    "                                nn.KLDivLoss ou nn.BCELoss.\n",
    "        \"\"\"\n",
    "        super(ConsistencyRegularization, self).__init__()\n",
    "        self.transformation_fn = transformation_fn\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def forward(self, model, images):\n",
    "        \"\"\"\n",
    "        Calcule la perte de consistance.\n",
    "\n",
    "        Args:\n",
    "            model (torch.nn.Module): Le modèle de segmentation.\n",
    "            images (torch.Tensor): Batch d'images d'entrée.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: La perte de consistance.\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            # Prédictions de base\n",
    "            original_predictions = F.softmax(model(images), dim=1)\n",
    "\n",
    "        # Augmenter les images\n",
    "        augmented_images = self.transformation_fn(images)\n",
    "\n",
    "        # Prédictions pour les images augmentées\n",
    "        augmented_predictions = F.softmax(model(augmented_images), dim=1)\n",
    "\n",
    "        # Calcul de la perte de consistance\n",
    "        consistency_loss = self.loss_fn(original_predictions, augmented_predictions)\n",
    "\n",
    "        return consistency_loss\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "657ddeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_transformation_fn(images):\n",
    "  \n",
    "    # Random horizontal flip\n",
    "    if np.random.random() > 0.5:\n",
    "        images = torch.flip(images, dims=[2])\n",
    "    # Random vertical flip\n",
    "    if np.random.random() > 0.5:\n",
    "        images = torch.flip(images, dims=[3])\n",
    "    # Random rotation of random angle\n",
    "    if np.random.random() > 0.5:\n",
    "        angle = np.random.randint(0, 360)\n",
    "        images = torch.rot90(images, k=angle//90, dims=[2, 3])\n",
    "    return images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f5c928",
   "metadata": {},
   "source": [
    "### Training of the model \n",
    "\n",
    "At each epoch, the model sees once every exemple of unlabeled data, and sees several time the labeled data. We first train it with the labeled data, and then we train it on the unsupervised data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186cae12",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(\"~~~~~~~~  Starting the training... ~~~~~~\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "num_classes = 4\n",
    "\n",
    "# Set device depending on the availability of GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "# elif torch.mps.is_available():  # Apple M-series of chips\n",
    "#     device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "print(\"~~~~~~~~~~~ Creating the UNet model ~~~~~~~~~~\")\n",
    "print(\" Model Name: {}\".format(modelName))\n",
    "\n",
    "## CREATION OF YOUR MODEL\n",
    "net = UNet(num_classes).to(device)\n",
    "\n",
    "print(\n",
    "    \"Total params: {0:,}\".format(\n",
    "        sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "    )\n",
    ")\n",
    "\n",
    "# DEFINE YOUR OUTPUT COMPONENTS (e.g., SOFTMAX, LOSS FUNCTION, ETC)\n",
    "softMax = torch.nn.Softmax(dim=1)\n",
    "CE_loss = torch.nn.CrossEntropyLoss()\n",
    "consistency_regularizer = ConsistencyRegularization(transformation_fn=random_transformation_fn)\n",
    "\n",
    "\n",
    "## PUT EVERYTHING IN GPU RESOURCES\n",
    "# if torch.cuda.is_available():\n",
    "#     net.cuda()\n",
    "#     softMax.cuda()\n",
    "#     CE_loss.cuda()\n",
    "\n",
    "## DEFINE YOUR OPTIMIZER\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "### To save statistics ####\n",
    "train_losses = []\n",
    "train_dc_losses = []\n",
    "val_losses = []\n",
    "val_dc_losses = []\n",
    "\n",
    "best_loss_val = 1000\n",
    "\n",
    "directory = \"Results/Statistics/\" + modelName\n",
    "\n",
    "print(\"~~~~~~~~~~~ Starting the training ~~~~~~~~~~\")\n",
    "if os.path.exists(directory) == False:\n",
    "    os.makedirs(directory)\n",
    "\n",
    "## START THE TRAINING\n",
    "\n",
    "## FOR EACH EPOCH\n",
    "for epoch in range(total_epochs):\n",
    "    net.train()\n",
    "    supervised_iter = iter(supervised_loader)\n",
    "    unsupervised_iter = iter(unsupervised_loader)\n",
    "    \n",
    "    num_batches = max(len(supervised_loader), len(unsupervised_loader))\n",
    "    print(\"Number of batches: \", num_batches)\n",
    "\n",
    "    running_train_loss = 0\n",
    "    running_dice_loss = 0\n",
    "\n",
    "    # Training loop\n",
    "    for idx in range(num_batches):\n",
    "        ### SUPERVISED BATCH\n",
    "        try :\n",
    "            supervised_data = next(supervised_iter)\n",
    "        except StopIteration:\n",
    "            supervised_iter = iter(supervised_loader)\n",
    "            supervised_data = next(supervised_iter)\n",
    "\n",
    "        ### Set to zero all the gradients\n",
    "        net.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        ## GET IMAGES, LABELS and IMG NAMES\n",
    "        images, labels, img_names = supervised_data\n",
    "\n",
    "        ### From numpy to torch variables\n",
    "        labels = utils.to_var(labels).to(device)\n",
    "        images = utils.to_var(images).to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        net_predictions = net(images)\n",
    "\n",
    "        # Get the segmentation classes\n",
    "        segmentation_classes = utils.getTargetSegmentation(labels)\n",
    "\n",
    "        # Compute the loss\n",
    "        ce_loss = CE_loss(net_predictions, segmentation_classes) / n_train_label\n",
    "        running_train_loss += ce_loss.item()\n",
    "        # dice_loss = dice_coefficient(net_predictions, labels)\n",
    "        dice_loss = utils.compute_dsc(net_predictions, labels)\n",
    "        running_dice_loss += dice_loss\n",
    "\n",
    "        # Backprop\n",
    "        ce_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        ### UNSUPERVISED BATCH\n",
    "        try :\n",
    "            unsupervised_data = next(unsupervised_iter)\n",
    "        except StopIteration:\n",
    "            unsupervised_iter = iter(unsupervised_loader)\n",
    "            unsupervised_data = next(unsupervised_iter)\n",
    "        \n",
    "        unsupervised_images, _, _ = unsupervised_data\n",
    "        unsupervised_images = utils.to_var(unsupervised_images).to(device)\n",
    "\n",
    "        net.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        consistency_loss = consistency_regularizer(net, unsupervised_images) / n_train_unlabel\n",
    "        (alpha_TC * consistency_loss).backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_train_loss += consistency_loss.item()\n",
    "        running_dice_loss += 0\n",
    "\n",
    "        # Add the loss to the tensorboard every 5 batches\n",
    "        if idx % 10 == 0:\n",
    "            writer.add_scalar(\n",
    "                \"Loss/train\", running_train_loss / (idx + 1), epoch * len(supervised_loader) + idx\n",
    "            )\n",
    "            writer.add_scalar(\n",
    "                \"Dice/train\", running_dice_loss / (idx + 1), epoch * len(supervised_loader) + idx\n",
    "            )\n",
    "\n",
    "        if idx % 100 == 0:\n",
    "            # Also add visualizations of the images\n",
    "            probs = torch.softmax(net_predictions, dim=1)\n",
    "            y_pred = torch.argmax(probs, dim=1)\n",
    "            writer.add_figure('predictions vs. actuals',\n",
    "                        utils.plot_net_predictions(images, labels, y_pred, batch_size),\n",
    "                        global_step=epoch * len(supervised_loader) + idx)\n",
    "\n",
    "        # THIS IS JUST TO VISUALIZE THE TRAINING\n",
    "        printProgressBar(\n",
    "            idx + 1,\n",
    "            num_batches,\n",
    "            prefix=\"[Training] Epoch: {} \".format(epoch),\n",
    "            length=15,\n",
    "            suffix=\" Loss: {:.4f}, \".format(running_train_loss / (idx + 1)),\n",
    "        )\n",
    "\n",
    "    train_loss = running_train_loss / num_batches\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    train_dc_loss = running_dice_loss / num_batches\n",
    "    train_dc_losses.append(train_dc_loss)\n",
    "\n",
    "    net.eval()\n",
    "    val_running_loss = 0\n",
    "    val_running_dc = 0\n",
    "\n",
    "    # Validation loop\n",
    "    with torch.no_grad():\n",
    "        for idx, data in enumerate(val_loader):\n",
    "            images, labels, img_names = data\n",
    "\n",
    "            labels = utils.to_var(labels).to(device)\n",
    "            images = utils.to_var(images).to(device)\n",
    "\n",
    "            net_predictions = net(images)\n",
    "\n",
    "            segmentation_classes = utils.getTargetSegmentation(labels)\n",
    "\n",
    "            loss = CE_loss(net_predictions, segmentation_classes) \n",
    "            val_running_loss += loss.item()\n",
    "\n",
    "            # dice_loss = dice_coefficient(net_predictions, labels)\n",
    "            dice_loss = utils.compute_dsc(net_predictions, labels)\n",
    "            val_running_dc += dice_loss\n",
    "\n",
    "            if idx % 10 == 0:\n",
    "                writer.add_scalar(\n",
    "                    \"Loss/val\",\n",
    "                    val_running_loss / (idx + 1),\n",
    "                    epoch * len(val_loader) + idx,\n",
    "                )\n",
    "                writer.add_scalar(\n",
    "                    \"Dice/val\",\n",
    "                    val_running_dc / (idx + 1),\n",
    "                    epoch * len(val_loader) + idx,\n",
    "                )\n",
    "\n",
    "            printProgressBar(\n",
    "                idx + 1,\n",
    "                len(val_loader),\n",
    "                prefix=\"[Validation] Epoch: {} \".format(epoch),\n",
    "                length=15,\n",
    "                suffix=\" Loss: {:.4f}, \".format(val_running_loss / (idx + 1)),\n",
    "            )\n",
    "\n",
    "    val_loss = val_running_loss / len(val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    dc_loss = val_running_dc / len(val_loader)\n",
    "    val_dc_losses.append(dc_loss)\n",
    "\n",
    "    # Check if model performed best and save it if true\n",
    "    if val_loss < best_loss_val:\n",
    "        best_loss_val = val_loss\n",
    "        if not os.path.exists(\"./models/\" + modelName):\n",
    "            os.makedirs(\"./models/\" + modelName)\n",
    "        torch.save(\n",
    "            net.state_dict(), \"./models/\" + modelName + \"/\" + str(epoch) + \"_Epoch\"\n",
    "        )\n",
    "\n",
    "    printProgressBar(\n",
    "        num_batches,\n",
    "        num_batches,\n",
    "        done=\"[Epoch: {}, TrainLoss: {:.4f}, TrainDice: {:.4f}, ValLoss: {:.4f}\".format(\n",
    "            epoch, train_loss, train_dc_loss, val_loss\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    np.save(os.path.join(directory, \"Losses.npy\"), train_losses)\n",
    "writer.flush()  # Flush the writer to ensure that all the data is written to disk\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
