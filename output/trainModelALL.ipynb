{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c6e025f",
   "metadata": {},
   "source": [
    "# Project MTI865 - Heart segmentation using UNet \n",
    "\n",
    "---\n",
    "\n",
    "# Model training - CE-DSC with Transformation consistency (MSE) \n",
    "\n",
    "$$\n",
    "\\mathcal{L} = \\frac{1}{n_{l}} \\left(w_{CE} \\mathcal{L}_{CE} + w_{DSC} \\mathcal{L}_{DSC} \\right)  + \\frac{\\alpha_{TC}}{n_{u}} \\mathcal{L}_{TC-MSE}\n",
    "$$\n",
    "\n",
    "PAS ENCORE IMPLEMENTÉ !!!! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31b841f",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ac7f232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding .. to path \n",
    "import sys \n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b07cf2f-b81d-43ef-907a-c49fed2d95ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.transforms import v2\n",
    "from progressBar import printProgressBar\n",
    "\n",
    "import medicalDataLoader\n",
    "import argparse\n",
    "import utils\n",
    "\n",
    "from UNet_Base import *\n",
    "import random\n",
    "import torch\n",
    "import pdb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e976350-3fd5-4406-8511-86a06a9b4494",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6136411",
   "metadata": {},
   "source": [
    "## Loading data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19e19f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "batch_size_val = 4\n",
    "batch_size_unlabel = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37a65765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image and mask transformations\n",
    "transform = v2.Compose([\n",
    "    v2.ToTensor(),\n",
    "    v2.Normalize(mean=[0.137], std=[0.1733]) # Normalisation values for the training set (mean and std) \n",
    "])\n",
    "\n",
    "mask_transform = v2.Compose([\n",
    "    v2.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "029239f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Fonction de regroupement pour le DataLoader.\n",
    "\n",
    "    Args:\n",
    "    -----\n",
    "        batch (list): Liste de tuples (image, masque, chemin de l'image).\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "        imgs_tensor (torch.Tensor): Batch d'images.\n",
    "        masks_tensor (torch.Tensor): Batch de masques.\n",
    "        img_paths (list): Liste des chemins des images.\n",
    "    \"\"\"\n",
    "    imgs = []\n",
    "    masks = []\n",
    "    img_paths = []\n",
    "\n",
    "    for item in batch:\n",
    "        img, mask, img_path = item[0], item[1], item[2]\n",
    "        imgs.append(img)\n",
    "        img_paths.append(img_path)\n",
    "        \n",
    "        # Si le masque est None, ajouter un tenseur de zéros correspondant à sa taille\n",
    "        if mask is not None:\n",
    "            masks.append(mask)\n",
    "        else:\n",
    "            masks.append(torch.zeros_like(img[0, :, :]))  # Même taille que le canal de l'image (assumant CxHxW)\n",
    "\n",
    "    # Stack les images et les masques\n",
    "    imgs_tensor = torch.stack(imgs)  # Tensor de forme (B, C, H, W)\n",
    "    masks_tensor = torch.stack(masks)  # Tensor de forme (B, H, W)\n",
    "\n",
    "    return imgs_tensor, masks_tensor, img_paths\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3566dc5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dataset: ../data/ \n",
      "Found 204 items in train\n",
      "First item:  ('../data/train\\\\Img\\\\patient006_01_1.png', '../data/train\\\\GT\\\\patient006_01_1.png')\n",
      "Found 74 items in val\n",
      "First item:  ('../data/val\\\\Img\\\\patient001_01_1.png', '../data/val\\\\GT\\\\patient001_01_1.png')\n",
      "Found 1004 items in train-unlabelled\n",
      "First item:  ('../data/train\\\\Img-Unlabeled\\\\patient007_01_1.png', None)\n",
      "Train set:  204\n",
      "Validation set:  74\n",
      "Image shape:  torch.Size([1, 256, 256])\n",
      "Mask shape:  torch.Size([1, 256, 256])\n",
      "Number of batches:  51\n",
      "Image shape:  torch.Size([1, 256, 256])\n",
      "Mask shape:  torch.Size([1, 256, 256])\n",
      "Number of batches:  19\n",
      "Image shape:  torch.Size([1, 256, 256])\n",
      "Mask shape:  torch.Size([1, 256, 256])\n",
      "Number of batches:  126\n"
     ]
    }
   ],
   "source": [
    "# Define dataloaders\n",
    "root_dir = '../data/'\n",
    "print(' Dataset: {} '.format(root_dir))\n",
    "\n",
    "supervised_set = medicalDataLoader.MedicalImageDataset(\n",
    "    'train',\n",
    "    root_dir,\n",
    "    transform=transform,\n",
    "    mask_transform=mask_transform,\n",
    "    augment=True,\n",
    "    equalize=False)\n",
    "\n",
    "\n",
    "supervised_loader = DataLoader(\n",
    "    supervised_set,\n",
    "    batch_size=batch_size,\n",
    "    worker_init_fn=np.random.seed(0),\n",
    "    num_workers=0,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "val_set = medicalDataLoader.MedicalImageDataset(\n",
    "    'val',  \n",
    "    root_dir,\n",
    "    transform=transform,\n",
    "    mask_transform=mask_transform,\n",
    "    equalize=False)\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_set,\n",
    "    batch_size=batch_size_val,\n",
    "    worker_init_fn=np.random.seed(0),\n",
    "    num_workers=0,\n",
    "    shuffle=False)\n",
    "\n",
    "unsupervised_set = medicalDataLoader.MedicalImageDataset(\n",
    "    'train-unlabelled',\n",
    "    root_dir,\n",
    "    transform=transform,\n",
    "    mask_transform=mask_transform,\n",
    "    augment=False,\n",
    "    equalize=False)\n",
    "\n",
    "unsupervised_loader = DataLoader(\n",
    "    unsupervised_set,\n",
    "    batch_size=batch_size_unlabel,\n",
    "    worker_init_fn=np.random.seed(0),\n",
    "    num_workers=0,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "\n",
    "print('Train set: ', len(supervised_set))\n",
    "print('Validation set: ', len(val_set))\n",
    "\n",
    "n_train_label = len(supervised_set)\n",
    "n_train_unlabel = len(unsupervised_set)\n",
    "\n",
    "# shape of the image a  nd mask\n",
    "img, mask, _ = supervised_set[0]\n",
    "print('Image shape: ', img.shape)\n",
    "print('Mask shape: ', mask.shape)\n",
    "print('Number of batches: ', len(supervised_loader))\n",
    "\n",
    "img, mask, _ = val_set[0]\n",
    "print('Image shape: ', img.shape)\n",
    "print('Mask shape: ', mask.shape)\n",
    "print('Number of batches: ', len(val_loader))\n",
    "\n",
    "img, _, __ = unsupervised_set[0]\n",
    "print('Image shape: ', img.shape)\n",
    "print('Mask shape: ', mask.shape)\n",
    "print('Number of batches: ', len(unsupervised_loader))\n",
    "\n",
    "\n",
    "# print('First of the supervised set')\n",
    "# img, mask, path_tuple = supervised_set[0]\n",
    "# print(img)\n",
    "# print(mask)\n",
    "# print(path_tuple)\n",
    "\n",
    "# print('First of the unsupervised set')\n",
    "# img, mask, path_tuple = unsupervised_set[0]\n",
    "# print(img)\n",
    "# print(mask)\n",
    "# print(path_tuple)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef7c545",
   "metadata": {},
   "source": [
    "## Model using both labeled and unlabeled data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db31076c",
   "metadata": {},
   "source": [
    "### Hyperparameters of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "369d8a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters saved to models/TransformationConsistencyL2Model-150epochs0.0005lr0.1alphaTC1e-05wd/params.txt\n",
      "Parameters saved to models/TransformationConsistencyL2Model-150epochs0.0005lr0.1alphaTC1e-05wd/params.txt\n"
     ]
    }
   ],
   "source": [
    "# Parameters \n",
    "lr =  0.0005    # Learning Rate\n",
    "total_epochs = 150  # Number of epochs\n",
    "weight_TC = 0.1 # Alpha parameter for the consistency loss term \n",
    "weight_decay = 1e-5  # Weight decay\n",
    "ce_loss_weight = 0.7 # Cross Entropy Loss Weight proportion\n",
    "dice_loss_weight = 0.3 # Dice Loss Weight proportion \n",
    "\n",
    "modelName = f\"TransformationConsistencyL2Model-{total_epochs}epochs{lr}lr{weight_TC}alphaTC{weight_decay}wd\"\n",
    "model_dir = f\"models/{modelName}\"\n",
    "# write params in a file \n",
    "param_dict = {\n",
    "    \"lr\": lr,\n",
    "    \"total_epochs\": total_epochs,\n",
    "    \"weight_TC\": weight_TC,\n",
    "    \"weight_decay\": weight_decay,\n",
    "    \"ce_loss_weight\": ce_loss_weight,\n",
    "    \"dice_loss_weight\": dice_loss_weight,\n",
    "    \"modelName\": modelName,\n",
    "    \"model\": \"ALL\"\n",
    "}\n",
    "\n",
    "\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "with open(f\"{model_dir}/params.txt\", 'w') as f:\n",
    "    print(param_dict, file=f)\n",
    "\n",
    "print(f\"Parameters saved to {model_dir}/params.txt\")\n",
    "\n",
    "print(f\"Parameters saved to {model_dir}/params.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cf0784",
   "metadata": {},
   "source": [
    "### Transformation consistency regularisation\n",
    "\n",
    "The transformation consistency consists in the principle that transformation T suchs as rotation and flipping should affect the mask f(y) only by the same rotation, which means that f and T should be symetrical. In this implementation, we used the 2-norm to measure the difference, and we included it in the optimisation problem.  $\\mathcal{L}_{TC}(y_u) = \\|f(T(y_u))-T(F(y))\\|_2$. \n",
    "Il est aussi possible de faire une régularisation avec la CE : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16443fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "class ConsistencyRegularization(nn.Module):\n",
    "    def __init__(self, transformation_fn, loss_fn=nn.MSELoss()):\n",
    "        \"\"\"\n",
    "        Régularisation basée sur la consistance à la transformation.\n",
    "\n",
    "        Args:\n",
    "        -----\n",
    "            transformation_fn (callable): Fonction d'augmentation/transformation appliquée aux images.\n",
    "            loss_fn (callable): Fonction de perte utilisée pour comparer les prédictions (par défaut MSELoss). Aussi possible d'utiliser \n",
    "                                nn.KLDivLoss ou nn.BCELoss.\n",
    "        \"\"\"\n",
    "        super(ConsistencyRegularization, self).__init__()\n",
    "        self.transformation_fn = transformation_fn\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def forward(self, model, images):\n",
    "        \"\"\"\n",
    "        Calcule la perte de consistance.\n",
    "\n",
    "        Args:\n",
    "            model (torch.nn.Module): Le modèle de segmentation.\n",
    "            images (torch.Tensor): Batch d'images d'entrée.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: La perte de consistance.\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            # Prédictions de base\n",
    "            original_predictions = F.softmax(model(images), dim=1)\n",
    "\n",
    "        # Augmenter les images\n",
    "        augmented_images = self.transformation_fn(images)\n",
    "\n",
    "        # Prédictions pour les images augmentées\n",
    "        augmented_predictions = F.softmax(model(augmented_images), dim=1)\n",
    "\n",
    "        # Calcul de la perte de consistance\n",
    "        consistency_loss = self.loss_fn(original_predictions, augmented_predictions)\n",
    "\n",
    "        return consistency_loss\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "657ddeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_transformation_fn(images):\n",
    "  \n",
    "    # Random horizontal flip\n",
    "    if np.random.random() > 0.5:\n",
    "        images = torch.flip(images, dims=[2])\n",
    "    # Random vertical flip\n",
    "    if np.random.random() > 0.5:\n",
    "        images = torch.flip(images, dims=[3])\n",
    "    # Random rotation of random angle\n",
    "    if np.random.random() > 0.5:\n",
    "        angle = np.random.randint(0, 360)\n",
    "        images = torch.rot90(images, k=angle//90, dims=[2, 3])\n",
    "    return images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f5c928",
   "metadata": {},
   "source": [
    "### Training of the model \n",
    "\n",
    "At each epoch, the model sees once every exemple of unlabeled data, and sees several time the labeled data. We first train it with the labeled data, and then we train it on the unsupervised data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "186cae12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "~~~~~~~~  Starting the training... ~~~~~~\n",
      "----------------------------------------\n",
      "Using device: cpu\n",
      "~~~~~~~~~~~ Creating the UNet model ~~~~~~~~~~\n",
      " Model Name: TransformationConsistencyL2Model-150epochs0.0005lr0.1alphaTC1e-05wd\n",
      "Total params: 60,664\n",
      "~~~~~~~~~~~ Starting the training ~~~~~~~~~~\n",
      "Number of batches:  126\n",
      "[Training] Epoch: 0 [>              ] 0.8% Loss: 1.4232, Epoch 0, Batch 0, CE_loss: 1.2124372720718384, Dice_loss: 0.20997017621994019, Consistency_loss: 0.0008164049359038472\n",
      "[Training] Epoch: 0 [>              ] 1.6% Loss: 1.4025, Epoch 0, Batch 1, CE_loss: 1.1755757331848145, Dice_loss: 0.20536848902702332, Consistency_loss: 0.0008156333933584392\n",
      "[Training] Epoch: 0 [>              ] 2.4% Loss: 1.3952, Epoch 0, Batch 2, CE_loss: 1.1751430034637451, Dice_loss: 0.20456987619400024, Consistency_loss: 0.0009126115473918617\n",
      "[Training] Epoch: 0 [>              ] 3.2% Loss: 1.3929, Epoch 0, Batch 3, CE_loss: 1.1803746223449707, Dice_loss: 0.20574603974819183, Consistency_loss: 5.878310275875265e-06\n",
      "[Training] Epoch: 0 [>              ] 4.0% Loss: 1.3854, Epoch 0, Batch 4, CE_loss: 1.1514462232589722, Dice_loss: 0.2028215080499649, Consistency_loss: 0.0010611749021336436\n",
      "[Training] Epoch: 0 [>              ] 4.8% Loss: 1.3818, Epoch 0, Batch 5, CE_loss: 1.1592823266983032, Dice_loss: 0.20314493775367737, Consistency_loss: 0.001019377144984901\n",
      "[Training] Epoch: 0 [>              ] 5.6% Loss: 1.3815, Epoch 0, Batch 6, CE_loss: 1.173407793045044, Dice_loss: 0.2055990844964981, Consistency_loss: 0.001031787134706974\n",
      "[Training] Epoch: 0 [>              ] 6.3% Loss: 1.3791, Epoch 0, Batch 7, CE_loss: 1.1581395864486694, Dice_loss: 0.2044842541217804, Consistency_loss: 4.393333256302867e-06\n",
      "[Training] Epoch: 0 [=>             ] 7.1% Loss: 1.3770, Epoch 0, Batch 8, CE_loss: 1.155156135559082, Dice_loss: 0.20361217856407166, Consistency_loss: 0.0009618668118491769\n",
      "[Training] Epoch: 0 [=>             ] 7.9% Loss: 1.3767, Epoch 0, Batch 9, CE_loss: 1.1669247150421143, Dice_loss: 0.20584307610988617, Consistency_loss: 0.00091679731849581\n",
      "[Training] Epoch: 0 [=>             ] 8.7% Loss: 1.3743, Epoch 0, Batch 10, CE_loss: 1.1463719606399536, Dice_loss: 0.20318712294101715, Consistency_loss: 0.001024099183268845\n",
      "[Training] Epoch: 0 [=>             ] 9.5% Loss: 1.3725, Epoch 0, Batch 11, CE_loss: 1.148550271987915, Dice_loss: 0.20379939675331116, Consistency_loss: 0.0010727567132562399\n",
      "[Training] Epoch: 0 [=>             ] 10.3% Loss: 1.3693, Epoch 0, Batch 12, CE_loss: 1.1278409957885742, Dice_loss: 0.20129108428955078, Consistency_loss: 0.0010540620423853397\n",
      "[Training] Epoch: 0 [=>             ] 11.1% Loss: 1.3660, Epoch 0, Batch 13, CE_loss: 1.1214673519134521, Dice_loss: 0.20038087666034698, Consistency_loss: 0.0011153538944199681\n",
      "[Training] Epoch: 0 [=>             ] 11.9% Loss: 1.3614, Epoch 0, Batch 14, CE_loss: 1.0986806154251099, Dice_loss: 0.19754992425441742, Consistency_loss: 0.0008934136712923646\n",
      "[Training] Epoch: 0 [=>             ] 12.7% Loss: 1.3582, Epoch 0, Batch 15, CE_loss: 1.1101253032684326, Dice_loss: 0.19941560924053192, Consistency_loss: 2.395372575847432e-06\n",
      "[Training] Epoch: 0 [==>            ] 13.5% Loss: 1.3558, Epoch 0, Batch 16, CE_loss: 1.116381049156189, Dice_loss: 0.20088256895542145, Consistency_loss: 0.0006953306146897376\n",
      "[Training] Epoch: 0 [==>            ] 14.3% Loss: 1.3532, Epoch 0, Batch 17, CE_loss: 1.1090298891067505, Dice_loss: 0.19938577711582184, Consistency_loss: 0.0008715676376596093\n",
      "[Training] Epoch: 0 [==>            ] 15.1% Loss: 1.3504, Epoch 0, Batch 18, CE_loss: 1.1013892889022827, Dice_loss: 0.19811083376407623, Consistency_loss: 0.0008974390220828354\n",
      "[Training] Epoch: 0 [==>            ] 15.9% Loss: 1.3484, Epoch 0, Batch 19, CE_loss: 1.1092686653137207, Dice_loss: 0.19947421550750732, Consistency_loss: 0.0008228889782913029\n",
      "[Training] Epoch: 0 [==>            ] 16.7% Loss: 1.3460, Epoch 0, Batch 20, CE_loss: 1.099459171295166, Dice_loss: 0.1976005584001541, Consistency_loss: 0.0009426377946510911\n",
      "[Training] Epoch: 0 [==>            ] 17.5% Loss: 1.3442, Epoch 0, Batch 21, CE_loss: 1.1070383787155151, Dice_loss: 0.19897624850273132, Consistency_loss: 0.0009105557692237198\n",
      "[Training] Epoch: 0 [==>            ] 18.3% Loss: 1.3420, Epoch 0, Batch 22, CE_loss: 1.0957188606262207, Dice_loss: 0.19764406979084015, Consistency_loss: 0.0008707325905561447\n",
      "[Training] Epoch: 0 [==>            ] 19.0% Loss: 1.3401, Epoch 0, Batch 23, CE_loss: 1.0976427793502808, Dice_loss: 0.19749930500984192, Consistency_loss: 0.0009317492949776351\n",
      "[Training] Epoch: 0 [==>            ] 19.8% Loss: 1.3381, Epoch 0, Batch 24, CE_loss: 1.0927081108093262, Dice_loss: 0.1970646232366562, Consistency_loss: 0.0008863871335051954\n",
      "[Training] Epoch: 0 [===>           ] 20.6% Loss: 1.3359, Epoch 0, Batch 25, CE_loss: 1.0845668315887451, Dice_loss: 0.19622895121574402, Consistency_loss: 1.2095277952539618e-06\n",
      "[Training] Epoch: 0 [===>           ] 21.4% Loss: 1.3339, Epoch 0, Batch 26, CE_loss: 1.0850499868392944, Dice_loss: 0.19623950123786926, Consistency_loss: 0.000528327189385891\n",
      "[Training] Epoch: 0 [===>           ] 22.2% Loss: 1.3325, Epoch 0, Batch 27, CE_loss: 1.0956465005874634, Dice_loss: 0.1977260261774063, Consistency_loss: 3.3770007235034427e-07\n",
      "[Training] Epoch: 0 [===>           ] 23.0% Loss: 1.3302, Epoch 0, Batch 28, CE_loss: 1.0724012851715088, Dice_loss: 0.19404122233390808, Consistency_loss: 5.484802727551141e-07\n",
      "[Training] Epoch: 0 [===>           ] 23.8% Loss: 1.3282, Epoch 0, Batch 29, CE_loss: 1.0756758451461792, Dice_loss: 0.19502024352550507, Consistency_loss: 1.475950398344139e-06\n",
      "[Training] Epoch: 0 [===>           ] 24.6% Loss: 1.3261, Epoch 0, Batch 30, CE_loss: 1.0689599514007568, Dice_loss: 0.19410566985607147, Consistency_loss: 0.0008635537815280259\n",
      "[Training] Epoch: 0 [===>           ] 25.4% Loss: 1.3237, Epoch 0, Batch 31, CE_loss: 1.0555808544158936, Dice_loss: 0.1915060132741928, Consistency_loss: 0.0007833538693375885\n",
      "[Training] Epoch: 0 [===>           ] 26.2% Loss: 1.3218, Epoch 0, Batch 32, CE_loss: 1.0662667751312256, Dice_loss: 0.19324277341365814, Consistency_loss: 0.0007970733568072319\n",
      "[Training] Epoch: 0 [====>          ] 27.0% Loss: 1.3197, Epoch 0, Batch 33, CE_loss: 1.056673288345337, Dice_loss: 0.1923435479402542, Consistency_loss: 0.0008246544748544693\n",
      "[Training] Epoch: 0 [====>          ] 27.8% Loss: 1.3176, Epoch 0, Batch 34, CE_loss: 1.0549466609954834, Dice_loss: 0.1916167289018631, Consistency_loss: 0.0007574326009489596\n",
      "[Training] Epoch: 0 [====>          ] 28.6% Loss: 1.3158, Epoch 0, Batch 35, CE_loss: 1.0604881048202515, Dice_loss: 0.19255457818508148, Consistency_loss: 0.0007789572700858116\n",
      "[Training] Epoch: 0 [====>          ] 29.4% Loss: 1.3137, Epoch 0, Batch 36, CE_loss: 1.047329306602478, Dice_loss: 0.19110114872455597, Consistency_loss: 1.2278957228772924e-06\n",
      "[Training] Epoch: 0 [====>          ] 30.2% Loss: 1.3119, Epoch 0, Batch 37, CE_loss: 1.051682472229004, Dice_loss: 0.19130387902259827, Consistency_loss: 8.138009661706747e-07\n",
      "[Training] Epoch: 0 [====>          ] 31.0% Loss: 1.3099, Epoch 0, Batch 38, CE_loss: 1.0437039136886597, Dice_loss: 0.19008733332157135, Consistency_loss: 0.0007120372611097991\n",
      "[Training] Epoch: 0 [====>          ] 31.7% Loss: 1.3079, Epoch 0, Batch 39, CE_loss: 1.0399699211120605, Dice_loss: 0.18989282846450806, Consistency_loss: 0.0007279505371116102\n",
      "[Training] Epoch: 0 [====>          ] 32.5% Loss: 1.3061, Epoch 0, Batch 40, CE_loss: 1.0414924621582031, Dice_loss: 0.1901121288537979, Consistency_loss: 0.0006685549742542207\n",
      "[Training] Epoch: 0 [=====>         ] 33.3% Loss: 1.3042, Epoch 0, Batch 41, CE_loss: 1.037925362586975, Dice_loss: 0.1894219070672989, Consistency_loss: 0.0006629395647905767\n",
      "[Training] Epoch: 0 [=====>         ] 34.1% Loss: 1.3023, Epoch 0, Batch 42, CE_loss: 1.033113956451416, Dice_loss: 0.18874727189540863, Consistency_loss: 6.519190947074094e-07\n",
      "[Training] Epoch: 0 [=====>         ] 34.9% Loss: 1.3004, Epoch 0, Batch 43, CE_loss: 1.0295213460922241, Dice_loss: 0.188168466091156, Consistency_loss: 1.1801008668044233e-06\n",
      "[Training] Epoch: 0 [=====>         ] 35.7% Loss: 1.2987, Epoch 0, Batch 44, CE_loss: 1.0351191759109497, Dice_loss: 0.1891186684370041, Consistency_loss: 0.0005956270615570247\n",
      "[Training] Epoch: 0 [=====>         ] 36.5% Loss: 1.2969, Epoch 0, Batch 45, CE_loss: 1.0298439264297485, Dice_loss: 0.188369020819664, Consistency_loss: 0.0005211412790231407\n",
      "[Training] Epoch: 0 [=====>         ] 37.3% Loss: 1.2946, Epoch 0, Batch 46, CE_loss: 1.0035566091537476, Dice_loss: 0.18421293795108795, Consistency_loss: 0.0005235378630459309\n",
      "[Training] Epoch: 0 [=====>         ] 38.1% Loss: 1.2928, Epoch 0, Batch 47, CE_loss: 1.018956184387207, Dice_loss: 0.18645714223384857, Consistency_loss: 8.229357604250254e-07\n",
      "[Training] Epoch: 0 [=====>         ] 38.9% Loss: 1.2908, Epoch 0, Batch 48, CE_loss: 1.0111732482910156, Dice_loss: 0.18539810180664062, Consistency_loss: 7.105065265022859e-07\n",
      "[Training] Epoch: 0 [=====>         ] 39.7% Loss: 1.2887, Epoch 0, Batch 49, CE_loss: 1.0029404163360596, Dice_loss: 0.1840914934873581, Consistency_loss: 8.240591569119715e-07\n",
      "[Training] Epoch: 0 [======>        ] 40.5% Loss: 1.2869, Epoch 0, Batch 50, CE_loss: 1.0100560188293457, Dice_loss: 0.185213103890419, Consistency_loss: 0.0005475718062371016\n",
      "[Training] Epoch: 0 [======>        ] 41.3% Loss: 1.2851, Epoch 0, Batch 51, CE_loss: 1.0054007768630981, Dice_loss: 0.1844780445098877, Consistency_loss: 0.0004962583770975471\n",
      "[Training] Epoch: 0 [======>        ] 42.1% Loss: 1.2833, Epoch 0, Batch 52, CE_loss: 1.0070080757141113, Dice_loss: 0.18457552790641785, Consistency_loss: 9.525562632006768e-07\n",
      "[Training] Epoch: 0 [======>        ] 42.9% Loss: 1.2815, Epoch 0, Batch 53, CE_loss: 1.000515103340149, Dice_loss: 0.183858260512352, Consistency_loss: 0.0004760311567224562\n",
      "[Training] Epoch: 0 [======>        ] 43.7% Loss: 1.2796, Epoch 0, Batch 54, CE_loss: 0.9952065944671631, Dice_loss: 0.18296357989311218, Consistency_loss: 0.00041200112900696695\n",
      "[Training] Epoch: 0 [======>        ] 44.4% Loss: 1.2775, Epoch 0, Batch 55, CE_loss: 0.9813494682312012, Dice_loss: 0.18099364638328552, Consistency_loss: 0.00043150116107426584\n",
      "[Training] Epoch: 0 [======>        ] 45.2% Loss: 1.2758, Epoch 0, Batch 56, CE_loss: 0.9945442080497742, Dice_loss: 0.1827111542224884, Consistency_loss: 0.0005111587233841419\n",
      "[Training] Epoch: 0 [======>        ] 46.0% Loss: 1.2739, Epoch 0, Batch 57, CE_loss: 0.9863649606704712, Dice_loss: 0.1813773810863495, Consistency_loss: 0.0003896397538483143\n",
      "[Training] Epoch: 0 [=======>       ] 46.8% Loss: 1.2720, Epoch 0, Batch 58, CE_loss: 0.9810938835144043, Dice_loss: 0.18053656816482544, Consistency_loss: 0.0004960884689353406\n",
      "[Training] Epoch: 0 [=======>       ] 47.6% Loss: 1.2704, Epoch 0, Batch 59, CE_loss: 0.9929507970809937, Dice_loss: 0.18250276148319244, Consistency_loss: 0.0005319357733242214\n",
      "[Training] Epoch: 0 [=======>       ] 48.4% Loss: 1.2685, Epoch 0, Batch 60, CE_loss: 0.9740205407142639, Dice_loss: 0.17949815094470978, Consistency_loss: 2.8336921786831226e-06\n",
      "[Training] Epoch: 0 [=======>       ] 49.2% Loss: 1.2668, Epoch 0, Batch 61, CE_loss: 0.9805030822753906, Dice_loss: 0.18056169152259827, Consistency_loss: 0.0005941682029515505\n",
      "[Training] Epoch: 0 [=======>       ] 50.0% Loss: 1.2649, Epoch 0, Batch 62, CE_loss: 0.9691575169563293, Dice_loss: 0.1788158118724823, Consistency_loss: 2.1903445031057345e-06\n",
      "[Training] Epoch: 0 [=======>       ] 50.8% Loss: 1.2631, Epoch 0, Batch 63, CE_loss: 0.9703927040100098, Dice_loss: 0.1790471076965332, Consistency_loss: 0.0005254445713944733\n",
      "[Training] Epoch: 0 [=======>       ] 51.6% Loss: 1.2613, Epoch 0, Batch 64, CE_loss: 0.9660648107528687, Dice_loss: 0.17838963866233826, Consistency_loss: 9.99332200990466e-07\n",
      "[Training] Epoch: 0 [=======>       ] 52.4% Loss: 1.2595, Epoch 0, Batch 65, CE_loss: 0.9640055894851685, Dice_loss: 0.17794787883758545, Consistency_loss: 1.2447287645045435e-06\n",
      "[Training] Epoch: 0 [=======>       ] 53.2% Loss: 1.2578, Epoch 0, Batch 66, CE_loss: 0.9682120680809021, Dice_loss: 0.1784142255783081, Consistency_loss: 0.00045109103666618466\n",
      "[Training] Epoch: 0 [========>      ] 54.0% Loss: 1.2560, Epoch 0, Batch 67, CE_loss: 0.9594554305076599, Dice_loss: 0.1771540492773056, Consistency_loss: 0.00034334012889303267\n",
      "[Training] Epoch: 0 [========>      ] 54.8% Loss: 1.2543, Epoch 0, Batch 68, CE_loss: 0.962031364440918, Dice_loss: 0.17732080817222595, Consistency_loss: 1.4758526276636985e-06\n",
      "[Training] Epoch: 0 [========>      ] 55.6% Loss: 1.2525, Epoch 0, Batch 69, CE_loss: 0.9481279850006104, Dice_loss: 0.17518937587738037, Consistency_loss: 0.00042569730430841446\n",
      "[Training] Epoch: 0 [========>      ] 56.3% Loss: 1.2507, Epoch 0, Batch 70, CE_loss: 0.9538207054138184, Dice_loss: 0.1761188507080078, Consistency_loss: 0.000538898108061403\n",
      "[Training] Epoch: 0 [========>      ] 57.1% Loss: 1.2490, Epoch 0, Batch 71, CE_loss: 0.9480240345001221, Dice_loss: 0.1752908080816269, Consistency_loss: 0.0005231068353168666\n",
      "[Training] Epoch: 0 [========>      ] 57.9% Loss: 1.2473, Epoch 0, Batch 72, CE_loss: 0.9506915807723999, Dice_loss: 0.17538538575172424, Consistency_loss: 0.0004899251507595181\n",
      "[Training] Epoch: 0 [========>      ] 58.7% Loss: 1.2457, Epoch 0, Batch 73, CE_loss: 0.9505366086959839, Dice_loss: 0.1754833459854126, Consistency_loss: 2.904062284869724e-06\n",
      "[Training] Epoch: 0 [========>      ] 59.5% Loss: 1.2441, Epoch 0, Batch 74, CE_loss: 0.9521825909614563, Dice_loss: 0.1757463663816452, Consistency_loss: 0.0004542080860119313\n",
      "[Training] Epoch: 0 [=========>     ] 60.3% Loss: 1.2424, Epoch 0, Batch 75, CE_loss: 0.9396011829376221, Dice_loss: 0.17350716888904572, Consistency_loss: 3.367295448697405e-06\n",
      "[Training] Epoch: 0 [=========>     ] 61.1% Loss: 1.2407, Epoch 0, Batch 76, CE_loss: 0.9394276142120361, Dice_loss: 0.17338669300079346, Consistency_loss: 0.00048674477147869766\n",
      "[Training] Epoch: 0 [=========>     ] 61.9% Loss: 1.2392, Epoch 0, Batch 77, CE_loss: 0.9502497911453247, Dice_loss: 0.17503513395786285, Consistency_loss: 0.0005046729347668588\n",
      "[Training] Epoch: 0 [=========>     ] 62.7% Loss: 1.2375, Epoch 0, Batch 78, CE_loss: 0.9289960265159607, Dice_loss: 0.17174263298511505, Consistency_loss: 0.00039710590499453247\n",
      "[Training] Epoch: 0 [=========>     ] 63.5% Loss: 1.2357, Epoch 0, Batch 79, CE_loss: 0.927402138710022, Dice_loss: 0.1715807020664215, Consistency_loss: 0.00044909631833434105\n",
      "[Training] Epoch: 0 [=========>     ] 64.3% Loss: 1.2342, Epoch 0, Batch 80, CE_loss: 0.9360096454620361, Dice_loss: 0.1724516898393631, Consistency_loss: 0.00042760084033943713\n",
      "[Training] Epoch: 0 [=========>     ] 65.1% Loss: 1.2327, Epoch 0, Batch 81, CE_loss: 0.9378867149353027, Dice_loss: 0.17313334345817566, Consistency_loss: 4.310243184590945e-06\n",
      "[Training] Epoch: 0 [=========>     ] 65.9% Loss: 1.2310, Epoch 0, Batch 82, CE_loss: 0.9203429222106934, Dice_loss: 0.1701914668083191, Consistency_loss: 0.0004484303935896605\n",
      "[Training] Epoch: 0 [==========>    ] 66.7% Loss: 1.2294, Epoch 0, Batch 83, CE_loss: 0.924599826335907, Dice_loss: 0.17078068852424622, Consistency_loss: 0.0004481009382288903\n",
      "[Training] Epoch: 0 [==========>    ] 67.5% Loss: 1.2276, Epoch 0, Batch 84, CE_loss: 0.908675491809845, Dice_loss: 0.1679728925228119, Consistency_loss: 0.0004742742166854441\n",
      "[Training] Epoch: 0 [==========>    ] 68.3% Loss: 1.2259, Epoch 0, Batch 85, CE_loss: 0.915034294128418, Dice_loss: 0.16883538663387299, Consistency_loss: 4.631879619410029e-06\n",
      "[Training] Epoch: 0 [==========>    ] 69.0% Loss: 1.2245, Epoch 0, Batch 86, CE_loss: 0.9305944442749023, Dice_loss: 0.17167223989963531, Consistency_loss: 0.0004872583958785981\n",
      "[Training] Epoch: 0 [==========>    ] 69.8% Loss: 1.2229, Epoch 0, Batch 87, CE_loss: 0.9145572185516357, Dice_loss: 0.16871318221092224, Consistency_loss: 0.00041126515134237707\n",
      "[Training] Epoch: 0 [==========>    ] 70.6% Loss: 1.2215, Epoch 0, Batch 88, CE_loss: 0.9273642301559448, Dice_loss: 0.17068585753440857, Consistency_loss: 0.0004829573445022106\n",
      "[Training] Epoch: 0 [==========>    ] 71.4% Loss: 1.2201, Epoch 0, Batch 89, CE_loss: 0.9231463074684143, Dice_loss: 0.1699693351984024, Consistency_loss: 0.00047264687600545585\n",
      "[Training] Epoch: 0 [==========>    ] 72.2% Loss: 1.2186, Epoch 0, Batch 90, CE_loss: 0.9150537252426147, Dice_loss: 0.16874919831752777, Consistency_loss: 0.0004985500709153712\n",
      "[Training] Epoch: 0 [==========>    ] 73.0% Loss: 1.2172, Epoch 0, Batch 91, CE_loss: 0.9188255667686462, Dice_loss: 0.16930556297302246, Consistency_loss: 0.00048485994921065867\n",
      "[Training] Epoch: 0 [===========>   ] 73.8% Loss: 1.2157, Epoch 0, Batch 92, CE_loss: 0.9135973453521729, Dice_loss: 0.1689307987689972, Consistency_loss: 0.00035397871397435665\n",
      "[Training] Epoch: 0 [===========>   ] 74.6% Loss: 1.2142, Epoch 0, Batch 93, CE_loss: 0.9028924107551575, Dice_loss: 0.16651621460914612, Consistency_loss: 0.0004280128632672131\n",
      "[Training] Epoch: 0 [===========>   ] 75.4% Loss: 1.2127, Epoch 0, Batch 94, CE_loss: 0.9103395938873291, Dice_loss: 0.16790631413459778, Consistency_loss: 0.00048473943024873734\n",
      "[Training] Epoch: 0 [===========>   ] 76.2% Loss: 1.2113, Epoch 0, Batch 95, CE_loss: 0.9104323983192444, Dice_loss: 0.16811174154281616, Consistency_loss: 0.00041881040669977665\n",
      "[Training] Epoch: 0 [===========>   ] 77.0% Loss: 1.2100, Epoch 0, Batch 96, CE_loss: 0.9098884463310242, Dice_loss: 0.16771161556243896, Consistency_loss: 0.0004342010652180761\n",
      "[Training] Epoch: 0 [===========>   ] 77.8% Loss: 1.2085, Epoch 0, Batch 97, CE_loss: 0.9024797677993774, Dice_loss: 0.16649629175662994, Consistency_loss: 0.00043863928294740617\n",
      "[Training] Epoch: 0 [===========>   ] 78.6% Loss: 1.2071, Epoch 0, Batch 98, CE_loss: 0.9019519686698914, Dice_loss: 0.16644665598869324, Consistency_loss: 0.00045718770707026124\n",
      "[Training] Epoch: 0 [===========>   ] 79.4% Loss: 1.2057, Epoch 0, Batch 99, CE_loss: 0.9005149006843567, Dice_loss: 0.16596829891204834, Consistency_loss: 0.0005459159729070961\n",
      "[Training] Epoch: 0 [============>  ] 80.2% Loss: 1.2043, Epoch 0, Batch 100, CE_loss: 0.8956581950187683, Dice_loss: 0.16504719853401184, Consistency_loss: 0.0005039802053943276\n",
      "[Training] Epoch: 0 [============>  ] 81.0% Loss: 1.2029, Epoch 0, Batch 101, CE_loss: 0.893670380115509, Dice_loss: 0.1648893803358078, Consistency_loss: 0.0005124908057041466\n",
      "[Training] Epoch: 0 [============>  ] 81.7% Loss: 1.2014, Epoch 0, Batch 102, CE_loss: 0.8840454816818237, Dice_loss: 0.1628343015909195, Consistency_loss: 4.3569311856117565e-06\n",
      "[Training] Epoch: 0 [============>  ] 82.5% Loss: 1.1999, Epoch 0, Batch 103, CE_loss: 0.887407124042511, Dice_loss: 0.16342346370220184, Consistency_loss: 0.000525760930031538\n",
      "[Training] Epoch: 0 [============>  ] 83.3% Loss: 1.1985, Epoch 0, Batch 104, CE_loss: 0.8908624053001404, Dice_loss: 0.1638564020395279, Consistency_loss: 0.0005676992586813867\n",
      "[Training] Epoch: 0 [============>  ] 84.1% Loss: 1.1971, Epoch 0, Batch 105, CE_loss: 0.8838986158370972, Dice_loss: 0.16260844469070435, Consistency_loss: 0.0005592898232862353\n",
      "[Training] Epoch: 0 [============>  ] 84.9% Loss: 1.1957, Epoch 0, Batch 106, CE_loss: 0.8854154348373413, Dice_loss: 0.16275817155838013, Consistency_loss: 0.000488729274366051\n",
      "[Training] Epoch: 0 [============>  ] 85.7% Loss: 1.1943, Epoch 0, Batch 107, CE_loss: 0.8827903866767883, Dice_loss: 0.1620146930217743, Consistency_loss: 0.0005202877218835056\n",
      "[Training] Epoch: 0 [============>  ] 86.5% Loss: 1.1930, Epoch 0, Batch 108, CE_loss: 0.8871083855628967, Dice_loss: 0.16290608048439026, Consistency_loss: 0.0005723339854739606\n",
      "[Training] Epoch: 0 [=============> ] 87.3% Loss: 1.1915, Epoch 0, Batch 109, CE_loss: 0.8712954521179199, Dice_loss: 0.16025081276893616, Consistency_loss: 0.0005918520619161427\n",
      "[Training] Epoch: 0 [=============> ] 88.1% Loss: 1.1902, Epoch 0, Batch 110, CE_loss: 0.8839936852455139, Dice_loss: 0.1626664698123932, Consistency_loss: 1.0475596354808658e-05\n",
      "[Training] Epoch: 0 [=============> ] 88.9% Loss: 1.1888, Epoch 0, Batch 111, CE_loss: 0.8711727857589722, Dice_loss: 0.15998096764087677, Consistency_loss: 0.0005552086513489485\n",
      "[Training] Epoch: 0 [=============> ] 89.7% Loss: 1.1875, Epoch 0, Batch 112, CE_loss: 0.8768844604492188, Dice_loss: 0.1606837660074234, Consistency_loss: 0.00048658670857548714\n",
      "[Training] Epoch: 0 [=============> ] 90.5% Loss: 1.1862, Epoch 0, Batch 113, CE_loss: 0.876887321472168, Dice_loss: 0.16093450784683228, Consistency_loss: 1.4888871191942599e-05\n",
      "[Training] Epoch: 0 [=============> ] 91.3% Loss: 1.1849, Epoch 0, Batch 114, CE_loss: 0.8799657821655273, Dice_loss: 0.16082867980003357, Consistency_loss: 0.0005898978561162949\n",
      "[Training] Epoch: 0 [=============> ] 92.1% Loss: 1.1835, Epoch 0, Batch 115, CE_loss: 0.8578444123268127, Dice_loss: 0.15722697973251343, Consistency_loss: 2.0056491848663427e-05\n",
      "[Training] Epoch: 0 [=============> ] 92.9% Loss: 1.1820, Epoch 0, Batch 116, CE_loss: 0.8601784110069275, Dice_loss: 0.15756380558013916, Consistency_loss: 0.0005592054221779108\n",
      "[Training] Epoch: 0 [==============>] 93.7% Loss: 1.1808, Epoch 0, Batch 117, CE_loss: 0.874772846698761, Dice_loss: 0.16010485589504242, Consistency_loss: 0.0006225911201909184\n",
      "[Training] Epoch: 0 [==============>] 94.4% Loss: 1.1794, Epoch 0, Batch 118, CE_loss: 0.8594929575920105, Dice_loss: 0.15739363431930542, Consistency_loss: 0.0006261293310672045\n",
      "[Training] Epoch: 0 [==============>] 95.2% Loss: 1.1781, Epoch 0, Batch 119, CE_loss: 0.8593896627426147, Dice_loss: 0.1574205756187439, Consistency_loss: 0.000562980945687741\n",
      "[Training] Epoch: 0 [==============>] 96.0% Loss: 1.1769, Epoch 0, Batch 120, CE_loss: 0.8767834901809692, Dice_loss: 0.16039453446865082, Consistency_loss: 0.0006045443587936461\n",
      "[Training] Epoch: 0 [==============>] 96.8% Loss: 1.1757, Epoch 0, Batch 121, CE_loss: 0.8659980297088623, Dice_loss: 0.15828800201416016, Consistency_loss: 0.0005366691621020436\n",
      "[Training] Epoch: 0 [==============>] 97.6% Loss: 1.1743, Epoch 0, Batch 122, CE_loss: 0.8494462370872498, Dice_loss: 0.1553761065006256, Consistency_loss: 0.00048070578486658633\n",
      "[Training] Epoch: 0 [==============>] 98.4% Loss: 1.1730, Epoch 0, Batch 123, CE_loss: 0.8533035516738892, Dice_loss: 0.15605264902114868, Consistency_loss: 0.000581680447794497\n",
      "[Training] Epoch: 0 [==============>] 99.2% Loss: 1.1717, Epoch 0, Batch 124, CE_loss: 0.8575502634048462, Dice_loss: 0.15677444636821747, Consistency_loss: 0.0005969286430627108\n",
      "[Training] Epoch: 0 [DONE]                                 \n",
      "Epoch 0, Batch 125, CE_loss: 0.8595755100250244, Dice_loss: 0.15698418021202087, Consistency_loss: 0.0006579898181371391\n",
      "[Validation] Epoch: 0 [DONE]                                 \n",
      "[Epoch: 0, TrainLoss: 1.1705, TrainDice: 0.1803, ValLoss: 1.2001                                             \n",
      "Number of batches:  126\n",
      "[Training] Epoch: 1 [>              ] 0.8% Loss: 1.0429, Epoch 1, Batch 0, CE_loss: 0.8812296986579895, Dice_loss: 0.16122181713581085, Consistency_loss: 0.0004727444320451468\n",
      "[Training] Epoch: 1 [>              ] 1.6% Loss: 1.0348, Epoch 1, Batch 1, CE_loss: 0.8682414293289185, Dice_loss: 0.15836259722709656, Consistency_loss: 9.843402949627489e-06\n",
      "[Training] Epoch: 1 [>              ] 2.4% Loss: 1.0282, Epoch 1, Batch 2, CE_loss: 0.8578665852546692, Dice_loss: 0.15649044513702393, Consistency_loss: 0.0006573863211087883\n",
      "[Training] Epoch: 1 [>              ] 3.2% Loss: 1.0212, Epoch 1, Batch 3, CE_loss: 0.8452975153923035, Dice_loss: 0.15434493124485016, Consistency_loss: 0.0007022762438282371\n",
      "[Training] Epoch: 1 [>              ] 4.0% Loss: 1.0157, Epoch 1, Batch 4, CE_loss: 0.8395732641220093, Dice_loss: 0.15332597494125366, Consistency_loss: 0.0007393190753646195\n",
      "[Training] Epoch: 1 [>              ] 4.8% Loss: 1.0129, Epoch 1, Batch 5, CE_loss: 0.8437340259552002, Dice_loss: 0.15422284603118896, Consistency_loss: 0.0007062143995426595\n",
      "[Training] Epoch: 1 [>              ] 5.6% Loss: 1.0124, Epoch 1, Batch 6, CE_loss: 0.853073000907898, Dice_loss: 0.15559667348861694, Consistency_loss: 0.000628921901807189\n",
      "[Training] Epoch: 1 [>              ] 6.3% Loss: 1.0122, Epoch 1, Batch 7, CE_loss: 0.8547717928886414, Dice_loss: 0.15589632093906403, Consistency_loss: 0.0005608110805042088\n",
      "[Training] Epoch: 1 [=>             ] 7.1% Loss: 1.0109, Epoch 1, Batch 8, CE_loss: 0.8457655906677246, Dice_loss: 0.15424568951129913, Consistency_loss: 0.0007054284797050059\n",
      "[Training] Epoch: 1 [=>             ] 7.9% Loss: 1.0099, Epoch 1, Batch 9, CE_loss: 0.8455521464347839, Dice_loss: 0.15467295050621033, Consistency_loss: 1.4560064300894737e-05\n",
      "[Training] Epoch: 1 [=>             ] 8.7% Loss: 1.0091, Epoch 1, Batch 10, CE_loss: 0.8461799621582031, Dice_loss: 0.15434159338474274, Consistency_loss: 0.0006398496334441006\n",
      "[Training] Epoch: 1 [=>             ] 9.5% Loss: 1.0067, Epoch 1, Batch 11, CE_loss: 0.8293232917785645, Dice_loss: 0.15101368725299835, Consistency_loss: 0.0006373510113917291\n",
      "[Training] Epoch: 1 [=>             ] 10.3% Loss: 1.0044, Epoch 1, Batch 12, CE_loss: 0.8254109621047974, Dice_loss: 0.15051372349262238, Consistency_loss: 0.0006145106162875891\n",
      "[Training] Epoch: 1 [=>             ] 11.1% Loss: 1.0032, Epoch 1, Batch 13, CE_loss: 0.8350550532341003, Dice_loss: 0.15180012583732605, Consistency_loss: 0.0007186827133409679\n",
      "[Training] Epoch: 1 [=>             ] 11.9% Loss: 1.0022, Epoch 1, Batch 14, CE_loss: 0.8354498744010925, Dice_loss: 0.15239858627319336, Consistency_loss: 0.0006890688091516495\n",
      "[Training] Epoch: 1 [=>             ] 12.7% Loss: 1.0019, Epoch 1, Batch 15, CE_loss: 0.8423095941543579, Dice_loss: 0.15342426300048828, Consistency_loss: 0.0005783817614428699\n",
      "[Training] Epoch: 1 [==>            ] 13.5% Loss: 1.0008, Epoch 1, Batch 16, CE_loss: 0.8322214484214783, Dice_loss: 0.1515025794506073, Consistency_loss: 0.0005425327690318227\n",
      "[Training] Epoch: 1 [==>            ] 14.3% Loss: 1.0005, Epoch 1, Batch 17, CE_loss: 0.8420966267585754, Dice_loss: 0.1529759019613266, Consistency_loss: 0.0005442615947686136\n",
      "[Training] Epoch: 1 [==>            ] 15.1% Loss: 1.0002, Epoch 1, Batch 18, CE_loss: 0.8399797677993774, Dice_loss: 0.15275952219963074, Consistency_loss: 0.0006529106758534908\n",
      "[Training] Epoch: 1 [==>            ] 15.9% Loss: 0.9997, Epoch 1, Batch 19, CE_loss: 0.8381197452545166, Dice_loss: 0.15231329202651978, Consistency_loss: 0.000605185457970947\n",
      "[Training] Epoch: 1 [==>            ] 16.7% Loss: 0.9982, Epoch 1, Batch 20, CE_loss: 0.8180104494094849, Dice_loss: 0.1485120803117752, Consistency_loss: 0.0006737116491422057\n",
      "[Training] Epoch: 1 [==>            ] 17.5% Loss: 0.9973, Epoch 1, Batch 21, CE_loss: 0.8275355100631714, Dice_loss: 0.15004080533981323, Consistency_loss: 0.0006845103926025331\n",
      "[Training] Epoch: 1 [==>            ] 18.3% Loss: 0.9970, Epoch 1, Batch 22, CE_loss: 0.8380446434020996, Dice_loss: 0.15165145695209503, Consistency_loss: 0.0006872639642097056\n",
      "[Training] Epoch: 1 [==>            ] 19.0% Loss: 0.9965, Epoch 1, Batch 23, CE_loss: 0.8343995809555054, Dice_loss: 0.1516011357307434, Consistency_loss: 0.0007094609318301082\n",
      "[Training] Epoch: 1 [==>            ] 19.8% Loss: 0.9957, Epoch 1, Batch 24, CE_loss: 0.825114905834198, Dice_loss: 0.14952631294727325, Consistency_loss: 1.5376896044472232e-05\n",
      "[Training] Epoch: 1 [===>           ] 20.6% Loss: 0.9956, Epoch 1, Batch 25, CE_loss: 0.8414769172668457, Dice_loss: 0.1532178372144699, Consistency_loss: 0.000703688245266676\n",
      "[Training] Epoch: 1 [===>           ] 21.4% Loss: 0.9949, Epoch 1, Batch 26, CE_loss: 0.825100302696228, Dice_loss: 0.14967679977416992, Consistency_loss: 0.0005085437442176044\n",
      "[Training] Epoch: 1 [===>           ] 22.2% Loss: 0.9943, Epoch 1, Batch 27, CE_loss: 0.82831209897995, Dice_loss: 0.15017643570899963, Consistency_loss: 0.0005335930618457496\n",
      "[Training] Epoch: 1 [===>           ] 23.0% Loss: 0.9935, Epoch 1, Batch 28, CE_loss: 0.820138692855835, Dice_loss: 0.14853866398334503, Consistency_loss: 0.0005815332988277078\n",
      "[Training] Epoch: 1 [===>           ] 23.8% Loss: 0.9930, Epoch 1, Batch 29, CE_loss: 0.8290296196937561, Dice_loss: 0.15043576061725616, Consistency_loss: 0.0007360809831880033\n",
      "[Training] Epoch: 1 [===>           ] 24.6% Loss: 0.9920, Epoch 1, Batch 30, CE_loss: 0.8146188259124756, Dice_loss: 0.14773698151111603, Consistency_loss: 1.288163366552908e-05\n",
      "[Training] Epoch: 1 [===>           ] 25.4% Loss: 0.9908, Epoch 1, Batch 31, CE_loss: 0.8064231276512146, Dice_loss: 0.14611972868442535, Consistency_loss: 1.654835978115443e-05\n",
      "[Training] Epoch: 1 [===>           ] 26.2% Loss: 0.9899, Epoch 1, Batch 32, CE_loss: 0.8119684457778931, Dice_loss: 0.14704860746860504, Consistency_loss: 0.000735956709831953\n",
      "[Training] Epoch: 1 [====>          ] 27.0% Loss: 0.9888, Epoch 1, Batch 33, CE_loss: 0.808591365814209, Dice_loss: 0.14626090228557587, Consistency_loss: 0.0007586873834952712\n",
      "[Training] Epoch: 1 [====>          ] 27.8% Loss: 0.9882, Epoch 1, Batch 34, CE_loss: 0.818129301071167, Dice_loss: 0.14812569320201874, Consistency_loss: 0.0006510924431495368\n",
      "[Training] Epoch: 1 [====>          ] 28.6% Loss: 0.9873, Epoch 1, Batch 35, CE_loss: 0.8067410588264465, Dice_loss: 0.1462700515985489, Consistency_loss: 0.0007027514511719346\n",
      "[Training] Epoch: 1 [====>          ] 29.4% Loss: 0.9863, Epoch 1, Batch 36, CE_loss: 0.8046309947967529, Dice_loss: 0.14554643630981445, Consistency_loss: 1.7803484297473915e-05\n",
      "[Training] Epoch: 1 [====>          ] 30.2% Loss: 0.9853, Epoch 1, Batch 37, CE_loss: 0.8026391267776489, Dice_loss: 0.14541217684745789, Consistency_loss: 2.039640639850404e-05\n",
      "[Training] Epoch: 1 [====>          ] 31.0% Loss: 0.9843, Epoch 1, Batch 38, CE_loss: 0.802061140537262, Dice_loss: 0.14523552358150482, Consistency_loss: 0.0007930141291581094\n",
      "[Training] Epoch: 1 [====>          ] 31.7% Loss: 0.9829, Epoch 1, Batch 39, CE_loss: 0.7857714891433716, Dice_loss: 0.1420210897922516, Consistency_loss: 0.0007463798974640667\n",
      "[Training] Epoch: 1 [====>          ] 32.5% Loss: 0.9823, Epoch 1, Batch 40, CE_loss: 0.8099445700645447, Dice_loss: 0.14628303050994873, Consistency_loss: 0.000764489930588752\n",
      "[Training] Epoch: 1 [=====>         ] 33.3% Loss: 0.9813, Epoch 1, Batch 41, CE_loss: 0.7974986433982849, Dice_loss: 0.14401912689208984, Consistency_loss: 2.2693759092362598e-05\n",
      "[Training] Epoch: 1 [=====>         ] 34.1% Loss: 0.9803, Epoch 1, Batch 42, CE_loss: 0.794529914855957, Dice_loss: 0.1433001309633255, Consistency_loss: 0.0007530999719165266\n",
      "[Training] Epoch: 1 [=====>         ] 34.9% Loss: 0.9792, Epoch 1, Batch 43, CE_loss: 0.787560760974884, Dice_loss: 0.14191295206546783, Consistency_loss: 0.0007682557916268706\n",
      "[Training] Epoch: 1 [=====>         ] 35.7% Loss: 0.9785, Epoch 1, Batch 44, CE_loss: 0.8047407865524292, Dice_loss: 0.14522366225719452, Consistency_loss: 0.0007974656182341278\n",
      "[Training] Epoch: 1 [=====>         ] 36.5% Loss: 0.9776, Epoch 1, Batch 45, CE_loss: 0.7911602258682251, Dice_loss: 0.14284734427928925, Consistency_loss: 1.6026266166591085e-05\n",
      "[Training] Epoch: 1 [=====>         ] 37.3% Loss: 0.9768, Epoch 1, Batch 46, CE_loss: 0.7961532473564148, Dice_loss: 0.14368776977062225, Consistency_loss: 0.0007287228363566101\n",
      "[Training] Epoch: 1 [=====>         ] 38.1% Loss: 0.9765, Epoch 1, Batch 47, CE_loss: 0.8144804835319519, Dice_loss: 0.14697861671447754, Consistency_loss: 0.0006614079466089606\n",
      "[Training] Epoch: 1 [=====>         ] 38.9% Loss: 0.9754, Epoch 1, Batch 48, CE_loss: 0.7836040258407593, Dice_loss: 0.14109951257705688, Consistency_loss: 0.0007522880914621055\n",
      "[Training] Epoch: 1 [=====>         ] 39.7% Loss: 0.9747, Epoch 1, Batch 49, CE_loss: 0.7943702340126038, Dice_loss: 0.14311404526233673, Consistency_loss: 9.040395525516942e-06\n",
      "[Training] Epoch: 1 [======>        ] 40.5% Loss: 0.9739, Epoch 1, Batch 50, CE_loss: 0.7930202484130859, Dice_loss: 0.14246037602424622, Consistency_loss: 0.0008128584595397115\n",
      "[Training] Epoch: 1 [======>        ] 41.3% Loss: 0.9733, Epoch 1, Batch 51, CE_loss: 0.7967543005943298, Dice_loss: 0.14338666200637817, Consistency_loss: 1.0094910066982266e-05\n",
      "[Training] Epoch: 1 [======>        ] 42.1% Loss: 0.9724, Epoch 1, Batch 52, CE_loss: 0.7848550081253052, Dice_loss: 0.1413935422897339, Consistency_loss: 2.695296825550031e-05\n",
      "[Training] Epoch: 1 [======>        ] 42.9% Loss: 0.9717, Epoch 1, Batch 53, CE_loss: 0.7915207743644714, Dice_loss: 0.14224450290203094, Consistency_loss: 0.0009461404988542199\n",
      "[Training] Epoch: 1 [======>        ] 43.7% Loss: 0.9709, Epoch 1, Batch 54, CE_loss: 0.7862935066223145, Dice_loss: 0.14118552207946777, Consistency_loss: 0.0008792013977654278\n",
      "[Training] Epoch: 1 [======>        ] 44.4% Loss: 0.9701, Epoch 1, Batch 55, CE_loss: 0.7860061526298523, Dice_loss: 0.14131546020507812, Consistency_loss: 0.0008127918699756265\n",
      "[Training] Epoch: 1 [======>        ] 45.2% Loss: 0.9693, Epoch 1, Batch 56, CE_loss: 0.7816212773323059, Dice_loss: 0.14042825996875763, Consistency_loss: 0.0007880156044848263\n",
      "[Training] Epoch: 1 [======>        ] 46.0% Loss: 0.9683, Epoch 1, Batch 57, CE_loss: 0.7712178230285645, Dice_loss: 0.13840658962726593, Consistency_loss: 0.0007027999963611364\n",
      "[Training] Epoch: 1 [=======>       ] 46.8% Loss: 0.9673, Epoch 1, Batch 58, CE_loss: 0.7696619629859924, Dice_loss: 0.13791728019714355, Consistency_loss: 0.0008324178052134812\n",
      "[Training] Epoch: 1 [=======>       ] 47.6% Loss: 0.9664, Epoch 1, Batch 59, CE_loss: 0.7742835879325867, Dice_loss: 0.13857018947601318, Consistency_loss: 0.0009909834479913116\n",
      "[Training] Epoch: 1 [=======>       ] 48.4% Loss: 0.9658, Epoch 1, Batch 60, CE_loss: 0.7891660928726196, Dice_loss: 0.14137212932109833, Consistency_loss: 0.000929621048271656\n",
      "[Training] Epoch: 1 [=======>       ] 49.2% Loss: 0.9651, Epoch 1, Batch 61, CE_loss: 0.7792401909828186, Dice_loss: 0.13986879587173462, Consistency_loss: 0.000920704216696322\n",
      "[Training] Epoch: 1 [=======>       ] 50.0% Loss: 0.9641, Epoch 1, Batch 62, CE_loss: 0.7668812870979309, Dice_loss: 0.13700515031814575, Consistency_loss: 0.0008596642292104661\n",
      "[Training] Epoch: 1 [=======>       ] 50.8% Loss: 0.9635, Epoch 1, Batch 63, CE_loss: 0.785142183303833, Dice_loss: 0.14058423042297363, Consistency_loss: 0.0008689220412634313\n",
      "[Training] Epoch: 1 [=======>       ] 51.6% Loss: 0.9629, Epoch 1, Batch 64, CE_loss: 0.7788920402526855, Dice_loss: 0.13977597653865814, Consistency_loss: 0.000684439844917506\n",
      "[Training] Epoch: 1 [=======>       ] 52.4% Loss: 0.9621, Epoch 1, Batch 65, CE_loss: 0.7758625149726868, Dice_loss: 0.13874024152755737, Consistency_loss: 1.0614821803756058e-05\n",
      "[Training] Epoch: 1 [=======>       ] 53.2% Loss: 0.9616, Epoch 1, Batch 66, CE_loss: 0.7844336628913879, Dice_loss: 0.14085672795772552, Consistency_loss: 0.0008174892864190042\n",
      "[Training] Epoch: 1 [========>      ] 54.0% Loss: 0.9609, Epoch 1, Batch 67, CE_loss: 0.7756170630455017, Dice_loss: 0.1388060599565506, Consistency_loss: 0.000778714194893837\n",
      "[Training] Epoch: 1 [========>      ] 54.8% Loss: 0.9601, Epoch 1, Batch 68, CE_loss: 0.7689282894134521, Dice_loss: 0.137823686003685, Consistency_loss: 0.0008127178880386055\n",
      "[Training] Epoch: 1 [========>      ] 55.6% Loss: 0.9596, Epoch 1, Batch 69, CE_loss: 0.781285285949707, Dice_loss: 0.1402006447315216, Consistency_loss: 0.0006111764232628047\n",
      "[Training] Epoch: 1 [========>      ] 56.3% Loss: 0.9589, Epoch 1, Batch 70, CE_loss: 0.7729378342628479, Dice_loss: 0.13848355412483215, Consistency_loss: 0.0008363661472685635\n",
      "[Training] Epoch: 1 [========>      ] 57.1% Loss: 0.9582, Epoch 1, Batch 71, CE_loss: 0.770787239074707, Dice_loss: 0.13785219192504883, Consistency_loss: 0.0008901703404262662\n",
      "[Training] Epoch: 1 [========>      ] 57.9% Loss: 0.9575, Epoch 1, Batch 72, CE_loss: 0.7694426774978638, Dice_loss: 0.13747769594192505, Consistency_loss: 0.0007873221184127033\n",
      "[Training] Epoch: 1 [========>      ] 58.7% Loss: 0.9568, Epoch 1, Batch 73, CE_loss: 0.7670028805732727, Dice_loss: 0.13727764785289764, Consistency_loss: 2.8209118681843393e-05\n",
      "[Training] Epoch: 1 [========>      ] 59.5% Loss: 0.9561, Epoch 1, Batch 74, CE_loss: 0.7629827260971069, Dice_loss: 0.13648393750190735, Consistency_loss: 0.0009040861623361707\n",
      "[Training] Epoch: 1 [=========>     ] 60.3% Loss: 0.9550, Epoch 1, Batch 75, CE_loss: 0.7444144487380981, Dice_loss: 0.13266384601593018, Consistency_loss: 1.2495077498897444e-05\n",
      "[Training] Epoch: 1 [=========>     ] 61.1% Loss: 0.9542, Epoch 1, Batch 76, CE_loss: 0.758267343044281, Dice_loss: 0.13547906279563904, Consistency_loss: 0.0008168701315298676\n",
      "[Training] Epoch: 1 [=========>     ] 61.9% Loss: 0.9533, Epoch 1, Batch 77, CE_loss: 0.7441136240959167, Dice_loss: 0.13247895240783691, Consistency_loss: 0.000858665385749191\n",
      "[Training] Epoch: 1 [=========>     ] 62.7% Loss: 0.9525, Epoch 1, Batch 78, CE_loss: 0.7571983933448792, Dice_loss: 0.1350719928741455, Consistency_loss: 1.9248593162046745e-05\n",
      "[Training] Epoch: 1 [=========>     ] 63.5% Loss: 0.9518, Epoch 1, Batch 79, CE_loss: 0.7590872645378113, Dice_loss: 0.13515083491802216, Consistency_loss: 0.0007204791763797402\n",
      "[Training] Epoch: 1 [=========>     ] 64.3% Loss: 0.9512, Epoch 1, Batch 80, CE_loss: 0.7659593820571899, Dice_loss: 0.1364993005990982, Consistency_loss: 0.0007823288324289024\n",
      "[Training] Epoch: 1 [=========>     ] 65.1% Loss: 0.9505, Epoch 1, Batch 81, CE_loss: 0.7593509554862976, Dice_loss: 0.1355961114168167, Consistency_loss: 0.0008206019410863519\n",
      "[Training] Epoch: 1 [=========>     ] 65.9% Loss: 0.9498, Epoch 1, Batch 82, CE_loss: 0.756747305393219, Dice_loss: 0.13504895567893982, Consistency_loss: 2.3615530153620057e-05\n",
      "[Training] Epoch: 1 [==========>    ] 66.7% Loss: 0.9491, Epoch 1, Batch 83, CE_loss: 0.7549286484718323, Dice_loss: 0.1340763419866562, Consistency_loss: 0.000916475139092654\n",
      "[Training] Epoch: 1 [==========>    ] 67.5% Loss: 0.9482, Epoch 1, Batch 84, CE_loss: 0.7451007962226868, Dice_loss: 0.13270673155784607, Consistency_loss: 0.0007325298502109945\n",
      "[Training] Epoch: 1 [==========>    ] 68.3% Loss: 0.9476, Epoch 1, Batch 85, CE_loss: 0.7561807036399841, Dice_loss: 0.134743794798851, Consistency_loss: 0.0009233361924998462\n",
      "[Training] Epoch: 1 [==========>    ] 69.0% Loss: 0.9469, Epoch 1, Batch 86, CE_loss: 0.7532706260681152, Dice_loss: 0.1338459700345993, Consistency_loss: 0.0006291930330917239\n",
      "[Training] Epoch: 1 [==========>    ] 69.8% Loss: 0.9461, Epoch 1, Batch 87, CE_loss: 0.7420995235443115, Dice_loss: 0.13203564286231995, Consistency_loss: 1.474589680583449e-05\n",
      "[Training] Epoch: 1 [==========>    ] 70.6% Loss: 0.9454, Epoch 1, Batch 88, CE_loss: 0.7511113882064819, Dice_loss: 0.13332605361938477, Consistency_loss: 0.0009658289491198957\n",
      "[Training] Epoch: 1 [==========>    ] 71.4% Loss: 0.9447, Epoch 1, Batch 89, CE_loss: 0.7454679608345032, Dice_loss: 0.13266143202781677, Consistency_loss: 0.0007352325483225286\n",
      "[Training] Epoch: 1 [==========>    ] 72.2% Loss: 0.9438, Epoch 1, Batch 90, CE_loss: 0.7378371357917786, Dice_loss: 0.1304764449596405, Consistency_loss: 2.7496105758473277e-05\n",
      "[Training] Epoch: 1 [==========>    ] 73.0% Loss: 0.9431, Epoch 1, Batch 91, CE_loss: 0.7413622736930847, Dice_loss: 0.13150574266910553, Consistency_loss: 0.000966668885666877\n",
      "[Training] Epoch: 1 [===========>   ] 73.8% Loss: 0.9426, Epoch 1, Batch 92, CE_loss: 0.7636693120002747, Dice_loss: 0.13558410108089447, Consistency_loss: 0.000997004914097488\n",
      "[Training] Epoch: 1 [===========>   ] 74.6% Loss: 0.9420, Epoch 1, Batch 93, CE_loss: 0.7497071623802185, Dice_loss: 0.1331339180469513, Consistency_loss: 0.0009305332787334919\n",
      "[Training] Epoch: 1 [===========>   ] 75.4% Loss: 0.9413, Epoch 1, Batch 94, CE_loss: 0.7428048849105835, Dice_loss: 0.13181103765964508, Consistency_loss: 1.0529028259043116e-05\n",
      "[Training] Epoch: 1 [===========>   ] 76.2% Loss: 0.9405, Epoch 1, Batch 95, CE_loss: 0.7342545986175537, Dice_loss: 0.12999314069747925, Consistency_loss: 0.0009333166526630521\n",
      "[Training] Epoch: 1 [===========>   ] 77.0% Loss: 0.9399, Epoch 1, Batch 96, CE_loss: 0.7495248317718506, Dice_loss: 0.1329692304134369, Consistency_loss: 0.0009634014568291605\n",
      "[Training] Epoch: 1 [===========>   ] 77.8% Loss: 0.9394, Epoch 1, Batch 97, CE_loss: 0.7545998096466064, Dice_loss: 0.1339137852191925, Consistency_loss: 0.0008191863889805973\n",
      "[Training] Epoch: 1 [===========>   ] 78.6% Loss: 0.9387, Epoch 1, Batch 98, CE_loss: 0.7454520463943481, Dice_loss: 0.1317984163761139, Consistency_loss: 0.0009203031659126282\n",
      "[Training] Epoch: 1 [===========>   ] 79.4% Loss: 0.9382, Epoch 1, Batch 99, CE_loss: 0.7487256526947021, Dice_loss: 0.1329411268234253, Consistency_loss: 0.000871760246809572\n",
      "[Training] Epoch: 1 [============>  ] 80.2% Loss: 0.9375, Epoch 1, Batch 100, CE_loss: 0.7403628826141357, Dice_loss: 0.1312299370765686, Consistency_loss: 4.499638180277543e-06\n",
      "[Training] Epoch: 1 [============>  ] 81.0% Loss: 0.9370, Epoch 1, Batch 101, CE_loss: 0.7474803924560547, Dice_loss: 0.13258135318756104, Consistency_loss: 9.789654541236814e-06\n",
      "[Training] Epoch: 1 [============>  ] 81.7% Loss: 0.9364, Epoch 1, Batch 102, CE_loss: 0.7475705146789551, Dice_loss: 0.13216540217399597, Consistency_loss: 0.0009429319179616868\n",
      "[Training] Epoch: 1 [============>  ] 82.5% Loss: 0.9358, Epoch 1, Batch 103, CE_loss: 0.7409905195236206, Dice_loss: 0.13098692893981934, Consistency_loss: 0.0006519939634017646\n",
      "[Training] Epoch: 1 [============>  ] 83.3% Loss: 0.9353, Epoch 1, Batch 104, CE_loss: 0.7460455298423767, Dice_loss: 0.1319059133529663, Consistency_loss: 0.000928735826164484\n",
      "[Training] Epoch: 1 [============>  ] 84.1% Loss: 0.9345, Epoch 1, Batch 105, CE_loss: 0.7247232794761658, Dice_loss: 0.1281786859035492, Consistency_loss: 0.0009750174358487129\n",
      "[Training] Epoch: 1 [============>  ] 84.9% Loss: 0.9338, Epoch 1, Batch 106, CE_loss: 0.7336441874504089, Dice_loss: 0.12949205935001373, Consistency_loss: 2.310433228558395e-05\n",
      "[Training] Epoch: 1 [============>  ] 85.7% Loss: 0.9331, Epoch 1, Batch 107, CE_loss: 0.7245779037475586, Dice_loss: 0.12762027978897095, Consistency_loss: 0.000895334524102509\n",
      "[Training] Epoch: 1 [============>  ] 86.5% Loss: 0.9324, Epoch 1, Batch 108, CE_loss: 0.7322583794593811, Dice_loss: 0.12881916761398315, Consistency_loss: 0.0009170548291876912\n",
      "[Training] Epoch: 1 [=============> ] 87.3% Loss: 0.9318, Epoch 1, Batch 109, CE_loss: 0.7329496145248413, Dice_loss: 0.12923647463321686, Consistency_loss: 0.0008492795168422163\n",
      "[Training] Epoch: 1 [=============> ] 88.1% Loss: 0.9313, Epoch 1, Batch 110, CE_loss: 0.7399083375930786, Dice_loss: 0.13024993240833282, Consistency_loss: 0.0011640343582257628\n",
      "[Training] Epoch: 1 [=============> ] 88.9% Loss: 0.9307, Epoch 1, Batch 111, CE_loss: 0.7355790138244629, Dice_loss: 0.12969061732292175, Consistency_loss: 2.5211431420757435e-05\n",
      "[Training] Epoch: 1 [=============> ] 89.7% Loss: 0.9301, Epoch 1, Batch 112, CE_loss: 0.7397598028182983, Dice_loss: 0.13102418184280396, Consistency_loss: 2.1037185433669947e-05\n",
      "[Training] Epoch: 1 [=============> ] 90.5% Loss: 0.9294, Epoch 1, Batch 113, CE_loss: 0.7221968173980713, Dice_loss: 0.12709495425224304, Consistency_loss: 0.0010339312721043825\n",
      "[Training] Epoch: 1 [=============> ] 91.3% Loss: 0.9288, Epoch 1, Batch 114, CE_loss: 0.7264337539672852, Dice_loss: 0.12812474370002747, Consistency_loss: 0.0009133263374678791\n",
      "[Training] Epoch: 1 [=============> ] 92.1% Loss: 0.9281, Epoch 1, Batch 115, CE_loss: 0.7213869690895081, Dice_loss: 0.12729895114898682, Consistency_loss: 4.880383494310081e-05\n",
      "[Training] Epoch: 1 [=============> ] 92.9% Loss: 0.9274, Epoch 1, Batch 116, CE_loss: 0.7176061272621155, Dice_loss: 0.1262199729681015, Consistency_loss: 1.3388574188866187e-05\n",
      "[Training] Epoch: 1 [==============>] 93.7% Loss: 0.9267, Epoch 1, Batch 117, CE_loss: 0.717938244342804, Dice_loss: 0.12622562050819397, Consistency_loss: 0.0009536032448522747\n",
      "[Training] Epoch: 1 [==============>] 94.4% Loss: 0.9261, Epoch 1, Batch 118, CE_loss: 0.730643630027771, Dice_loss: 0.12853631377220154, Consistency_loss: 5.940253231528914e-06\n",
      "[Training] Epoch: 1 [==============>] 95.2% Loss: 0.9254, Epoch 1, Batch 119, CE_loss: 0.7174609303474426, Dice_loss: 0.12608030438423157, Consistency_loss: 0.0009958295850083232\n",
      "[Training] Epoch: 1 [==============>] 96.0% Loss: 0.9249, Epoch 1, Batch 120, CE_loss: 0.7298694849014282, Dice_loss: 0.12910978496074677, Consistency_loss: 0.0008308303658850491\n",
      "[Training] Epoch: 1 [==============>] 96.8% Loss: 0.9243, Epoch 1, Batch 121, CE_loss: 0.7207509875297546, Dice_loss: 0.12664568424224854, Consistency_loss: 4.283355883671902e-05\n",
      "[Training] Epoch: 1 [==============>] 97.6% Loss: 0.9237, Epoch 1, Batch 122, CE_loss: 0.7221122980117798, Dice_loss: 0.12695705890655518, Consistency_loss: 0.0007013510912656784\n",
      "[Training] Epoch: 1 [==============>] 98.4% Loss: 0.9230, Epoch 1, Batch 123, CE_loss: 0.718352735042572, Dice_loss: 0.12617263197898865, Consistency_loss: 0.0010311369551345706\n",
      "[Training] Epoch: 1 [==============>] 99.2% Loss: 0.9224, Epoch 1, Batch 124, CE_loss: 0.7143386602401733, Dice_loss: 0.12529297173023224, Consistency_loss: 0.0008277712622657418\n",
      "[Training] Epoch: 1 [DONE]                                 \n",
      "Epoch 1, Batch 125, CE_loss: 0.7167771458625793, Dice_loss: 0.12513339519500732, Consistency_loss: 0.0011725815711542964\n",
      "[Validation] Epoch: 1 [DONE]                                 \n",
      "[Epoch: 1, TrainLoss: 0.9217, TrainDice: 0.1401, ValLoss: 0.9600                                             \n",
      "Number of batches:  126\n",
      "[Training] Epoch: 2 [>              ] 0.8% Loss: 0.8388, Epoch 2, Batch 0, CE_loss: 0.7137429714202881, Dice_loss: 0.1250506341457367, Consistency_loss: 1.1481221008580178e-05\n",
      "[Training] Epoch: 2 [>              ] 1.6% Loss: 0.8382, Epoch 2, Batch 1, CE_loss: 0.7121933698654175, Dice_loss: 0.12460050731897354, Consistency_loss: 0.0008973405929282308\n",
      "[Training] Epoch: 2 [>              ] 2.4% Loss: 0.8369, Epoch 2, Batch 2, CE_loss: 0.7089722156524658, Dice_loss: 0.12426473945379257, Consistency_loss: 0.001033647102303803\n",
      "[Training] Epoch: 2 [>              ] 3.2% Loss: 0.8331, Epoch 2, Batch 3, CE_loss: 0.6983716487884521, Dice_loss: 0.12210286408662796, Consistency_loss: 0.0010459758341312408\n",
      "[Training] Epoch: 2 [>              ] 4.0% Loss: 0.8340, Epoch 2, Batch 4, CE_loss: 0.7125269770622253, Dice_loss: 0.12415086477994919, Consistency_loss: 0.0009726515272632241\n",
      "[Training] Epoch: 2 [>              ] 4.8% Loss: 0.8343, Epoch 2, Batch 5, CE_loss: 0.7105408906936646, Dice_loss: 0.12441330403089523, Consistency_loss: 0.0011654479894787073\n",
      "[Training] Epoch: 2 [>              ] 5.6% Loss: 0.8332, Epoch 2, Batch 6, CE_loss: 0.7031094431877136, Dice_loss: 0.12252653390169144, Consistency_loss: 0.0008926998707465827\n",
      "[Training] Epoch: 2 [>              ] 6.3% Loss: 0.8342, Epoch 2, Batch 7, CE_loss: 0.7152471542358398, Dice_loss: 0.12483074516057968, Consistency_loss: 0.0011839442886412144\n",
      "[Training] Epoch: 2 [=>             ] 7.1% Loss: 0.8328, Epoch 2, Batch 8, CE_loss: 0.6978718042373657, Dice_loss: 0.12204089015722275, Consistency_loss: 0.0009971470572054386\n",
      "[Training] Epoch: 2 [=>             ] 7.9% Loss: 0.8321, Epoch 2, Batch 9, CE_loss: 0.703591525554657, Dice_loss: 0.12292065471410751, Consistency_loss: 3.04253426293144e-05\n",
      "[Training] Epoch: 2 [=>             ] 8.7% Loss: 0.8320, Epoch 2, Batch 10, CE_loss: 0.7063350677490234, Dice_loss: 0.12338091433048248, Consistency_loss: 0.0008760993368923664\n",
      "[Training] Epoch: 2 [=>             ] 9.5% Loss: 0.8314, Epoch 2, Batch 11, CE_loss: 0.7011840343475342, Dice_loss: 0.12230626493692398, Consistency_loss: 0.001090413425117731\n",
      "[Training] Epoch: 2 [=>             ] 10.3% Loss: 0.8314, Epoch 2, Batch 12, CE_loss: 0.7073830962181091, Dice_loss: 0.12352218478918076, Consistency_loss: 0.0008380453218705952\n",
      "[Training] Epoch: 2 [=>             ] 11.1% Loss: 0.8304, Epoch 2, Batch 13, CE_loss: 0.695209801197052, Dice_loss: 0.1206527054309845, Consistency_loss: 0.0010684868320822716\n",
      "[Training] Epoch: 2 [=>             ] 11.9% Loss: 0.8304, Epoch 2, Batch 14, CE_loss: 0.7075068354606628, Dice_loss: 0.1235947236418724, Consistency_loss: 1.1342570360284299e-05\n",
      "[Training] Epoch: 2 [=>             ] 12.7% Loss: 0.8302, Epoch 2, Batch 15, CE_loss: 0.7035931944847107, Dice_loss: 0.12256016582250595, Consistency_loss: 0.0008781664073467255\n",
      "[Training] Epoch: 2 [==>            ] 13.5% Loss: 0.8293, Epoch 2, Batch 16, CE_loss: 0.6939324140548706, Dice_loss: 0.12068421393632889, Consistency_loss: 0.0007163301925174892\n",
      "[Training] Epoch: 2 [==>            ] 14.3% Loss: 0.8288, Epoch 2, Batch 17, CE_loss: 0.6973987221717834, Dice_loss: 0.1212349683046341, Consistency_loss: 0.0009551774710416794\n",
      "[Training] Epoch: 2 [==>            ] 15.1% Loss: 0.8282, Epoch 2, Batch 18, CE_loss: 0.6966663002967834, Dice_loss: 0.12075750529766083, Consistency_loss: 0.0009025337058119476\n",
      "[Training] Epoch: 2 [==>            ] 15.9% Loss: 0.8281, Epoch 2, Batch 19, CE_loss: 0.7028732895851135, Dice_loss: 0.1223163902759552, Consistency_loss: 0.0007275989628396928\n",
      "[Training] Epoch: 2 [==>            ] 16.7% Loss: 0.8276, Epoch 2, Batch 20, CE_loss: 0.6964170932769775, Dice_loss: 0.12158031016588211, Consistency_loss: 2.3886916096671484e-05\n",
      "[Training] Epoch: 2 [==>            ] 17.5% Loss: 0.8267, Epoch 2, Batch 21, CE_loss: 0.6877614259719849, Dice_loss: 0.11915353685617447, Consistency_loss: 0.0009883374441415071\n",
      "[Training] Epoch: 2 [==>            ] 18.3% Loss: 0.8256, Epoch 2, Batch 22, CE_loss: 0.6810048818588257, Dice_loss: 0.11806251853704453, Consistency_loss: 0.001103979186154902\n",
      "[Training] Epoch: 2 [==>            ] 19.0% Loss: 0.8247, Epoch 2, Batch 23, CE_loss: 0.6840528845787048, Dice_loss: 0.1185738742351532, Consistency_loss: 0.0008593361126258969\n",
      "[Training] Epoch: 2 [==>            ] 19.8% Loss: 0.8241, Epoch 2, Batch 24, CE_loss: 0.6910791993141174, Dice_loss: 0.11956459283828735, Consistency_loss: 2.3612939912709408e-05\n",
      "[Training] Epoch: 2 [===>           ] 20.6% Loss: 0.8233, Epoch 2, Batch 25, CE_loss: 0.6845895051956177, Dice_loss: 0.11835787445306778, Consistency_loss: 2.5553015802870505e-05\n",
      "[Training] Epoch: 2 [===>           ] 21.4% Loss: 0.8225, Epoch 2, Batch 26, CE_loss: 0.683769941329956, Dice_loss: 0.1179732158780098, Consistency_loss: 0.0010076959151774645\n",
      "[Training] Epoch: 2 [===>           ] 22.2% Loss: 0.8214, Epoch 2, Batch 27, CE_loss: 0.6748849749565125, Dice_loss: 0.11657527834177017, Consistency_loss: 3.17412122967653e-05\n",
      "[Training] Epoch: 2 [===>           ] 23.0% Loss: 0.8206, Epoch 2, Batch 28, CE_loss: 0.6786871552467346, Dice_loss: 0.1171654686331749, Consistency_loss: 0.0009128077072091401\n",
      "[Training] Epoch: 2 [===>           ] 23.8% Loss: 0.8198, Epoch 2, Batch 29, CE_loss: 0.6787328720092773, Dice_loss: 0.11749526113271713, Consistency_loss: 0.0010490468703210354\n",
      "[Training] Epoch: 2 [===>           ] 24.6% Loss: 0.8196, Epoch 2, Batch 30, CE_loss: 0.6939048767089844, Dice_loss: 0.1206199899315834, Consistency_loss: 1.280992273677839e-05\n",
      "[Training] Epoch: 2 [===>           ] 25.4% Loss: 0.8191, Epoch 2, Batch 31, CE_loss: 0.6824158430099487, Dice_loss: 0.11797598749399185, Consistency_loss: 0.000968601496424526\n",
      "[Training] Epoch: 2 [===>           ] 26.2% Loss: 0.8187, Epoch 2, Batch 32, CE_loss: 0.687846302986145, Dice_loss: 0.1187192052602768, Consistency_loss: 0.0010371280368417501\n",
      "[Training] Epoch: 2 [====>          ] 27.0% Loss: 0.8184, Epoch 2, Batch 33, CE_loss: 0.6881780624389648, Dice_loss: 0.11892121285200119, Consistency_loss: 0.0011310505215078592\n",
      "[Training] Epoch: 2 [====>          ] 27.8% Loss: 0.8179, Epoch 2, Batch 34, CE_loss: 0.6813554763793945, Dice_loss: 0.11781532317399979, Consistency_loss: 0.0011190026998519897\n",
      "[Training] Epoch: 2 [====>          ] 28.6% Loss: 0.8176, Epoch 2, Batch 35, CE_loss: 0.6871367692947388, Dice_loss: 0.11881367117166519, Consistency_loss: 0.0013211973709985614\n",
      "[Training] Epoch: 2 [====>          ] 29.4% Loss: 0.8169, Epoch 2, Batch 36, CE_loss: 0.6752439141273499, Dice_loss: 0.11643069237470627, Consistency_loss: 0.001281195436604321\n",
      "[Training] Epoch: 2 [====>          ] 30.2% Loss: 0.8161, Epoch 2, Batch 37, CE_loss: 0.6702152490615845, Dice_loss: 0.11527840048074722, Consistency_loss: 0.0012404666049405932\n",
      "[Training] Epoch: 2 [====>          ] 31.0% Loss: 0.8155, Epoch 2, Batch 38, CE_loss: 0.6745408177375793, Dice_loss: 0.116009421646595, Consistency_loss: 0.0010908853728324175\n",
      "[Training] Epoch: 2 [====>          ] 31.7% Loss: 0.8148, Epoch 2, Batch 39, CE_loss: 0.6696792840957642, Dice_loss: 0.11533057689666748, Consistency_loss: 0.0010147042339667678\n",
      "[Training] Epoch: 2 [====>          ] 32.5% Loss: 0.8145, Epoch 2, Batch 40, CE_loss: 0.6858646273612976, Dice_loss: 0.1182556077837944, Consistency_loss: 0.0010079581988975406\n",
      "[Training] Epoch: 2 [=====>         ] 33.3% Loss: 0.8139, Epoch 2, Batch 41, CE_loss: 0.6725817322731018, Dice_loss: 0.11550939828157425, Consistency_loss: 3.4682496334426105e-05\n",
      "[Training] Epoch: 2 [=====>         ] 34.1% Loss: 0.8132, Epoch 2, Batch 42, CE_loss: 0.668194055557251, Dice_loss: 0.11491567641496658, Consistency_loss: 0.0011245144996792078\n",
      "[Training] Epoch: 2 [=====>         ] 34.9% Loss: 0.8125, Epoch 2, Batch 43, CE_loss: 0.6683729290962219, Dice_loss: 0.11457463353872299, Consistency_loss: 0.0010064947418868542\n",
      "[Training] Epoch: 2 [=====>         ] 35.7% Loss: 0.8117, Epoch 2, Batch 44, CE_loss: 0.6597892642021179, Dice_loss: 0.11293553560972214, Consistency_loss: 0.0013052599970251322\n",
      "[Training] Epoch: 2 [=====>         ] 36.5% Loss: 0.8109, Epoch 2, Batch 45, CE_loss: 0.6610518097877502, Dice_loss: 0.11332143843173981, Consistency_loss: 0.0009784569265320897\n",
      "[Training] Epoch: 2 [=====>         ] 37.3% Loss: 0.8102, Epoch 2, Batch 46, CE_loss: 0.6643761992454529, Dice_loss: 0.11398961395025253, Consistency_loss: 2.160412259399891e-05\n",
      "[Training] Epoch: 2 [=====>         ] 38.1% Loss: 0.8094, Epoch 2, Batch 47, CE_loss: 0.6570696234703064, Dice_loss: 0.1123538687825203, Consistency_loss: 0.0009742929833009839\n",
      "[Training] Epoch: 2 [=====>         ] 38.9% Loss: 0.8087, Epoch 2, Batch 48, CE_loss: 0.6620631814002991, Dice_loss: 0.11341477185487747, Consistency_loss: 0.0009924342157319188\n",
      "[Training] Epoch: 2 [=====>         ] 39.7% Loss: 0.8081, Epoch 2, Batch 49, CE_loss: 0.6622616648674011, Dice_loss: 0.11356080323457718, Consistency_loss: 1.672736652835738e-05\n",
      "[Training] Epoch: 2 [======>        ] 40.5% Loss: 0.8076, Epoch 2, Batch 50, CE_loss: 0.6708194017410278, Dice_loss: 0.11498695611953735, Consistency_loss: 2.4402557755820453e-05\n",
      "[Training] Epoch: 2 [======>        ] 41.3% Loss: 0.8069, Epoch 2, Batch 51, CE_loss: 0.6583989858627319, Dice_loss: 0.11323122680187225, Consistency_loss: 0.001075303996913135\n",
      "[Training] Epoch: 2 [======>        ] 42.1% Loss: 0.8062, Epoch 2, Batch 52, CE_loss: 0.6540948748588562, Dice_loss: 0.11169137060642242, Consistency_loss: 1.6995725673041306e-05\n",
      "[Training] Epoch: 2 [======>        ] 42.9% Loss: 0.8058, Epoch 2, Batch 53, CE_loss: 0.6689887046813965, Dice_loss: 0.11485815048217773, Consistency_loss: 0.0009589694673195481\n",
      "[Training] Epoch: 2 [======>        ] 43.7% Loss: 0.8052, Epoch 2, Batch 54, CE_loss: 0.6588732600212097, Dice_loss: 0.11304179579019547, Consistency_loss: 8.068045644904487e-06\n",
      "[Training] Epoch: 2 [======>        ] 44.4% Loss: 0.8049, Epoch 2, Batch 55, CE_loss: 0.6740607619285583, Dice_loss: 0.11560223251581192, Consistency_loss: 0.0008106237510219216\n",
      "[Training] Epoch: 2 [======>        ] 45.2% Loss: 0.8041, Epoch 2, Batch 56, CE_loss: 0.6508166790008545, Dice_loss: 0.11107700318098068, Consistency_loss: 7.143441962398356e-06\n",
      "[Training] Epoch: 2 [======>        ] 46.0% Loss: 0.8034, Epoch 2, Batch 57, CE_loss: 0.651854932308197, Dice_loss: 0.11113736033439636, Consistency_loss: 1.8800681573338807e-05\n",
      "[Training] Epoch: 2 [=======>       ] 46.8% Loss: 0.8029, Epoch 2, Batch 58, CE_loss: 0.6583925485610962, Dice_loss: 0.11308791488409042, Consistency_loss: 2.6921477910946123e-05\n",
      "[Training] Epoch: 2 [=======>       ] 47.6% Loss: 0.8022, Epoch 2, Batch 59, CE_loss: 0.6473660469055176, Dice_loss: 0.1106635332107544, Consistency_loss: 0.0011668013175949454\n",
      "[Training] Epoch: 2 [=======>       ] 48.4% Loss: 0.8015, Epoch 2, Batch 60, CE_loss: 0.6484389305114746, Dice_loss: 0.11047729849815369, Consistency_loss: 4.296695624361746e-05\n",
      "[Training] Epoch: 2 [=======>       ] 49.2% Loss: 0.8010, Epoch 2, Batch 61, CE_loss: 0.6589488387107849, Dice_loss: 0.11218854784965515, Consistency_loss: 0.000868820701725781\n",
      "[Training] Epoch: 2 [=======>       ] 50.0% Loss: 0.8001, Epoch 2, Batch 62, CE_loss: 0.6384497880935669, Dice_loss: 0.10849208384752274, Consistency_loss: 0.0010829452658072114\n",
      "[Training] Epoch: 2 [=======>       ] 50.8% Loss: 0.7995, Epoch 2, Batch 63, CE_loss: 0.647138774394989, Dice_loss: 0.11007053405046463, Consistency_loss: 0.0009205975802615285\n",
      "[Training] Epoch: 2 [=======>       ] 51.6% Loss: 0.7987, Epoch 2, Batch 64, CE_loss: 0.6421594023704529, Dice_loss: 0.10860588401556015, Consistency_loss: 1.4565047422365751e-05\n",
      "[Training] Epoch: 2 [=======>       ] 52.4% Loss: 0.7979, Epoch 2, Batch 65, CE_loss: 0.6335320472717285, Dice_loss: 0.10754340887069702, Consistency_loss: 0.0008517535752616823\n",
      "[Training] Epoch: 2 [=======>       ] 53.2% Loss: 0.7972, Epoch 2, Batch 66, CE_loss: 0.644232988357544, Dice_loss: 0.10931098461151123, Consistency_loss: 0.0009530223906040192\n",
      "[Training] Epoch: 2 [========>      ] 54.0% Loss: 0.7967, Epoch 2, Batch 67, CE_loss: 0.6507905721664429, Dice_loss: 0.11072935909032822, Consistency_loss: 0.0010286548640578985\n",
      "[Training] Epoch: 2 [========>      ] 54.8% Loss: 0.7962, Epoch 2, Batch 68, CE_loss: 0.6513825058937073, Dice_loss: 0.1106661856174469, Consistency_loss: 3.025589649041649e-05\n",
      "[Training] Epoch: 2 [========>      ] 55.6% Loss: 0.7956, Epoch 2, Batch 69, CE_loss: 0.6460872292518616, Dice_loss: 0.10933221876621246, Consistency_loss: 0.0009133726707659662\n",
      "[Training] Epoch: 2 [========>      ] 56.3% Loss: 0.7948, Epoch 2, Batch 70, CE_loss: 0.6292548179626465, Dice_loss: 0.10620015114545822, Consistency_loss: 0.0010550747392699122\n",
      "[Training] Epoch: 2 [========>      ] 57.1% Loss: 0.7940, Epoch 2, Batch 71, CE_loss: 0.6290192604064941, Dice_loss: 0.10604093968868256, Consistency_loss: 0.0009657744667492807\n",
      "[Training] Epoch: 2 [========>      ] 57.9% Loss: 0.7934, Epoch 2, Batch 72, CE_loss: 0.6386421322822571, Dice_loss: 0.10803855210542679, Consistency_loss: 0.000909718219190836\n",
      "[Training] Epoch: 2 [========>      ] 58.7% Loss: 0.7926, Epoch 2, Batch 73, CE_loss: 0.6270133852958679, Dice_loss: 0.10607745498418808, Consistency_loss: 0.0008486310252919793\n",
      "[Training] Epoch: 2 [========>      ] 59.5% Loss: 0.7919, Epoch 2, Batch 74, CE_loss: 0.6359649300575256, Dice_loss: 0.10694216936826706, Consistency_loss: 0.0008112579816952348\n",
      "[Training] Epoch: 2 [=========>     ] 60.3% Loss: 0.7911, Epoch 2, Batch 75, CE_loss: 0.6227307319641113, Dice_loss: 0.10509014874696732, Consistency_loss: 9.545005923428107e-06\n",
      "[Training] Epoch: 2 [=========>     ] 61.1% Loss: 0.7903, Epoch 2, Batch 76, CE_loss: 0.6287928223609924, Dice_loss: 0.10629306733608246, Consistency_loss: 0.0007793859113007784\n",
      "[Training] Epoch: 2 [=========>     ] 61.9% Loss: 0.7895, Epoch 2, Batch 77, CE_loss: 0.620648980140686, Dice_loss: 0.1045985221862793, Consistency_loss: 0.0007596450159326196\n",
      "[Training] Epoch: 2 [=========>     ] 62.7% Loss: 0.7887, Epoch 2, Batch 78, CE_loss: 0.623103678226471, Dice_loss: 0.10482782870531082, Consistency_loss: 0.0006437384872697294\n",
      "[Training] Epoch: 2 [=========>     ] 63.5% Loss: 0.7879, Epoch 2, Batch 79, CE_loss: 0.6180678009986877, Dice_loss: 0.10378702729940414, Consistency_loss: 0.0008799933711998165\n",
      "[Training] Epoch: 2 [=========>     ] 64.3% Loss: 0.7870, Epoch 2, Batch 80, CE_loss: 0.6123806238174438, Dice_loss: 0.10261509567499161, Consistency_loss: 1.2270999832253437e-05\n",
      "[Training] Epoch: 2 [=========>     ] 65.1% Loss: 0.7861, Epoch 2, Batch 81, CE_loss: 0.6066994667053223, Dice_loss: 0.10149554163217545, Consistency_loss: 0.0006617600447498262\n",
      "[Training] Epoch: 2 [=========>     ] 65.9% Loss: 0.7853, Epoch 2, Batch 82, CE_loss: 0.6162549257278442, Dice_loss: 0.1033109724521637, Consistency_loss: 0.0008177109993994236\n",
      "[Training] Epoch: 2 [==========>    ] 66.7% Loss: 0.7845, Epoch 2, Batch 83, CE_loss: 0.6169335246086121, Dice_loss: 0.10350845009088516, Consistency_loss: 0.0008489728788845241\n",
      "[Training] Epoch: 2 [==========>    ] 67.5% Loss: 0.7838, Epoch 2, Batch 84, CE_loss: 0.6212651133537292, Dice_loss: 0.10437121242284775, Consistency_loss: 0.0009443453745916486\n",
      "[Training] Epoch: 2 [==========>    ] 68.3% Loss: 0.7830, Epoch 2, Batch 85, CE_loss: 0.612395167350769, Dice_loss: 0.10268258303403854, Consistency_loss: 0.0008216762798838317\n",
      "[Training] Epoch: 2 [==========>    ] 69.0% Loss: 0.7823, Epoch 2, Batch 86, CE_loss: 0.6125680208206177, Dice_loss: 0.10260120779275894, Consistency_loss: 3.0451235943473876e-05\n",
      "[Training] Epoch: 2 [==========>    ] 69.8% Loss: 0.7815, Epoch 2, Batch 87, CE_loss: 0.6148977279663086, Dice_loss: 0.1029319018125534, Consistency_loss: 0.0008479044190607965\n",
      "[Training] Epoch: 2 [==========>    ] 70.6% Loss: 0.7808, Epoch 2, Batch 88, CE_loss: 0.6093568205833435, Dice_loss: 0.101822130382061, Consistency_loss: 0.0005074168439023197\n",
      "[Training] Epoch: 2 [==========>    ] 71.4% Loss: 0.7801, Epoch 2, Batch 89, CE_loss: 0.6199619770050049, Dice_loss: 0.10427102446556091, Consistency_loss: 0.000823223905172199\n",
      "[Training] Epoch: 2 [==========>    ] 72.2% Loss: 0.7794, Epoch 2, Batch 90, CE_loss: 0.6103470921516418, Dice_loss: 0.10221310704946518, Consistency_loss: 0.0008303752401843667\n",
      "[Training] Epoch: 2 [==========>    ] 73.0% Loss: 0.7787, Epoch 2, Batch 91, CE_loss: 0.6116832494735718, Dice_loss: 0.10249241441488266, Consistency_loss: 3.892940731020644e-05\n",
      "[Training] Epoch: 2 [===========>   ] 73.8% Loss: 0.7779, Epoch 2, Batch 92, CE_loss: 0.6006266474723816, Dice_loss: 0.10018069297075272, Consistency_loss: 0.0008276502485387027\n",
      "[Training] Epoch: 2 [===========>   ] 74.6% Loss: 0.7770, Epoch 2, Batch 93, CE_loss: 0.599599301815033, Dice_loss: 0.10001204907894135, Consistency_loss: 0.0007515721372328699\n",
      "[Training] Epoch: 2 [===========>   ] 75.4% Loss: 0.7763, Epoch 2, Batch 94, CE_loss: 0.6012832522392273, Dice_loss: 0.10010568052530289, Consistency_loss: 0.0008599903667345643\n",
      "[Training] Epoch: 2 [===========>   ] 76.2% Loss: 0.7755, Epoch 2, Batch 95, CE_loss: 0.6000982522964478, Dice_loss: 0.10002182424068451, Consistency_loss: 0.000875404744874686\n",
      "[Training] Epoch: 2 [===========>   ] 77.0% Loss: 0.7747, Epoch 2, Batch 96, CE_loss: 0.6032313704490662, Dice_loss: 0.09991542249917984, Consistency_loss: 0.0010364995105192065\n",
      "[Training] Epoch: 2 [===========>   ] 77.8% Loss: 0.7740, Epoch 2, Batch 97, CE_loss: 0.6012184619903564, Dice_loss: 0.09978776425123215, Consistency_loss: 0.0007159306551329792\n",
      "[Training] Epoch: 2 [===========>   ] 78.6% Loss: 0.7732, Epoch 2, Batch 98, CE_loss: 0.5954118967056274, Dice_loss: 0.0986405685544014, Consistency_loss: 0.0007321487064473331\n",
      "[Training] Epoch: 2 [===========>   ] 79.4% Loss: 0.7724, Epoch 2, Batch 99, CE_loss: 0.5949872136116028, Dice_loss: 0.09853661805391312, Consistency_loss: 0.0009198157349601388\n",
      "[Training] Epoch: 2 [============>  ] 80.2% Loss: 0.7716, Epoch 2, Batch 100, CE_loss: 0.5955007076263428, Dice_loss: 0.09868858009576797, Consistency_loss: 0.0006514675333164632\n",
      "[Training] Epoch: 2 [============>  ] 81.0% Loss: 0.7709, Epoch 2, Batch 101, CE_loss: 0.5999351739883423, Dice_loss: 0.09955650568008423, Consistency_loss: 0.0007910559070296586\n",
      "[Training] Epoch: 2 [============>  ] 81.7% Loss: 0.7703, Epoch 2, Batch 102, CE_loss: 0.6011624932289124, Dice_loss: 0.09939566254615784, Consistency_loss: 0.000478539353935048\n",
      "[Training] Epoch: 2 [============>  ] 82.5% Loss: 0.7694, Epoch 2, Batch 103, CE_loss: 0.5873503088951111, Dice_loss: 0.09676999598741531, Consistency_loss: 0.00042103888699784875\n",
      "[Training] Epoch: 2 [============>  ] 83.3% Loss: 0.7686, Epoch 2, Batch 104, CE_loss: 0.5877377986907959, Dice_loss: 0.09688452631235123, Consistency_loss: 0.0008775041787885129\n",
      "[Training] Epoch: 2 [============>  ] 84.1% Loss: 0.7679, Epoch 2, Batch 105, CE_loss: 0.5946280360221863, Dice_loss: 0.09836399555206299, Consistency_loss: 4.669203553930856e-05\n",
      "[Training] Epoch: 2 [============>  ] 84.9% Loss: 0.7671, Epoch 2, Batch 106, CE_loss: 0.5851985216140747, Dice_loss: 0.09665205329656601, Consistency_loss: 0.0008490910986438394\n",
      "[Training] Epoch: 2 [============>  ] 85.7% Loss: 0.7664, Epoch 2, Batch 107, CE_loss: 0.5870411396026611, Dice_loss: 0.09686443954706192, Consistency_loss: 0.0006668925052508712\n",
      "[Training] Epoch: 2 [============>  ] 86.5% Loss: 0.7656, Epoch 2, Batch 108, CE_loss: 0.588185727596283, Dice_loss: 0.09713046997785568, Consistency_loss: 4.4936907215742394e-05\n",
      "[Training] Epoch: 2 [=============> ] 87.3% Loss: 0.7648, Epoch 2, Batch 109, CE_loss: 0.5833310484886169, Dice_loss: 0.09599029272794724, Consistency_loss: 0.0009975287830457091\n",
      "[Training] Epoch: 2 [=============> ] 88.1% Loss: 0.7641, Epoch 2, Batch 110, CE_loss: 0.5895276069641113, Dice_loss: 0.09686896950006485, Consistency_loss: 0.000884666689671576\n",
      "[Training] Epoch: 2 [=============> ] 88.9% Loss: 0.7634, Epoch 2, Batch 111, CE_loss: 0.5814563632011414, Dice_loss: 0.09575150161981583, Consistency_loss: 0.0009901444427669048\n",
      "[Training] Epoch: 2 [=============> ] 89.7% Loss: 0.7626, Epoch 2, Batch 112, CE_loss: 0.5772095918655396, Dice_loss: 0.09471249580383301, Consistency_loss: 3.671210288302973e-05\n",
      "[Training] Epoch: 2 [=============> ] 90.5% Loss: 0.7619, Epoch 2, Batch 113, CE_loss: 0.5853829383850098, Dice_loss: 0.09654263406991959, Consistency_loss: 0.0008858982473611832\n",
      "[Training] Epoch: 2 [=============> ] 91.3% Loss: 0.7612, Epoch 2, Batch 114, CE_loss: 0.5829983353614807, Dice_loss: 0.09553708136081696, Consistency_loss: 0.0010695025557652116\n",
      "[Training] Epoch: 2 [=============> ] 92.1% Loss: 0.7604, Epoch 2, Batch 115, CE_loss: 0.5805572867393494, Dice_loss: 0.0953153520822525, Consistency_loss: 0.0005609814543277025\n",
      "[Training] Epoch: 2 [=============> ] 92.9% Loss: 0.7596, Epoch 2, Batch 116, CE_loss: 0.5747133493423462, Dice_loss: 0.09400756657123566, Consistency_loss: 3.4551991120679304e-05\n",
      "[Training] Epoch: 2 [==============>] 93.7% Loss: 0.7589, Epoch 2, Batch 117, CE_loss: 0.5753462910652161, Dice_loss: 0.09400790929794312, Consistency_loss: 0.0008910589967854321\n",
      "[Training] Epoch: 2 [==============>] 94.4% Loss: 0.7582, Epoch 2, Batch 118, CE_loss: 0.5817345380783081, Dice_loss: 0.09525591880083084, Consistency_loss: 0.0009864000603556633\n",
      "[Training] Epoch: 2 [==============>] 95.2% Loss: 0.7574, Epoch 2, Batch 119, CE_loss: 0.5716387033462524, Dice_loss: 0.09315203130245209, Consistency_loss: 0.0007397946319542825\n",
      "[Training] Epoch: 2 [==============>] 96.0% Loss: 0.7566, Epoch 2, Batch 120, CE_loss: 0.569258451461792, Dice_loss: 0.09295482933521271, Consistency_loss: 4.9693157052388415e-05\n",
      "[Training] Epoch: 2 [==============>] 96.8% Loss: 0.7559, Epoch 2, Batch 121, CE_loss: 0.5721494555473328, Dice_loss: 0.09332937747240067, Consistency_loss: 0.0012621866771951318\n",
      "[Training] Epoch: 2 [==============>] 97.6% Loss: 0.7552, Epoch 2, Batch 122, CE_loss: 0.577171802520752, Dice_loss: 0.09445905685424805, Consistency_loss: 0.0011403115931898355\n",
      "[Training] Epoch: 2 [==============>] 98.4% Loss: 0.7546, Epoch 2, Batch 123, CE_loss: 0.5808628797531128, Dice_loss: 0.09464051574468613, Consistency_loss: 3.0094359317445196e-05\n",
      "[Training] Epoch: 2 [==============>] 99.2% Loss: 0.7539, Epoch 2, Batch 124, CE_loss: 0.5754079222679138, Dice_loss: 0.09398185461759567, Consistency_loss: 0.0009780236287042499\n",
      "[Training] Epoch: 2 [DONE]                                 \n",
      "Epoch 2, Batch 125, CE_loss: 0.5596188306808472, Dice_loss: 0.09072253853082657, Consistency_loss: 0.0009472427191212773\n",
      "[Validation] Epoch: 2 [DONE]                                 \n",
      "[Epoch: 2, TrainLoss: 0.7531, TrainDice: 0.1092, ValLoss: 0.8823                                             \n",
      "Number of batches:  126\n",
      "[Training] Epoch: 3 [>              ] 0.8% Loss: 0.6728, Epoch 3, Batch 0, CE_loss: 0.5776059031486511, Dice_loss: 0.0945405587553978, Consistency_loss: 0.0006718701333738863\n",
      "[Training] Epoch: 3 [>              ] 1.6% Loss: 0.6670, Epoch 3, Batch 1, CE_loss: 0.5681610107421875, Dice_loss: 0.09237898141145706, Consistency_loss: 0.0006126320222392678\n",
      "[Training] Epoch: 3 [>              ] 2.4% Loss: 0.6672, Epoch 3, Batch 2, CE_loss: 0.5734469890594482, Dice_loss: 0.09323594719171524, Consistency_loss: 0.0008436270873062313\n",
      "[Training] Epoch: 3 [>              ] 3.2% Loss: 0.6656, Epoch 3, Batch 3, CE_loss: 0.5679076313972473, Dice_loss: 0.09239740669727325, Consistency_loss: 0.0004147012368775904\n",
      "[Training] Epoch: 3 [>              ] 4.0% Loss: 0.6632, Epoch 3, Batch 4, CE_loss: 0.5622565746307373, Dice_loss: 0.09109941869974136, Consistency_loss: 0.00046070344978943467\n",
      "[Training] Epoch: 3 [>              ] 4.8% Loss: 0.6617, Epoch 3, Batch 5, CE_loss: 0.5623654723167419, Dice_loss: 0.09099914878606796, Consistency_loss: 0.000586894282605499\n",
      "[Training] Epoch: 3 [>              ] 5.6% Loss: 0.6600, Epoch 3, Batch 6, CE_loss: 0.5587791204452515, Dice_loss: 0.09047642350196838, Consistency_loss: 0.0005945133743807673\n",
      "[Training] Epoch: 3 [>              ] 6.3% Loss: 0.6607, Epoch 3, Batch 7, CE_loss: 0.5718725323677063, Dice_loss: 0.09288632869720459, Consistency_loss: 0.000899970531463623\n",
      "[Training] Epoch: 3 [=>             ] 7.1% Loss: 0.6601, Epoch 3, Batch 8, CE_loss: 0.5627719163894653, Dice_loss: 0.09123153239488602, Consistency_loss: 0.0011813794262707233\n",
      "[Training] Epoch: 3 [=>             ] 7.9% Loss: 0.6592, Epoch 3, Batch 9, CE_loss: 0.5593169331550598, Dice_loss: 0.09031715244054794, Consistency_loss: 0.0013569928705692291\n",
      "[Training] Epoch: 3 [=>             ] 8.7% Loss: 0.6579, Epoch 3, Batch 10, CE_loss: 0.5559797883033752, Dice_loss: 0.08967150747776031, Consistency_loss: 7.17322327545844e-05\n",
      "[Training] Epoch: 3 [=>             ] 9.5% Loss: 0.6566, Epoch 3, Batch 11, CE_loss: 0.5527837872505188, Dice_loss: 0.08899743109941483, Consistency_loss: 0.00010266724711982533\n",
      "[Training] Epoch: 3 [=>             ] 10.3% Loss: 0.6566, Epoch 3, Batch 12, CE_loss: 0.5653859376907349, Dice_loss: 0.09119069576263428, Consistency_loss: 5.4561551223741844e-05\n",
      "[Training] Epoch: 3 [=>             ] 11.1% Loss: 0.6558, Epoch 3, Batch 13, CE_loss: 0.5551559925079346, Dice_loss: 0.0893978700041771, Consistency_loss: 7.54589491407387e-05\n",
      "[Training] Epoch: 3 [=>             ] 11.9% Loss: 0.6544, Epoch 3, Batch 14, CE_loss: 0.5464667081832886, Dice_loss: 0.08778930455446243, Consistency_loss: 0.0009039427968673408\n",
      "[Training] Epoch: 3 [=>             ] 12.7% Loss: 0.6543, Epoch 3, Batch 15, CE_loss: 0.5617166757583618, Dice_loss: 0.09049540758132935, Consistency_loss: 0.0010520156938582659\n",
      "[Training] Epoch: 3 [==>            ] 13.5% Loss: 0.6545, Epoch 3, Batch 16, CE_loss: 0.5651596188545227, Dice_loss: 0.09087216854095459, Consistency_loss: 0.0011987983016297221\n",
      "[Training] Epoch: 3 [==>            ] 14.3% Loss: 0.6544, Epoch 3, Batch 17, CE_loss: 0.5621567368507385, Dice_loss: 0.0901859700679779, Consistency_loss: 1.4421809282794129e-05\n",
      "[Training] Epoch: 3 [==>            ] 15.1% Loss: 0.6536, Epoch 3, Batch 18, CE_loss: 0.5506399869918823, Dice_loss: 0.08838815987110138, Consistency_loss: 0.0009010853245854378\n",
      "[Training] Epoch: 3 [==>            ] 15.9% Loss: 0.6523, Epoch 3, Batch 19, CE_loss: 0.5408051013946533, Dice_loss: 0.0863487720489502, Consistency_loss: 2.2869533495395444e-05\n",
      "[Training] Epoch: 3 [==>            ] 16.7% Loss: 0.6517, Epoch 3, Batch 20, CE_loss: 0.5514309406280518, Dice_loss: 0.08866260200738907, Consistency_loss: 0.0007802394102327526\n",
      "[Training] Epoch: 3 [==>            ] 17.5% Loss: 0.6512, Epoch 3, Batch 21, CE_loss: 0.5520739555358887, Dice_loss: 0.08820924162864685, Consistency_loss: 2.2287644242169335e-05\n",
      "[Training] Epoch: 3 [==>            ] 18.3% Loss: 0.6503, Epoch 3, Batch 22, CE_loss: 0.5438947081565857, Dice_loss: 0.08687999099493027, Consistency_loss: 5.559728742809966e-05\n",
      "[Training] Epoch: 3 [==>            ] 19.0% Loss: 0.6494, Epoch 3, Batch 23, CE_loss: 0.5412875413894653, Dice_loss: 0.08634798228740692, Consistency_loss: 5.3385516366688535e-05\n",
      "[Training] Epoch: 3 [==>            ] 19.8% Loss: 0.6492, Epoch 3, Batch 24, CE_loss: 0.554357647895813, Dice_loss: 0.08871052414178848, Consistency_loss: 0.000655275653116405\n",
      "[Training] Epoch: 3 [===>           ] 20.6% Loss: 0.6484, Epoch 3, Batch 25, CE_loss: 0.5428456664085388, Dice_loss: 0.08647912740707397, Consistency_loss: 0.0009208997944369912\n",
      "[Training] Epoch: 3 [===>           ] 21.4% Loss: 0.6478, Epoch 3, Batch 26, CE_loss: 0.5433748364448547, Dice_loss: 0.08663059771060944, Consistency_loss: 0.0009692850871942937\n",
      "[Training] Epoch: 3 [===>           ] 22.2% Loss: 0.6473, Epoch 3, Batch 27, CE_loss: 0.5448803901672363, Dice_loss: 0.08711205422878265, Consistency_loss: 0.001003064215183258\n",
      "[Training] Epoch: 3 [===>           ] 23.0% Loss: 0.6467, Epoch 3, Batch 28, CE_loss: 0.5436957478523254, Dice_loss: 0.08661618828773499, Consistency_loss: 0.0009442958398722112\n",
      "[Training] Epoch: 3 [===>           ] 23.8% Loss: 0.6460, Epoch 3, Batch 29, CE_loss: 0.5391572117805481, Dice_loss: 0.08579159528017044, Consistency_loss: 5.459631938720122e-05\n",
      "[Training] Epoch: 3 [===>           ] 24.6% Loss: 0.6455, Epoch 3, Batch 30, CE_loss: 0.543714702129364, Dice_loss: 0.08646979182958603, Consistency_loss: 0.0009340962278656662\n",
      "[Training] Epoch: 3 [===>           ] 25.4% Loss: 0.6453, Epoch 3, Batch 31, CE_loss: 0.55118727684021, Dice_loss: 0.08813747763633728, Consistency_loss: 0.0009151303092949092\n",
      "[Training] Epoch: 3 [===>           ] 26.2% Loss: 0.6450, Epoch 3, Batch 32, CE_loss: 0.5464327335357666, Dice_loss: 0.08689284324645996, Consistency_loss: 0.0009117342415265739\n",
      "[Training] Epoch: 3 [====>          ] 27.0% Loss: 0.6444, Epoch 3, Batch 33, CE_loss: 0.5382536053657532, Dice_loss: 0.08558394759893417, Consistency_loss: 0.0009739025845192373\n",
      "[Training] Epoch: 3 [====>          ] 27.8% Loss: 0.6437, Epoch 3, Batch 34, CE_loss: 0.5338939428329468, Dice_loss: 0.08457860350608826, Consistency_loss: 0.000867674418259412\n",
      "[Training] Epoch: 3 [====>          ] 28.6% Loss: 0.6432, Epoch 3, Batch 35, CE_loss: 0.5396720767021179, Dice_loss: 0.08551621437072754, Consistency_loss: 0.0009585127118043602\n",
      "[Training] Epoch: 3 [====>          ] 29.4% Loss: 0.6428, Epoch 3, Batch 36, CE_loss: 0.5418081879615784, Dice_loss: 0.08567178249359131, Consistency_loss: 0.0011499108513817191\n",
      "[Training] Epoch: 3 [====>          ] 30.2% Loss: 0.6420, Epoch 3, Batch 37, CE_loss: 0.5279585123062134, Dice_loss: 0.08366116136312485, Consistency_loss: 0.0013871300034224987\n",
      "[Training] Epoch: 3 [====>          ] 31.0% Loss: 0.6418, Epoch 3, Batch 38, CE_loss: 0.5464266538619995, Dice_loss: 0.08680503070354462, Consistency_loss: 0.0008262148476205766\n",
      "[Training] Epoch: 3 [====>          ] 31.7% Loss: 0.6413, Epoch 3, Batch 39, CE_loss: 0.5370019674301147, Dice_loss: 0.08490431308746338, Consistency_loss: 0.000811197271104902\n",
      "[Training] Epoch: 3 [====>          ] 32.5% Loss: 0.6410, Epoch 3, Batch 40, CE_loss: 0.5423119068145752, Dice_loss: 0.08588957786560059, Consistency_loss: 4.113763498025946e-05\n",
      "[Training] Epoch: 3 [=====>         ] 33.3% Loss: 0.6408, Epoch 3, Batch 41, CE_loss: 0.5461900234222412, Dice_loss: 0.08629220724105835, Consistency_loss: 0.0008552541839890182\n",
      "[Training] Epoch: 3 [=====>         ] 34.1% Loss: 0.6403, Epoch 3, Batch 42, CE_loss: 0.5319319367408752, Dice_loss: 0.08351428061723709, Consistency_loss: 0.0009366458398289979\n",
      "[Training] Epoch: 3 [=====>         ] 34.9% Loss: 0.6398, Epoch 3, Batch 43, CE_loss: 0.534515917301178, Dice_loss: 0.08397874981164932, Consistency_loss: 0.000771425839047879\n",
      "[Training] Epoch: 3 [=====>         ] 35.7% Loss: 0.6396, Epoch 3, Batch 44, CE_loss: 0.5428356528282166, Dice_loss: 0.08636938780546188, Consistency_loss: 0.0009643535013310611\n",
      "[Training] Epoch: 3 [=====>         ] 36.5% Loss: 0.6389, Epoch 3, Batch 45, CE_loss: 0.5259535908699036, Dice_loss: 0.08272499591112137, Consistency_loss: 0.0006468835636042058\n",
      "[Training] Epoch: 3 [=====>         ] 37.3% Loss: 0.6387, Epoch 3, Batch 46, CE_loss: 0.5427786707878113, Dice_loss: 0.08600547164678574, Consistency_loss: 0.0009515092824585736\n",
      "[Training] Epoch: 3 [=====>         ] 38.1% Loss: 0.6383, Epoch 3, Batch 47, CE_loss: 0.533520519733429, Dice_loss: 0.08436708897352219, Consistency_loss: 0.0010026668896898627\n",
      "[Training] Epoch: 3 [=====>         ] 38.9% Loss: 0.6379, Epoch 3, Batch 48, CE_loss: 0.5328414440155029, Dice_loss: 0.08358943462371826, Consistency_loss: 0.0008673849515616894\n",
      "[Training] Epoch: 3 [=====>         ] 39.7% Loss: 0.6373, Epoch 3, Batch 49, CE_loss: 0.5268115997314453, Dice_loss: 0.08279970288276672, Consistency_loss: 1.3206469702709e-05\n",
      "[Training] Epoch: 3 [======>        ] 40.5% Loss: 0.6369, Epoch 3, Batch 50, CE_loss: 0.531450092792511, Dice_loss: 0.08333498239517212, Consistency_loss: 0.0007984754047356546\n",
      "[Training] Epoch: 3 [======>        ] 41.3% Loss: 0.6365, Epoch 3, Batch 51, CE_loss: 0.5338034629821777, Dice_loss: 0.08373922854661942, Consistency_loss: 0.0009575315634720027\n",
      "[Training] Epoch: 3 [======>        ] 42.1% Loss: 0.6363, Epoch 3, Batch 52, CE_loss: 0.538625955581665, Dice_loss: 0.08477729558944702, Consistency_loss: 0.0010595403145998716\n",
      "[Training] Epoch: 3 [======>        ] 42.9% Loss: 0.6359, Epoch 3, Batch 53, CE_loss: 0.5301351547241211, Dice_loss: 0.08352617174386978, Consistency_loss: 0.001147690461948514\n",
      "[Training] Epoch: 3 [======>        ] 43.7% Loss: 0.6350, Epoch 3, Batch 54, CE_loss: 0.5059341788291931, Dice_loss: 0.07844951748847961, Consistency_loss: 0.0009124424541369081\n",
      "[Training] Epoch: 3 [======>        ] 44.4% Loss: 0.6344, Epoch 3, Batch 55, CE_loss: 0.520663321018219, Dice_loss: 0.08137992024421692, Consistency_loss: 0.0007185383583419025\n",
      "[Training] Epoch: 3 [======>        ] 45.2% Loss: 0.6338, Epoch 3, Batch 56, CE_loss: 0.5186722278594971, Dice_loss: 0.08108392357826233, Consistency_loss: 0.0008776718750596046\n",
      "[Training] Epoch: 3 [======>        ] 46.0% Loss: 0.6333, Epoch 3, Batch 57, CE_loss: 0.5210506319999695, Dice_loss: 0.08095932006835938, Consistency_loss: 2.3575650629936717e-05\n",
      "[Training] Epoch: 3 [=======>       ] 46.8% Loss: 0.6329, Epoch 3, Batch 58, CE_loss: 0.5262529253959656, Dice_loss: 0.08218603581190109, Consistency_loss: 0.000830568082164973\n",
      "[Training] Epoch: 3 [=======>       ] 47.6% Loss: 0.6324, Epoch 3, Batch 59, CE_loss: 0.5245129466056824, Dice_loss: 0.08164548128843307, Consistency_loss: 0.0007828209782019258\n",
      "[Training] Epoch: 3 [=======>       ] 48.4% Loss: 0.6318, Epoch 3, Batch 60, CE_loss: 0.513960063457489, Dice_loss: 0.07983552664518356, Consistency_loss: 7.226357411127537e-05\n",
      "[Training] Epoch: 3 [=======>       ] 49.2% Loss: 0.6313, Epoch 3, Batch 61, CE_loss: 0.5187847018241882, Dice_loss: 0.08085834980010986, Consistency_loss: 0.0008732720161788166\n",
      "[Training] Epoch: 3 [=======>       ] 50.0% Loss: 0.6306, Epoch 3, Batch 62, CE_loss: 0.5054513812065125, Dice_loss: 0.07810187339782715, Consistency_loss: 0.0010297870030626655\n",
      "[Training] Epoch: 3 [=======>       ] 50.8% Loss: 0.6298, Epoch 3, Batch 63, CE_loss: 0.5028441548347473, Dice_loss: 0.07747675478458405, Consistency_loss: 0.0010136344935745\n",
      "[Training] Epoch: 3 [=======>       ] 51.6% Loss: 0.6296, Epoch 3, Batch 64, CE_loss: 0.5317487120628357, Dice_loss: 0.08316528797149658, Consistency_loss: 0.0004063848464284092\n",
      "[Training] Epoch: 3 [=======>       ] 52.4% Loss: 0.6291, Epoch 3, Batch 65, CE_loss: 0.5182963013648987, Dice_loss: 0.08048433065414429, Consistency_loss: 0.0008456554496660829\n",
      "[Training] Epoch: 3 [=======>       ] 53.2% Loss: 0.6288, Epoch 3, Batch 66, CE_loss: 0.5249105095863342, Dice_loss: 0.08175978064537048, Consistency_loss: 4.123307371628471e-05\n",
      "[Training] Epoch: 3 [========>      ] 54.0% Loss: 0.6283, Epoch 3, Batch 67, CE_loss: 0.5170658826828003, Dice_loss: 0.07997791469097137, Consistency_loss: 0.0010766031919047236\n",
      "[Training] Epoch: 3 [========>      ] 54.8% Loss: 0.6281, Epoch 3, Batch 68, CE_loss: 0.5267899036407471, Dice_loss: 0.08190540224313736, Consistency_loss: 0.0010596447391435504\n",
      "[Training] Epoch: 3 [========>      ] 55.6% Loss: 0.6274, Epoch 3, Batch 69, CE_loss: 0.5046004056930542, Dice_loss: 0.07775130867958069, Consistency_loss: 0.0007294833776541054\n",
      "[Training] Epoch: 3 [========>      ] 56.3% Loss: 0.6268, Epoch 3, Batch 70, CE_loss: 0.5054975152015686, Dice_loss: 0.07787729799747467, Consistency_loss: 0.0011206615017727017\n",
      "[Training] Epoch: 3 [========>      ] 57.1% Loss: 0.6264, Epoch 3, Batch 71, CE_loss: 0.5169578194618225, Dice_loss: 0.07974943518638611, Consistency_loss: 0.0009541849722154438\n",
      "[Training] Epoch: 3 [========>      ] 57.9% Loss: 0.6258, Epoch 3, Batch 72, CE_loss: 0.5063303112983704, Dice_loss: 0.07791486382484436, Consistency_loss: 0.0010225906735286117\n",
      "[Training] Epoch: 3 [========>      ] 58.7% Loss: 0.6252, Epoch 3, Batch 73, CE_loss: 0.49816644191741943, Dice_loss: 0.07666703313589096, Consistency_loss: 0.0010099299252033234\n",
      "[Training] Epoch: 3 [========>      ] 59.5% Loss: 0.6246, Epoch 3, Batch 74, CE_loss: 0.5013555288314819, Dice_loss: 0.07688058912754059, Consistency_loss: 0.0006953924312256277\n",
      "[Training] Epoch: 3 [=========>     ] 60.3% Loss: 0.6241, Epoch 3, Batch 75, CE_loss: 0.5081228613853455, Dice_loss: 0.07802700251340866, Consistency_loss: 0.0007780662272125483\n",
      "[Training] Epoch: 3 [=========>     ] 61.1% Loss: 0.6236, Epoch 3, Batch 76, CE_loss: 0.5081310272216797, Dice_loss: 0.07849180698394775, Consistency_loss: 0.0007381406030617654\n",
      "[Training] Epoch: 3 [=========>     ] 61.9% Loss: 0.6233, Epoch 3, Batch 77, CE_loss: 0.5200634002685547, Dice_loss: 0.08020903915166855, Consistency_loss: 0.001054369262419641\n",
      "[Training] Epoch: 3 [=========>     ] 62.7% Loss: 0.6228, Epoch 3, Batch 78, CE_loss: 0.5069099068641663, Dice_loss: 0.07770243287086487, Consistency_loss: 4.86971803184133e-05\n",
      "[Training] Epoch: 3 [=========>     ] 63.5% Loss: 0.6223, Epoch 3, Batch 79, CE_loss: 0.5076979398727417, Dice_loss: 0.07801441103219986, Consistency_loss: 5.365872857510112e-05\n",
      "[Training] Epoch: 3 [=========>     ] 64.3% Loss: 0.6217, Epoch 3, Batch 80, CE_loss: 0.497885137796402, Dice_loss: 0.07608304172754288, Consistency_loss: 2.7482115910970606e-05\n",
      "[Training] Epoch: 3 [=========>     ] 65.1% Loss: 0.6211, Epoch 3, Batch 81, CE_loss: 0.4955848455429077, Dice_loss: 0.07596466690301895, Consistency_loss: 0.0009725727140903473\n",
      "[Training] Epoch: 3 [=========>     ] 65.9% Loss: 0.6206, Epoch 3, Batch 82, CE_loss: 0.49633219838142395, Dice_loss: 0.07583627849817276, Consistency_loss: 0.0009948334190994501\n",
      "[Training] Epoch: 3 [==========>    ] 66.7% Loss: 0.6200, Epoch 3, Batch 83, CE_loss: 0.4985544681549072, Dice_loss: 0.0759117603302002, Consistency_loss: 0.0008166849729605019\n",
      "[Training] Epoch: 3 [==========>    ] 67.5% Loss: 0.6195, Epoch 3, Batch 84, CE_loss: 0.49723851680755615, Dice_loss: 0.07570461183786392, Consistency_loss: 0.0007385753560811281\n",
      "[Training] Epoch: 3 [==========>    ] 68.3% Loss: 0.6189, Epoch 3, Batch 85, CE_loss: 0.4934144914150238, Dice_loss: 0.07497039437294006, Consistency_loss: 4.042138971271925e-05\n",
      "[Training] Epoch: 3 [==========>    ] 69.0% Loss: 0.6185, Epoch 3, Batch 86, CE_loss: 0.50411456823349, Dice_loss: 0.07720763981342316, Consistency_loss: 0.0007754105026833713\n",
      "[Training] Epoch: 3 [==========>    ] 69.8% Loss: 0.6181, Epoch 3, Batch 87, CE_loss: 0.5039573907852173, Dice_loss: 0.07661764323711395, Consistency_loss: 0.0011565287131816149\n",
      "[Training] Epoch: 3 [==========>    ] 70.6% Loss: 0.6175, Epoch 3, Batch 88, CE_loss: 0.4946179687976837, Dice_loss: 0.0752268135547638, Consistency_loss: 4.7662557335570455e-05\n",
      "[Training] Epoch: 3 [==========>    ] 71.4% Loss: 0.6170, Epoch 3, Batch 89, CE_loss: 0.4981773793697357, Dice_loss: 0.0757957249879837, Consistency_loss: 0.000972989306319505\n",
      "[Training] Epoch: 3 [==========>    ] 72.2% Loss: 0.6166, Epoch 3, Batch 90, CE_loss: 0.4979747533798218, Dice_loss: 0.07599508762359619, Consistency_loss: 7.410331454593688e-05\n",
      "[Training] Epoch: 3 [==========>    ] 73.0% Loss: 0.6161, Epoch 3, Batch 91, CE_loss: 0.4989156723022461, Dice_loss: 0.07567612826824188, Consistency_loss: 0.0009081342141143978\n",
      "[Training] Epoch: 3 [===========>   ] 73.8% Loss: 0.6155, Epoch 3, Batch 92, CE_loss: 0.4857715964317322, Dice_loss: 0.07378485798835754, Consistency_loss: 3.7360950955189764e-05\n",
      "[Training] Epoch: 3 [===========>   ] 74.6% Loss: 0.6149, Epoch 3, Batch 93, CE_loss: 0.48546478152275085, Dice_loss: 0.07327309995889664, Consistency_loss: 0.000898917845916003\n",
      "[Training] Epoch: 3 [===========>   ] 75.4% Loss: 0.6144, Epoch 3, Batch 94, CE_loss: 0.4868090748786926, Dice_loss: 0.07379751652479172, Consistency_loss: 0.0009471267694607377\n",
      "[Training] Epoch: 3 [===========>   ] 76.2% Loss: 0.6138, Epoch 3, Batch 95, CE_loss: 0.4832766056060791, Dice_loss: 0.07289593666791916, Consistency_loss: 0.0009316095383837819\n",
      "[Training] Epoch: 3 [===========>   ] 77.0% Loss: 0.6132, Epoch 3, Batch 96, CE_loss: 0.48421409726142883, Dice_loss: 0.07286699116230011, Consistency_loss: 0.0010869853431358933\n",
      "[Training] Epoch: 3 [===========>   ] 77.8% Loss: 0.6126, Epoch 3, Batch 97, CE_loss: 0.4837072789669037, Dice_loss: 0.07280910015106201, Consistency_loss: 0.0009277512435801327\n",
      "[Training] Epoch: 3 [===========>   ] 78.6% Loss: 0.6121, Epoch 3, Batch 98, CE_loss: 0.48651254177093506, Dice_loss: 0.0735521987080574, Consistency_loss: 0.000977998017333448\n",
      "[Training] Epoch: 3 [===========>   ] 79.4% Loss: 0.6115, Epoch 3, Batch 99, CE_loss: 0.48329493403434753, Dice_loss: 0.07291306555271149, Consistency_loss: 0.0009042538586072624\n",
      "[Training] Epoch: 3 [============>  ] 80.2% Loss: 0.6112, Epoch 3, Batch 100, CE_loss: 0.49845507740974426, Dice_loss: 0.07576964795589447, Consistency_loss: 3.5375909646973014e-05\n",
      "[Training] Epoch: 3 [============>  ] 81.0% Loss: 0.6108, Epoch 3, Batch 101, CE_loss: 0.4930783808231354, Dice_loss: 0.074813112616539, Consistency_loss: 0.0007857830496504903\n",
      "[Training] Epoch: 3 [============>  ] 81.7% Loss: 0.6102, Epoch 3, Batch 102, CE_loss: 0.48399001359939575, Dice_loss: 0.07288932055234909, Consistency_loss: 3.798990655923262e-05\n",
      "[Training] Epoch: 3 [============>  ] 82.5% Loss: 0.6097, Epoch 3, Batch 103, CE_loss: 0.4847763180732727, Dice_loss: 0.07299245148897171, Consistency_loss: 0.001097567961551249\n",
      "[Training] Epoch: 3 [============>  ] 83.3% Loss: 0.6092, Epoch 3, Batch 104, CE_loss: 0.4779627323150635, Dice_loss: 0.07166126370429993, Consistency_loss: 0.0008683815831318498\n",
      "[Training] Epoch: 3 [============>  ] 84.1% Loss: 0.6086, Epoch 3, Batch 105, CE_loss: 0.47640714049339294, Dice_loss: 0.07143718749284744, Consistency_loss: 7.623770216014236e-05\n",
      "[Training] Epoch: 3 [============>  ] 84.9% Loss: 0.6082, Epoch 3, Batch 106, CE_loss: 0.49218854308128357, Dice_loss: 0.07427870482206345, Consistency_loss: 4.7985377022996545e-05\n",
      "[Training] Epoch: 3 [============>  ] 85.7% Loss: 0.6078, Epoch 3, Batch 107, CE_loss: 0.48533299565315247, Dice_loss: 0.07320614904165268, Consistency_loss: 0.0010000384645536542\n",
      "[Training] Epoch: 3 [============>  ] 86.5% Loss: 0.6072, Epoch 3, Batch 108, CE_loss: 0.47915753722190857, Dice_loss: 0.0717286467552185, Consistency_loss: 0.0010280314600095153\n",
      "[Training] Epoch: 3 [=============> ] 87.3% Loss: 0.6067, Epoch 3, Batch 109, CE_loss: 0.4732843041419983, Dice_loss: 0.07050888985395432, Consistency_loss: 0.0008687800145708025\n",
      "[Training] Epoch: 3 [=============> ] 88.1% Loss: 0.6062, Epoch 3, Batch 110, CE_loss: 0.4785228371620178, Dice_loss: 0.07149258255958557, Consistency_loss: 0.0010907629039138556\n",
      "[Training] Epoch: 3 [=============> ] 88.9% Loss: 0.6057, Epoch 3, Batch 111, CE_loss: 0.4807136058807373, Dice_loss: 0.07212082296609879, Consistency_loss: 0.001429442665539682\n",
      "[Training] Epoch: 3 [=============> ] 89.7% Loss: 0.6052, Epoch 3, Batch 112, CE_loss: 0.4777703583240509, Dice_loss: 0.071149080991745, Consistency_loss: 7.425079093081877e-05\n",
      "[Training] Epoch: 3 [=============> ] 90.5% Loss: 0.6048, Epoch 3, Batch 113, CE_loss: 0.4797871708869934, Dice_loss: 0.07159202545881271, Consistency_loss: 0.0020124963484704494\n",
      "[Training] Epoch: 3 [=============> ] 91.3% Loss: 0.6042, Epoch 3, Batch 114, CE_loss: 0.4708501696586609, Dice_loss: 0.06995752453804016, Consistency_loss: 0.0010273627704009414\n",
      "[Training] Epoch: 3 [=============> ] 92.1% Loss: 0.6037, Epoch 3, Batch 115, CE_loss: 0.4728901982307434, Dice_loss: 0.07019077241420746, Consistency_loss: 0.0006294281920418143\n",
      "[Training] Epoch: 3 [=============> ] 92.9% Loss: 0.6032, Epoch 3, Batch 116, CE_loss: 0.4713122546672821, Dice_loss: 0.07000723481178284, Consistency_loss: 0.0008303993381559849\n",
      "[Training] Epoch: 3 [==============>] 93.7% Loss: 0.6029, Epoch 3, Batch 117, CE_loss: 0.4959964454174042, Dice_loss: 0.07425253093242645, Consistency_loss: 0.0007536962511949241\n",
      "[Training] Epoch: 3 [==============>] 94.4% Loss: 0.6024, Epoch 3, Batch 118, CE_loss: 0.47611573338508606, Dice_loss: 0.07114313542842865, Consistency_loss: 0.0004367239016573876\n",
      "[Training] Epoch: 3 [==============>] 95.2% Loss: 0.6019, Epoch 3, Batch 119, CE_loss: 0.4728080928325653, Dice_loss: 0.07028710842132568, Consistency_loss: 5.645175770041533e-05\n",
      "[Training] Epoch: 3 [==============>] 96.0% Loss: 0.6014, Epoch 3, Batch 120, CE_loss: 0.4713902175426483, Dice_loss: 0.06966007500886917, Consistency_loss: 6.402341387001798e-05\n",
      "[Training] Epoch: 3 [==============>] 96.8% Loss: 0.6010, Epoch 3, Batch 121, CE_loss: 0.4759843945503235, Dice_loss: 0.07105161249637604, Consistency_loss: 5.683765630237758e-05\n",
      "[Training] Epoch: 3 [==============>] 97.6% Loss: 0.6005, Epoch 3, Batch 122, CE_loss: 0.4699232578277588, Dice_loss: 0.07001540064811707, Consistency_loss: 0.0004602450062520802\n",
      "[Training] Epoch: 3 [==============>] 98.4% Loss: 0.6001, Epoch 3, Batch 123, CE_loss: 0.48368752002716064, Dice_loss: 0.07256978750228882, Consistency_loss: 0.0005503977881744504\n",
      "[Training] Epoch: 3 [==============>] 99.2% Loss: 0.5997, Epoch 3, Batch 124, CE_loss: 0.4730655252933502, Dice_loss: 0.06995106488466263, Consistency_loss: 0.0007632371271029115\n",
      "[Training] Epoch: 3 [DONE]                                 \n",
      "Epoch 3, Batch 125, CE_loss: 0.46595120429992676, Dice_loss: 0.06914975494146347, Consistency_loss: 0.000956028641667217\n",
      "[Validation] Epoch: 3 [DONE]                                 \n",
      "[Epoch: 3, TrainLoss: 0.5992, TrainDice: 0.0806, ValLoss: 0.6271                                             \n",
      "Number of batches:  126\n",
      "[Training] Epoch: 4 [>              ] 0.8% Loss: 0.5329, Epoch 4, Batch 0, CE_loss: 0.4636651575565338, Dice_loss: 0.06835165619850159, Consistency_loss: 0.0008403320098295808\n",
      "[Training] Epoch: 4 [>              ] 1.6% Loss: 0.5334, Epoch 4, Batch 1, CE_loss: 0.4643552899360657, Dice_loss: 0.0683855190873146, Consistency_loss: 0.001111911959014833\n",
      "[Training] Epoch: 4 [>              ] 2.4% Loss: 0.5342, Epoch 4, Batch 2, CE_loss: 0.46639910340309143, Dice_loss: 0.06847307831048965, Consistency_loss: 0.0010707915062084794\n",
      "[Training] Epoch: 4 [>              ] 3.2% Loss: 0.5348, Epoch 4, Batch 3, CE_loss: 0.46720802783966064, Dice_loss: 0.06860536336898804, Consistency_loss: 0.0007319108699448407\n",
      "[Training] Epoch: 4 [>              ] 4.0% Loss: 0.5382, Epoch 4, Batch 4, CE_loss: 0.4797779619693756, Dice_loss: 0.07126766443252563, Consistency_loss: 0.0007761187735013664\n",
      "[Training] Epoch: 4 [>              ] 4.8% Loss: 0.5372, Epoch 4, Batch 5, CE_loss: 0.4635968506336212, Dice_loss: 0.06815644353628159, Consistency_loss: 0.0006623404333367944\n",
      "[Training] Epoch: 4 [>              ] 5.6% Loss: 0.5369, Epoch 4, Batch 6, CE_loss: 0.46530085802078247, Dice_loss: 0.06860727816820145, Consistency_loss: 0.0007089502178132534\n",
      "[Training] Epoch: 4 [>              ] 6.3% Loss: 0.5372, Epoch 4, Batch 7, CE_loss: 0.469523161649704, Dice_loss: 0.06904448568820953, Consistency_loss: 0.0006614279700443149\n",
      "[Training] Epoch: 4 [=>             ] 7.1% Loss: 0.5364, Epoch 4, Batch 8, CE_loss: 0.46108657121658325, Dice_loss: 0.06748361140489578, Consistency_loss: 0.0019386004423722625\n",
      "[Training] Epoch: 4 [=>             ] 7.9% Loss: 0.5363, Epoch 4, Batch 9, CE_loss: 0.46683669090270996, Dice_loss: 0.06851114332675934, Consistency_loss: 6.408290937542915e-05\n",
      "[Training] Epoch: 4 [=>             ] 8.7% Loss: 0.5356, Epoch 4, Batch 10, CE_loss: 0.4603256285190582, Dice_loss: 0.06766443699598312, Consistency_loss: 9.024109749589115e-05\n",
      "[Training] Epoch: 4 [=>             ] 9.5% Loss: 0.5353, Epoch 4, Batch 11, CE_loss: 0.4636074900627136, Dice_loss: 0.06795048713684082, Consistency_loss: 0.0009269934380427003\n",
      "[Training] Epoch: 4 [=>             ] 10.3% Loss: 0.5352, Epoch 4, Batch 12, CE_loss: 0.4646902084350586, Dice_loss: 0.06804391741752625, Consistency_loss: 0.0008987096371129155\n",
      "[Training] Epoch: 4 [=>             ] 11.1% Loss: 0.5350, Epoch 4, Batch 13, CE_loss: 0.46405351161956787, Dice_loss: 0.0676250010728836, Consistency_loss: 0.0007388968952000141\n",
      "[Training] Epoch: 4 [=>             ] 11.9% Loss: 0.5342, Epoch 4, Batch 14, CE_loss: 0.4571382403373718, Dice_loss: 0.0667123943567276, Consistency_loss: 3.058362926822156e-05\n",
      "[Training] Epoch: 4 [=>             ] 12.7% Loss: 0.5338, Epoch 4, Batch 15, CE_loss: 0.4587176442146301, Dice_loss: 0.0667608305811882, Consistency_loss: 0.0014632130041718483\n",
      "[Training] Epoch: 4 [==>            ] 13.5% Loss: 0.5330, Epoch 4, Batch 16, CE_loss: 0.4536922574043274, Dice_loss: 0.06582216173410416, Consistency_loss: 0.0015141525072976947\n",
      "[Training] Epoch: 4 [==>            ] 14.3% Loss: 0.5321, Epoch 4, Batch 17, CE_loss: 0.45023006200790405, Dice_loss: 0.06533190608024597, Consistency_loss: 0.0009692739695310593\n",
      "[Training] Epoch: 4 [==>            ] 15.1% Loss: 0.5323, Epoch 4, Batch 18, CE_loss: 0.4662870466709137, Dice_loss: 0.06797108799219131, Consistency_loss: 0.0009754158672876656\n",
      "[Training] Epoch: 4 [==>            ] 15.9% Loss: 0.5315, Epoch 4, Batch 19, CE_loss: 0.45023423433303833, Dice_loss: 0.06523747742176056, Consistency_loss: 0.0010657522361725569\n",
      "[Training] Epoch: 4 [==>            ] 16.7% Loss: 0.5311, Epoch 4, Batch 20, CE_loss: 0.45618945360183716, Dice_loss: 0.0663788691163063, Consistency_loss: 0.0011193292448297143\n",
      "[Training] Epoch: 4 [==>            ] 17.5% Loss: 0.5310, Epoch 4, Batch 21, CE_loss: 0.46017253398895264, Dice_loss: 0.06719178706407547, Consistency_loss: 0.0012291761813685298\n",
      "[Training] Epoch: 4 [==>            ] 18.3% Loss: 0.5302, Epoch 4, Batch 22, CE_loss: 0.4472733438014984, Dice_loss: 0.06450702995061874, Consistency_loss: 0.0006353915086947381\n",
      "[Training] Epoch: 4 [==>            ] 19.0% Loss: 0.5298, Epoch 4, Batch 23, CE_loss: 0.4535024166107178, Dice_loss: 0.06591486185789108, Consistency_loss: 0.0011599891586229205\n",
      "[Training] Epoch: 4 [==>            ] 19.8% Loss: 0.5296, Epoch 4, Batch 24, CE_loss: 0.4589538872241974, Dice_loss: 0.06666047871112823, Consistency_loss: 8.122652070596814e-05\n",
      "[Training] Epoch: 4 [===>           ] 20.6% Loss: 0.5294, Epoch 4, Batch 25, CE_loss: 0.454977810382843, Dice_loss: 0.06604284793138504, Consistency_loss: 0.0013452088460326195\n",
      "[Training] Epoch: 4 [===>           ] 21.4% Loss: 0.5289, Epoch 4, Batch 26, CE_loss: 0.4509935975074768, Dice_loss: 0.06553159654140472, Consistency_loss: 0.0011783897643908858\n",
      "[Training] Epoch: 4 [===>           ] 22.2% Loss: 0.5281, Epoch 4, Batch 27, CE_loss: 0.442837655544281, Dice_loss: 0.06359944492578506, Consistency_loss: 0.0001162909684353508\n",
      "[Training] Epoch: 4 [===>           ] 23.0% Loss: 0.5276, Epoch 4, Batch 28, CE_loss: 0.44912660121917725, Dice_loss: 0.06463387608528137, Consistency_loss: 4.134220944251865e-05\n",
      "[Training] Epoch: 4 [===>           ] 23.8% Loss: 0.5272, Epoch 4, Batch 29, CE_loss: 0.44864359498023987, Dice_loss: 0.06451085954904556, Consistency_loss: 0.001050067599862814\n",
      "[Training] Epoch: 4 [===>           ] 24.6% Loss: 0.5264, Epoch 4, Batch 30, CE_loss: 0.44020089507102966, Dice_loss: 0.06290815025568008, Consistency_loss: 0.0011474706698209047\n",
      "[Training] Epoch: 4 [===>           ] 25.4% Loss: 0.5263, Epoch 4, Batch 31, CE_loss: 0.45573508739471436, Dice_loss: 0.06601379066705704, Consistency_loss: 8.937013626564294e-05\n",
      "[Training] Epoch: 4 [===>           ] 26.2% Loss: 0.5261, Epoch 4, Batch 32, CE_loss: 0.4538087248802185, Dice_loss: 0.06534705311059952, Consistency_loss: 8.962250285549089e-05\n",
      "[Training] Epoch: 4 [====>          ] 27.0% Loss: 0.5256, Epoch 4, Batch 33, CE_loss: 0.4449772238731384, Dice_loss: 0.06403566151857376, Consistency_loss: 0.00096462870715186\n",
      "[Training] Epoch: 4 [====>          ] 27.8% Loss: 0.5250, Epoch 4, Batch 34, CE_loss: 0.4401082396507263, Dice_loss: 0.06305667757987976, Consistency_loss: 0.0010945808608084917\n",
      "[Training] Epoch: 4 [====>          ] 28.6% Loss: 0.5249, Epoch 4, Batch 35, CE_loss: 0.4558342695236206, Dice_loss: 0.06584133952856064, Consistency_loss: 0.001252182642929256\n",
      "[Training] Epoch: 4 [====>          ] 29.4% Loss: 0.5243, Epoch 4, Batch 36, CE_loss: 0.43604108691215515, Dice_loss: 0.062096744775772095, Consistency_loss: 0.0012336020590737462\n",
      "[Training] Epoch: 4 [====>          ] 30.2% Loss: 0.5240, Epoch 4, Batch 37, CE_loss: 0.45107218623161316, Dice_loss: 0.06485073268413544, Consistency_loss: 0.0001274123351322487\n",
      "[Training] Epoch: 4 [====>          ] 31.0% Loss: 0.5236, Epoch 4, Batch 38, CE_loss: 0.4408046305179596, Dice_loss: 0.06290002167224884, Consistency_loss: 0.0015630613779649138\n",
      "[Training] Epoch: 4 [====>          ] 31.7% Loss: 0.5230, Epoch 4, Batch 39, CE_loss: 0.43766510486602783, Dice_loss: 0.06267641484737396, Consistency_loss: 0.0014930748147889972\n",
      "[Training] Epoch: 4 [====>          ] 32.5% Loss: 0.5224, Epoch 4, Batch 40, CE_loss: 0.43429991602897644, Dice_loss: 0.06181549280881882, Consistency_loss: 0.0014179121935740113\n",
      "[Training] Epoch: 4 [=====>         ] 33.3% Loss: 0.5217, Epoch 4, Batch 41, CE_loss: 0.4312468469142914, Dice_loss: 0.061143409460783005, Consistency_loss: 0.0015968062216416001\n",
      "[Training] Epoch: 4 [=====>         ] 34.1% Loss: 0.5213, Epoch 4, Batch 42, CE_loss: 0.44020646810531616, Dice_loss: 0.06327075511217117, Consistency_loss: 0.0012783634010702372\n",
      "[Training] Epoch: 4 [=====>         ] 34.9% Loss: 0.5209, Epoch 4, Batch 43, CE_loss: 0.4416014850139618, Dice_loss: 0.06304923444986343, Consistency_loss: 0.00011301077756797895\n",
      "[Training] Epoch: 4 [=====>         ] 35.7% Loss: 0.5204, Epoch 4, Batch 44, CE_loss: 0.4325304627418518, Dice_loss: 0.06152454763650894, Consistency_loss: 0.0011543120490387082\n",
      "[Training] Epoch: 4 [=====>         ] 36.5% Loss: 0.5198, Epoch 4, Batch 45, CE_loss: 0.43194302916526794, Dice_loss: 0.06108535826206207, Consistency_loss: 6.535912689287215e-05\n",
      "[Training] Epoch: 4 [=====>         ] 37.3% Loss: 0.5194, Epoch 4, Batch 46, CE_loss: 0.4400317072868347, Dice_loss: 0.06311433762311935, Consistency_loss: 6.803651194786653e-05\n",
      "[Training] Epoch: 4 [=====>         ] 38.1% Loss: 0.5190, Epoch 4, Batch 47, CE_loss: 0.43655359745025635, Dice_loss: 0.062020666897296906, Consistency_loss: 0.001384177478030324\n",
      "[Training] Epoch: 4 [=====>         ] 38.9% Loss: 0.5186, Epoch 4, Batch 48, CE_loss: 0.4368056058883667, Dice_loss: 0.062185660004615784, Consistency_loss: 0.001503648585639894\n",
      "[Training] Epoch: 4 [=====>         ] 39.7% Loss: 0.5182, Epoch 4, Batch 49, CE_loss: 0.4342467486858368, Dice_loss: 0.06169363111257553, Consistency_loss: 0.0010658138198778033\n",
      "[Training] Epoch: 4 [======>        ] 40.5% Loss: 0.5179, Epoch 4, Batch 50, CE_loss: 0.4391387701034546, Dice_loss: 0.06239912286400795, Consistency_loss: 5.907273953198455e-05\n",
      "[Training] Epoch: 4 [======>        ] 41.3% Loss: 0.5174, Epoch 4, Batch 51, CE_loss: 0.4305441975593567, Dice_loss: 0.06082580238580704, Consistency_loss: 0.0009168838150799274\n",
      "[Training] Epoch: 4 [======>        ] 42.1% Loss: 0.5169, Epoch 4, Batch 52, CE_loss: 0.4311946630477905, Dice_loss: 0.06102842465043068, Consistency_loss: 0.0009667789563536644\n",
      "[Training] Epoch: 4 [======>        ] 42.9% Loss: 0.5165, Epoch 4, Batch 53, CE_loss: 0.4333451986312866, Dice_loss: 0.06135326996445656, Consistency_loss: 0.0011106478050351143\n",
      "[Training] Epoch: 4 [======>        ] 43.7% Loss: 0.5164, Epoch 4, Batch 54, CE_loss: 0.4420032203197479, Dice_loss: 0.06303027272224426, Consistency_loss: 0.0013393298722803593\n",
      "[Training] Epoch: 4 [======>        ] 44.4% Loss: 0.5160, Epoch 4, Batch 55, CE_loss: 0.43357616662979126, Dice_loss: 0.061490923166275024, Consistency_loss: 0.0012508794898167253\n",
      "[Training] Epoch: 4 [======>        ] 45.2% Loss: 0.5155, Epoch 4, Batch 56, CE_loss: 0.42530128359794617, Dice_loss: 0.059755466878414154, Consistency_loss: 0.001496535143814981\n",
      "[Training] Epoch: 4 [======>        ] 46.0% Loss: 0.5150, Epoch 4, Batch 57, CE_loss: 0.4278101921081543, Dice_loss: 0.06057358533143997, Consistency_loss: 0.0010802281321957707\n",
      "[Training] Epoch: 4 [=======>       ] 46.8% Loss: 0.5146, Epoch 4, Batch 58, CE_loss: 0.4292605221271515, Dice_loss: 0.0606091283261776, Consistency_loss: 0.0012247151462361217\n",
      "[Training] Epoch: 4 [=======>       ] 47.6% Loss: 0.5142, Epoch 4, Batch 59, CE_loss: 0.42616787552833557, Dice_loss: 0.05983549728989601, Consistency_loss: 0.000119362237455789\n",
      "[Training] Epoch: 4 [=======>       ] 48.4% Loss: 0.5138, Epoch 4, Batch 60, CE_loss: 0.43229997158050537, Dice_loss: 0.06103834509849548, Consistency_loss: 0.00123438925947994\n",
      "[Training] Epoch: 4 [=======>       ] 49.2% Loss: 0.5136, Epoch 4, Batch 61, CE_loss: 0.4388123154640198, Dice_loss: 0.06213349103927612, Consistency_loss: 0.001348374760709703\n",
      "[Training] Epoch: 4 [=======>       ] 50.0% Loss: 0.5132, Epoch 4, Batch 62, CE_loss: 0.4267725646495819, Dice_loss: 0.05960463359951973, Consistency_loss: 0.0002057971287285909\n",
      "[Training] Epoch: 4 [=======>       ] 50.8% Loss: 0.5127, Epoch 4, Batch 63, CE_loss: 0.4214191436767578, Dice_loss: 0.058880582451820374, Consistency_loss: 0.0012684750836342573\n",
      "[Training] Epoch: 4 [=======>       ] 51.6% Loss: 0.5129, Epoch 4, Batch 64, CE_loss: 0.45466184616088867, Dice_loss: 0.06584346294403076, Consistency_loss: 0.0007889978005550802\n",
      "[Training] Epoch: 4 [=======>       ] 52.4% Loss: 0.5125, Epoch 4, Batch 65, CE_loss: 0.4294548034667969, Dice_loss: 0.060428351163864136, Consistency_loss: 0.0010536119807511568\n",
      "[Training] Epoch: 4 [=======>       ] 53.2% Loss: 0.5122, Epoch 4, Batch 66, CE_loss: 0.4265119135379791, Dice_loss: 0.05975370854139328, Consistency_loss: 0.001241382327862084\n",
      "[Training] Epoch: 4 [========>      ] 54.0% Loss: 0.5118, Epoch 4, Batch 67, CE_loss: 0.42542433738708496, Dice_loss: 0.05954122170805931, Consistency_loss: 0.00016170558228623122\n",
      "[Training] Epoch: 4 [========>      ] 54.8% Loss: 0.5114, Epoch 4, Batch 68, CE_loss: 0.42632943391799927, Dice_loss: 0.059408120810985565, Consistency_loss: 0.0001214425647049211\n",
      "[Training] Epoch: 4 [========>      ] 55.6% Loss: 0.5109, Epoch 4, Batch 69, CE_loss: 0.42039042711257935, Dice_loss: 0.05876832455396652, Consistency_loss: 0.0010217532981187105\n",
      "[Training] Epoch: 4 [========>      ] 56.3% Loss: 0.5105, Epoch 4, Batch 70, CE_loss: 0.42231622338294983, Dice_loss: 0.059013888239860535, Consistency_loss: 9.270596638089046e-05\n",
      "[Training] Epoch: 4 [========>      ] 57.1% Loss: 0.5102, Epoch 4, Batch 71, CE_loss: 0.42672011256217957, Dice_loss: 0.05998995900154114, Consistency_loss: 0.0012125546345487237\n",
      "[Training] Epoch: 4 [========>      ] 57.9% Loss: 0.5097, Epoch 4, Batch 72, CE_loss: 0.41882601380348206, Dice_loss: 0.05808822438120842, Consistency_loss: 0.00010541039955569431\n",
      "[Training] Epoch: 4 [========>      ] 58.7% Loss: 0.5094, Epoch 4, Batch 73, CE_loss: 0.42029306292533875, Dice_loss: 0.058786164969205856, Consistency_loss: 0.001437984174117446\n",
      "[Training] Epoch: 4 [========>      ] 59.5% Loss: 0.5089, Epoch 4, Batch 74, CE_loss: 0.4183187782764435, Dice_loss: 0.05791987106204033, Consistency_loss: 0.0011779553024098277\n",
      "[Training] Epoch: 4 [=========>     ] 60.3% Loss: 0.5085, Epoch 4, Batch 75, CE_loss: 0.4190230667591095, Dice_loss: 0.05846361070871353, Consistency_loss: 0.0012006242759525776\n",
      "[Training] Epoch: 4 [=========>     ] 61.1% Loss: 0.5081, Epoch 4, Batch 76, CE_loss: 0.4170334041118622, Dice_loss: 0.058184538036584854, Consistency_loss: 9.969488019123673e-05\n",
      "[Training] Epoch: 4 [=========>     ] 61.9% Loss: 0.5078, Epoch 4, Batch 77, CE_loss: 0.4215583801269531, Dice_loss: 0.0584895946085453, Consistency_loss: 0.0015797860687598586\n",
      "[Training] Epoch: 4 [=========>     ] 62.7% Loss: 0.5073, Epoch 4, Batch 78, CE_loss: 0.4125244617462158, Dice_loss: 0.05681963637471199, Consistency_loss: 0.001087978365831077\n",
      "[Training] Epoch: 4 [=========>     ] 63.5% Loss: 0.5068, Epoch 4, Batch 79, CE_loss: 0.41200175881385803, Dice_loss: 0.05680163577198982, Consistency_loss: 0.001220938516780734\n",
      "[Training] Epoch: 4 [=========>     ] 64.3% Loss: 0.5065, Epoch 4, Batch 80, CE_loss: 0.42157259583473206, Dice_loss: 0.05850529298186302, Consistency_loss: 0.0009963017655536532\n",
      "[Training] Epoch: 4 [=========>     ] 65.1% Loss: 0.5060, Epoch 4, Batch 81, CE_loss: 0.4085123836994171, Dice_loss: 0.0561925433576107, Consistency_loss: 0.00014404368994291872\n",
      "[Training] Epoch: 4 [=========>     ] 65.9% Loss: 0.5055, Epoch 4, Batch 82, CE_loss: 0.405807226896286, Dice_loss: 0.05588242784142494, Consistency_loss: 0.0010820653988048434\n",
      "[Training] Epoch: 4 [==========>    ] 66.7% Loss: 0.5051, Epoch 4, Batch 83, CE_loss: 0.41353821754455566, Dice_loss: 0.057051610201597214, Consistency_loss: 0.00107323017437011\n",
      "[Training] Epoch: 4 [==========>    ] 67.5% Loss: 0.5045, Epoch 4, Batch 84, CE_loss: 0.40395084023475647, Dice_loss: 0.05514286831021309, Consistency_loss: 0.0001317205314990133\n",
      "[Training] Epoch: 4 [==========>    ] 68.3% Loss: 0.5043, Epoch 4, Batch 85, CE_loss: 0.4258439838886261, Dice_loss: 0.059501249343156815, Consistency_loss: 0.0012428342597559094\n",
      "[Training] Epoch: 4 [==========>    ] 69.0% Loss: 0.5039, Epoch 4, Batch 86, CE_loss: 0.40834692120552063, Dice_loss: 0.05595650151371956, Consistency_loss: 0.00018138579616788775\n",
      "[Training] Epoch: 4 [==========>    ] 69.8% Loss: 0.5034, Epoch 4, Batch 87, CE_loss: 0.4056316614151001, Dice_loss: 0.05560193583369255, Consistency_loss: 0.001243105041794479\n",
      "[Training] Epoch: 4 [==========>    ] 70.6% Loss: 0.5031, Epoch 4, Batch 88, CE_loss: 0.4146910607814789, Dice_loss: 0.05724577605724335, Consistency_loss: 0.0011957624228671193\n",
      "[Training] Epoch: 4 [==========>    ] 71.4% Loss: 0.5027, Epoch 4, Batch 89, CE_loss: 0.4109620451927185, Dice_loss: 0.05643131211400032, Consistency_loss: 0.0012798095121979713\n",
      "[Training] Epoch: 4 [==========>    ] 72.2% Loss: 0.5023, Epoch 4, Batch 90, CE_loss: 0.4077428877353668, Dice_loss: 0.055856723338365555, Consistency_loss: 0.0012360595865175128\n",
      "[Training] Epoch: 4 [==========>    ] 73.0% Loss: 0.5018, Epoch 4, Batch 91, CE_loss: 0.40426042675971985, Dice_loss: 0.05508894845843315, Consistency_loss: 0.00022546549735125154\n",
      "[Training] Epoch: 4 [===========>   ] 73.8% Loss: 0.5013, Epoch 4, Batch 92, CE_loss: 0.39900830388069153, Dice_loss: 0.05420595407485962, Consistency_loss: 0.0012279165675863624\n",
      "[Training] Epoch: 4 [===========>   ] 74.6% Loss: 0.5008, Epoch 4, Batch 93, CE_loss: 0.40337204933166504, Dice_loss: 0.05525333806872368, Consistency_loss: 0.0007389054517261684\n",
      "[Training] Epoch: 4 [===========>   ] 75.4% Loss: 0.5004, Epoch 4, Batch 94, CE_loss: 0.4036482870578766, Dice_loss: 0.055087652057409286, Consistency_loss: 0.0011124956654384732\n",
      "[Training] Epoch: 4 [===========>   ] 76.2% Loss: 0.4999, Epoch 4, Batch 95, CE_loss: 0.39774346351623535, Dice_loss: 0.05371859297156334, Consistency_loss: 0.0010366025380790234\n",
      "[Training] Epoch: 4 [===========>   ] 77.0% Loss: 0.4994, Epoch 4, Batch 96, CE_loss: 0.3982345461845398, Dice_loss: 0.05395294353365898, Consistency_loss: 0.0008497557719238102\n",
      "[Training] Epoch: 4 [===========>   ] 77.8% Loss: 0.4990, Epoch 4, Batch 97, CE_loss: 0.4046456813812256, Dice_loss: 0.055448416620492935, Consistency_loss: 0.00016006172518245876\n",
      "[Training] Epoch: 4 [===========>   ] 78.6% Loss: 0.4988, Epoch 4, Batch 98, CE_loss: 0.41937196254730225, Dice_loss: 0.05762304365634918, Consistency_loss: 0.0007907756953500211\n",
      "[Training] Epoch: 4 [===========>   ] 79.4% Loss: 0.4984, Epoch 4, Batch 99, CE_loss: 0.3980005383491516, Dice_loss: 0.053759150207042694, Consistency_loss: 0.0011545541929081082\n",
      "[Training] Epoch: 4 [============>  ] 80.2% Loss: 0.4980, Epoch 4, Batch 100, CE_loss: 0.4063538908958435, Dice_loss: 0.055488839745521545, Consistency_loss: 0.00013513572048395872\n",
      "[Training] Epoch: 4 [============>  ] 81.0% Loss: 0.4976, Epoch 4, Batch 101, CE_loss: 0.39928120374679565, Dice_loss: 0.05449529364705086, Consistency_loss: 0.0008630641968920827\n",
      "[Training] Epoch: 4 [============>  ] 81.7% Loss: 0.4973, Epoch 4, Batch 102, CE_loss: 0.4088764786720276, Dice_loss: 0.05569157004356384, Consistency_loss: 0.0009726841235533357\n",
      "[Training] Epoch: 4 [============>  ] 82.5% Loss: 0.4968, Epoch 4, Batch 103, CE_loss: 0.3961390256881714, Dice_loss: 0.05343389883637428, Consistency_loss: 0.0008534574881196022\n",
      "[Training] Epoch: 4 [============>  ] 83.3% Loss: 0.4964, Epoch 4, Batch 104, CE_loss: 0.39587220549583435, Dice_loss: 0.05330364406108856, Consistency_loss: 0.00016077123291324824\n",
      "[Training] Epoch: 4 [============>  ] 84.1% Loss: 0.4959, Epoch 4, Batch 105, CE_loss: 0.39606258273124695, Dice_loss: 0.053330693393945694, Consistency_loss: 0.0011956768576055765\n",
      "[Training] Epoch: 4 [============>  ] 84.9% Loss: 0.4955, Epoch 4, Batch 106, CE_loss: 0.39601239562034607, Dice_loss: 0.05351461470127106, Consistency_loss: 0.0008220989257097244\n",
      "[Training] Epoch: 4 [============>  ] 85.7% Loss: 0.4951, Epoch 4, Batch 107, CE_loss: 0.40001431107521057, Dice_loss: 0.05401703715324402, Consistency_loss: 0.0011082434793934226\n",
      "[Training] Epoch: 4 [============>  ] 86.5% Loss: 0.4947, Epoch 4, Batch 108, CE_loss: 0.3925362229347229, Dice_loss: 0.05311116203665733, Consistency_loss: 0.00014940470282454044\n",
      "[Training] Epoch: 4 [=============> ] 87.3% Loss: 0.4943, Epoch 4, Batch 109, CE_loss: 0.3981155455112457, Dice_loss: 0.053721774369478226, Consistency_loss: 0.0011936555383726954\n",
      "[Training] Epoch: 4 [=============> ] 88.1% Loss: 0.4939, Epoch 4, Batch 110, CE_loss: 0.4002699553966522, Dice_loss: 0.05417410284280777, Consistency_loss: 0.0009320595418103039\n",
      "[Training] Epoch: 4 [=============> ] 88.9% Loss: 0.4936, Epoch 4, Batch 111, CE_loss: 0.3996771574020386, Dice_loss: 0.05400466173887253, Consistency_loss: 0.00017246142670046538\n",
      "[Training] Epoch: 4 [=============> ] 89.7% Loss: 0.4931, Epoch 4, Batch 112, CE_loss: 0.38630175590515137, Dice_loss: 0.051254790276288986, Consistency_loss: 0.00014818584895692766\n",
      "[Training] Epoch: 4 [=============> ] 90.5% Loss: 0.4926, Epoch 4, Batch 113, CE_loss: 0.3889663815498352, Dice_loss: 0.05193323642015457, Consistency_loss: 0.0009138045716099441\n",
      "[Training] Epoch: 4 [=============> ] 91.3% Loss: 0.4923, Epoch 4, Batch 114, CE_loss: 0.396200031042099, Dice_loss: 0.05341101065278053, Consistency_loss: 0.00019595050252974033\n",
      "[Training] Epoch: 4 [=============> ] 92.1% Loss: 0.4919, Epoch 4, Batch 115, CE_loss: 0.39148566126823425, Dice_loss: 0.05240171030163765, Consistency_loss: 0.0008827343699522316\n",
      "[Training] Epoch: 4 [=============> ] 92.9% Loss: 0.4915, Epoch 4, Batch 116, CE_loss: 0.3981115221977234, Dice_loss: 0.053707022219896317, Consistency_loss: 0.0003138070460408926\n",
      "[Training] Epoch: 4 [==============>] 93.7% Loss: 0.4910, Epoch 4, Batch 117, CE_loss: 0.38382887840270996, Dice_loss: 0.05099688097834587, Consistency_loss: 0.0008939685649238527\n",
      "[Training] Epoch: 4 [==============>] 94.4% Loss: 0.4906, Epoch 4, Batch 118, CE_loss: 0.39011961221694946, Dice_loss: 0.05208278447389603, Consistency_loss: 0.00022294108930509537\n",
      "[Training] Epoch: 4 [==============>] 95.2% Loss: 0.4902, Epoch 4, Batch 119, CE_loss: 0.38985657691955566, Dice_loss: 0.051806606352329254, Consistency_loss: 0.0007217543316073716\n",
      "[Training] Epoch: 4 [==============>] 96.0% Loss: 0.4899, Epoch 4, Batch 120, CE_loss: 0.39338186383247375, Dice_loss: 0.05269748345017433, Consistency_loss: 0.0011052353074774146\n",
      "[Training] Epoch: 4 [==============>] 96.8% Loss: 0.4895, Epoch 4, Batch 121, CE_loss: 0.3862167298793793, Dice_loss: 0.05132953077554703, Consistency_loss: 0.0013037585886195302\n",
      "[Training] Epoch: 4 [==============>] 97.6% Loss: 0.4890, Epoch 4, Batch 122, CE_loss: 0.38255828619003296, Dice_loss: 0.050478946417570114, Consistency_loss: 0.00019498777692206204\n",
      "[Training] Epoch: 4 [==============>] 98.4% Loss: 0.4887, Epoch 4, Batch 123, CE_loss: 0.3959105610847473, Dice_loss: 0.05294235050678253, Consistency_loss: 0.0016839889576658607\n",
      "[Training] Epoch: 4 [==============>] 99.2% Loss: 0.4883, Epoch 4, Batch 124, CE_loss: 0.3833905756473541, Dice_loss: 0.050600599497556686, Consistency_loss: 0.0009949143277481198\n",
      "[Training] Epoch: 4 [DONE]                                 \n",
      "Epoch 4, Batch 125, CE_loss: 0.3844732940196991, Dice_loss: 0.05078379437327385, Consistency_loss: 0.001125544193200767\n",
      "[Validation] Epoch: 4 [DONE]                                 \n",
      "[Epoch: 4, TrainLoss: 0.4879, TrainDice: 0.0600, ValLoss: 0.4720                                             \n",
      "Number of batches:  126\n",
      "[Training] Epoch: 5 [>              ] 0.8% Loss: 0.4279, Epoch 5, Batch 0, CE_loss: 0.3773688077926636, Dice_loss: 0.049695760011672974, Consistency_loss: 0.0008717493037693202\n",
      "[Training] Epoch: 5 [>              ] 1.6% Loss: 0.4346, Epoch 5, Batch 1, CE_loss: 0.38872042298316956, Dice_loss: 0.051660336554050446, Consistency_loss: 0.000932765135075897\n",
      "[Training] Epoch: 5 [>              ] 2.4% Loss: 0.4330, Epoch 5, Batch 2, CE_loss: 0.3795783221721649, Dice_loss: 0.049897532910108566, Consistency_loss: 0.00014710529649164528\n",
      "[Training] Epoch: 5 [>              ] 3.2% Loss: 0.4323, Epoch 5, Batch 3, CE_loss: 0.3796597719192505, Dice_loss: 0.04978225752711296, Consistency_loss: 0.0006958804442547262\n",
      "[Training] Epoch: 5 [>              ] 4.0% Loss: 0.4330, Epoch 5, Batch 4, CE_loss: 0.38420042395591736, Dice_loss: 0.05083112791180611, Consistency_loss: 0.0008407207205891609\n",
      "[Training] Epoch: 5 [>              ] 4.8% Loss: 0.4335, Epoch 5, Batch 5, CE_loss: 0.38475170731544495, Dice_loss: 0.050753381103277206, Consistency_loss: 0.0005742909270338714\n",
      "[Training] Epoch: 5 [>              ] 5.6% Loss: 0.4336, Epoch 5, Batch 6, CE_loss: 0.3829043209552765, Dice_loss: 0.05045144632458687, Consistency_loss: 0.0006298233638517559\n",
      "[Training] Epoch: 5 [>              ] 6.3% Loss: 0.4334, Epoch 5, Batch 7, CE_loss: 0.3816757798194885, Dice_loss: 0.050112802535295486, Consistency_loss: 0.0008621808374300599\n",
      "[Training] Epoch: 5 [=>             ] 7.1% Loss: 0.4334, Epoch 5, Batch 8, CE_loss: 0.3821355402469635, Dice_loss: 0.0502578429877758, Consistency_loss: 0.0009573473944328725\n",
      "[Training] Epoch: 5 [=>             ] 7.9% Loss: 0.4327, Epoch 5, Batch 9, CE_loss: 0.3757069408893585, Dice_loss: 0.04924085736274719, Consistency_loss: 0.0008016711217351258\n",
      "[Training] Epoch: 5 [=>             ] 8.7% Loss: 0.4325, Epoch 5, Batch 10, CE_loss: 0.3795951306819916, Dice_loss: 0.049929916858673096, Consistency_loss: 0.0013364366022869945\n",
      "[Training] Epoch: 5 [=>             ] 9.5% Loss: 0.4330, Epoch 5, Batch 11, CE_loss: 0.38688531517982483, Dice_loss: 0.05087268725037575, Consistency_loss: 0.001168042654171586\n",
      "[Training] Epoch: 5 [=>             ] 10.3% Loss: 0.4323, Epoch 5, Batch 12, CE_loss: 0.3743559420108795, Dice_loss: 0.048807695508003235, Consistency_loss: 0.0008002897957339883\n",
      "[Training] Epoch: 5 [=>             ] 11.1% Loss: 0.4314, Epoch 5, Batch 13, CE_loss: 0.37040820717811584, Dice_loss: 0.04833294078707695, Consistency_loss: 0.0011007541324943304\n",
      "[Training] Epoch: 5 [=>             ] 11.9% Loss: 0.4311, Epoch 5, Batch 14, CE_loss: 0.3766816258430481, Dice_loss: 0.049178462475538254, Consistency_loss: 0.0007496673497371376\n",
      "[Training] Epoch: 5 [=>             ] 12.7% Loss: 0.4310, Epoch 5, Batch 15, CE_loss: 0.3792659342288971, Dice_loss: 0.04960024729371071, Consistency_loss: 0.0008849170408211648\n",
      "[Training] Epoch: 5 [==>            ] 13.5% Loss: 0.4309, Epoch 5, Batch 16, CE_loss: 0.3777585029602051, Dice_loss: 0.049352385103702545, Consistency_loss: 0.0010076191974803805\n",
      "[Training] Epoch: 5 [==>            ] 14.3% Loss: 0.4304, Epoch 5, Batch 17, CE_loss: 0.37275123596191406, Dice_loss: 0.048338230699300766, Consistency_loss: 0.0009110664832405746\n",
      "[Training] Epoch: 5 [==>            ] 15.1% Loss: 0.4305, Epoch 5, Batch 18, CE_loss: 0.3814975321292877, Dice_loss: 0.04988108202815056, Consistency_loss: 0.0009631898137740791\n",
      "[Training] Epoch: 5 [==>            ] 15.9% Loss: 0.4304, Epoch 5, Batch 19, CE_loss: 0.37840744853019714, Dice_loss: 0.04960520938038826, Consistency_loss: 0.0007754905964247882\n",
      "[Training] Epoch: 5 [==>            ] 16.7% Loss: 0.4297, Epoch 5, Batch 20, CE_loss: 0.367829293012619, Dice_loss: 0.047637563198804855, Consistency_loss: 0.001035279594361782\n",
      "[Training] Epoch: 5 [==>            ] 17.5% Loss: 0.4293, Epoch 5, Batch 21, CE_loss: 0.37147361040115356, Dice_loss: 0.04813370853662491, Consistency_loss: 0.0010068955598399043\n",
      "[Training] Epoch: 5 [==>            ] 18.3% Loss: 0.4297, Epoch 5, Batch 22, CE_loss: 0.3862746059894562, Dice_loss: 0.050832558423280716, Consistency_loss: 0.000673794187605381\n",
      "[Training] Epoch: 5 [==>            ] 19.0% Loss: 0.4292, Epoch 5, Batch 23, CE_loss: 0.36973825097084045, Dice_loss: 0.04772975668311119, Consistency_loss: 0.000833381898701191\n",
      "[Training] Epoch: 5 [==>            ] 19.8% Loss: 0.4294, Epoch 5, Batch 24, CE_loss: 0.38257867097854614, Dice_loss: 0.05067185312509537, Consistency_loss: 0.0013411956606432796\n",
      "[Training] Epoch: 5 [===>           ] 20.6% Loss: 0.4297, Epoch 5, Batch 25, CE_loss: 0.38446590304374695, Dice_loss: 0.050406742841005325, Consistency_loss: 0.0013201039982959628\n",
      "[Training] Epoch: 5 [===>           ] 21.4% Loss: 0.4293, Epoch 5, Batch 26, CE_loss: 0.3689206540584564, Dice_loss: 0.04908512160181999, Consistency_loss: 0.0012610114645212889\n",
      "[Training] Epoch: 5 [===>           ] 22.2% Loss: 0.4289, Epoch 5, Batch 27, CE_loss: 0.3694324195384979, Dice_loss: 0.04809098318219185, Consistency_loss: 0.00031610013684257865\n",
      "[Training] Epoch: 5 [===>           ] 23.0% Loss: 0.4283, Epoch 5, Batch 28, CE_loss: 0.36582738161087036, Dice_loss: 0.04690663889050484, Consistency_loss: 0.0003745954018086195\n",
      "[Training] Epoch: 5 [===>           ] 23.8% Loss: 0.4280, Epoch 5, Batch 29, CE_loss: 0.3686388432979584, Dice_loss: 0.04737379774451256, Consistency_loss: 0.0008953882497735322\n",
      "[Training] Epoch: 5 [===>           ] 24.6% Loss: 0.4280, Epoch 5, Batch 30, CE_loss: 0.3790176808834076, Dice_loss: 0.04922453686594963, Consistency_loss: 0.001069331425242126\n",
      "[Training] Epoch: 5 [===>           ] 25.4% Loss: 0.4275, Epoch 5, Batch 31, CE_loss: 0.3652806878089905, Dice_loss: 0.047100313007831573, Consistency_loss: 0.00016861663607414812\n",
      "[Training] Epoch: 5 [===>           ] 26.2% Loss: 0.4272, Epoch 5, Batch 32, CE_loss: 0.3684859275817871, Dice_loss: 0.047618020325899124, Consistency_loss: 0.0009648740524426103\n",
      "[Training] Epoch: 5 [====>          ] 27.0% Loss: 0.4269, Epoch 5, Batch 33, CE_loss: 0.36951926350593567, Dice_loss: 0.04760286584496498, Consistency_loss: 0.0008184911566786468\n",
      "[Training] Epoch: 5 [====>          ] 27.8% Loss: 0.4266, Epoch 5, Batch 34, CE_loss: 0.36760178208351135, Dice_loss: 0.04744419828057289, Consistency_loss: 0.0009327957523055375\n",
      "[Training] Epoch: 5 [====>          ] 28.6% Loss: 0.4263, Epoch 5, Batch 35, CE_loss: 0.36690351366996765, Dice_loss: 0.04702591150999069, Consistency_loss: 0.0010950638679787517\n",
      "[Training] Epoch: 5 [====>          ] 29.4% Loss: 0.4260, Epoch 5, Batch 36, CE_loss: 0.36750584840774536, Dice_loss: 0.047076091170310974, Consistency_loss: 0.0010181417455896735\n",
      "[Training] Epoch: 5 [====>          ] 30.2% Loss: 0.4256, Epoch 5, Batch 37, CE_loss: 0.3621191084384918, Dice_loss: 0.04628901556134224, Consistency_loss: 0.0010632863268256187\n",
      "[Training] Epoch: 5 [====>          ] 31.0% Loss: 0.4254, Epoch 5, Batch 38, CE_loss: 0.3690849542617798, Dice_loss: 0.04723174870014191, Consistency_loss: 0.0010778316063806415\n",
      "[Training] Epoch: 5 [====>          ] 31.7% Loss: 0.4251, Epoch 5, Batch 39, CE_loss: 0.36787840723991394, Dice_loss: 0.047152549028396606, Consistency_loss: 0.0012952847173437476\n",
      "[Training] Epoch: 5 [====>          ] 32.5% Loss: 0.4247, Epoch 5, Batch 40, CE_loss: 0.3604162931442261, Dice_loss: 0.045778192579746246, Consistency_loss: 0.00015895259275566787\n",
      "[Training] Epoch: 5 [=====>         ] 33.3% Loss: 0.4243, Epoch 5, Batch 41, CE_loss: 0.36015233397483826, Dice_loss: 0.046204157173633575, Consistency_loss: 0.0012030400102958083\n",
      "[Training] Epoch: 5 [=====>         ] 34.1% Loss: 0.4239, Epoch 5, Batch 42, CE_loss: 0.3608073592185974, Dice_loss: 0.046135928481817245, Consistency_loss: 0.00020962038252037019\n",
      "[Training] Epoch: 5 [=====>         ] 34.9% Loss: 0.4235, Epoch 5, Batch 43, CE_loss: 0.3583546578884125, Dice_loss: 0.04563029482960701, Consistency_loss: 0.0014198069693520665\n",
      "[Training] Epoch: 5 [=====>         ] 35.7% Loss: 0.4228, Epoch 5, Batch 44, CE_loss: 0.3505752384662628, Dice_loss: 0.04409917816519737, Consistency_loss: 0.0010495147434994578\n",
      "[Training] Epoch: 5 [=====>         ] 36.5% Loss: 0.4225, Epoch 5, Batch 45, CE_loss: 0.3590078055858612, Dice_loss: 0.04572022706270218, Consistency_loss: 0.0009461326408199966\n",
      "[Training] Epoch: 5 [=====>         ] 37.3% Loss: 0.4221, Epoch 5, Batch 46, CE_loss: 0.3580595552921295, Dice_loss: 0.04530693218111992, Consistency_loss: 0.00016847490041982383\n",
      "[Training] Epoch: 5 [=====>         ] 38.1% Loss: 0.4219, Epoch 5, Batch 47, CE_loss: 0.36441341042518616, Dice_loss: 0.046319298446178436, Consistency_loss: 0.0011501424014568329\n",
      "[Training] Epoch: 5 [=====>         ] 38.9% Loss: 0.4215, Epoch 5, Batch 48, CE_loss: 0.3573864996433258, Dice_loss: 0.045254677534103394, Consistency_loss: 0.0015005192253738642\n",
      "[Training] Epoch: 5 [=====>         ] 39.7% Loss: 0.4214, Epoch 5, Batch 49, CE_loss: 0.3687033951282501, Dice_loss: 0.04702512547373772, Consistency_loss: 0.00016069950652308762\n",
      "[Training] Epoch: 5 [======>        ] 40.5% Loss: 0.4211, Epoch 5, Batch 50, CE_loss: 0.3584027588367462, Dice_loss: 0.045346807688474655, Consistency_loss: 0.001262150937691331\n",
      "[Training] Epoch: 5 [======>        ] 41.3% Loss: 0.4207, Epoch 5, Batch 51, CE_loss: 0.3563466966152191, Dice_loss: 0.04500533267855644, Consistency_loss: 0.0012635058956220746\n",
      "[Training] Epoch: 5 [======>        ] 42.1% Loss: 0.4202, Epoch 5, Batch 52, CE_loss: 0.35143861174583435, Dice_loss: 0.04416390508413315, Consistency_loss: 0.0008589941426180303\n",
      "[Training] Epoch: 5 [======>        ] 42.9% Loss: 0.4200, Epoch 5, Batch 53, CE_loss: 0.36119192838668823, Dice_loss: 0.04589448869228363, Consistency_loss: 0.001196830766275525\n",
      "[Training] Epoch: 5 [======>        ] 43.7% Loss: 0.4196, Epoch 5, Batch 54, CE_loss: 0.3521128296852112, Dice_loss: 0.04427219182252884, Consistency_loss: 0.0009681428200565279\n",
      "[Training] Epoch: 5 [======>        ] 44.4% Loss: 0.4193, Epoch 5, Batch 55, CE_loss: 0.3555849492549896, Dice_loss: 0.04515016824007034, Consistency_loss: 0.0008044759160839021\n",
      "[Training] Epoch: 5 [======>        ] 45.2% Loss: 0.4188, Epoch 5, Batch 56, CE_loss: 0.34882092475891113, Dice_loss: 0.04363468661904335, Consistency_loss: 0.0001285246980842203\n",
      "[Training] Epoch: 5 [======>        ] 46.0% Loss: 0.4186, Epoch 5, Batch 57, CE_loss: 0.35887202620506287, Dice_loss: 0.045327842235565186, Consistency_loss: 0.0011224029585719109\n",
      "[Training] Epoch: 5 [=======>       ] 46.8% Loss: 0.4183, Epoch 5, Batch 58, CE_loss: 0.35670438408851624, Dice_loss: 0.045183274894952774, Consistency_loss: 0.0009413886000402272\n",
      "[Training] Epoch: 5 [=======>       ] 47.6% Loss: 0.4180, Epoch 5, Batch 59, CE_loss: 0.3506232500076294, Dice_loss: 0.04477088525891304, Consistency_loss: 0.0010978494537994266\n",
      "[Training] Epoch: 5 [=======>       ] 48.4% Loss: 0.4176, Epoch 5, Batch 60, CE_loss: 0.35306093096733093, Dice_loss: 0.04451391100883484, Consistency_loss: 0.0003137452877126634\n",
      "[Training] Epoch: 5 [=======>       ] 49.2% Loss: 0.4172, Epoch 5, Batch 61, CE_loss: 0.3480187654495239, Dice_loss: 0.043391600251197815, Consistency_loss: 0.0011052658082917333\n",
      "[Training] Epoch: 5 [=======>       ] 50.0% Loss: 0.4168, Epoch 5, Batch 62, CE_loss: 0.3444283902645111, Dice_loss: 0.042775869369506836, Consistency_loss: 0.001323409378528595\n",
      "[Training] Epoch: 5 [=======>       ] 50.8% Loss: 0.4165, Epoch 5, Batch 63, CE_loss: 0.3525865375995636, Dice_loss: 0.04397009313106537, Consistency_loss: 0.001294534420594573\n",
      "[Training] Epoch: 5 [=======>       ] 51.6% Loss: 0.4161, Epoch 5, Batch 64, CE_loss: 0.3471106290817261, Dice_loss: 0.04308974742889404, Consistency_loss: 0.001184422872029245\n",
      "[Training] Epoch: 5 [=======>       ] 52.4% Loss: 0.4159, Epoch 5, Batch 65, CE_loss: 0.35600629448890686, Dice_loss: 0.045001644641160965, Consistency_loss: 0.0011667804792523384\n",
      "[Training] Epoch: 5 [=======>       ] 53.2% Loss: 0.4156, Epoch 5, Batch 66, CE_loss: 0.3531031608581543, Dice_loss: 0.044017206877470016, Consistency_loss: 0.0008853147155605257\n",
      "[Training] Epoch: 5 [========>      ] 54.0% Loss: 0.4153, Epoch 5, Batch 67, CE_loss: 0.34860724210739136, Dice_loss: 0.04384809732437134, Consistency_loss: 0.00018593623826745898\n",
      "[Training] Epoch: 5 [========>      ] 54.8% Loss: 0.4149, Epoch 5, Batch 68, CE_loss: 0.3470345139503479, Dice_loss: 0.043085187673568726, Consistency_loss: 0.00019056898599956185\n",
      "[Training] Epoch: 5 [========>      ] 55.6% Loss: 0.4147, Epoch 5, Batch 69, CE_loss: 0.35497844219207764, Dice_loss: 0.04440512880682945, Consistency_loss: 0.0008264416246674955\n",
      "[Training] Epoch: 5 [========>      ] 56.3% Loss: 0.4144, Epoch 5, Batch 70, CE_loss: 0.35068589448928833, Dice_loss: 0.043842192739248276, Consistency_loss: 0.001098494860343635\n",
      "[Training] Epoch: 5 [========>      ] 57.1% Loss: 0.4141, Epoch 5, Batch 71, CE_loss: 0.3477688729763031, Dice_loss: 0.04299197345972061, Consistency_loss: 0.0005663334741257131\n",
      "[Training] Epoch: 5 [========>      ] 57.9% Loss: 0.4138, Epoch 5, Batch 72, CE_loss: 0.34435099363327026, Dice_loss: 0.042479805648326874, Consistency_loss: 0.0010265710297971964\n",
      "[Training] Epoch: 5 [========>      ] 58.7% Loss: 0.4135, Epoch 5, Batch 73, CE_loss: 0.3478599786758423, Dice_loss: 0.04324755072593689, Consistency_loss: 0.0014922282425686717\n",
      "[Training] Epoch: 5 [========>      ] 59.5% Loss: 0.4132, Epoch 5, Batch 74, CE_loss: 0.3460705280303955, Dice_loss: 0.04278488829731941, Consistency_loss: 0.001170241623185575\n",
      "[Training] Epoch: 5 [=========>     ] 60.3% Loss: 0.4129, Epoch 5, Batch 75, CE_loss: 0.3486135005950928, Dice_loss: 0.04330182075500488, Consistency_loss: 0.0008806716650724411\n",
      "[Training] Epoch: 5 [=========>     ] 61.1% Loss: 0.4127, Epoch 5, Batch 76, CE_loss: 0.35367509722709656, Dice_loss: 0.04405592009425163, Consistency_loss: 0.0009794809157028794\n",
      "[Training] Epoch: 5 [=========>     ] 61.9% Loss: 0.4124, Epoch 5, Batch 77, CE_loss: 0.34919413924217224, Dice_loss: 0.0436549037694931, Consistency_loss: 0.00010299387940904126\n",
      "[Training] Epoch: 5 [=========>     ] 62.7% Loss: 0.4120, Epoch 5, Batch 78, CE_loss: 0.33878377079963684, Dice_loss: 0.041524190455675125, Consistency_loss: 0.00010175529314437881\n",
      "[Training] Epoch: 5 [=========>     ] 63.5% Loss: 0.4117, Epoch 5, Batch 79, CE_loss: 0.3436284065246582, Dice_loss: 0.04236280918121338, Consistency_loss: 0.0001233244256582111\n",
      "[Training] Epoch: 5 [=========>     ] 64.3% Loss: 0.4115, Epoch 5, Batch 80, CE_loss: 0.34611380100250244, Dice_loss: 0.04282425343990326, Consistency_loss: 0.0010995101183652878\n",
      "[Training] Epoch: 5 [=========>     ] 65.1% Loss: 0.4110, Epoch 5, Batch 81, CE_loss: 0.334575355052948, Dice_loss: 0.040853895246982574, Consistency_loss: 0.0016595869092270732\n",
      "[Training] Epoch: 5 [=========>     ] 65.9% Loss: 0.4107, Epoch 5, Batch 82, CE_loss: 0.340555340051651, Dice_loss: 0.04187217354774475, Consistency_loss: 0.0014072032645344734\n",
      "[Training] Epoch: 5 [==========>    ] 66.7% Loss: 0.4104, Epoch 5, Batch 83, CE_loss: 0.3416052758693695, Dice_loss: 0.04214105382561684, Consistency_loss: 0.0008841283852234483\n",
      "[Training] Epoch: 5 [==========>    ] 67.5% Loss: 0.4100, Epoch 5, Batch 84, CE_loss: 0.3352304995059967, Dice_loss: 0.04103407636284828, Consistency_loss: 0.0010095125762745738\n",
      "[Training] Epoch: 5 [==========>    ] 68.3% Loss: 0.4097, Epoch 5, Batch 85, CE_loss: 0.33702677488327026, Dice_loss: 0.041426703333854675, Consistency_loss: 0.0013370601227506995\n",
      "[Training] Epoch: 5 [==========>    ] 69.0% Loss: 0.4093, Epoch 5, Batch 86, CE_loss: 0.3388151526451111, Dice_loss: 0.04165985807776451, Consistency_loss: 0.0001691574143478647\n",
      "[Training] Epoch: 5 [==========>    ] 69.8% Loss: 0.4090, Epoch 5, Batch 87, CE_loss: 0.33865252137184143, Dice_loss: 0.04159463569521904, Consistency_loss: 0.001055894885212183\n",
      "[Training] Epoch: 5 [==========>    ] 70.6% Loss: 0.4087, Epoch 5, Batch 88, CE_loss: 0.34031084179878235, Dice_loss: 0.04166512191295624, Consistency_loss: 0.0012634671293199062\n",
      "[Training] Epoch: 5 [==========>    ] 71.4% Loss: 0.4083, Epoch 5, Batch 89, CE_loss: 0.3329111635684967, Dice_loss: 0.04027663916349411, Consistency_loss: 0.0001011848435155116\n",
      "[Training] Epoch: 5 [==========>    ] 72.2% Loss: 0.4080, Epoch 5, Batch 90, CE_loss: 0.3369136452674866, Dice_loss: 0.0412641204893589, Consistency_loss: 0.0012153321877121925\n",
      "[Training] Epoch: 5 [==========>    ] 73.0% Loss: 0.4078, Epoch 5, Batch 91, CE_loss: 0.34294813871383667, Dice_loss: 0.042173080146312714, Consistency_loss: 0.0013860658509656787\n",
      "[Training] Epoch: 5 [===========>   ] 73.8% Loss: 0.4075, Epoch 5, Batch 92, CE_loss: 0.33896398544311523, Dice_loss: 0.04145325720310211, Consistency_loss: 0.0009312741458415985\n",
      "[Training] Epoch: 5 [===========>   ] 74.6% Loss: 0.4071, Epoch 5, Batch 93, CE_loss: 0.32788148522377014, Dice_loss: 0.03942073509097099, Consistency_loss: 9.531318210065365e-05\n",
      "[Training] Epoch: 5 [===========>   ] 75.4% Loss: 0.4066, Epoch 5, Batch 94, CE_loss: 0.32672828435897827, Dice_loss: 0.03916480392217636, Consistency_loss: 0.00010320528963347897\n",
      "[Training] Epoch: 5 [===========>   ] 76.2% Loss: 0.4065, Epoch 5, Batch 95, CE_loss: 0.3510068655014038, Dice_loss: 0.043373387306928635, Consistency_loss: 0.0008366062538698316\n",
      "[Training] Epoch: 5 [===========>   ] 77.0% Loss: 0.4064, Epoch 5, Batch 96, CE_loss: 0.3485584855079651, Dice_loss: 0.04298201948404312, Consistency_loss: 0.0008736326708458364\n",
      "[Training] Epoch: 5 [===========>   ] 77.8% Loss: 0.4061, Epoch 5, Batch 97, CE_loss: 0.3364115357398987, Dice_loss: 0.040716901421546936, Consistency_loss: 0.0006100353202782571\n",
      "[Training] Epoch: 5 [===========>   ] 78.6% Loss: 0.4058, Epoch 5, Batch 98, CE_loss: 0.3358187973499298, Dice_loss: 0.04094274342060089, Consistency_loss: 0.0007183919078670442\n",
      "[Training] Epoch: 5 [===========>   ] 79.4% Loss: 0.4053, Epoch 5, Batch 99, CE_loss: 0.3214632272720337, Dice_loss: 0.03835156187415123, Consistency_loss: 0.0010958348866552114\n",
      "[Training] Epoch: 5 [============>  ] 80.2% Loss: 0.4050, Epoch 5, Batch 100, CE_loss: 0.334756463766098, Dice_loss: 0.040576234459877014, Consistency_loss: 0.00016878182941582054\n",
      "[Training] Epoch: 5 [============>  ] 81.0% Loss: 0.4047, Epoch 5, Batch 101, CE_loss: 0.3282548189163208, Dice_loss: 0.039330724626779556, Consistency_loss: 0.0012410752242431045\n",
      "[Training] Epoch: 5 [============>  ] 81.7% Loss: 0.4044, Epoch 5, Batch 102, CE_loss: 0.3363124430179596, Dice_loss: 0.04067537188529968, Consistency_loss: 0.00014537977403961122\n",
      "[Training] Epoch: 5 [============>  ] 82.5% Loss: 0.4040, Epoch 5, Batch 103, CE_loss: 0.3240809142589569, Dice_loss: 0.03891262784600258, Consistency_loss: 0.0014783547958359122\n",
      "[Training] Epoch: 5 [============>  ] 83.3% Loss: 0.4036, Epoch 5, Batch 104, CE_loss: 0.3223816752433777, Dice_loss: 0.03843023627996445, Consistency_loss: 0.0012400213163346052\n",
      "[Training] Epoch: 5 [============>  ] 84.1% Loss: 0.4033, Epoch 5, Batch 105, CE_loss: 0.32851794362068176, Dice_loss: 0.039546385407447815, Consistency_loss: 0.0002376193879172206\n",
      "[Training] Epoch: 5 [============>  ] 84.9% Loss: 0.4029, Epoch 5, Batch 106, CE_loss: 0.3233017325401306, Dice_loss: 0.038397688418626785, Consistency_loss: 0.0013075177557766438\n",
      "[Training] Epoch: 5 [============>  ] 85.7% Loss: 0.4026, Epoch 5, Batch 107, CE_loss: 0.32945516705513, Dice_loss: 0.039768896996974945, Consistency_loss: 0.00150671589653939\n",
      "[Training] Epoch: 5 [============>  ] 86.5% Loss: 0.4023, Epoch 5, Batch 108, CE_loss: 0.3271850347518921, Dice_loss: 0.039355482906103134, Consistency_loss: 0.0012608164688572288\n",
      "[Training] Epoch: 5 [=============> ] 87.3% Loss: 0.4021, Epoch 5, Batch 109, CE_loss: 0.3363896608352661, Dice_loss: 0.04085155948996544, Consistency_loss: 0.00020650778606068343\n",
      "[Training] Epoch: 5 [=============> ] 88.1% Loss: 0.4018, Epoch 5, Batch 110, CE_loss: 0.3318776786327362, Dice_loss: 0.04032662510871887, Consistency_loss: 0.0011031153844669461\n",
      "[Training] Epoch: 5 [=============> ] 88.9% Loss: 0.4016, Epoch 5, Batch 111, CE_loss: 0.3363867402076721, Dice_loss: 0.04060208797454834, Consistency_loss: 0.0013690092600882053\n",
      "[Training] Epoch: 5 [=============> ] 89.7% Loss: 0.4014, Epoch 5, Batch 112, CE_loss: 0.33151775598526, Dice_loss: 0.04009557515382767, Consistency_loss: 0.0011218645377084613\n",
      "[Training] Epoch: 5 [=============> ] 90.5% Loss: 0.4011, Epoch 5, Batch 113, CE_loss: 0.33219245076179504, Dice_loss: 0.04002566635608673, Consistency_loss: 0.0014175829710438848\n",
      "[Training] Epoch: 5 [=============> ] 91.3% Loss: 0.4008, Epoch 5, Batch 114, CE_loss: 0.32722505927085876, Dice_loss: 0.03931216523051262, Consistency_loss: 0.0014629882061854005\n",
      "[Training] Epoch: 5 [=============> ] 92.1% Loss: 0.4006, Epoch 5, Batch 115, CE_loss: 0.33459970355033875, Dice_loss: 0.04029148817062378, Consistency_loss: 0.0014444603584706783\n",
      "[Training] Epoch: 5 [=============> ] 92.9% Loss: 0.4004, Epoch 5, Batch 116, CE_loss: 0.335220605134964, Dice_loss: 0.04066670686006546, Consistency_loss: 0.0014297354500740767\n",
      "[Training] Epoch: 5 [==============>] 93.7% Loss: 0.4001, Epoch 5, Batch 117, CE_loss: 0.3236757218837738, Dice_loss: 0.03863886371254921, Consistency_loss: 0.0012989258393645287\n",
      "[Training] Epoch: 5 [==============>] 94.4% Loss: 0.3999, Epoch 5, Batch 118, CE_loss: 0.33098483085632324, Dice_loss: 0.03968341648578644, Consistency_loss: 0.000899994745850563\n",
      "[Training] Epoch: 5 [==============>] 95.2% Loss: 0.3996, Epoch 5, Batch 119, CE_loss: 0.32794472575187683, Dice_loss: 0.039439670741558075, Consistency_loss: 0.0006831979262642562\n",
      "[Training] Epoch: 5 [==============>] 96.0% Loss: 0.3993, Epoch 5, Batch 120, CE_loss: 0.32434916496276855, Dice_loss: 0.038681041449308395, Consistency_loss: 0.00020640227012336254\n",
      "[Training] Epoch: 5 [==============>] 96.8% Loss: 0.3990, Epoch 5, Batch 121, CE_loss: 0.32160666584968567, Dice_loss: 0.03830749914050102, Consistency_loss: 0.0008893762133084238\n",
      "[Training] Epoch: 5 [==============>] 97.6% Loss: 0.3987, Epoch 5, Batch 122, CE_loss: 0.3231744170188904, Dice_loss: 0.03859148174524307, Consistency_loss: 0.0009393075597472489\n",
      "[Training] Epoch: 5 [==============>] 98.4% Loss: 0.3984, Epoch 5, Batch 123, CE_loss: 0.32477831840515137, Dice_loss: 0.0384761244058609, Consistency_loss: 0.00015283386164810508\n",
      "[Training] Epoch: 5 [==============>] 99.2% Loss: 0.3980, Epoch 5, Batch 124, CE_loss: 0.3155783414840698, Dice_loss: 0.037662044167518616, Consistency_loss: 0.0015079728327691555\n",
      "[Training] Epoch: 5 [DONE]                                 \n",
      "Epoch 5, Batch 125, CE_loss: 0.33319878578186035, Dice_loss: 0.04019290953874588, Consistency_loss: 0.0020556249655783176\n",
      "[Validation] Epoch: 5 [DONE]                                 \n",
      "[Epoch: 5, TrainLoss: 0.3979, TrainDice: 0.0443, ValLoss: 0.3598                                             \n",
      "Number of batches:  126\n",
      "[Training] Epoch: 6 [>              ] 0.8% Loss: 0.3582, Epoch 6, Batch 0, CE_loss: 0.31881606578826904, Dice_loss: 0.03798976540565491, Consistency_loss: 0.001425573485903442\n",
      "[Training] Epoch: 6 [>              ] 1.6% Loss: 0.3538, Epoch 6, Batch 1, CE_loss: 0.3115895986557007, Dice_loss: 0.03653993457555771, Consistency_loss: 0.0012771239271387458\n",
      "[Training] Epoch: 6 [>              ] 2.4% Loss: 0.3636, Epoch 6, Batch 2, CE_loss: 0.3411489427089691, Dice_loss: 0.04132039099931717, Consistency_loss: 0.000798862602096051\n",
      "[Training] Epoch: 6 [>              ] 3.2% Loss: 0.3606, Epoch 6, Batch 3, CE_loss: 0.3144812285900116, Dice_loss: 0.03686867654323578, Consistency_loss: 0.00013263153959996998\n",
      "[Training] Epoch: 6 [>              ] 4.0% Loss: 0.3599, Epoch 6, Batch 4, CE_loss: 0.31819531321525574, Dice_loss: 0.03781312704086304, Consistency_loss: 0.0011569923954084516\n",
      "[Training] Epoch: 6 [>              ] 4.8% Loss: 0.3594, Epoch 6, Batch 5, CE_loss: 0.31879961490631104, Dice_loss: 0.037619829177856445, Consistency_loss: 0.0006710776942782104\n",
      "[Training] Epoch: 6 [>              ] 5.6% Loss: 0.3591, Epoch 6, Batch 6, CE_loss: 0.31888020038604736, Dice_loss: 0.037516143172979355, Consistency_loss: 0.0006498013390228152\n",
      "[Training] Epoch: 6 [>              ] 6.3% Loss: 0.3576, Epoch 6, Batch 7, CE_loss: 0.31002408266067505, Dice_loss: 0.03625183552503586, Consistency_loss: 0.0006335052894428372\n",
      "[Training] Epoch: 6 [=>             ] 7.1% Loss: 0.3584, Epoch 6, Batch 8, CE_loss: 0.32612529397010803, Dice_loss: 0.03862530738115311, Consistency_loss: 0.00042138967546634376\n",
      "[Training] Epoch: 6 [=>             ] 7.9% Loss: 0.3579, Epoch 6, Batch 9, CE_loss: 0.3157587945461273, Dice_loss: 0.03686627745628357, Consistency_loss: 0.0005996948457323015\n",
      "[Training] Epoch: 6 [=>             ] 8.7% Loss: 0.3584, Epoch 6, Batch 10, CE_loss: 0.3238537013530731, Dice_loss: 0.038539573550224304, Consistency_loss: 0.0008995174430310726\n",
      "[Training] Epoch: 6 [=>             ] 9.5% Loss: 0.3580, Epoch 6, Batch 11, CE_loss: 0.3166508078575134, Dice_loss: 0.0370216891169548, Consistency_loss: 0.0001775162381818518\n",
      "[Training] Epoch: 6 [=>             ] 10.3% Loss: 0.3576, Epoch 6, Batch 12, CE_loss: 0.31581586599349976, Dice_loss: 0.03684639558196068, Consistency_loss: 0.00013047989341430366\n",
      "[Training] Epoch: 6 [=>             ] 11.1% Loss: 0.3570, Epoch 6, Batch 13, CE_loss: 0.3113633990287781, Dice_loss: 0.036234576255083084, Consistency_loss: 0.0008589367498643696\n",
      "[Training] Epoch: 6 [=>             ] 11.9% Loss: 0.3566, Epoch 6, Batch 14, CE_loss: 0.31382396817207336, Dice_loss: 0.03656736761331558, Consistency_loss: 0.0009228886337950826\n",
      "[Training] Epoch: 6 [=>             ] 12.7% Loss: 0.3564, Epoch 6, Batch 15, CE_loss: 0.31625452637672424, Dice_loss: 0.03718003258109093, Consistency_loss: 0.0007088342099450529\n",
      "[Training] Epoch: 6 [==>            ] 13.5% Loss: 0.3561, Epoch 6, Batch 16, CE_loss: 0.3133188486099243, Dice_loss: 0.03645053505897522, Consistency_loss: 0.0006095338612794876\n",
      "[Training] Epoch: 6 [==>            ] 14.3% Loss: 0.3555, Epoch 6, Batch 17, CE_loss: 0.3096719980239868, Dice_loss: 0.0359811931848526, Consistency_loss: 0.0008209106745198369\n",
      "[Training] Epoch: 6 [==>            ] 15.1% Loss: 0.3551, Epoch 6, Batch 18, CE_loss: 0.3105241656303406, Dice_loss: 0.03598134219646454, Consistency_loss: 0.0008495381334796548\n",
      "[Training] Epoch: 6 [==>            ] 15.9% Loss: 0.3547, Epoch 6, Batch 19, CE_loss: 0.31064242124557495, Dice_loss: 0.03600044921040535, Consistency_loss: 0.00019314065866637975\n",
      "[Training] Epoch: 6 [==>            ] 16.7% Loss: 0.3544, Epoch 6, Batch 20, CE_loss: 0.3109438717365265, Dice_loss: 0.03611792251467705, Consistency_loss: 0.0013731088256463408\n",
      "[Training] Epoch: 6 [==>            ] 17.5% Loss: 0.3544, Epoch 6, Batch 21, CE_loss: 0.31676244735717773, Dice_loss: 0.03724820166826248, Consistency_loss: 0.0012790824985131621\n",
      "[Training] Epoch: 6 [==>            ] 18.3% Loss: 0.3541, Epoch 6, Batch 22, CE_loss: 0.3107624351978302, Dice_loss: 0.03600141406059265, Consistency_loss: 0.0008110023336485028\n",
      "[Training] Epoch: 6 [==>            ] 19.0% Loss: 0.3537, Epoch 6, Batch 23, CE_loss: 0.30605411529541016, Dice_loss: 0.035534411668777466, Consistency_loss: 0.0011552150826901197\n",
      "[Training] Epoch: 6 [==>            ] 19.8% Loss: 0.3537, Epoch 6, Batch 24, CE_loss: 0.316072016954422, Dice_loss: 0.03762179613113403, Consistency_loss: 0.0008819533395580947\n",
      "[Training] Epoch: 6 [===>           ] 20.6% Loss: 0.3534, Epoch 6, Batch 25, CE_loss: 0.3093704283237457, Dice_loss: 0.03586874157190323, Consistency_loss: 0.0011635374976322055\n",
      "[Training] Epoch: 6 [===>           ] 21.4% Loss: 0.3536, Epoch 6, Batch 26, CE_loss: 0.31990036368370056, Dice_loss: 0.03741879388689995, Consistency_loss: 0.0010667698225006461\n",
      "[Training] Epoch: 6 [===>           ] 22.2% Loss: 0.3531, Epoch 6, Batch 27, CE_loss: 0.3049492835998535, Dice_loss: 0.03504567593336105, Consistency_loss: 0.00025169970467686653\n",
      "[Training] Epoch: 6 [===>           ] 23.0% Loss: 0.3529, Epoch 6, Batch 28, CE_loss: 0.3096182346343994, Dice_loss: 0.035762760788202286, Consistency_loss: 0.00013293321535456926\n",
      "[Training] Epoch: 6 [===>           ] 23.8% Loss: 0.3527, Epoch 6, Batch 29, CE_loss: 0.31067538261413574, Dice_loss: 0.03604533150792122, Consistency_loss: 0.00018293938774149865\n",
      "[Training] Epoch: 6 [===>           ] 24.6% Loss: 0.3523, Epoch 6, Batch 30, CE_loss: 0.30558153986930847, Dice_loss: 0.035352349281311035, Consistency_loss: 0.001400468056090176\n",
      "[Training] Epoch: 6 [===>           ] 25.4% Loss: 0.3518, Epoch 6, Batch 31, CE_loss: 0.29920274019241333, Dice_loss: 0.03389572352170944, Consistency_loss: 0.001205453067086637\n",
      "[Training] Epoch: 6 [===>           ] 26.2% Loss: 0.3511, Epoch 6, Batch 32, CE_loss: 0.294842392206192, Dice_loss: 0.03334695100784302, Consistency_loss: 0.0002125576138496399\n",
      "[Training] Epoch: 6 [====>          ] 27.0% Loss: 0.3510, Epoch 6, Batch 33, CE_loss: 0.31127604842185974, Dice_loss: 0.036271195858716965, Consistency_loss: 0.0013590793823823333\n",
      "[Training] Epoch: 6 [====>          ] 27.8% Loss: 0.3507, Epoch 6, Batch 34, CE_loss: 0.3037267327308655, Dice_loss: 0.03516656905412674, Consistency_loss: 0.0013073725858703256\n",
      "[Training] Epoch: 6 [====>          ] 28.6% Loss: 0.3503, Epoch 6, Batch 35, CE_loss: 0.30060911178588867, Dice_loss: 0.034427039325237274, Consistency_loss: 0.0002887572627514601\n",
      "[Training] Epoch: 6 [====>          ] 29.4% Loss: 0.3499, Epoch 6, Batch 36, CE_loss: 0.30073827505111694, Dice_loss: 0.0344286784529686, Consistency_loss: 0.0002764787641353905\n",
      "[Training] Epoch: 6 [====>          ] 30.2% Loss: 0.3498, Epoch 6, Batch 37, CE_loss: 0.30963006615638733, Dice_loss: 0.03623669967055321, Consistency_loss: 0.0012090710224583745\n",
      "[Training] Epoch: 6 [====>          ] 31.0% Loss: 0.3496, Epoch 6, Batch 38, CE_loss: 0.3043343126773834, Dice_loss: 0.034988515079021454, Consistency_loss: 0.0015102315228432417\n",
      "[Training] Epoch: 6 [====>          ] 31.7% Loss: 0.3495, Epoch 6, Batch 39, CE_loss: 0.3098733127117157, Dice_loss: 0.03562777116894722, Consistency_loss: 0.0016095098108053207\n",
      "[Training] Epoch: 6 [====>          ] 32.5% Loss: 0.3494, Epoch 6, Batch 40, CE_loss: 0.30897870659828186, Dice_loss: 0.03610809147357941, Consistency_loss: 0.0013514527818188071\n",
      "[Training] Epoch: 6 [=====>         ] 33.3% Loss: 0.3491, Epoch 6, Batch 41, CE_loss: 0.30085691809654236, Dice_loss: 0.034364547580480576, Consistency_loss: 0.00021992649999447167\n",
      "[Training] Epoch: 6 [=====>         ] 34.1% Loss: 0.3486, Epoch 6, Batch 42, CE_loss: 0.29538971185684204, Dice_loss: 0.03372044116258621, Consistency_loss: 0.0009672562009654939\n",
      "[Training] Epoch: 6 [=====>         ] 34.9% Loss: 0.3483, Epoch 6, Batch 43, CE_loss: 0.2982271611690521, Dice_loss: 0.034035176038742065, Consistency_loss: 0.0012620677007362247\n",
      "[Training] Epoch: 6 [=====>         ] 35.7% Loss: 0.3478, Epoch 6, Batch 44, CE_loss: 0.2920151352882385, Dice_loss: 0.03277982026338577, Consistency_loss: 0.0015658254269510508\n",
      "[Training] Epoch: 6 [=====>         ] 36.5% Loss: 0.3477, Epoch 6, Batch 45, CE_loss: 0.30636417865753174, Dice_loss: 0.03539339080452919, Consistency_loss: 0.0012603019131347537\n",
      "[Training] Epoch: 6 [=====>         ] 37.3% Loss: 0.3476, Epoch 6, Batch 46, CE_loss: 0.3048514425754547, Dice_loss: 0.03477342799305916, Consistency_loss: 0.0009866462787613273\n",
      "[Training] Epoch: 6 [=====>         ] 38.1% Loss: 0.3471, Epoch 6, Batch 47, CE_loss: 0.2932458817958832, Dice_loss: 0.033112168312072754, Consistency_loss: 0.000296872720355168\n",
      "[Training] Epoch: 6 [=====>         ] 38.9% Loss: 0.3467, Epoch 6, Batch 48, CE_loss: 0.2934662103652954, Dice_loss: 0.033242929726839066, Consistency_loss: 0.001898517832159996\n",
      "[Training] Epoch: 6 [=====>         ] 39.7% Loss: 0.3466, Epoch 6, Batch 49, CE_loss: 0.30505141615867615, Dice_loss: 0.03488036245107651, Consistency_loss: 0.0012350669130682945\n",
      "[Training] Epoch: 6 [======>        ] 40.5% Loss: 0.3465, Epoch 6, Batch 50, CE_loss: 0.30303147435188293, Dice_loss: 0.034548986703157425, Consistency_loss: 0.0011319894110783935\n",
      "[Training] Epoch: 6 [======>        ] 41.3% Loss: 0.3462, Epoch 6, Batch 51, CE_loss: 0.2966257631778717, Dice_loss: 0.03360357880592346, Consistency_loss: 0.0010574187617748976\n",
      "[Training] Epoch: 6 [======>        ] 42.1% Loss: 0.3460, Epoch 6, Batch 52, CE_loss: 0.299181193113327, Dice_loss: 0.03446579352021217, Consistency_loss: 0.0010075164027512074\n",
      "[Training] Epoch: 6 [======>        ] 42.9% Loss: 0.3457, Epoch 6, Batch 53, CE_loss: 0.2972594201564789, Dice_loss: 0.03355056792497635, Consistency_loss: 0.0011179776629433036\n",
      "[Training] Epoch: 6 [======>        ] 43.7% Loss: 0.3455, Epoch 6, Batch 54, CE_loss: 0.2976021468639374, Dice_loss: 0.03348498418927193, Consistency_loss: 0.0011553074000403285\n",
      "[Training] Epoch: 6 [======>        ] 44.4% Loss: 0.3452, Epoch 6, Batch 55, CE_loss: 0.2973848879337311, Dice_loss: 0.033534932881593704, Consistency_loss: 0.0008377729100175202\n",
      "[Training] Epoch: 6 [======>        ] 45.2% Loss: 0.3449, Epoch 6, Batch 56, CE_loss: 0.2918736934661865, Dice_loss: 0.03270091861486435, Consistency_loss: 0.00014166948676574975\n",
      "[Training] Epoch: 6 [======>        ] 46.0% Loss: 0.3449, Epoch 6, Batch 57, CE_loss: 0.30995216965675354, Dice_loss: 0.03547459468245506, Consistency_loss: 0.0009906993946060538\n",
      "[Training] Epoch: 6 [=======>       ] 46.8% Loss: 0.3447, Epoch 6, Batch 58, CE_loss: 0.2987603545188904, Dice_loss: 0.03365829214453697, Consistency_loss: 0.0008186483173631132\n",
      "[Training] Epoch: 6 [=======>       ] 47.6% Loss: 0.3447, Epoch 6, Batch 59, CE_loss: 0.3072117567062378, Dice_loss: 0.03499484062194824, Consistency_loss: 0.00014937110245227814\n",
      "[Training] Epoch: 6 [=======>       ] 48.4% Loss: 0.3442, Epoch 6, Batch 60, CE_loss: 0.286561518907547, Dice_loss: 0.03171659633517265, Consistency_loss: 0.0007390831015072763\n",
      "[Training] Epoch: 6 [=======>       ] 49.2% Loss: 0.3439, Epoch 6, Batch 61, CE_loss: 0.2892967462539673, Dice_loss: 0.032199740409851074, Consistency_loss: 0.001068447483703494\n",
      "[Training] Epoch: 6 [=======>       ] 50.0% Loss: 0.3435, Epoch 6, Batch 62, CE_loss: 0.2891777455806732, Dice_loss: 0.03230004385113716, Consistency_loss: 0.0013167145662009716\n",
      "[Training] Epoch: 6 [=======>       ] 50.8% Loss: 0.3431, Epoch 6, Batch 63, CE_loss: 0.2852709889411926, Dice_loss: 0.03160080313682556, Consistency_loss: 0.0010793274268507957\n",
      "[Training] Epoch: 6 [=======>       ] 51.6% Loss: 0.3431, Epoch 6, Batch 64, CE_loss: 0.3058738708496094, Dice_loss: 0.03505852445960045, Consistency_loss: 0.00023891768069006503\n",
      "[Training] Epoch: 6 [=======>       ] 52.4% Loss: 0.3428, Epoch 6, Batch 65, CE_loss: 0.2886192202568054, Dice_loss: 0.03206721320748329, Consistency_loss: 0.001252265996299684\n",
      "[Training] Epoch: 6 [=======>       ] 53.2% Loss: 0.3426, Epoch 6, Batch 66, CE_loss: 0.296592116355896, Dice_loss: 0.03354094922542572, Consistency_loss: 0.00019875307043548673\n",
      "[Training] Epoch: 6 [========>      ] 54.0% Loss: 0.3425, Epoch 6, Batch 67, CE_loss: 0.3017430007457733, Dice_loss: 0.034079182893037796, Consistency_loss: 0.001462121494114399\n",
      "[Training] Epoch: 6 [========>      ] 54.8% Loss: 0.3425, Epoch 6, Batch 68, CE_loss: 0.30290523171424866, Dice_loss: 0.034176528453826904, Consistency_loss: 0.0009132951381616294\n",
      "[Training] Epoch: 6 [========>      ] 55.6% Loss: 0.3422, Epoch 6, Batch 69, CE_loss: 0.28959235548973083, Dice_loss: 0.03236581012606621, Consistency_loss: 0.0011427579447627068\n",
      "[Training] Epoch: 6 [========>      ] 56.3% Loss: 0.3420, Epoch 6, Batch 70, CE_loss: 0.295293927192688, Dice_loss: 0.03316120803356171, Consistency_loss: 0.000758002104703337\n",
      "[Training] Epoch: 6 [========>      ] 57.1% Loss: 0.3418, Epoch 6, Batch 71, CE_loss: 0.29510509967803955, Dice_loss: 0.03299228474497795, Consistency_loss: 0.000707147759385407\n",
      "[Training] Epoch: 6 [========>      ] 57.9% Loss: 0.3415, Epoch 6, Batch 72, CE_loss: 0.288480281829834, Dice_loss: 0.031829625368118286, Consistency_loss: 0.0013163825497031212\n",
      "[Training] Epoch: 6 [========>      ] 58.7% Loss: 0.3412, Epoch 6, Batch 73, CE_loss: 0.2800830602645874, Dice_loss: 0.030701329931616783, Consistency_loss: 0.0015877083642408252\n",
      "[Training] Epoch: 6 [========>      ] 59.5% Loss: 0.3409, Epoch 6, Batch 74, CE_loss: 0.2901158928871155, Dice_loss: 0.032506804913282394, Consistency_loss: 0.0015180821064859629\n",
      "[Training] Epoch: 6 [=========>     ] 60.3% Loss: 0.3406, Epoch 6, Batch 75, CE_loss: 0.28305962681770325, Dice_loss: 0.031247315928339958, Consistency_loss: 0.00022013911802787334\n",
      "[Training] Epoch: 6 [=========>     ] 61.1% Loss: 0.3404, Epoch 6, Batch 76, CE_loss: 0.28977417945861816, Dice_loss: 0.03231149911880493, Consistency_loss: 0.0011932799825444818\n",
      "[Training] Epoch: 6 [=========>     ] 61.9% Loss: 0.3402, Epoch 6, Batch 77, CE_loss: 0.2927255928516388, Dice_loss: 0.03287629410624504, Consistency_loss: 0.0015494131948798895\n",
      "[Training] Epoch: 6 [=========>     ] 62.7% Loss: 0.3399, Epoch 6, Batch 78, CE_loss: 0.2883014380931854, Dice_loss: 0.032393500208854675, Consistency_loss: 0.0002649280650075525\n",
      "[Training] Epoch: 6 [=========>     ] 63.5% Loss: 0.3396, Epoch 6, Batch 79, CE_loss: 0.27985575795173645, Dice_loss: 0.030560174956917763, Consistency_loss: 0.0012534157140180469\n",
      "[Training] Epoch: 6 [=========>     ] 64.3% Loss: 0.3394, Epoch 6, Batch 80, CE_loss: 0.2930709421634674, Dice_loss: 0.03266328200697899, Consistency_loss: 0.0011997100664302707\n",
      "[Training] Epoch: 6 [=========>     ] 65.1% Loss: 0.3392, Epoch 6, Batch 81, CE_loss: 0.2862274944782257, Dice_loss: 0.03196785971522331, Consistency_loss: 0.0016508169937878847\n",
      "[Training] Epoch: 6 [=========>     ] 65.9% Loss: 0.3389, Epoch 6, Batch 82, CE_loss: 0.2844734787940979, Dice_loss: 0.03152723237872124, Consistency_loss: 0.00020525165018625557\n",
      "[Training] Epoch: 6 [==========>    ] 66.7% Loss: 0.3386, Epoch 6, Batch 83, CE_loss: 0.28292691707611084, Dice_loss: 0.03133605793118477, Consistency_loss: 0.0008524952572770417\n",
      "[Training] Epoch: 6 [==========>    ] 67.5% Loss: 0.3385, Epoch 6, Batch 84, CE_loss: 0.29669344425201416, Dice_loss: 0.033308327198028564, Consistency_loss: 0.0008988417685031891\n",
      "[Training] Epoch: 6 [==========>    ] 68.3% Loss: 0.3382, Epoch 6, Batch 85, CE_loss: 0.27571314573287964, Dice_loss: 0.029870502650737762, Consistency_loss: 0.0007342031458392739\n",
      "[Training] Epoch: 6 [==========>    ] 69.0% Loss: 0.3380, Epoch 6, Batch 86, CE_loss: 0.28947582840919495, Dice_loss: 0.03207738697528839, Consistency_loss: 0.0008493779459968209\n",
      "[Training] Epoch: 6 [==========>    ] 69.8% Loss: 0.3377, Epoch 6, Batch 87, CE_loss: 0.28210046887397766, Dice_loss: 0.03079160489141941, Consistency_loss: 0.000150295949424617\n",
      "[Training] Epoch: 6 [==========>    ] 70.6% Loss: 0.3374, Epoch 6, Batch 88, CE_loss: 0.2828502655029297, Dice_loss: 0.030958786606788635, Consistency_loss: 0.001191797899082303\n",
      "[Training] Epoch: 6 [==========>    ] 71.4% Loss: 0.3371, Epoch 6, Batch 89, CE_loss: 0.2773478329181671, Dice_loss: 0.029985547065734863, Consistency_loss: 0.00018517950957175344\n",
      "[Training] Epoch: 6 [==========>    ] 72.2% Loss: 0.3368, Epoch 6, Batch 90, CE_loss: 0.2778102457523346, Dice_loss: 0.030279386788606644, Consistency_loss: 0.0012382144341245294\n",
      "[Training] Epoch: 6 [==========>    ] 73.0% Loss: 0.3365, Epoch 6, Batch 91, CE_loss: 0.27604442834854126, Dice_loss: 0.030018091201782227, Consistency_loss: 0.0009325132123194635\n",
      "[Training] Epoch: 6 [===========>   ] 73.8% Loss: 0.3362, Epoch 6, Batch 92, CE_loss: 0.280079185962677, Dice_loss: 0.031163062900304794, Consistency_loss: 0.0009611995192244649\n",
      "[Training] Epoch: 6 [===========>   ] 74.6% Loss: 0.3360, Epoch 6, Batch 93, CE_loss: 0.2836471199989319, Dice_loss: 0.031208941712975502, Consistency_loss: 0.0011607888154685497\n",
      "[Training] Epoch: 6 [===========>   ] 75.4% Loss: 0.3357, Epoch 6, Batch 94, CE_loss: 0.2774186432361603, Dice_loss: 0.030126765370368958, Consistency_loss: 0.0010843562195077538\n",
      "[Training] Epoch: 6 [===========>   ] 76.2% Loss: 0.3354, Epoch 6, Batch 95, CE_loss: 0.2750574052333832, Dice_loss: 0.029527442529797554, Consistency_loss: 0.0011784909293055534\n",
      "[Training] Epoch: 6 [===========>   ] 77.0% Loss: 0.3352, Epoch 6, Batch 96, CE_loss: 0.28042399883270264, Dice_loss: 0.030774075537919998, Consistency_loss: 0.00019130599685013294\n",
      "[Training] Epoch: 6 [===========>   ] 77.8% Loss: 0.3349, Epoch 6, Batch 97, CE_loss: 0.2758614420890808, Dice_loss: 0.02982228435575962, Consistency_loss: 0.0006928035872988403\n",
      "[Training] Epoch: 6 [===========>   ] 78.6% Loss: 0.3348, Epoch 6, Batch 98, CE_loss: 0.29745757579803467, Dice_loss: 0.03339574486017227, Consistency_loss: 0.0008851027232594788\n",
      "[Training] Epoch: 6 [===========>   ] 79.4% Loss: 0.3345, Epoch 6, Batch 99, CE_loss: 0.27209073305130005, Dice_loss: 0.029266763478517532, Consistency_loss: 0.001409613061696291\n",
      "[Training] Epoch: 6 [============>  ] 80.2% Loss: 0.3342, Epoch 6, Batch 100, CE_loss: 0.27301889657974243, Dice_loss: 0.02936176396906376, Consistency_loss: 0.0001860863558249548\n",
      "[Training] Epoch: 6 [============>  ] 81.0% Loss: 0.3339, Epoch 6, Batch 101, CE_loss: 0.2697065472602844, Dice_loss: 0.028964947909116745, Consistency_loss: 0.001273520290851593\n",
      "[Training] Epoch: 6 [============>  ] 81.7% Loss: 0.3337, Epoch 6, Batch 102, CE_loss: 0.2863853871822357, Dice_loss: 0.03147641569375992, Consistency_loss: 0.001309873885475099\n",
      "[Training] Epoch: 6 [============>  ] 82.5% Loss: 0.3336, Epoch 6, Batch 103, CE_loss: 0.28641805052757263, Dice_loss: 0.03163955733180046, Consistency_loss: 0.0014893601182848215\n",
      "[Training] Epoch: 6 [============>  ] 83.3% Loss: 0.3334, Epoch 6, Batch 104, CE_loss: 0.28237152099609375, Dice_loss: 0.031122829765081406, Consistency_loss: 0.00017607463814783841\n",
      "[Training] Epoch: 6 [============>  ] 84.1% Loss: 0.3331, Epoch 6, Batch 105, CE_loss: 0.26928219199180603, Dice_loss: 0.028658371418714523, Consistency_loss: 0.00133889343123883\n",
      "[Training] Epoch: 6 [============>  ] 84.9% Loss: 0.3328, Epoch 6, Batch 106, CE_loss: 0.27017009258270264, Dice_loss: 0.02930539660155773, Consistency_loss: 0.0015628855908289552\n",
      "[Training] Epoch: 6 [============>  ] 85.7% Loss: 0.3326, Epoch 6, Batch 107, CE_loss: 0.28004610538482666, Dice_loss: 0.030732953920960426, Consistency_loss: 0.0016443760832771659\n",
      "[Training] Epoch: 6 [============>  ] 86.5% Loss: 0.3323, Epoch 6, Batch 108, CE_loss: 0.2685803174972534, Dice_loss: 0.02909271977841854, Consistency_loss: 0.00020190340001136065\n",
      "[Training] Epoch: 6 [=============> ] 87.3% Loss: 0.3320, Epoch 6, Batch 109, CE_loss: 0.2739265263080597, Dice_loss: 0.029637087136507034, Consistency_loss: 0.00030247049289755523\n",
      "[Training] Epoch: 6 [=============> ] 88.1% Loss: 0.3318, Epoch 6, Batch 110, CE_loss: 0.2744566798210144, Dice_loss: 0.02973354421555996, Consistency_loss: 0.001289675710722804\n",
      "[Training] Epoch: 6 [=============> ] 88.9% Loss: 0.3316, Epoch 6, Batch 111, CE_loss: 0.2832677960395813, Dice_loss: 0.031513508409261703, Consistency_loss: 0.0010881474008783698\n",
      "[Training] Epoch: 6 [=============> ] 89.7% Loss: 0.3314, Epoch 6, Batch 112, CE_loss: 0.2741815745830536, Dice_loss: 0.029636524617671967, Consistency_loss: 0.001212280592881143\n",
      "[Training] Epoch: 6 [=============> ] 90.5% Loss: 0.3312, Epoch 6, Batch 113, CE_loss: 0.274153470993042, Dice_loss: 0.029790975153446198, Consistency_loss: 0.001165941939689219\n",
      "[Training] Epoch: 6 [=============> ] 91.3% Loss: 0.3310, Epoch 6, Batch 114, CE_loss: 0.2777738869190216, Dice_loss: 0.030107641592621803, Consistency_loss: 0.001990201650187373\n",
      "[Training] Epoch: 6 [=============> ] 92.1% Loss: 0.3307, Epoch 6, Batch 115, CE_loss: 0.2666466534137726, Dice_loss: 0.028305554762482643, Consistency_loss: 0.0003314425703138113\n",
      "[Training] Epoch: 6 [=============> ] 92.9% Loss: 0.3305, Epoch 6, Batch 116, CE_loss: 0.2770821452140808, Dice_loss: 0.030430395156145096, Consistency_loss: 0.00157789362128824\n",
      "[Training] Epoch: 6 [==============>] 93.7% Loss: 0.3303, Epoch 6, Batch 117, CE_loss: 0.2742171883583069, Dice_loss: 0.029808565974235535, Consistency_loss: 0.00035935683990828693\n",
      "[Training] Epoch: 6 [==============>] 94.4% Loss: 0.3301, Epoch 6, Batch 118, CE_loss: 0.274441659450531, Dice_loss: 0.029983239248394966, Consistency_loss: 0.0009922441095113754\n",
      "[Training] Epoch: 6 [==============>] 95.2% Loss: 0.3298, Epoch 6, Batch 119, CE_loss: 0.2684948444366455, Dice_loss: 0.029086850583553314, Consistency_loss: 0.00016730425704736263\n",
      "[Training] Epoch: 6 [==============>] 96.0% Loss: 0.3295, Epoch 6, Batch 120, CE_loss: 0.27017486095428467, Dice_loss: 0.02928701415657997, Consistency_loss: 0.0007977871573530138\n",
      "[Training] Epoch: 6 [==============>] 96.8% Loss: 0.3293, Epoch 6, Batch 121, CE_loss: 0.269416868686676, Dice_loss: 0.028646888211369514, Consistency_loss: 0.00022841298778075725\n",
      "[Training] Epoch: 6 [==============>] 97.6% Loss: 0.3291, Epoch 6, Batch 122, CE_loss: 0.27625772356987, Dice_loss: 0.030170412734150887, Consistency_loss: 0.0008481984259560704\n",
      "[Training] Epoch: 6 [==============>] 98.4% Loss: 0.3288, Epoch 6, Batch 123, CE_loss: 0.2681388854980469, Dice_loss: 0.028604960069060326, Consistency_loss: 0.00013857102021574974\n",
      "[Training] Epoch: 6 [==============>] 99.2% Loss: 0.3286, Epoch 6, Batch 124, CE_loss: 0.26362770795822144, Dice_loss: 0.02778281457722187, Consistency_loss: 0.0014300115872174501\n",
      "[Training] Epoch: 6 [DONE]                                 \n",
      "Epoch 6, Batch 125, CE_loss: 0.2709520757198334, Dice_loss: 0.029109228402376175, Consistency_loss: 0.0013910125708207488\n",
      "[Validation] Epoch: 6 [DONE]                                 \n",
      "[Epoch: 6, TrainLoss: 0.3283, TrainDice: 0.0332, ValLoss: 0.3144                                             \n",
      "Number of batches:  126\n",
      "[Training] Epoch: 7 [>              ] 0.8% Loss: 0.2888, Epoch 7, Batch 0, CE_loss: 0.26046860218048096, Dice_loss: 0.027402043342590332, Consistency_loss: 0.0009493375546298921\n",
      "[Training] Epoch: 7 [>              ] 1.6% Loss: 0.2928, Epoch 7, Batch 1, CE_loss: 0.26731550693511963, Dice_loss: 0.028292004019021988, Consistency_loss: 0.001205120817758143\n",
      "[Training] Epoch: 7 [>              ] 2.4% Loss: 0.2921, Epoch 7, Batch 2, CE_loss: 0.26198795437812805, Dice_loss: 0.027826081961393356, Consistency_loss: 0.000713881105184555\n",
      "[Training] Epoch: 7 [>              ] 3.2% Loss: 0.2946, Epoch 7, Batch 3, CE_loss: 0.2725118398666382, Dice_loss: 0.029008153825998306, Consistency_loss: 0.0006600969354622066\n",
      "[Training] Epoch: 7 [>              ] 4.0% Loss: 0.2976, Epoch 7, Batch 4, CE_loss: 0.27864375710487366, Dice_loss: 0.030354434624314308, Consistency_loss: 0.0008309814147651196\n",
      "[Training] Epoch: 7 [>              ] 4.8% Loss: 0.2978, Epoch 7, Batch 5, CE_loss: 0.2692415416240692, Dice_loss: 0.02879214659333229, Consistency_loss: 0.0007603370468132198\n",
      "[Training] Epoch: 7 [>              ] 5.6% Loss: 0.2990, Epoch 7, Batch 6, CE_loss: 0.27565404772758484, Dice_loss: 0.02955758199095726, Consistency_loss: 0.0006831804639659822\n",
      "[Training] Epoch: 7 [>              ] 6.3% Loss: 0.2987, Epoch 7, Batch 7, CE_loss: 0.26768413186073303, Dice_loss: 0.02853616513311863, Consistency_loss: 0.0008124131709337234\n",
      "[Training] Epoch: 7 [=>             ] 7.1% Loss: 0.3001, Epoch 7, Batch 8, CE_loss: 0.2797410488128662, Dice_loss: 0.03055763989686966, Consistency_loss: 0.0005247479421086609\n",
      "[Training] Epoch: 7 [=>             ] 7.9% Loss: 0.2985, Epoch 7, Batch 9, CE_loss: 0.2570909261703491, Dice_loss: 0.026808010414242744, Consistency_loss: 0.00013718442642129958\n",
      "[Training] Epoch: 7 [=>             ] 8.7% Loss: 0.2978, Epoch 7, Batch 10, CE_loss: 0.26205694675445557, Dice_loss: 0.02785373665392399, Consistency_loss: 0.0012335029896348715\n",
      "[Training] Epoch: 7 [=>             ] 9.5% Loss: 0.2978, Epoch 7, Batch 11, CE_loss: 0.267844557762146, Dice_loss: 0.028735490515828133, Consistency_loss: 0.001309855142608285\n",
      "[Training] Epoch: 7 [=>             ] 10.3% Loss: 0.2974, Epoch 7, Batch 12, CE_loss: 0.2636030614376068, Dice_loss: 0.0278520155698061, Consistency_loss: 0.0007988071301952004\n",
      "[Training] Epoch: 7 [=>             ] 11.1% Loss: 0.2973, Epoch 7, Batch 13, CE_loss: 0.26652222871780396, Dice_loss: 0.028723567724227905, Consistency_loss: 0.0011617721756920218\n",
      "[Training] Epoch: 7 [=>             ] 11.9% Loss: 0.2972, Epoch 7, Batch 14, CE_loss: 0.26670852303504944, Dice_loss: 0.028004221618175507, Consistency_loss: 0.0007654120563529432\n",
      "[Training] Epoch: 7 [=>             ] 12.7% Loss: 0.2973, Epoch 7, Batch 15, CE_loss: 0.26926761865615845, Dice_loss: 0.02847306616604328, Consistency_loss: 0.0006994213908910751\n",
      "[Training] Epoch: 7 [==>            ] 13.5% Loss: 0.2967, Epoch 7, Batch 16, CE_loss: 0.25920698046684265, Dice_loss: 0.027370138093829155, Consistency_loss: 0.0006216785404831171\n",
      "[Training] Epoch: 7 [==>            ] 14.3% Loss: 0.2967, Epoch 7, Batch 17, CE_loss: 0.2681938707828522, Dice_loss: 0.028249353170394897, Consistency_loss: 0.0009614272858016193\n",
      "[Training] Epoch: 7 [==>            ] 15.1% Loss: 0.2969, Epoch 7, Batch 18, CE_loss: 0.2693251371383667, Dice_loss: 0.028667254373431206, Consistency_loss: 0.0012398535618558526\n",
      "[Training] Epoch: 7 [==>            ] 15.9% Loss: 0.2969, Epoch 7, Batch 19, CE_loss: 0.26824265718460083, Dice_loss: 0.02840231917798519, Consistency_loss: 0.0011867990251630545\n",
      "[Training] Epoch: 7 [==>            ] 16.7% Loss: 0.2968, Epoch 7, Batch 20, CE_loss: 0.26612070202827454, Dice_loss: 0.028409995138645172, Consistency_loss: 0.001063477131538093\n",
      "[Training] Epoch: 7 [==>            ] 17.5% Loss: 0.2969, Epoch 7, Batch 21, CE_loss: 0.2691081166267395, Dice_loss: 0.02880457416176796, Consistency_loss: 0.0010092015145346522\n",
      "[Training] Epoch: 7 [==>            ] 18.3% Loss: 0.2963, Epoch 7, Batch 22, CE_loss: 0.25531378388404846, Dice_loss: 0.026487145572900772, Consistency_loss: 0.0008913658675737679\n",
      "[Training] Epoch: 7 [==>            ] 19.0% Loss: 0.2959, Epoch 7, Batch 23, CE_loss: 0.2582099735736847, Dice_loss: 0.026947185397148132, Consistency_loss: 0.0011425336124375463\n",
      "[Training] Epoch: 7 [==>            ] 19.8% Loss: 0.2955, Epoch 7, Batch 24, CE_loss: 0.2581561207771301, Dice_loss: 0.027011478319764137, Consistency_loss: 0.0001961138768820092\n",
      "[Training] Epoch: 7 [===>           ] 20.6% Loss: 0.2960, Epoch 7, Batch 25, CE_loss: 0.27778956294059753, Dice_loss: 0.029678763821721077, Consistency_loss: 0.0012847472680732608\n",
      "[Training] Epoch: 7 [===>           ] 21.4% Loss: 0.2955, Epoch 7, Batch 26, CE_loss: 0.2550846338272095, Dice_loss: 0.02655556984245777, Consistency_loss: 0.001123693655245006\n",
      "[Training] Epoch: 7 [===>           ] 22.2% Loss: 0.2952, Epoch 7, Batch 27, CE_loss: 0.2581225633621216, Dice_loss: 0.026925677433609962, Consistency_loss: 0.0015864374581724405\n",
      "[Training] Epoch: 7 [===>           ] 23.0% Loss: 0.2953, Epoch 7, Batch 28, CE_loss: 0.26872801780700684, Dice_loss: 0.028874656185507774, Consistency_loss: 0.0006930170929990709\n",
      "[Training] Epoch: 7 [===>           ] 23.8% Loss: 0.2949, Epoch 7, Batch 29, CE_loss: 0.25487592816352844, Dice_loss: 0.026735549792647362, Consistency_loss: 0.0012625808594748378\n",
      "[Training] Epoch: 7 [===>           ] 24.6% Loss: 0.2951, Epoch 7, Batch 30, CE_loss: 0.27162256836891174, Dice_loss: 0.02933504432439804, Consistency_loss: 0.0014048665761947632\n",
      "[Training] Epoch: 7 [===>           ] 25.4% Loss: 0.2948, Epoch 7, Batch 31, CE_loss: 0.2576315104961395, Dice_loss: 0.02727542445063591, Consistency_loss: 0.0012426709290593863\n",
      "[Training] Epoch: 7 [===>           ] 26.2% Loss: 0.2951, Epoch 7, Batch 32, CE_loss: 0.27480193972587585, Dice_loss: 0.029147418215870857, Consistency_loss: 0.00019161384261678904\n",
      "[Training] Epoch: 7 [====>          ] 27.0% Loss: 0.2947, Epoch 7, Batch 33, CE_loss: 0.25235435366630554, Dice_loss: 0.026039360091090202, Consistency_loss: 0.0011225190246477723\n",
      "[Training] Epoch: 7 [====>          ] 27.8% Loss: 0.2946, Epoch 7, Batch 34, CE_loss: 0.26220566034317017, Dice_loss: 0.02773403748869896, Consistency_loss: 0.001186314388178289\n",
      "[Training] Epoch: 7 [====>          ] 28.6% Loss: 0.2943, Epoch 7, Batch 35, CE_loss: 0.25815480947494507, Dice_loss: 0.027197685092687607, Consistency_loss: 0.0009452654048800468\n",
      "[Training] Epoch: 7 [====>          ] 29.4% Loss: 0.2941, Epoch 7, Batch 36, CE_loss: 0.25943830609321594, Dice_loss: 0.026835864409804344, Consistency_loss: 0.0011618015123531222\n",
      "[Training] Epoch: 7 [====>          ] 30.2% Loss: 0.2937, Epoch 7, Batch 37, CE_loss: 0.2518863081932068, Dice_loss: 0.026234807446599007, Consistency_loss: 0.0011093224165961146\n",
      "[Training] Epoch: 7 [====>          ] 31.0% Loss: 0.2934, Epoch 7, Batch 38, CE_loss: 0.25096607208251953, Dice_loss: 0.026150815188884735, Consistency_loss: 0.0013645528815686703\n",
      "[Training] Epoch: 7 [====>          ] 31.7% Loss: 0.2932, Epoch 7, Batch 39, CE_loss: 0.2592051923274994, Dice_loss: 0.027204211801290512, Consistency_loss: 0.0013730527134612203\n",
      "[Training] Epoch: 7 [====>          ] 32.5% Loss: 0.2933, Epoch 7, Batch 40, CE_loss: 0.26588740944862366, Dice_loss: 0.02808801271021366, Consistency_loss: 0.0012909411452710629\n",
      "[Training] Epoch: 7 [=====>         ] 33.3% Loss: 0.2933, Epoch 7, Batch 41, CE_loss: 0.26679283380508423, Dice_loss: 0.028004901483654976, Consistency_loss: 0.00018014328088611364\n",
      "[Training] Epoch: 7 [=====>         ] 34.1% Loss: 0.2931, Epoch 7, Batch 42, CE_loss: 0.257775217294693, Dice_loss: 0.02696295641362667, Consistency_loss: 0.0013792157405987382\n",
      "[Training] Epoch: 7 [=====>         ] 34.9% Loss: 0.2928, Epoch 7, Batch 43, CE_loss: 0.25179558992385864, Dice_loss: 0.026511186733841896, Consistency_loss: 0.0012140057515352964\n",
      "[Training] Epoch: 7 [=====>         ] 35.7% Loss: 0.2923, Epoch 7, Batch 44, CE_loss: 0.2430058866739273, Dice_loss: 0.024704160168766975, Consistency_loss: 0.0016776695847511292\n",
      "[Training] Epoch: 7 [=====>         ] 36.5% Loss: 0.2919, Epoch 7, Batch 45, CE_loss: 0.2464514970779419, Dice_loss: 0.024936113506555557, Consistency_loss: 0.001191736082546413\n",
      "[Training] Epoch: 7 [=====>         ] 37.3% Loss: 0.2917, Epoch 7, Batch 46, CE_loss: 0.25540032982826233, Dice_loss: 0.02688467688858509, Consistency_loss: 0.000224348230403848\n",
      "[Training] Epoch: 7 [=====>         ] 38.1% Loss: 0.2913, Epoch 7, Batch 47, CE_loss: 0.24655406177043915, Dice_loss: 0.02525007165968418, Consistency_loss: 0.0013168982695788145\n",
      "[Training] Epoch: 7 [=====>         ] 38.9% Loss: 0.2911, Epoch 7, Batch 48, CE_loss: 0.25523847341537476, Dice_loss: 0.026430167257785797, Consistency_loss: 0.0018679228378459811\n",
      "[Training] Epoch: 7 [=====>         ] 39.7% Loss: 0.2908, Epoch 7, Batch 49, CE_loss: 0.24721691012382507, Dice_loss: 0.02529505081474781, Consistency_loss: 0.001387285883538425\n",
      "[Training] Epoch: 7 [======>        ] 40.5% Loss: 0.2906, Epoch 7, Batch 50, CE_loss: 0.2520087957382202, Dice_loss: 0.02591945230960846, Consistency_loss: 0.0015711266314610839\n",
      "[Training] Epoch: 7 [======>        ] 41.3% Loss: 0.2903, Epoch 7, Batch 51, CE_loss: 0.2505689263343811, Dice_loss: 0.026091525331139565, Consistency_loss: 0.0015610384289175272\n",
      "[Training] Epoch: 7 [======>        ] 42.1% Loss: 0.2900, Epoch 7, Batch 52, CE_loss: 0.248209610581398, Dice_loss: 0.025435684248805046, Consistency_loss: 0.0009208535775542259\n",
      "[Training] Epoch: 7 [======>        ] 42.9% Loss: 0.2898, Epoch 7, Batch 53, CE_loss: 0.24850979447364807, Dice_loss: 0.02561105228960514, Consistency_loss: 0.001269475556910038\n",
      "[Training] Epoch: 7 [======>        ] 43.7% Loss: 0.2895, Epoch 7, Batch 54, CE_loss: 0.24953113496303558, Dice_loss: 0.025471393018960953, Consistency_loss: 0.00019711069762706757\n",
      "[Training] Epoch: 7 [======>        ] 44.4% Loss: 0.2892, Epoch 7, Batch 55, CE_loss: 0.24762098491191864, Dice_loss: 0.02540651522576809, Consistency_loss: 0.00019302550936117768\n",
      "[Training] Epoch: 7 [======>        ] 45.2% Loss: 0.2891, Epoch 7, Batch 56, CE_loss: 0.25545045733451843, Dice_loss: 0.02661159634590149, Consistency_loss: 0.00014830472355242819\n",
      "[Training] Epoch: 7 [======>        ] 46.0% Loss: 0.2889, Epoch 7, Batch 57, CE_loss: 0.25149106979370117, Dice_loss: 0.025751907378435135, Consistency_loss: 0.00020931944891344756\n",
      "[Training] Epoch: 7 [=======>       ] 46.8% Loss: 0.2886, Epoch 7, Batch 58, CE_loss: 0.24435743689537048, Dice_loss: 0.024643082171678543, Consistency_loss: 0.0011136439861729741\n",
      "[Training] Epoch: 7 [=======>       ] 47.6% Loss: 0.2886, Epoch 7, Batch 59, CE_loss: 0.25932225584983826, Dice_loss: 0.02719159610569477, Consistency_loss: 0.0009711002930998802\n",
      "[Training] Epoch: 7 [=======>       ] 48.4% Loss: 0.2884, Epoch 7, Batch 60, CE_loss: 0.2539163827896118, Dice_loss: 0.026489166542887688, Consistency_loss: 0.0007546428241766989\n",
      "[Training] Epoch: 7 [=======>       ] 49.2% Loss: 0.2884, Epoch 7, Batch 61, CE_loss: 0.2570958435535431, Dice_loss: 0.026455393061041832, Consistency_loss: 0.0011823385721072555\n",
      "[Training] Epoch: 7 [=======>       ] 50.0% Loss: 0.2881, Epoch 7, Batch 62, CE_loss: 0.24678990244865417, Dice_loss: 0.02487429790198803, Consistency_loss: 0.0013591039460152388\n",
      "[Training] Epoch: 7 [=======>       ] 50.8% Loss: 0.2879, Epoch 7, Batch 63, CE_loss: 0.2463095337152481, Dice_loss: 0.025075512006878853, Consistency_loss: 0.0012350964825600386\n",
      "[Training] Epoch: 7 [=======>       ] 51.6% Loss: 0.2878, Epoch 7, Batch 64, CE_loss: 0.2543362081050873, Dice_loss: 0.026210995391011238, Consistency_loss: 0.0016531458823010325\n",
      "[Training] Epoch: 7 [=======>       ] 52.4% Loss: 0.2877, Epoch 7, Batch 65, CE_loss: 0.2536524832248688, Dice_loss: 0.02629820629954338, Consistency_loss: 0.0014872006140649319\n",
      "[Training] Epoch: 7 [=======>       ] 53.2% Loss: 0.2874, Epoch 7, Batch 66, CE_loss: 0.24046815931797028, Dice_loss: 0.024312598630785942, Consistency_loss: 0.0011828616261482239\n",
      "[Training] Epoch: 7 [========>      ] 54.0% Loss: 0.2872, Epoch 7, Batch 67, CE_loss: 0.24990378320217133, Dice_loss: 0.025977078825235367, Consistency_loss: 0.0015210964484140277\n",
      "[Training] Epoch: 7 [========>      ] 54.8% Loss: 0.2869, Epoch 7, Batch 68, CE_loss: 0.2368660718202591, Dice_loss: 0.023768432438373566, Consistency_loss: 0.0011461038375273347\n",
      "[Training] Epoch: 7 [========>      ] 55.6% Loss: 0.2867, Epoch 7, Batch 69, CE_loss: 0.2460261732339859, Dice_loss: 0.025033719837665558, Consistency_loss: 0.0011998895788565278\n",
      "[Training] Epoch: 7 [========>      ] 56.3% Loss: 0.2864, Epoch 7, Batch 70, CE_loss: 0.2434559017419815, Dice_loss: 0.024371929466724396, Consistency_loss: 0.00014524086145684123\n",
      "[Training] Epoch: 7 [========>      ] 57.1% Loss: 0.2861, Epoch 7, Batch 71, CE_loss: 0.24168851971626282, Dice_loss: 0.02408647909760475, Consistency_loss: 0.0014145917957648635\n",
      "[Training] Epoch: 7 [========>      ] 57.9% Loss: 0.2859, Epoch 7, Batch 72, CE_loss: 0.24512766301631927, Dice_loss: 0.02488495036959648, Consistency_loss: 0.0009880770230665803\n",
      "[Training] Epoch: 7 [========>      ] 58.7% Loss: 0.2857, Epoch 7, Batch 73, CE_loss: 0.2426750510931015, Dice_loss: 0.024636859074234962, Consistency_loss: 0.0013279038248583674\n",
      "[Training] Epoch: 7 [========>      ] 59.5% Loss: 0.2854, Epoch 7, Batch 74, CE_loss: 0.24139676988124847, Dice_loss: 0.024305107071995735, Consistency_loss: 0.0012812393251806498\n",
      "[Training] Epoch: 7 [=========>     ] 60.3% Loss: 0.2854, Epoch 7, Batch 75, CE_loss: 0.25908660888671875, Dice_loss: 0.026460574939846992, Consistency_loss: 0.00017828440468292683\n",
      "[Training] Epoch: 7 [=========>     ] 61.1% Loss: 0.2853, Epoch 7, Batch 76, CE_loss: 0.2482099086046219, Dice_loss: 0.024989699944853783, Consistency_loss: 0.0010963643435388803\n",
      "[Training] Epoch: 7 [=========>     ] 61.9% Loss: 0.2851, Epoch 7, Batch 77, CE_loss: 0.2417219579219818, Dice_loss: 0.024914700537919998, Consistency_loss: 0.0012949280207976699\n",
      "[Training] Epoch: 7 [=========>     ] 62.7% Loss: 0.2850, Epoch 7, Batch 78, CE_loss: 0.25460097193717957, Dice_loss: 0.026245679706335068, Consistency_loss: 0.0002457468362990767\n",
      "[Training] Epoch: 7 [=========>     ] 63.5% Loss: 0.2849, Epoch 7, Batch 79, CE_loss: 0.24691466987133026, Dice_loss: 0.02531871385872364, Consistency_loss: 0.0008017111686058342\n",
      "[Training] Epoch: 7 [=========>     ] 64.3% Loss: 0.2848, Epoch 7, Batch 80, CE_loss: 0.251706600189209, Dice_loss: 0.025980504229664803, Consistency_loss: 0.0009937146678566933\n",
      "[Training] Epoch: 7 [=========>     ] 65.1% Loss: 0.2845, Epoch 7, Batch 81, CE_loss: 0.23603375256061554, Dice_loss: 0.023443879559636116, Consistency_loss: 0.0015546961221843958\n",
      "[Training] Epoch: 7 [=========>     ] 65.9% Loss: 0.2843, Epoch 7, Batch 82, CE_loss: 0.24540361762046814, Dice_loss: 0.02501584216952324, Consistency_loss: 0.001187134301289916\n",
      "[Training] Epoch: 7 [==========>    ] 66.7% Loss: 0.2842, Epoch 7, Batch 83, CE_loss: 0.24286697804927826, Dice_loss: 0.025168191641569138, Consistency_loss: 0.000685504637658596\n",
      "[Training] Epoch: 7 [==========>    ] 67.5% Loss: 0.2840, Epoch 7, Batch 84, CE_loss: 0.24613505601882935, Dice_loss: 0.025261560454964638, Consistency_loss: 0.0011772202560678124\n",
      "[Training] Epoch: 7 [==========>    ] 68.3% Loss: 0.2838, Epoch 7, Batch 85, CE_loss: 0.23837609589099884, Dice_loss: 0.02428104169666767, Consistency_loss: 0.00025818365975283086\n",
      "[Training] Epoch: 7 [==========>    ] 69.0% Loss: 0.2836, Epoch 7, Batch 86, CE_loss: 0.24625056982040405, Dice_loss: 0.024907490238547325, Consistency_loss: 0.0007642200798727572\n",
      "[Training] Epoch: 7 [==========>    ] 69.8% Loss: 0.2836, Epoch 7, Batch 87, CE_loss: 0.25095418095588684, Dice_loss: 0.025492170825600624, Consistency_loss: 0.0008693133713677526\n",
      "[Training] Epoch: 7 [==========>    ] 70.6% Loss: 0.2835, Epoch 7, Batch 88, CE_loss: 0.2503245174884796, Dice_loss: 0.025684915482997894, Consistency_loss: 0.00030355938361026347\n",
      "[Training] Epoch: 7 [==========>    ] 71.4% Loss: 0.2833, Epoch 7, Batch 89, CE_loss: 0.24253469705581665, Dice_loss: 0.024500953033566475, Consistency_loss: 0.0013464830117300153\n",
      "[Training] Epoch: 7 [==========>    ] 72.2% Loss: 0.2831, Epoch 7, Batch 90, CE_loss: 0.2386302351951599, Dice_loss: 0.023972181603312492, Consistency_loss: 0.0013161728857085109\n",
      "[Training] Epoch: 7 [==========>    ] 73.0% Loss: 0.2830, Epoch 7, Batch 91, CE_loss: 0.2442741096019745, Dice_loss: 0.024682098999619484, Consistency_loss: 0.0016034416621550918\n",
      "[Training] Epoch: 7 [===========>   ] 73.8% Loss: 0.2827, Epoch 7, Batch 92, CE_loss: 0.23620450496673584, Dice_loss: 0.023801660165190697, Consistency_loss: 0.0010091183939948678\n",
      "[Training] Epoch: 7 [===========>   ] 74.6% Loss: 0.2826, Epoch 7, Batch 93, CE_loss: 0.24463464319705963, Dice_loss: 0.024466678500175476, Consistency_loss: 0.0010967530542984605\n",
      "[Training] Epoch: 7 [===========>   ] 75.4% Loss: 0.2825, Epoch 7, Batch 94, CE_loss: 0.2477024495601654, Dice_loss: 0.025502918288111687, Consistency_loss: 0.0010298884008079767\n",
      "[Training] Epoch: 7 [===========>   ] 76.2% Loss: 0.2823, Epoch 7, Batch 95, CE_loss: 0.24175286293029785, Dice_loss: 0.024526705965399742, Consistency_loss: 0.00023075588978827\n",
      "[Training] Epoch: 7 [===========>   ] 77.0% Loss: 0.2822, Epoch 7, Batch 96, CE_loss: 0.23844796419143677, Dice_loss: 0.02400067076086998, Consistency_loss: 0.0010257601970806718\n",
      "[Training] Epoch: 7 [===========>   ] 77.8% Loss: 0.2819, Epoch 7, Batch 97, CE_loss: 0.23548170924186707, Dice_loss: 0.023264341056346893, Consistency_loss: 0.00019933938165195286\n",
      "[Training] Epoch: 7 [===========>   ] 78.6% Loss: 0.2817, Epoch 7, Batch 98, CE_loss: 0.23309515416622162, Dice_loss: 0.023658612743020058, Consistency_loss: 0.00021456419199239463\n",
      "[Training] Epoch: 7 [===========>   ] 79.4% Loss: 0.2814, Epoch 7, Batch 99, CE_loss: 0.2326146513223648, Dice_loss: 0.023407286033034325, Consistency_loss: 0.0012289462611079216\n",
      "[Training] Epoch: 7 [============>  ] 80.2% Loss: 0.2812, Epoch 7, Batch 100, CE_loss: 0.2396393120288849, Dice_loss: 0.024117186665534973, Consistency_loss: 0.00018982600886374712\n",
      "[Training] Epoch: 7 [============>  ] 81.0% Loss: 0.2809, Epoch 7, Batch 101, CE_loss: 0.2250794768333435, Dice_loss: 0.02185387909412384, Consistency_loss: 0.0010811988031491637\n",
      "[Training] Epoch: 7 [============>  ] 81.7% Loss: 0.2807, Epoch 7, Batch 102, CE_loss: 0.23466989398002625, Dice_loss: 0.022979049012064934, Consistency_loss: 0.0001645595912123099\n",
      "[Training] Epoch: 7 [============>  ] 82.5% Loss: 0.2805, Epoch 7, Batch 103, CE_loss: 0.23360365629196167, Dice_loss: 0.02336740493774414, Consistency_loss: 0.0010904765222221613\n",
      "[Training] Epoch: 7 [============>  ] 83.3% Loss: 0.2803, Epoch 7, Batch 104, CE_loss: 0.23481273651123047, Dice_loss: 0.02332814782857895, Consistency_loss: 0.0009081985917873681\n",
      "[Training] Epoch: 7 [============>  ] 84.1% Loss: 0.2801, Epoch 7, Batch 105, CE_loss: 0.2357529103755951, Dice_loss: 0.023290641605854034, Consistency_loss: 0.0013688979670405388\n",
      "[Training] Epoch: 7 [============>  ] 84.9% Loss: 0.2800, Epoch 7, Batch 106, CE_loss: 0.24254877865314484, Dice_loss: 0.024784354493021965, Consistency_loss: 0.00021164007193874568\n",
      "[Training] Epoch: 7 [============>  ] 85.7% Loss: 0.2797, Epoch 7, Batch 107, CE_loss: 0.22990074753761292, Dice_loss: 0.02247033268213272, Consistency_loss: 0.0010888822143897414\n",
      "[Training] Epoch: 7 [============>  ] 86.5% Loss: 0.2797, Epoch 7, Batch 108, CE_loss: 0.2483191192150116, Dice_loss: 0.02552102692425251, Consistency_loss: 0.0011726965894922614\n",
      "[Training] Epoch: 7 [=============> ] 87.3% Loss: 0.2795, Epoch 7, Batch 109, CE_loss: 0.2369409203529358, Dice_loss: 0.023558584973216057, Consistency_loss: 0.0010984644759446383\n",
      "[Training] Epoch: 7 [=============> ] 88.1% Loss: 0.2795, Epoch 7, Batch 110, CE_loss: 0.2511110305786133, Dice_loss: 0.025549620389938354, Consistency_loss: 0.0011604726314544678\n",
      "[Training] Epoch: 7 [=============> ] 88.9% Loss: 0.2793, Epoch 7, Batch 111, CE_loss: 0.23560337722301483, Dice_loss: 0.023438412696123123, Consistency_loss: 0.0010950294090434909\n",
      "[Training] Epoch: 7 [=============> ] 89.7% Loss: 0.2790, Epoch 7, Batch 112, CE_loss: 0.2230469137430191, Dice_loss: 0.021469885483384132, Consistency_loss: 0.00012823796714656055\n",
      "[Training] Epoch: 7 [=============> ] 90.5% Loss: 0.2788, Epoch 7, Batch 113, CE_loss: 0.2307410091161728, Dice_loss: 0.02274082414805889, Consistency_loss: 0.0006691144080832601\n",
      "[Training] Epoch: 7 [=============> ] 91.3% Loss: 0.2787, Epoch 7, Batch 114, CE_loss: 0.23757445812225342, Dice_loss: 0.023608732968568802, Consistency_loss: 0.00029026117408648133\n",
      "[Training] Epoch: 7 [=============> ] 92.1% Loss: 0.2785, Epoch 7, Batch 115, CE_loss: 0.23266620934009552, Dice_loss: 0.02308841608464718, Consistency_loss: 0.0011183100286871195\n",
      "[Training] Epoch: 7 [=============> ] 92.9% Loss: 0.2783, Epoch 7, Batch 116, CE_loss: 0.2332429438829422, Dice_loss: 0.02308860793709755, Consistency_loss: 0.0012154789874330163\n",
      "[Training] Epoch: 7 [==============>] 93.7% Loss: 0.2781, Epoch 7, Batch 117, CE_loss: 0.2299395650625229, Dice_loss: 0.02255590818822384, Consistency_loss: 0.0013463138602674007\n",
      "[Training] Epoch: 7 [==============>] 94.4% Loss: 0.2780, Epoch 7, Batch 118, CE_loss: 0.2407509833574295, Dice_loss: 0.024310220032930374, Consistency_loss: 0.0007031813147477806\n",
      "[Training] Epoch: 7 [==============>] 95.2% Loss: 0.2778, Epoch 7, Batch 119, CE_loss: 0.23304978013038635, Dice_loss: 0.02340039610862732, Consistency_loss: 0.001236980315297842\n",
      "[Training] Epoch: 7 [==============>] 96.0% Loss: 0.2777, Epoch 7, Batch 120, CE_loss: 0.23763839900493622, Dice_loss: 0.023556774482131004, Consistency_loss: 0.0013839838793501258\n",
      "[Training] Epoch: 7 [==============>] 96.8% Loss: 0.2774, Epoch 7, Batch 121, CE_loss: 0.22216443717479706, Dice_loss: 0.02158251218497753, Consistency_loss: 0.0008919457904994488\n",
      "[Training] Epoch: 7 [==============>] 97.6% Loss: 0.2772, Epoch 7, Batch 122, CE_loss: 0.2339862585067749, Dice_loss: 0.02275821380317211, Consistency_loss: 0.000846570183057338\n",
      "[Training] Epoch: 7 [==============>] 98.4% Loss: 0.2771, Epoch 7, Batch 123, CE_loss: 0.2391223907470703, Dice_loss: 0.023816421627998352, Consistency_loss: 0.0009189250995405018\n",
      "[Training] Epoch: 7 [==============>] 99.2% Loss: 0.2769, Epoch 7, Batch 124, CE_loss: 0.2280452698469162, Dice_loss: 0.022284187376499176, Consistency_loss: 0.00019542717200238258\n",
      "[Training] Epoch: 7 [DONE]                                 \n",
      "Epoch 7, Batch 125, CE_loss: 0.22381138801574707, Dice_loss: 0.021807437762618065, Consistency_loss: 0.0017517987871542573\n",
      "[Validation] Epoch: 7 [DONE]                                 \n",
      "[Epoch: 7, TrainLoss: 0.2767, TrainDice: 0.0257, ValLoss: 0.2818                                             \n",
      "Number of batches:  126\n",
      "[Training] Epoch: 8 [>              ] 0.8% Loss: 0.2700, Epoch 8, Batch 0, CE_loss: 0.2436751276254654, Dice_loss: 0.025228457525372505, Consistency_loss: 0.0010839004535228014\n",
      "[Training] Epoch: 8 [>              ] 1.6% Loss: 0.2663, Epoch 8, Batch 1, CE_loss: 0.23747025430202484, Dice_loss: 0.023547910153865814, Consistency_loss: 0.0015237292973324656\n",
      "[Training] Epoch: 8 [>              ] 2.4% Loss: 0.2603, Epoch 8, Batch 2, CE_loss: 0.22561128437519073, Dice_loss: 0.0219770148396492, Consistency_loss: 0.0007854829891584814\n",
      "[Training] Epoch: 8 [>              ] 3.2% Loss: 0.2566, Epoch 8, Batch 3, CE_loss: 0.2228669822216034, Dice_loss: 0.021861765533685684, Consistency_loss: 0.0007881798082962632\n",
      "[Training] Epoch: 8 [>              ] 4.0% Loss: 0.2577, Epoch 8, Batch 4, CE_loss: 0.2371554970741272, Dice_loss: 0.023715181276202202, Consistency_loss: 0.0010712180519476533\n",
      "[Training] Epoch: 8 [>              ] 4.8% Loss: 0.2570, Epoch 8, Batch 5, CE_loss: 0.23040004074573517, Dice_loss: 0.022330043837428093, Consistency_loss: 0.0007449921104125679\n",
      "[Training] Epoch: 8 [>              ] 5.6% Loss: 0.2555, Epoch 8, Batch 6, CE_loss: 0.22446636855602264, Dice_loss: 0.021801821887493134, Consistency_loss: 0.000702821125742048\n",
      "[Training] Epoch: 8 [>              ] 6.3% Loss: 0.2534, Epoch 8, Batch 7, CE_loss: 0.21709713339805603, Dice_loss: 0.020342007279396057, Consistency_loss: 0.0006783473654650152\n",
      "[Training] Epoch: 8 [=>             ] 7.1% Loss: 0.2533, Epoch 8, Batch 8, CE_loss: 0.22980442643165588, Dice_loss: 0.022613946348428726, Consistency_loss: 0.00043312046909704804\n",
      "[Training] Epoch: 8 [=>             ] 7.9% Loss: 0.2536, Epoch 8, Batch 9, CE_loss: 0.23242919147014618, Dice_loss: 0.022875595837831497, Consistency_loss: 0.0005796549376100302\n",
      "[Training] Epoch: 8 [=>             ] 8.7% Loss: 0.2537, Epoch 8, Batch 10, CE_loss: 0.23082998394966125, Dice_loss: 0.022845573723316193, Consistency_loss: 0.0010134180774912238\n",
      "[Training] Epoch: 8 [=>             ] 9.5% Loss: 0.2528, Epoch 8, Batch 11, CE_loss: 0.22123727202415466, Dice_loss: 0.021143805235624313, Consistency_loss: 0.001126418705098331\n",
      "[Training] Epoch: 8 [=>             ] 10.3% Loss: 0.2526, Epoch 8, Batch 12, CE_loss: 0.22639980912208557, Dice_loss: 0.02191610261797905, Consistency_loss: 0.0009832651121541858\n",
      "[Training] Epoch: 8 [=>             ] 11.1% Loss: 0.2525, Epoch 8, Batch 13, CE_loss: 0.2279960960149765, Dice_loss: 0.022290095686912537, Consistency_loss: 0.0011208386858925223\n",
      "[Training] Epoch: 8 [=>             ] 11.9% Loss: 0.2517, Epoch 8, Batch 14, CE_loss: 0.21967220306396484, Dice_loss: 0.02092534862458706, Consistency_loss: 0.000658123753964901\n",
      "[Training] Epoch: 8 [=>             ] 12.7% Loss: 0.2519, Epoch 8, Batch 15, CE_loss: 0.23112507164478302, Dice_loss: 0.02303859405219555, Consistency_loss: 0.0006886389455758035\n",
      "[Training] Epoch: 8 [==>            ] 13.5% Loss: 0.2518, Epoch 8, Batch 16, CE_loss: 0.2267373502254486, Dice_loss: 0.022315174341201782, Consistency_loss: 0.0007202054257504642\n",
      "[Training] Epoch: 8 [==>            ] 14.3% Loss: 0.2513, Epoch 8, Batch 17, CE_loss: 0.22168336808681488, Dice_loss: 0.0213258508592844, Consistency_loss: 0.0006758776726201177\n",
      "[Training] Epoch: 8 [==>            ] 15.1% Loss: 0.2520, Epoch 8, Batch 18, CE_loss: 0.23876360058784485, Dice_loss: 0.023720063269138336, Consistency_loss: 0.001226932043209672\n",
      "[Training] Epoch: 8 [==>            ] 15.9% Loss: 0.2526, Epoch 8, Batch 19, CE_loss: 0.23972539603710175, Dice_loss: 0.024515852332115173, Consistency_loss: 0.0008337069302797318\n",
      "[Training] Epoch: 8 [==>            ] 16.7% Loss: 0.2526, Epoch 8, Batch 20, CE_loss: 0.22925028204917908, Dice_loss: 0.022128894925117493, Consistency_loss: 0.0010224573779851198\n",
      "[Training] Epoch: 8 [==>            ] 17.5% Loss: 0.2521, Epoch 8, Batch 21, CE_loss: 0.21988755464553833, Dice_loss: 0.021130666136741638, Consistency_loss: 0.0007990399608388543\n",
      "[Training] Epoch: 8 [==>            ] 18.3% Loss: 0.2523, Epoch 8, Batch 22, CE_loss: 0.232112854719162, Dice_loss: 0.023698963224887848, Consistency_loss: 0.0009313811897300184\n",
      "[Training] Epoch: 8 [==>            ] 19.0% Loss: 0.2523, Epoch 8, Batch 23, CE_loss: 0.2279980629682541, Dice_loss: 0.022210219874978065, Consistency_loss: 0.0012417752295732498\n",
      "[Training] Epoch: 8 [==>            ] 19.8% Loss: 0.2527, Epoch 8, Batch 24, CE_loss: 0.2361374944448471, Dice_loss: 0.024032147601246834, Consistency_loss: 0.0014428505674004555\n",
      "[Training] Epoch: 8 [===>           ] 20.6% Loss: 0.2527, Epoch 8, Batch 25, CE_loss: 0.22788532078266144, Dice_loss: 0.023063577711582184, Consistency_loss: 0.0014755595475435257\n",
      "[Training] Epoch: 8 [===>           ] 21.4% Loss: 0.2520, Epoch 8, Batch 26, CE_loss: 0.21359635889530182, Dice_loss: 0.02006029151380062, Consistency_loss: 0.0012561462353914976\n",
      "[Training] Epoch: 8 [===>           ] 22.2% Loss: 0.2518, Epoch 8, Batch 27, CE_loss: 0.2236870527267456, Dice_loss: 0.021877385675907135, Consistency_loss: 0.001694503822363913\n",
      "[Training] Epoch: 8 [===>           ] 23.0% Loss: 0.2512, Epoch 8, Batch 28, CE_loss: 0.2135743498802185, Dice_loss: 0.020137449726462364, Consistency_loss: 0.00022718627587892115\n",
      "[Training] Epoch: 8 [===>           ] 23.8% Loss: 0.2515, Epoch 8, Batch 29, CE_loss: 0.23437811434268951, Dice_loss: 0.02295847237110138, Consistency_loss: 0.0011932114139199257\n",
      "[Training] Epoch: 8 [===>           ] 24.6% Loss: 0.2508, Epoch 8, Batch 30, CE_loss: 0.21107131242752075, Dice_loss: 0.019612206146121025, Consistency_loss: 0.0008498748647980392\n",
      "[Training] Epoch: 8 [===>           ] 25.4% Loss: 0.2507, Epoch 8, Batch 31, CE_loss: 0.22382362186908722, Dice_loss: 0.02138558402657509, Consistency_loss: 0.0011330186389386654\n",
      "[Training] Epoch: 8 [===>           ] 26.2% Loss: 0.2511, Epoch 8, Batch 32, CE_loss: 0.23909521102905273, Dice_loss: 0.024545293301343918, Consistency_loss: 0.0012472578091546893\n",
      "[Training] Epoch: 8 [====>          ] 27.0% Loss: 0.2507, Epoch 8, Batch 33, CE_loss: 0.21654969453811646, Dice_loss: 0.020431101322174072, Consistency_loss: 0.0007645178702659905\n",
      "[Training] Epoch: 8 [====>          ] 27.8% Loss: 0.2506, Epoch 8, Batch 34, CE_loss: 0.224382221698761, Dice_loss: 0.021172214299440384, Consistency_loss: 0.000712596345692873\n",
      "[Training] Epoch: 8 [====>          ] 28.6% Loss: 0.2507, Epoch 8, Batch 35, CE_loss: 0.22970184683799744, Dice_loss: 0.02224735915660858, Consistency_loss: 0.0008674381533637643\n",
      "[Training] Epoch: 8 [====>          ] 29.4% Loss: 0.2503, Epoch 8, Batch 36, CE_loss: 0.2170095294713974, Dice_loss: 0.020727436989545822, Consistency_loss: 0.001020716386847198\n",
      "[Training] Epoch: 8 [====>          ] 30.2% Loss: 0.2507, Epoch 8, Batch 37, CE_loss: 0.23798827826976776, Dice_loss: 0.023712556809186935, Consistency_loss: 0.0011551568750292063\n",
      "[Training] Epoch: 8 [====>          ] 31.0% Loss: 0.2506, Epoch 8, Batch 38, CE_loss: 0.2234964817762375, Dice_loss: 0.021853910759091377, Consistency_loss: 0.001260388526134193\n",
      "[Training] Epoch: 8 [====>          ] 31.7% Loss: 0.2502, Epoch 8, Batch 39, CE_loss: 0.2139938771724701, Dice_loss: 0.020460784435272217, Consistency_loss: 0.001047048601321876\n",
      "[Training] Epoch: 8 [====>          ] 32.5% Loss: 0.2501, Epoch 8, Batch 40, CE_loss: 0.22411784529685974, Dice_loss: 0.021798931062221527, Consistency_loss: 0.0001249467022716999\n",
      "[Training] Epoch: 8 [=====>         ] 33.3% Loss: 0.2499, Epoch 8, Batch 41, CE_loss: 0.21942873299121857, Dice_loss: 0.02114241011440754, Consistency_loss: 0.00010781802848214284\n",
      "[Training] Epoch: 8 [=====>         ] 34.1% Loss: 0.2496, Epoch 8, Batch 42, CE_loss: 0.21615305542945862, Dice_loss: 0.020541707053780556, Consistency_loss: 0.0011629023356363177\n",
      "[Training] Epoch: 8 [=====>         ] 34.9% Loss: 0.2493, Epoch 8, Batch 43, CE_loss: 0.2140113264322281, Dice_loss: 0.02071322500705719, Consistency_loss: 0.0016055278247222304\n",
      "[Training] Epoch: 8 [=====>         ] 35.7% Loss: 0.2491, Epoch 8, Batch 44, CE_loss: 0.21780793368816376, Dice_loss: 0.020793352276086807, Consistency_loss: 0.0012011710787191987\n",
      "[Training] Epoch: 8 [=====>         ] 36.5% Loss: 0.2488, Epoch 8, Batch 45, CE_loss: 0.21332713961601257, Dice_loss: 0.020382920280098915, Consistency_loss: 0.0008478799718432128\n",
      "[Training] Epoch: 8 [=====>         ] 37.3% Loss: 0.2487, Epoch 8, Batch 46, CE_loss: 0.22182594239711761, Dice_loss: 0.021866289898753166, Consistency_loss: 0.0008039813837967813\n",
      "[Training] Epoch: 8 [=====>         ] 38.1% Loss: 0.2485, Epoch 8, Batch 47, CE_loss: 0.218007892370224, Dice_loss: 0.02121381089091301, Consistency_loss: 0.0012791568879038095\n",
      "[Training] Epoch: 8 [=====>         ] 38.9% Loss: 0.2484, Epoch 8, Batch 48, CE_loss: 0.22397631406784058, Dice_loss: 0.02180047333240509, Consistency_loss: 0.0002425121929263696\n",
      "[Training] Epoch: 8 [=====>         ] 39.7% Loss: 0.2482, Epoch 8, Batch 49, CE_loss: 0.21510720252990723, Dice_loss: 0.02036457508802414, Consistency_loss: 0.00021615569130517542\n",
      "[Training] Epoch: 8 [======>        ] 40.5% Loss: 0.2479, Epoch 8, Batch 50, CE_loss: 0.2109530121088028, Dice_loss: 0.01981145329773426, Consistency_loss: 0.001424821326509118\n",
      "[Training] Epoch: 8 [======>        ] 41.3% Loss: 0.2477, Epoch 8, Batch 51, CE_loss: 0.21626506745815277, Dice_loss: 0.02074616774916649, Consistency_loss: 0.0015071717789396644\n",
      "[Training] Epoch: 8 [======>        ] 42.1% Loss: 0.2475, Epoch 8, Batch 52, CE_loss: 0.21613238751888275, Dice_loss: 0.020635750144720078, Consistency_loss: 0.000794944993685931\n",
      "[Training] Epoch: 8 [======>        ] 42.9% Loss: 0.2472, Epoch 8, Batch 53, CE_loss: 0.21218346059322357, Dice_loss: 0.020031055435538292, Consistency_loss: 0.0009806257439777255\n",
      "[Training] Epoch: 8 [======>        ] 43.7% Loss: 0.2469, Epoch 8, Batch 54, CE_loss: 0.21027126908302307, Dice_loss: 0.019841713830828667, Consistency_loss: 0.0011930330656468868\n",
      "[Training] Epoch: 8 [======>        ] 44.4% Loss: 0.2466, Epoch 8, Batch 55, CE_loss: 0.20701389014720917, Dice_loss: 0.019265055656433105, Consistency_loss: 0.0007588611333630979\n",
      "[Training] Epoch: 8 [======>        ] 45.2% Loss: 0.2465, Epoch 8, Batch 56, CE_loss: 0.2168927639722824, Dice_loss: 0.021027138456702232, Consistency_loss: 0.0008967225439846516\n",
      "[Training] Epoch: 8 [======>        ] 46.0% Loss: 0.2465, Epoch 8, Batch 57, CE_loss: 0.22650973498821259, Dice_loss: 0.02218545414507389, Consistency_loss: 0.0011374105233699083\n",
      "[Training] Epoch: 8 [=======>       ] 46.8% Loss: 0.2461, Epoch 8, Batch 58, CE_loss: 0.20257122814655304, Dice_loss: 0.018336400389671326, Consistency_loss: 0.0011051809415221214\n",
      "[Training] Epoch: 8 [=======>       ] 47.6% Loss: 0.2460, Epoch 8, Batch 59, CE_loss: 0.2175108939409256, Dice_loss: 0.020871033892035484, Consistency_loss: 0.0006717561627738178\n",
      "[Training] Epoch: 8 [=======>       ] 48.4% Loss: 0.2459, Epoch 8, Batch 60, CE_loss: 0.2196294218301773, Dice_loss: 0.020874999463558197, Consistency_loss: 0.0006703121471218765\n",
      "[Training] Epoch: 8 [=======>       ] 49.2% Loss: 0.2457, Epoch 8, Batch 61, CE_loss: 0.21100284159183502, Dice_loss: 0.01964389532804489, Consistency_loss: 0.0011466930154711008\n",
      "[Training] Epoch: 8 [=======>       ] 50.0% Loss: 0.2454, Epoch 8, Batch 62, CE_loss: 0.21125979721546173, Dice_loss: 0.019607841968536377, Consistency_loss: 0.0001892014843178913\n",
      "[Training] Epoch: 8 [=======>       ] 50.8% Loss: 0.2455, Epoch 8, Batch 63, CE_loss: 0.22546827793121338, Dice_loss: 0.021634327247738838, Consistency_loss: 0.0015206317184492946\n",
      "[Training] Epoch: 8 [=======>       ] 51.6% Loss: 0.2453, Epoch 8, Batch 64, CE_loss: 0.21163028478622437, Dice_loss: 0.019981278106570244, Consistency_loss: 0.0002559846034273505\n",
      "[Training] Epoch: 8 [=======>       ] 52.4% Loss: 0.2453, Epoch 8, Batch 65, CE_loss: 0.2215288281440735, Dice_loss: 0.021220887079834938, Consistency_loss: 0.0015114082489162683\n",
      "[Training] Epoch: 8 [=======>       ] 53.2% Loss: 0.2452, Epoch 8, Batch 66, CE_loss: 0.21609383821487427, Dice_loss: 0.020598914474248886, Consistency_loss: 0.0011068516178056598\n",
      "[Training] Epoch: 8 [========>      ] 54.0% Loss: 0.2452, Epoch 8, Batch 67, CE_loss: 0.2243802845478058, Dice_loss: 0.022075077518820763, Consistency_loss: 0.0013704135781154037\n",
      "[Training] Epoch: 8 [========>      ] 54.8% Loss: 0.2449, Epoch 8, Batch 68, CE_loss: 0.2075822502374649, Dice_loss: 0.019529951736330986, Consistency_loss: 0.0002944542793557048\n",
      "[Training] Epoch: 8 [========>      ] 55.6% Loss: 0.2448, Epoch 8, Batch 69, CE_loss: 0.21517585217952728, Dice_loss: 0.020387722179293633, Consistency_loss: 0.001089368830434978\n",
      "[Training] Epoch: 8 [========>      ] 56.3% Loss: 0.2448, Epoch 8, Batch 70, CE_loss: 0.21792791783809662, Dice_loss: 0.02105836756527424, Consistency_loss: 0.0014692211989313364\n",
      "[Training] Epoch: 8 [========>      ] 57.1% Loss: 0.2445, Epoch 8, Batch 71, CE_loss: 0.20779010653495789, Dice_loss: 0.01950593665242195, Consistency_loss: 0.0016513727605342865\n",
      "[Training] Epoch: 8 [========>      ] 57.9% Loss: 0.2444, Epoch 8, Batch 72, CE_loss: 0.21371091902256012, Dice_loss: 0.02083403617143631, Consistency_loss: 0.0013084332458674908\n",
      "[Training] Epoch: 8 [========>      ] 58.7% Loss: 0.2442, Epoch 8, Batch 73, CE_loss: 0.20803943276405334, Dice_loss: 0.019543590024113655, Consistency_loss: 0.0011944770812988281\n",
      "[Training] Epoch: 8 [========>      ] 59.5% Loss: 0.2439, Epoch 8, Batch 74, CE_loss: 0.20182715356349945, Dice_loss: 0.01905674673616886, Consistency_loss: 0.0010665642330422997\n",
      "[Training] Epoch: 8 [=========>     ] 60.3% Loss: 0.2438, Epoch 8, Batch 75, CE_loss: 0.21539559960365295, Dice_loss: 0.020935215055942535, Consistency_loss: 0.0011965520679950714\n",
      "[Training] Epoch: 8 [=========>     ] 61.1% Loss: 0.2437, Epoch 8, Batch 76, CE_loss: 0.2119135856628418, Dice_loss: 0.020345700904726982, Consistency_loss: 0.00017274756100960076\n",
      "[Training] Epoch: 8 [=========>     ] 61.9% Loss: 0.2435, Epoch 8, Batch 77, CE_loss: 0.20988969504833221, Dice_loss: 0.02001335285604, Consistency_loss: 0.00017344670777674764\n",
      "[Training] Epoch: 8 [=========>     ] 62.7% Loss: 0.2433, Epoch 8, Batch 78, CE_loss: 0.2088211178779602, Dice_loss: 0.01918412558734417, Consistency_loss: 0.00022813657415099442\n",
      "[Training] Epoch: 8 [=========>     ] 63.5% Loss: 0.2431, Epoch 8, Batch 79, CE_loss: 0.20669445395469666, Dice_loss: 0.019663628190755844, Consistency_loss: 0.00017634693358559161\n",
      "[Training] Epoch: 8 [=========>     ] 64.3% Loss: 0.2431, Epoch 8, Batch 80, CE_loss: 0.21801835298538208, Dice_loss: 0.021328698843717575, Consistency_loss: 0.00015236364561133087\n",
      "[Training] Epoch: 8 [=========>     ] 65.1% Loss: 0.2431, Epoch 8, Batch 81, CE_loss: 0.22148741781711578, Dice_loss: 0.021096745505928993, Consistency_loss: 0.001074335421435535\n",
      "[Training] Epoch: 8 [=========>     ] 65.9% Loss: 0.2430, Epoch 8, Batch 82, CE_loss: 0.21412691473960876, Dice_loss: 0.020782247185707092, Consistency_loss: 0.00016293470980599523\n",
      "[Training] Epoch: 8 [==========>    ] 66.7% Loss: 0.2427, Epoch 8, Batch 83, CE_loss: 0.2045912891626358, Dice_loss: 0.01869102753698826, Consistency_loss: 0.0006894934922456741\n",
      "[Training] Epoch: 8 [==========>    ] 67.5% Loss: 0.2428, Epoch 8, Batch 84, CE_loss: 0.22236569225788116, Dice_loss: 0.021391363814473152, Consistency_loss: 0.0002139089920092374\n",
      "[Training] Epoch: 8 [==========>    ] 68.3% Loss: 0.2429, Epoch 8, Batch 85, CE_loss: 0.2290135771036148, Dice_loss: 0.02281012386083603, Consistency_loss: 0.0011937293456867337\n",
      "[Training] Epoch: 8 [==========>    ] 69.0% Loss: 0.2426, Epoch 8, Batch 86, CE_loss: 0.19902300834655762, Dice_loss: 0.017837829887866974, Consistency_loss: 0.0006824887241236866\n",
      "[Training] Epoch: 8 [==========>    ] 69.8% Loss: 0.2427, Epoch 8, Batch 87, CE_loss: 0.22961710393428802, Dice_loss: 0.02244877628982067, Consistency_loss: 0.0009570028050802648\n",
      "[Training] Epoch: 8 [==========>    ] 70.6% Loss: 0.2426, Epoch 8, Batch 88, CE_loss: 0.21231387555599213, Dice_loss: 0.020294930785894394, Consistency_loss: 0.001128460164181888\n",
      "[Training] Epoch: 8 [==========>    ] 71.4% Loss: 0.2426, Epoch 8, Batch 89, CE_loss: 0.2190285176038742, Dice_loss: 0.02138311229646206, Consistency_loss: 0.0013066291576251388\n",
      "[Training] Epoch: 8 [==========>    ] 72.2% Loss: 0.2425, Epoch 8, Batch 90, CE_loss: 0.2153727114200592, Dice_loss: 0.02117995172739029, Consistency_loss: 0.0011704782955348492\n",
      "[Training] Epoch: 8 [==========>    ] 73.0% Loss: 0.2423, Epoch 8, Batch 91, CE_loss: 0.20276853442192078, Dice_loss: 0.019531382247805595, Consistency_loss: 0.001593295717611909\n",
      "[Training] Epoch: 8 [===========>   ] 73.8% Loss: 0.2424, Epoch 8, Batch 92, CE_loss: 0.22828282415866852, Dice_loss: 0.023070991039276123, Consistency_loss: 0.0012509400257840753\n",
      "[Training] Epoch: 8 [===========>   ] 74.6% Loss: 0.2422, Epoch 8, Batch 93, CE_loss: 0.19996552169322968, Dice_loss: 0.018524471670389175, Consistency_loss: 0.001248884480446577\n",
      "[Training] Epoch: 8 [===========>   ] 75.4% Loss: 0.2420, Epoch 8, Batch 94, CE_loss: 0.20514938235282898, Dice_loss: 0.019270004704594612, Consistency_loss: 0.001168828341178596\n",
      "[Training] Epoch: 8 [===========>   ] 76.2% Loss: 0.2420, Epoch 8, Batch 95, CE_loss: 0.2180081009864807, Dice_loss: 0.021735088899731636, Consistency_loss: 0.0017179663991555572\n",
      "[Training] Epoch: 8 [===========>   ] 77.0% Loss: 0.2419, Epoch 8, Batch 96, CE_loss: 0.2094983011484146, Dice_loss: 0.02021922916173935, Consistency_loss: 0.0014676878927275538\n",
      "[Training] Epoch: 8 [===========>   ] 77.8% Loss: 0.2418, Epoch 8, Batch 97, CE_loss: 0.2101818323135376, Dice_loss: 0.019804278388619423, Consistency_loss: 0.0014619554858654737\n",
      "[Training] Epoch: 8 [===========>   ] 78.6% Loss: 0.2418, Epoch 8, Batch 98, CE_loss: 0.21561402082443237, Dice_loss: 0.02137928083539009, Consistency_loss: 0.0010446303058415651\n",
      "[Training] Epoch: 8 [===========>   ] 79.4% Loss: 0.2415, Epoch 8, Batch 99, CE_loss: 0.19682708382606506, Dice_loss: 0.018148010596632957, Consistency_loss: 0.0010009384714066982\n",
      "[Training] Epoch: 8 [============>  ] 80.2% Loss: 0.2413, Epoch 8, Batch 100, CE_loss: 0.20124730467796326, Dice_loss: 0.018482625484466553, Consistency_loss: 0.0011793129378929734\n",
      "[Training] Epoch: 8 [============>  ] 81.0% Loss: 0.2411, Epoch 8, Batch 101, CE_loss: 0.2041318118572235, Dice_loss: 0.019368916749954224, Consistency_loss: 0.001363994088023901\n",
      "[Training] Epoch: 8 [============>  ] 81.7% Loss: 0.2410, Epoch 8, Batch 102, CE_loss: 0.20296579599380493, Dice_loss: 0.01926676370203495, Consistency_loss: 0.0010051325662061572\n",
      "[Training] Epoch: 8 [============>  ] 82.5% Loss: 0.2409, Epoch 8, Batch 103, CE_loss: 0.21211284399032593, Dice_loss: 0.020376000553369522, Consistency_loss: 0.00110565684735775\n",
      "[Training] Epoch: 8 [============>  ] 83.3% Loss: 0.2407, Epoch 8, Batch 104, CE_loss: 0.19819994270801544, Dice_loss: 0.01807957887649536, Consistency_loss: 0.0010670338524505496\n",
      "[Training] Epoch: 8 [============>  ] 84.1% Loss: 0.2407, Epoch 8, Batch 105, CE_loss: 0.22079266607761383, Dice_loss: 0.020975187420845032, Consistency_loss: 0.0012077592546120286\n",
      "[Training] Epoch: 8 [============>  ] 84.9% Loss: 0.2406, Epoch 8, Batch 106, CE_loss: 0.20638960599899292, Dice_loss: 0.019219892099499702, Consistency_loss: 0.00013694228255189955\n",
      "[Training] Epoch: 8 [============>  ] 85.7% Loss: 0.2404, Epoch 8, Batch 107, CE_loss: 0.20169004797935486, Dice_loss: 0.01849306747317314, Consistency_loss: 0.0010893424041569233\n",
      "[Training] Epoch: 8 [============>  ] 86.5% Loss: 0.2404, Epoch 8, Batch 108, CE_loss: 0.21565772593021393, Dice_loss: 0.020642880350351334, Consistency_loss: 0.0011169888311997056\n",
      "[Training] Epoch: 8 [=============> ] 87.3% Loss: 0.2402, Epoch 8, Batch 109, CE_loss: 0.20263256132602692, Dice_loss: 0.01886080764234066, Consistency_loss: 0.0012046822812408209\n",
      "[Training] Epoch: 8 [=============> ] 88.1% Loss: 0.2400, Epoch 8, Batch 110, CE_loss: 0.20193465054035187, Dice_loss: 0.018411988392472267, Consistency_loss: 0.0009411941282451153\n",
      "[Training] Epoch: 8 [=============> ] 88.9% Loss: 0.2401, Epoch 8, Batch 111, CE_loss: 0.22595122456550598, Dice_loss: 0.022013001143932343, Consistency_loss: 0.0008504323777742684\n",
      "[Training] Epoch: 8 [=============> ] 89.7% Loss: 0.2399, Epoch 8, Batch 112, CE_loss: 0.20192697644233704, Dice_loss: 0.01862962730228901, Consistency_loss: 0.0009518650476820767\n",
      "[Training] Epoch: 8 [=============> ] 90.5% Loss: 0.2398, Epoch 8, Batch 113, CE_loss: 0.20363658666610718, Dice_loss: 0.018874384462833405, Consistency_loss: 0.0009830904891714454\n",
      "[Training] Epoch: 8 [=============> ] 91.3% Loss: 0.2397, Epoch 8, Batch 114, CE_loss: 0.20912303030490875, Dice_loss: 0.02007565088570118, Consistency_loss: 0.0011592501541599631\n",
      "[Training] Epoch: 8 [=============> ] 92.1% Loss: 0.2396, Epoch 8, Batch 115, CE_loss: 0.20724467933177948, Dice_loss: 0.019156524911522865, Consistency_loss: 0.0010609561577439308\n",
      "[Training] Epoch: 8 [=============> ] 92.9% Loss: 0.2393, Epoch 8, Batch 116, CE_loss: 0.19152960181236267, Dice_loss: 0.016845837235450745, Consistency_loss: 0.0011907228035852313\n",
      "[Training] Epoch: 8 [==============>] 93.7% Loss: 0.2393, Epoch 8, Batch 117, CE_loss: 0.21224430203437805, Dice_loss: 0.020602334290742874, Consistency_loss: 0.000311629701172933\n",
      "[Training] Epoch: 8 [==============>] 94.4% Loss: 0.2391, Epoch 8, Batch 118, CE_loss: 0.20011605322360992, Dice_loss: 0.01817404106259346, Consistency_loss: 0.0006297439686022699\n",
      "[Training] Epoch: 8 [==============>] 95.2% Loss: 0.2389, Epoch 8, Batch 119, CE_loss: 0.19443289935588837, Dice_loss: 0.017313597723841667, Consistency_loss: 0.0009366855374537408\n",
      "[Training] Epoch: 8 [==============>] 96.0% Loss: 0.2387, Epoch 8, Batch 120, CE_loss: 0.19359949231147766, Dice_loss: 0.017311446368694305, Consistency_loss: 0.00023066402354743332\n",
      "[Training] Epoch: 8 [==============>] 96.8% Loss: 0.2385, Epoch 8, Batch 121, CE_loss: 0.2022773176431656, Dice_loss: 0.018989678472280502, Consistency_loss: 0.0006372139323502779\n",
      "[Training] Epoch: 8 [==============>] 97.6% Loss: 0.2384, Epoch 8, Batch 122, CE_loss: 0.20676922798156738, Dice_loss: 0.01887109875679016, Consistency_loss: 0.0007811262621544302\n",
      "[Training] Epoch: 8 [==============>] 98.4% Loss: 0.2383, Epoch 8, Batch 123, CE_loss: 0.19839119911193848, Dice_loss: 0.017942173406481743, Consistency_loss: 0.001126204151660204\n",
      "[Training] Epoch: 8 [==============>] 99.2% Loss: 0.2382, Epoch 8, Batch 124, CE_loss: 0.20923244953155518, Dice_loss: 0.019781792536377907, Consistency_loss: 0.0013647013111039996\n",
      "[Training] Epoch: 8 [DONE]                                 \n",
      "Epoch 8, Batch 125, CE_loss: 0.198989599943161, Dice_loss: 0.018334008753299713, Consistency_loss: 0.0011860954109579325\n",
      "[Validation] Epoch: 8 [DONE]                                 \n",
      "[Epoch: 8, TrainLoss: 0.2380, TrainDice: 0.0207, ValLoss: 0.2385                                             \n",
      "Number of batches:  126\n",
      "[Training] Epoch: 9 [>              ] 0.8% Loss: 0.2065, Epoch 9, Batch 0, CE_loss: 0.18911555409431458, Dice_loss: 0.01718403398990631, Consistency_loss: 0.0001599849492777139\n",
      "[Training] Epoch: 9 [>              ] 1.6% Loss: 0.2135, Epoch 9, Batch 1, CE_loss: 0.20064570009708405, Dice_loss: 0.018667688593268394, Consistency_loss: 0.0012086353963240981\n",
      "[Training] Epoch: 9 [>              ] 2.4% Loss: 0.2195, Epoch 9, Batch 2, CE_loss: 0.210837721824646, Dice_loss: 0.020131561905145645, Consistency_loss: 0.00044662164873443544\n",
      "[Training] Epoch: 9 [>              ] 3.2% Loss: 0.2192, Epoch 9, Batch 3, CE_loss: 0.19900530576705933, Dice_loss: 0.018274681642651558, Consistency_loss: 0.0009258600766770542\n",
      "[Training] Epoch: 9 [>              ] 4.0% Loss: 0.2177, Epoch 9, Batch 4, CE_loss: 0.19349388778209686, Dice_loss: 0.017530927434563637, Consistency_loss: 0.0009114394197240472\n",
      "[Training] Epoch: 9 [>              ] 4.8% Loss: 0.2171, Epoch 9, Batch 5, CE_loss: 0.1959402710199356, Dice_loss: 0.017772505059838295, Consistency_loss: 0.0005983272567391396\n",
      "[Training] Epoch: 9 [>              ] 5.6% Loss: 0.2163, Epoch 9, Batch 6, CE_loss: 0.19338960945606232, Dice_loss: 0.017038224264979362, Consistency_loss: 0.0006453643436543643\n",
      "[Training] Epoch: 9 [>              ] 6.3% Loss: 0.2171, Epoch 9, Batch 7, CE_loss: 0.20345383882522583, Dice_loss: 0.018290851265192032, Consistency_loss: 0.000761448813136667\n",
      "[Training] Epoch: 9 [=>             ] 7.1% Loss: 0.2172, Epoch 9, Batch 8, CE_loss: 0.19929678738117218, Dice_loss: 0.018749400973320007, Consistency_loss: 0.0005409184377640486\n",
      "[Training] Epoch: 9 [=>             ] 7.9% Loss: 0.2172, Epoch 9, Batch 9, CE_loss: 0.19815656542778015, Dice_loss: 0.017830338329076767, Consistency_loss: 0.0006024634349159896\n",
      "[Training] Epoch: 9 [=>             ] 8.7% Loss: 0.2171, Epoch 9, Batch 10, CE_loss: 0.19734618067741394, Dice_loss: 0.018305808305740356, Consistency_loss: 0.0006659128121100366\n",
      "[Training] Epoch: 9 [=>             ] 9.5% Loss: 0.2176, Epoch 9, Batch 11, CE_loss: 0.20279963314533234, Dice_loss: 0.018817253410816193, Consistency_loss: 0.001126257237046957\n",
      "[Training] Epoch: 9 [=>             ] 10.3% Loss: 0.2165, Epoch 9, Batch 12, CE_loss: 0.18643561005592346, Dice_loss: 0.0165494903922081, Consistency_loss: 0.0006631548749282956\n",
      "[Training] Epoch: 9 [=>             ] 11.1% Loss: 0.2164, Epoch 9, Batch 13, CE_loss: 0.19649945199489594, Dice_loss: 0.01832839846611023, Consistency_loss: 0.0008932111086323857\n",
      "[Training] Epoch: 9 [=>             ] 11.9% Loss: 0.2164, Epoch 9, Batch 14, CE_loss: 0.19697898626327515, Dice_loss: 0.017809966579079628, Consistency_loss: 0.0005751032149419188\n",
      "[Training] Epoch: 9 [=>             ] 12.7% Loss: 0.2171, Epoch 9, Batch 15, CE_loss: 0.20701409876346588, Dice_loss: 0.01986079290509224, Consistency_loss: 0.0007351179956458509\n",
      "[Training] Epoch: 9 [==>            ] 13.5% Loss: 0.2169, Epoch 9, Batch 16, CE_loss: 0.1960785835981369, Dice_loss: 0.017856812104582787, Consistency_loss: 0.0009648284176364541\n",
      "[Training] Epoch: 9 [==>            ] 14.3% Loss: 0.2162, Epoch 9, Batch 17, CE_loss: 0.1872568428516388, Dice_loss: 0.01640195958316326, Consistency_loss: 0.0007838649908080697\n",
      "[Training] Epoch: 9 [==>            ] 15.1% Loss: 0.2164, Epoch 9, Batch 18, CE_loss: 0.1992833912372589, Dice_loss: 0.017970755696296692, Consistency_loss: 0.001220116624608636\n",
      "[Training] Epoch: 9 [==>            ] 15.9% Loss: 0.2164, Epoch 9, Batch 19, CE_loss: 0.19832783937454224, Dice_loss: 0.01841549389064312, Consistency_loss: 0.0010433160932734609\n",
      "[Training] Epoch: 9 [==>            ] 16.7% Loss: 0.2165, Epoch 9, Batch 20, CE_loss: 0.19915597140789032, Dice_loss: 0.018504735082387924, Consistency_loss: 0.0009210134157910943\n",
      "[Training] Epoch: 9 [==>            ] 17.5% Loss: 0.2168, Epoch 9, Batch 21, CE_loss: 0.20276503264904022, Dice_loss: 0.0191497802734375, Consistency_loss: 0.0007941005751490593\n",
      "[Training] Epoch: 9 [==>            ] 18.3% Loss: 0.2170, Epoch 9, Batch 22, CE_loss: 0.20097069442272186, Dice_loss: 0.018618183210492134, Consistency_loss: 0.0006936321151442826\n",
      "[Training] Epoch: 9 [==>            ] 19.0% Loss: 0.2172, Epoch 9, Batch 23, CE_loss: 0.2036227285861969, Dice_loss: 0.01868640072643757, Consistency_loss: 0.0008580991998314857\n",
      "[Training] Epoch: 9 [==>            ] 19.8% Loss: 0.2169, Epoch 9, Batch 24, CE_loss: 0.1910283863544464, Dice_loss: 0.017159540206193924, Consistency_loss: 0.0010011891135945916\n",
      "[Training] Epoch: 9 [===>           ] 20.6% Loss: 0.2175, Epoch 9, Batch 25, CE_loss: 0.21008026599884033, Dice_loss: 0.02034646086394787, Consistency_loss: 0.0012046097544953227\n",
      "[Training] Epoch: 9 [===>           ] 21.4% Loss: 0.2175, Epoch 9, Batch 26, CE_loss: 0.19843396544456482, Dice_loss: 0.018656762316823006, Consistency_loss: 0.0010417625308036804\n",
      "[Training] Epoch: 9 [===>           ] 22.2% Loss: 0.2172, Epoch 9, Batch 27, CE_loss: 0.18978308141231537, Dice_loss: 0.016687940806150436, Consistency_loss: 0.0016010772669687867\n",
      "[Training] Epoch: 9 [===>           ] 23.0% Loss: 0.2172, Epoch 9, Batch 28, CE_loss: 0.1998622715473175, Dice_loss: 0.018515288829803467, Consistency_loss: 0.000516452535521239\n",
      "[Training] Epoch: 9 [===>           ] 23.8% Loss: 0.2171, Epoch 9, Batch 29, CE_loss: 0.1962617039680481, Dice_loss: 0.01753377914428711, Consistency_loss: 0.0010869958205148578\n",
      "[Training] Epoch: 9 [===>           ] 24.6% Loss: 0.2173, Epoch 9, Batch 30, CE_loss: 0.20144283771514893, Dice_loss: 0.018999924883246422, Consistency_loss: 0.0012264996767044067\n",
      "[Training] Epoch: 9 [===>           ] 25.4% Loss: 0.2170, Epoch 9, Batch 31, CE_loss: 0.19187699258327484, Dice_loss: 0.01730245351791382, Consistency_loss: 0.0002018602390307933\n",
      "[Training] Epoch: 9 [===>           ] 26.2% Loss: 0.2168, Epoch 9, Batch 32, CE_loss: 0.1919104903936386, Dice_loss: 0.01724684238433838, Consistency_loss: 0.00020124021102674305\n",
      "[Training] Epoch: 9 [====>          ] 27.0% Loss: 0.2163, Epoch 9, Batch 33, CE_loss: 0.18202367424964905, Dice_loss: 0.016039535403251648, Consistency_loss: 0.0006804424338042736\n",
      "[Training] Epoch: 9 [====>          ] 27.8% Loss: 0.2162, Epoch 9, Batch 34, CE_loss: 0.19557121396064758, Dice_loss: 0.01776033639907837, Consistency_loss: 0.0009472686797380447\n",
      "[Training] Epoch: 9 [====>          ] 28.6% Loss: 0.2160, Epoch 9, Batch 35, CE_loss: 0.18883970379829407, Dice_loss: 0.01696961745619774, Consistency_loss: 0.0008896852959878743\n",
      "[Training] Epoch: 9 [====>          ] 29.4% Loss: 0.2155, Epoch 9, Batch 36, CE_loss: 0.18215887248516083, Dice_loss: 0.01583431474864483, Consistency_loss: 0.0008872018079273403\n",
      "[Training] Epoch: 9 [====>          ] 30.2% Loss: 0.2157, Epoch 9, Batch 37, CE_loss: 0.20260043442249298, Dice_loss: 0.018517980352044106, Consistency_loss: 0.0010648593306541443\n",
      "[Training] Epoch: 9 [====>          ] 31.0% Loss: 0.2155, Epoch 9, Batch 38, CE_loss: 0.1916360855102539, Dice_loss: 0.01689838245511055, Consistency_loss: 0.0010963584063574672\n",
      "[Training] Epoch: 9 [====>          ] 31.7% Loss: 0.2155, Epoch 9, Batch 39, CE_loss: 0.19501371681690216, Dice_loss: 0.017619118094444275, Consistency_loss: 0.0011973049258813262\n",
      "[Training] Epoch: 9 [====>          ] 32.5% Loss: 0.2154, Epoch 9, Batch 40, CE_loss: 0.1922263354063034, Dice_loss: 0.017668291926383972, Consistency_loss: 0.001083340379409492\n",
      "[Training] Epoch: 9 [=====>         ] 33.3% Loss: 0.2150, Epoch 9, Batch 41, CE_loss: 0.18510562181472778, Dice_loss: 0.016067638993263245, Consistency_loss: 0.00014950735203456134\n",
      "[Training] Epoch: 9 [=====>         ] 34.1% Loss: 0.2150, Epoch 9, Batch 42, CE_loss: 0.19565080106258392, Dice_loss: 0.017915941774845123, Consistency_loss: 0.00016766339831519872\n",
      "[Training] Epoch: 9 [=====>         ] 34.9% Loss: 0.2145, Epoch 9, Batch 43, CE_loss: 0.17644082009792328, Dice_loss: 0.014822938479483128, Consistency_loss: 0.00026694536791183054\n",
      "[Training] Epoch: 9 [=====>         ] 35.7% Loss: 0.2142, Epoch 9, Batch 44, CE_loss: 0.18491996824741364, Dice_loss: 0.01633261889219284, Consistency_loss: 0.0015578222228214145\n",
      "[Training] Epoch: 9 [=====>         ] 36.5% Loss: 0.2138, Epoch 9, Batch 45, CE_loss: 0.18004922568798065, Dice_loss: 0.016029369086027145, Consistency_loss: 0.0011346782557666302\n",
      "[Training] Epoch: 9 [=====>         ] 37.3% Loss: 0.2136, Epoch 9, Batch 46, CE_loss: 0.18505121767520905, Dice_loss: 0.016099710017442703, Consistency_loss: 0.0005523512954823673\n",
      "[Training] Epoch: 9 [=====>         ] 38.1% Loss: 0.2135, Epoch 9, Batch 47, CE_loss: 0.19243566691875458, Dice_loss: 0.01702525094151497, Consistency_loss: 0.0007870938861742616\n",
      "[Training] Epoch: 9 [=====>         ] 38.9% Loss: 0.2133, Epoch 9, Batch 48, CE_loss: 0.1833888739347458, Dice_loss: 0.01619236171245575, Consistency_loss: 0.0015448692720383406\n",
      "[Training] Epoch: 9 [=====>         ] 39.7% Loss: 0.2129, Epoch 9, Batch 49, CE_loss: 0.18123914301395416, Dice_loss: 0.016333796083927155, Consistency_loss: 0.00021883747831452638\n",
      "[Training] Epoch: 9 [======>        ] 40.5% Loss: 0.2127, Epoch 9, Batch 50, CE_loss: 0.1849588304758072, Dice_loss: 0.016544688493013382, Consistency_loss: 0.0013517597690224648\n",
      "[Training] Epoch: 9 [======>        ] 41.3% Loss: 0.2126, Epoch 9, Batch 51, CE_loss: 0.18721170723438263, Dice_loss: 0.01683683507144451, Consistency_loss: 0.0013647214509546757\n",
      "[Training] Epoch: 9 [======>        ] 42.1% Loss: 0.2126, Epoch 9, Batch 52, CE_loss: 0.19347113370895386, Dice_loss: 0.01738429069519043, Consistency_loss: 0.0007043105433695018\n",
      "[Training] Epoch: 9 [======>        ] 42.9% Loss: 0.2124, Epoch 9, Batch 53, CE_loss: 0.1843024045228958, Dice_loss: 0.015757907181978226, Consistency_loss: 0.0010177235817536712\n",
      "[Training] Epoch: 9 [======>        ] 43.7% Loss: 0.2122, Epoch 9, Batch 54, CE_loss: 0.18385998904705048, Dice_loss: 0.016315266489982605, Consistency_loss: 0.00014908496814314276\n",
      "[Training] Epoch: 9 [======>        ] 44.4% Loss: 0.2122, Epoch 9, Batch 55, CE_loss: 0.19670316576957703, Dice_loss: 0.018061401322484016, Consistency_loss: 0.0008454964845441282\n",
      "[Training] Epoch: 9 [======>        ] 45.2% Loss: 0.2120, Epoch 9, Batch 56, CE_loss: 0.1833290457725525, Dice_loss: 0.015844769775867462, Consistency_loss: 0.0010051305871456861\n",
      "[Training] Epoch: 9 [======>        ] 46.0% Loss: 0.2118, Epoch 9, Batch 57, CE_loss: 0.1843252331018448, Dice_loss: 0.01639808714389801, Consistency_loss: 0.0008565879543311894\n",
      "[Training] Epoch: 9 [=======>       ] 46.8% Loss: 0.2118, Epoch 9, Batch 58, CE_loss: 0.1904798448085785, Dice_loss: 0.016913514584302902, Consistency_loss: 0.0009438378037884831\n",
      "[Training] Epoch: 9 [=======>       ] 47.6% Loss: 0.2116, Epoch 9, Batch 59, CE_loss: 0.18479764461517334, Dice_loss: 0.01652241311967373, Consistency_loss: 0.0008857642533257604\n",
      "[Training] Epoch: 9 [=======>       ] 48.4% Loss: 0.2117, Epoch 9, Batch 60, CE_loss: 0.19557642936706543, Dice_loss: 0.017994217574596405, Consistency_loss: 0.0007935867761261761\n",
      "[Training] Epoch: 9 [=======>       ] 49.2% Loss: 0.2115, Epoch 9, Batch 61, CE_loss: 0.1864975541830063, Dice_loss: 0.01645032875239849, Consistency_loss: 0.0011484612477943301\n",
      "[Training] Epoch: 9 [=======>       ] 50.0% Loss: 0.2112, Epoch 9, Batch 62, CE_loss: 0.1779446005821228, Dice_loss: 0.015461625531315804, Consistency_loss: 0.00028582761297002435\n",
      "[Training] Epoch: 9 [=======>       ] 50.8% Loss: 0.2112, Epoch 9, Batch 63, CE_loss: 0.19229722023010254, Dice_loss: 0.01733858697116375, Consistency_loss: 0.00027548588695935905\n",
      "[Training] Epoch: 9 [=======>       ] 51.6% Loss: 0.2109, Epoch 9, Batch 64, CE_loss: 0.17566531896591187, Dice_loss: 0.015199404209852219, Consistency_loss: 0.0016695222584530711\n",
      "[Training] Epoch: 9 [=======>       ] 52.4% Loss: 0.2110, Epoch 9, Batch 65, CE_loss: 0.1965281367301941, Dice_loss: 0.018364017829298973, Consistency_loss: 0.0011438168585300446\n",
      "[Training] Epoch: 9 [=======>       ] 53.2% Loss: 0.2109, Epoch 9, Batch 66, CE_loss: 0.1837962418794632, Dice_loss: 0.016186147928237915, Consistency_loss: 0.0008815014734864235\n",
      "[Training] Epoch: 9 [========>      ] 54.0% Loss: 0.2107, Epoch 9, Batch 67, CE_loss: 0.1801947057247162, Dice_loss: 0.016114510595798492, Consistency_loss: 0.00031597312772646546\n",
      "[Training] Epoch: 9 [========>      ] 54.8% Loss: 0.2104, Epoch 9, Batch 68, CE_loss: 0.17917311191558838, Dice_loss: 0.015871061012148857, Consistency_loss: 0.0009663652745075524\n",
      "[Training] Epoch: 9 [========>      ] 55.6% Loss: 0.2105, Epoch 9, Batch 69, CE_loss: 0.19315920770168304, Dice_loss: 0.01773613877594471, Consistency_loss: 0.0008969359332695603\n",
      "[Training] Epoch: 9 [========>      ] 56.3% Loss: 0.2105, Epoch 9, Batch 70, CE_loss: 0.19327102601528168, Dice_loss: 0.018245378509163857, Consistency_loss: 0.0012661281507462263\n",
      "[Training] Epoch: 9 [========>      ] 57.1% Loss: 0.2104, Epoch 9, Batch 71, CE_loss: 0.18355301022529602, Dice_loss: 0.016296999529004097, Consistency_loss: 0.0014681849861517549\n",
      "[Training] Epoch: 9 [========>      ] 57.9% Loss: 0.2102, Epoch 9, Batch 72, CE_loss: 0.1814556121826172, Dice_loss: 0.01612166315317154, Consistency_loss: 0.0009560479084029794\n",
      "[Training] Epoch: 9 [========>      ] 58.7% Loss: 0.2100, Epoch 9, Batch 73, CE_loss: 0.1789332926273346, Dice_loss: 0.015997115522623062, Consistency_loss: 0.0011744514340534806\n",
      "[Training] Epoch: 9 [========>      ] 59.5% Loss: 0.2100, Epoch 9, Batch 74, CE_loss: 0.1899711787700653, Dice_loss: 0.01760350912809372, Consistency_loss: 0.0001976806961465627\n",
      "[Training] Epoch: 9 [=========>     ] 60.3% Loss: 0.2099, Epoch 9, Batch 75, CE_loss: 0.18490159511566162, Dice_loss: 0.017490189522504807, Consistency_loss: 0.001009722356684506\n",
      "[Training] Epoch: 9 [=========>     ] 61.1% Loss: 0.2098, Epoch 9, Batch 76, CE_loss: 0.18699079751968384, Dice_loss: 0.017007865011692047, Consistency_loss: 0.0012929649092257023\n",
      "[Training] Epoch: 9 [=========>     ] 61.9% Loss: 0.2096, Epoch 9, Batch 77, CE_loss: 0.17448623478412628, Dice_loss: 0.01505132857710123, Consistency_loss: 0.0012786546722054482\n",
      "[Training] Epoch: 9 [=========>     ] 62.7% Loss: 0.2094, Epoch 9, Batch 78, CE_loss: 0.18052536249160767, Dice_loss: 0.015313259325921535, Consistency_loss: 0.0002270229597343132\n",
      "[Training] Epoch: 9 [=========>     ] 63.5% Loss: 0.2094, Epoch 9, Batch 79, CE_loss: 0.19179648160934448, Dice_loss: 0.0175311416387558, Consistency_loss: 0.0007399037713184953\n",
      "[Training] Epoch: 9 [=========>     ] 64.3% Loss: 0.2093, Epoch 9, Batch 80, CE_loss: 0.1814621537923813, Dice_loss: 0.01620081625878811, Consistency_loss: 0.000984480488114059\n",
      "[Training] Epoch: 9 [=========>     ] 65.1% Loss: 0.2092, Epoch 9, Batch 81, CE_loss: 0.180869460105896, Dice_loss: 0.01566576398909092, Consistency_loss: 0.0011345756938681006\n",
      "[Training] Epoch: 9 [=========>     ] 65.9% Loss: 0.2090, Epoch 9, Batch 82, CE_loss: 0.1803947538137436, Dice_loss: 0.01619390957057476, Consistency_loss: 0.0010992372408509254\n",
      "[Training] Epoch: 9 [==========>    ] 66.7% Loss: 0.2089, Epoch 9, Batch 83, CE_loss: 0.18566220998764038, Dice_loss: 0.016597166657447815, Consistency_loss: 0.000694829155690968\n",
      "[Training] Epoch: 9 [==========>    ] 67.5% Loss: 0.2089, Epoch 9, Batch 84, CE_loss: 0.18889476358890533, Dice_loss: 0.0167795792222023, Consistency_loss: 0.00019524847448337823\n",
      "[Training] Epoch: 9 [==========>    ] 68.3% Loss: 0.2088, Epoch 9, Batch 85, CE_loss: 0.184115469455719, Dice_loss: 0.015711531043052673, Consistency_loss: 0.0007796843419782817\n",
      "[Training] Epoch: 9 [==========>    ] 69.0% Loss: 0.2088, Epoch 9, Batch 86, CE_loss: 0.19295455515384674, Dice_loss: 0.017073431983590126, Consistency_loss: 0.0013030277332291007\n",
      "[Training] Epoch: 9 [==========>    ] 69.8% Loss: 0.2086, Epoch 9, Batch 87, CE_loss: 0.17367203533649445, Dice_loss: 0.01509542390704155, Consistency_loss: 0.0007583912229165435\n",
      "[Training] Epoch: 9 [==========>    ] 70.6% Loss: 0.2085, Epoch 9, Batch 88, CE_loss: 0.1826949566602707, Dice_loss: 0.01666131615638733, Consistency_loss: 0.0012574739521369338\n",
      "[Training] Epoch: 9 [==========>    ] 71.4% Loss: 0.2086, Epoch 9, Batch 89, CE_loss: 0.19291764497756958, Dice_loss: 0.017981193959712982, Consistency_loss: 0.0012763915583491325\n",
      "[Training] Epoch: 9 [==========>    ] 72.2% Loss: 0.2084, Epoch 9, Batch 90, CE_loss: 0.17470048367977142, Dice_loss: 0.015383756719529629, Consistency_loss: 0.001264692866243422\n",
      "[Training] Epoch: 9 [==========>    ] 73.0% Loss: 0.2082, Epoch 9, Batch 91, CE_loss: 0.17650912702083588, Dice_loss: 0.015579182654619217, Consistency_loss: 0.0012577030574902892\n",
      "[Training] Epoch: 9 [===========>   ] 73.8% Loss: 0.2080, Epoch 9, Batch 92, CE_loss: 0.17202717065811157, Dice_loss: 0.014586586505174637, Consistency_loss: 0.0010162674589082599\n",
      "[Training] Epoch: 9 [===========>   ] 74.6% Loss: 0.2078, Epoch 9, Batch 93, CE_loss: 0.17197461426258087, Dice_loss: 0.014597887173295021, Consistency_loss: 0.00015459308633580804\n",
      "[Training] Epoch: 9 [===========>   ] 75.4% Loss: 0.2077, Epoch 9, Batch 94, CE_loss: 0.18379803001880646, Dice_loss: 0.016803888604044914, Consistency_loss: 0.0009314240305684507\n",
      "[Training] Epoch: 9 [===========>   ] 76.2% Loss: 0.2077, Epoch 9, Batch 95, CE_loss: 0.1887553632259369, Dice_loss: 0.017047325149178505, Consistency_loss: 0.0012559363385662436\n",
      "[Training] Epoch: 9 [===========>   ] 77.0% Loss: 0.2077, Epoch 9, Batch 96, CE_loss: 0.18628476560115814, Dice_loss: 0.016881363466382027, Consistency_loss: 0.0009648617706261575\n",
      "[Training] Epoch: 9 [===========>   ] 77.8% Loss: 0.2077, Epoch 9, Batch 97, CE_loss: 0.19114844501018524, Dice_loss: 0.017080016434192657, Consistency_loss: 0.0007659359253011644\n",
      "[Training] Epoch: 9 [===========>   ] 78.6% Loss: 0.2077, Epoch 9, Batch 98, CE_loss: 0.18962818384170532, Dice_loss: 0.01723334565758705, Consistency_loss: 0.0008090818300843239\n",
      "[Training] Epoch: 9 [===========>   ] 79.4% Loss: 0.2075, Epoch 9, Batch 99, CE_loss: 0.17323030531406403, Dice_loss: 0.014936418272554874, Consistency_loss: 0.0011822092346847057\n",
      "[Training] Epoch: 9 [============>  ] 80.2% Loss: 0.2075, Epoch 9, Batch 100, CE_loss: 0.1904258280992508, Dice_loss: 0.017397254705429077, Consistency_loss: 0.0009536466677673161\n",
      "[Training] Epoch: 9 [============>  ] 81.0% Loss: 0.2074, Epoch 9, Batch 101, CE_loss: 0.18259325623512268, Dice_loss: 0.016677990555763245, Consistency_loss: 0.0009810783667489886\n",
      "[Training] Epoch: 9 [============>  ] 81.7% Loss: 0.2073, Epoch 9, Batch 102, CE_loss: 0.1751217097043991, Dice_loss: 0.014873676933348179, Consistency_loss: 0.0008350305142812431\n",
      "[Training] Epoch: 9 [============>  ] 82.5% Loss: 0.2071, Epoch 9, Batch 103, CE_loss: 0.17483066022396088, Dice_loss: 0.015389921143651009, Consistency_loss: 0.0011425305856391788\n",
      "[Training] Epoch: 9 [============>  ] 83.3% Loss: 0.2070, Epoch 9, Batch 104, CE_loss: 0.17855574190616608, Dice_loss: 0.016288135200738907, Consistency_loss: 0.0010846740333363414\n",
      "[Training] Epoch: 9 [============>  ] 84.1% Loss: 0.2069, Epoch 9, Batch 105, CE_loss: 0.17718829214572906, Dice_loss: 0.01547166146337986, Consistency_loss: 0.001283177174627781\n",
      "[Training] Epoch: 9 [============>  ] 84.9% Loss: 0.2068, Epoch 9, Batch 106, CE_loss: 0.18099577724933624, Dice_loss: 0.015888910740613937, Consistency_loss: 0.0011494567152112722\n",
      "[Training] Epoch: 9 [============>  ] 85.7% Loss: 0.2068, Epoch 9, Batch 107, CE_loss: 0.1845056116580963, Dice_loss: 0.016829945147037506, Consistency_loss: 0.00020587157632689923\n",
      "[Training] Epoch: 9 [============>  ] 86.5% Loss: 0.2066, Epoch 9, Batch 108, CE_loss: 0.17168185114860535, Dice_loss: 0.014960039407014847, Consistency_loss: 0.0011862864485010505\n",
      "[Training] Epoch: 9 [=============> ] 87.3% Loss: 0.2064, Epoch 9, Batch 109, CE_loss: 0.17068518698215485, Dice_loss: 0.014515561051666737, Consistency_loss: 0.0014029222074896097\n",
      "[Training] Epoch: 9 [=============> ] 88.1% Loss: 0.2062, Epoch 9, Batch 110, CE_loss: 0.16887116432189941, Dice_loss: 0.014488082379102707, Consistency_loss: 0.0008747048559598625\n",
      "[Training] Epoch: 9 [=============> ] 88.9% Loss: 0.2060, Epoch 9, Batch 111, CE_loss: 0.16938990354537964, Dice_loss: 0.01467156782746315, Consistency_loss: 0.0002685854851733893\n",
      "[Training] Epoch: 9 [=============> ] 89.7% Loss: 0.2059, Epoch 9, Batch 112, CE_loss: 0.17627277970314026, Dice_loss: 0.0158077385276556, Consistency_loss: 0.0009729680023156106\n",
      "[Training] Epoch: 9 [=============> ] 90.5% Loss: 0.2057, Epoch 9, Batch 113, CE_loss: 0.16684415936470032, Dice_loss: 0.014364718459546566, Consistency_loss: 0.000713310029823333\n",
      "[Training] Epoch: 9 [=============> ] 91.3% Loss: 0.2055, Epoch 9, Batch 114, CE_loss: 0.1659744679927826, Dice_loss: 0.013896109536290169, Consistency_loss: 0.0012214859016239643\n",
      "[Training] Epoch: 9 [=============> ] 92.1% Loss: 0.2054, Epoch 9, Batch 115, CE_loss: 0.18083703517913818, Dice_loss: 0.015798494219779968, Consistency_loss: 0.00139604730065912\n",
      "[Training] Epoch: 9 [=============> ] 92.9% Loss: 0.2055, Epoch 9, Batch 116, CE_loss: 0.1933031678199768, Dice_loss: 0.017329087480902672, Consistency_loss: 0.0010531385196372867\n",
      "[Training] Epoch: 9 [==============>] 93.7% Loss: 0.2054, Epoch 9, Batch 117, CE_loss: 0.17753185331821442, Dice_loss: 0.015210744924843311, Consistency_loss: 0.0003054289554711431\n",
      "[Training] Epoch: 9 [==============>] 94.4% Loss: 0.2052, Epoch 9, Batch 118, CE_loss: 0.17038322985172272, Dice_loss: 0.014374325051903725, Consistency_loss: 0.0006310762837529182\n",
      "[Training] Epoch: 9 [==============>] 95.2% Loss: 0.2050, Epoch 9, Batch 119, CE_loss: 0.17172248661518097, Dice_loss: 0.01397413108497858, Consistency_loss: 0.0007751592784188688\n",
      "[Training] Epoch: 9 [==============>] 96.0% Loss: 0.2049, Epoch 9, Batch 120, CE_loss: 0.17423568665981293, Dice_loss: 0.015051609836518764, Consistency_loss: 0.0009348129970021546\n",
      "[Training] Epoch: 9 [==============>] 96.8% Loss: 0.2049, Epoch 9, Batch 121, CE_loss: 0.19207763671875, Dice_loss: 0.017150022089481354, Consistency_loss: 0.00019179291848558933\n",
      "[Training] Epoch: 9 [==============>] 97.6% Loss: 0.2049, Epoch 9, Batch 122, CE_loss: 0.18107521533966064, Dice_loss: 0.016484303399920464, Consistency_loss: 0.0006428365013562143\n",
      "[Training] Epoch: 9 [==============>] 98.4% Loss: 0.2048, Epoch 9, Batch 123, CE_loss: 0.18132513761520386, Dice_loss: 0.016013553366065025, Consistency_loss: 0.00016953088925220072\n",
      "[Training] Epoch: 9 [==============>] 99.2% Loss: 0.2047, Epoch 9, Batch 124, CE_loss: 0.17379628121852875, Dice_loss: 0.015652500092983246, Consistency_loss: 0.0009616894531063735\n",
      "[Training] Epoch: 9 [DONE]                                 \n",
      "Epoch 9, Batch 125, CE_loss: 0.17011210322380066, Dice_loss: 0.014118705876171589, Consistency_loss: 0.0016309981001541018\n",
      "[Validation] Epoch: 9 [DONE]                                 \n",
      "[Epoch: 9, TrainLoss: 0.2046, TrainDice: 0.0167, ValLoss: 0.2239                                             \n",
      "Number of batches:  126\n",
      "[Training] Epoch: 10 [>              ] 0.8% Loss: 0.1746, Epoch 10, Batch 0, CE_loss: 0.1604427993297577, Dice_loss: 0.013149597682058811, Consistency_loss: 0.0010567940771579742\n",
      "[Training] Epoch: 10 [>              ] 1.6% Loss: 0.1811, Epoch 10, Batch 1, CE_loss: 0.1716359257698059, Dice_loss: 0.014514336362481117, Consistency_loss: 0.001348475692793727\n",
      "[Training] Epoch: 10 [>              ] 2.4% Loss: 0.1790, Epoch 10, Batch 2, CE_loss: 0.16124171018600464, Dice_loss: 0.01292191818356514, Consistency_loss: 0.0006647574482485652\n",
      "[Training] Epoch: 10 [>              ] 3.2% Loss: 0.1797, Epoch 10, Batch 3, CE_loss: 0.16692423820495605, Dice_loss: 0.013927804306149483, Consistency_loss: 0.0008861824753694236\n",
      "[Training] Epoch: 10 [>              ] 4.0% Loss: 0.1808, Epoch 10, Batch 4, CE_loss: 0.17007938027381897, Dice_loss: 0.01430619228631258, Consistency_loss: 0.0009408020414412022\n",
      "[Training] Epoch: 10 [>              ] 4.8% Loss: 0.1839, Epoch 10, Batch 5, CE_loss: 0.18187552690505981, Dice_loss: 0.016719385981559753, Consistency_loss: 0.0004921491490676999\n",
      "[Training] Epoch: 10 [>              ] 5.6% Loss: 0.1857, Epoch 10, Batch 6, CE_loss: 0.18034860491752625, Dice_loss: 0.01628580130636692, Consistency_loss: 0.00012755136413034052\n",
      "[Training] Epoch: 10 [>              ] 6.3% Loss: 0.1851, Epoch 10, Batch 7, CE_loss: 0.16627450287342072, Dice_loss: 0.013462879694998264, Consistency_loss: 0.0007908130064606667\n",
      "[Training] Epoch: 10 [=>             ] 7.1% Loss: 0.1858, Epoch 10, Batch 8, CE_loss: 0.17626552283763885, Dice_loss: 0.01516138855367899, Consistency_loss: 0.00034567920374684036\n",
      "[Training] Epoch: 10 [=>             ] 7.9% Loss: 0.1855, Epoch 10, Batch 9, CE_loss: 0.16763897240161896, Dice_loss: 0.0142290610820055, Consistency_loss: 0.0006441795849241316\n",
      "[Training] Epoch: 10 [=>             ] 8.7% Loss: 0.1853, Epoch 10, Batch 10, CE_loss: 0.16854886710643768, Dice_loss: 0.013951251283288002, Consistency_loss: 0.0007465644157491624\n",
      "[Training] Epoch: 10 [=>             ] 9.5% Loss: 0.1851, Epoch 10, Batch 11, CE_loss: 0.16762402653694153, Dice_loss: 0.01418075431138277, Consistency_loss: 0.000985926715657115\n",
      "[Training] Epoch: 10 [=>             ] 10.3% Loss: 0.1847, Epoch 10, Batch 12, CE_loss: 0.16541315615177155, Dice_loss: 0.014445345848798752, Consistency_loss: 0.0009023017482832074\n",
      "[Training] Epoch: 10 [=>             ] 11.1% Loss: 0.1859, Epoch 10, Batch 13, CE_loss: 0.18485240638256073, Dice_loss: 0.016601158306002617, Consistency_loss: 0.00029091103351674974\n",
      "[Training] Epoch: 10 [=>             ] 11.9% Loss: 0.1862, Epoch 10, Batch 14, CE_loss: 0.17338943481445312, Dice_loss: 0.015159680508077145, Consistency_loss: 0.000537210435140878\n",
      "[Training] Epoch: 10 [=>             ] 12.7% Loss: 0.1868, Epoch 10, Batch 15, CE_loss: 0.17912602424621582, Dice_loss: 0.01645132154226303, Consistency_loss: 0.0007380855968222022\n",
      "[Training] Epoch: 10 [==>            ] 13.5% Loss: 0.1873, Epoch 10, Batch 16, CE_loss: 0.1771857589483261, Dice_loss: 0.016531558707356453, Consistency_loss: 0.001006582286208868\n",
      "[Training] Epoch: 10 [==>            ] 14.3% Loss: 0.1876, Epoch 10, Batch 17, CE_loss: 0.1763605922460556, Dice_loss: 0.016193538904190063, Consistency_loss: 0.0008888463489711285\n",
      "[Training] Epoch: 10 [==>            ] 15.1% Loss: 0.1874, Epoch 10, Batch 18, CE_loss: 0.16921469569206238, Dice_loss: 0.014468877576291561, Consistency_loss: 0.0006881204317323864\n",
      "[Training] Epoch: 10 [==>            ] 15.9% Loss: 0.1872, Epoch 10, Batch 19, CE_loss: 0.16683299839496613, Dice_loss: 0.014444487169384956, Consistency_loss: 0.000994030269794166\n",
      "[Training] Epoch: 10 [==>            ] 16.7% Loss: 0.1873, Epoch 10, Batch 20, CE_loss: 0.17480339109897614, Dice_loss: 0.015208308584988117, Consistency_loss: 0.0007656459929421544\n",
      "[Training] Epoch: 10 [==>            ] 17.5% Loss: 0.1875, Epoch 10, Batch 21, CE_loss: 0.17379535734653473, Dice_loss: 0.015879254788160324, Consistency_loss: 0.0001100382796721533\n",
      "[Training] Epoch: 10 [==>            ] 18.3% Loss: 0.1876, Epoch 10, Batch 22, CE_loss: 0.1754734367132187, Dice_loss: 0.015989841893315315, Consistency_loss: 0.00019633684132713825\n",
      "[Training] Epoch: 10 [==>            ] 19.0% Loss: 0.1877, Epoch 10, Batch 23, CE_loss: 0.17500720918178558, Dice_loss: 0.01518351212143898, Consistency_loss: 9.618238254915923e-05\n",
      "[Training] Epoch: 10 [==>            ] 19.8% Loss: 0.1876, Epoch 10, Batch 24, CE_loss: 0.16782809793949127, Dice_loss: 0.014600127004086971, Consistency_loss: 0.0008418593788519502\n",
      "[Training] Epoch: 10 [===>           ] 20.6% Loss: 0.1878, Epoch 10, Batch 25, CE_loss: 0.17654715478420258, Dice_loss: 0.015920892357826233, Consistency_loss: 0.0009867468615993857\n",
      "[Training] Epoch: 10 [===>           ] 21.4% Loss: 0.1879, Epoch 10, Batch 26, CE_loss: 0.17408882081508636, Dice_loss: 0.01529089454561472, Consistency_loss: 0.00028576096519827843\n",
      "[Training] Epoch: 10 [===>           ] 22.2% Loss: 0.1879, Epoch 10, Batch 27, CE_loss: 0.17072859406471252, Dice_loss: 0.015267214737832546, Consistency_loss: 0.0015224477974697948\n",
      "[Training] Epoch: 10 [===>           ] 23.0% Loss: 0.1879, Epoch 10, Batch 28, CE_loss: 0.17425769567489624, Dice_loss: 0.01517257746309042, Consistency_loss: 0.0008417122880928218\n",
      "[Training] Epoch: 10 [===>           ] 23.8% Loss: 0.1876, Epoch 10, Batch 29, CE_loss: 0.1631704717874527, Dice_loss: 0.0139636704698205, Consistency_loss: 0.00015871399955358356\n",
      "[Training] Epoch: 10 [===>           ] 24.6% Loss: 0.1873, Epoch 10, Batch 30, CE_loss: 0.1636948585510254, Dice_loss: 0.014228122308850288, Consistency_loss: 0.001171940821222961\n",
      "[Training] Epoch: 10 [===>           ] 25.4% Loss: 0.1875, Epoch 10, Batch 31, CE_loss: 0.17616964876651764, Dice_loss: 0.015203315764665604, Consistency_loss: 0.0007518014754168689\n",
      "[Training] Epoch: 10 [===>           ] 26.2% Loss: 0.1875, Epoch 10, Batch 32, CE_loss: 0.17183920741081238, Dice_loss: 0.015122482553124428, Consistency_loss: 0.001078024273738265\n",
      "[Training] Epoch: 10 [====>          ] 27.0% Loss: 0.1869, Epoch 10, Batch 33, CE_loss: 0.15409183502197266, Dice_loss: 0.012108081951737404, Consistency_loss: 0.0007831736584194005\n",
      "[Training] Epoch: 10 [====>          ] 27.8% Loss: 0.1871, Epoch 10, Batch 34, CE_loss: 0.179374098777771, Dice_loss: 0.01547317672520876, Consistency_loss: 0.0010257924441248178\n",
      "[Training] Epoch: 10 [====>          ] 28.6% Loss: 0.1869, Epoch 10, Batch 35, CE_loss: 0.16381250321865082, Dice_loss: 0.013176710344851017, Consistency_loss: 0.0007841382175683975\n",
      "[Training] Epoch: 10 [====>          ] 29.4% Loss: 0.1868, Epoch 10, Batch 36, CE_loss: 0.16897302865982056, Dice_loss: 0.014279504306614399, Consistency_loss: 0.0006723745609633625\n",
      "[Training] Epoch: 10 [====>          ] 30.2% Loss: 0.1867, Epoch 10, Batch 37, CE_loss: 0.1684531569480896, Dice_loss: 0.014166485518217087, Consistency_loss: 0.0008163374150171876\n",
      "[Training] Epoch: 10 [====>          ] 31.0% Loss: 0.1865, Epoch 10, Batch 38, CE_loss: 0.1637410670518875, Dice_loss: 0.013585626147687435, Consistency_loss: 0.0010392069816589355\n",
      "[Training] Epoch: 10 [====>          ] 31.7% Loss: 0.1867, Epoch 10, Batch 39, CE_loss: 0.17814090847969055, Dice_loss: 0.01565961353480816, Consistency_loss: 0.001057239598594606\n",
      "[Training] Epoch: 10 [====>          ] 32.5% Loss: 0.1868, Epoch 10, Batch 40, CE_loss: 0.17357228696346283, Dice_loss: 0.014494206756353378, Consistency_loss: 0.0009441198781132698\n",
      "[Training] Epoch: 10 [=====>         ] 33.3% Loss: 0.1869, Epoch 10, Batch 41, CE_loss: 0.17476271092891693, Dice_loss: 0.015375317074358463, Consistency_loss: 0.0006455056718550622\n",
      "[Training] Epoch: 10 [=====>         ] 34.1% Loss: 0.1866, Epoch 10, Batch 42, CE_loss: 0.15995481610298157, Dice_loss: 0.013231905177235603, Consistency_loss: 0.0008810536819510162\n",
      "[Training] Epoch: 10 [=====>         ] 34.9% Loss: 0.1864, Epoch 10, Batch 43, CE_loss: 0.16689512133598328, Dice_loss: 0.014085393399000168, Consistency_loss: 0.00023375501041300595\n",
      "[Training] Epoch: 10 [=====>         ] 35.7% Loss: 0.1864, Epoch 10, Batch 44, CE_loss: 0.16791418194770813, Dice_loss: 0.014212346635758877, Consistency_loss: 0.0010333397658541799\n",
      "[Training] Epoch: 10 [=====>         ] 36.5% Loss: 0.1862, Epoch 10, Batch 45, CE_loss: 0.16290263831615448, Dice_loss: 0.014087592251598835, Consistency_loss: 0.0007074598106555641\n",
      "[Training] Epoch: 10 [=====>         ] 37.3% Loss: 0.1862, Epoch 10, Batch 46, CE_loss: 0.17049221694469452, Dice_loss: 0.015169770456850529, Consistency_loss: 0.0007553021423518658\n",
      "[Training] Epoch: 10 [=====>         ] 38.1% Loss: 0.1861, Epoch 10, Batch 47, CE_loss: 0.1667966991662979, Dice_loss: 0.01496629323810339, Consistency_loss: 0.0008558369590900838\n",
      "[Training] Epoch: 10 [=====>         ] 38.9% Loss: 0.1859, Epoch 10, Batch 48, CE_loss: 0.16064618527889252, Dice_loss: 0.013528048060834408, Consistency_loss: 0.001812572474591434\n",
      "[Training] Epoch: 10 [=====>         ] 39.7% Loss: 0.1861, Epoch 10, Batch 49, CE_loss: 0.1804129034280777, Dice_loss: 0.016524575650691986, Consistency_loss: 0.0010939413914456964\n",
      "[Training] Epoch: 10 [======>        ] 40.5% Loss: 0.1861, Epoch 10, Batch 50, CE_loss: 0.1703689694404602, Dice_loss: 0.015240379609167576, Consistency_loss: 0.0008781876531429589\n",
      "[Training] Epoch: 10 [======>        ] 41.3% Loss: 0.1859, Epoch 10, Batch 51, CE_loss: 0.16015173494815826, Dice_loss: 0.013385890983045101, Consistency_loss: 0.0013410198735073209\n",
      "[Training] Epoch: 10 [======>        ] 42.1% Loss: 0.1858, Epoch 10, Batch 52, CE_loss: 0.16522274911403656, Dice_loss: 0.014200830832123756, Consistency_loss: 0.0006099367165006697\n",
      "[Training] Epoch: 10 [======>        ] 42.9% Loss: 0.1857, Epoch 10, Batch 53, CE_loss: 0.16254079341888428, Dice_loss: 0.013706405647099018, Consistency_loss: 0.0007817390724085271\n",
      "[Training] Epoch: 10 [======>        ] 43.7% Loss: 0.1856, Epoch 10, Batch 54, CE_loss: 0.16628055274486542, Dice_loss: 0.014278378337621689, Consistency_loss: 0.0009162177448160946\n",
      "[Training] Epoch: 10 [======>        ] 44.4% Loss: 0.1854, Epoch 10, Batch 55, CE_loss: 0.16096176207065582, Dice_loss: 0.013458856381475925, Consistency_loss: 0.0007329931831918657\n",
      "[Training] Epoch: 10 [======>        ] 45.2% Loss: 0.1853, Epoch 10, Batch 56, CE_loss: 0.1628039926290512, Dice_loss: 0.013651201501488686, Consistency_loss: 0.0008461961406283081\n",
      "[Training] Epoch: 10 [======>        ] 46.0% Loss: 0.1851, Epoch 10, Batch 57, CE_loss: 0.161604106426239, Dice_loss: 0.013426459394395351, Consistency_loss: 0.0009016291587613523\n",
      "[Training] Epoch: 10 [=======>       ] 46.8% Loss: 0.1849, Epoch 10, Batch 58, CE_loss: 0.16013221442699432, Dice_loss: 0.012922392226755619, Consistency_loss: 0.0008671989780850708\n",
      "[Training] Epoch: 10 [=======>       ] 47.6% Loss: 0.1850, Epoch 10, Batch 59, CE_loss: 0.17261095345020294, Dice_loss: 0.015117962844669819, Consistency_loss: 0.0008779082563705742\n",
      "[Training] Epoch: 10 [=======>       ] 48.4% Loss: 0.1847, Epoch 10, Batch 60, CE_loss: 0.15470746159553528, Dice_loss: 0.01269561517983675, Consistency_loss: 9.274677722714841e-05\n",
      "[Training] Epoch: 10 [=======>       ] 49.2% Loss: 0.1848, Epoch 10, Batch 61, CE_loss: 0.1734379380941391, Dice_loss: 0.01507785078138113, Consistency_loss: 0.0007852408452890813\n",
      "[Training] Epoch: 10 [=======>       ] 50.0% Loss: 0.1846, Epoch 10, Batch 62, CE_loss: 0.16252484917640686, Dice_loss: 0.01383910421282053, Consistency_loss: 0.00017184072930831462\n",
      "[Training] Epoch: 10 [=======>       ] 50.8% Loss: 0.1844, Epoch 10, Batch 63, CE_loss: 0.1559232920408249, Dice_loss: 0.012349910102784634, Consistency_loss: 0.0010213837958872318\n",
      "[Training] Epoch: 10 [=======>       ] 51.6% Loss: 0.1843, Epoch 10, Batch 64, CE_loss: 0.16197609901428223, Dice_loss: 0.013948158361017704, Consistency_loss: 0.0013444566866382957\n",
      "[Training] Epoch: 10 [=======>       ] 52.4% Loss: 0.1842, Epoch 10, Batch 65, CE_loss: 0.16665564477443695, Dice_loss: 0.014443669468164444, Consistency_loss: 0.0013611881295219064\n",
      "[Training] Epoch: 10 [=======>       ] 53.2% Loss: 0.1841, Epoch 10, Batch 66, CE_loss: 0.16252824664115906, Dice_loss: 0.0137536795809865, Consistency_loss: 0.0007788991206325591\n",
      "[Training] Epoch: 10 [========>      ] 54.0% Loss: 0.1841, Epoch 10, Batch 67, CE_loss: 0.1642908751964569, Dice_loss: 0.013987917453050613, Consistency_loss: 0.00037395680556073785\n",
      "[Training] Epoch: 10 [========>      ] 54.8% Loss: 0.1840, Epoch 10, Batch 68, CE_loss: 0.16520068049430847, Dice_loss: 0.014440991915762424, Consistency_loss: 0.0007967518758960068\n",
      "[Training] Epoch: 10 [========>      ] 55.6% Loss: 0.1840, Epoch 10, Batch 69, CE_loss: 0.16676396131515503, Dice_loss: 0.014667915180325508, Consistency_loss: 0.000855675374623388\n",
      "[Training] Epoch: 10 [========>      ] 56.3% Loss: 0.1841, Epoch 10, Batch 70, CE_loss: 0.17409607768058777, Dice_loss: 0.015550446696579456, Consistency_loss: 0.0001441243221051991\n",
      "[Training] Epoch: 10 [========>      ] 57.1% Loss: 0.1840, Epoch 10, Batch 71, CE_loss: 0.1624266803264618, Dice_loss: 0.014223258942365646, Consistency_loss: 0.0007499670027755201\n",
      "[Training] Epoch: 10 [========>      ] 57.9% Loss: 0.1839, Epoch 10, Batch 72, CE_loss: 0.16208243370056152, Dice_loss: 0.013490313664078712, Consistency_loss: 0.0007474127341993153\n",
      "[Training] Epoch: 10 [========>      ] 58.7% Loss: 0.1836, Epoch 10, Batch 73, CE_loss: 0.14997048676013947, Dice_loss: 0.012131404131650925, Consistency_loss: 0.000998698640614748\n",
      "[Training] Epoch: 10 [========>      ] 59.5% Loss: 0.1832, Epoch 10, Batch 74, CE_loss: 0.1441752314567566, Dice_loss: 0.011397949419915676, Consistency_loss: 0.0007643554708920419\n",
      "[Training] Epoch: 10 [=========>     ] 60.3% Loss: 0.1831, Epoch 10, Batch 75, CE_loss: 0.1630783975124359, Dice_loss: 0.01324115414172411, Consistency_loss: 0.0010060721542686224\n",
      "[Training] Epoch: 10 [=========>     ] 61.1% Loss: 0.1829, Epoch 10, Batch 76, CE_loss: 0.15115869045257568, Dice_loss: 0.011875190772116184, Consistency_loss: 0.0011328510008752346\n",
      "[Training] Epoch: 10 [=========>     ] 61.9% Loss: 0.1830, Epoch 10, Batch 77, CE_loss: 0.17145280539989471, Dice_loss: 0.015151629224419594, Consistency_loss: 0.0012253738241270185\n",
      "[Training] Epoch: 10 [=========>     ] 62.7% Loss: 0.1829, Epoch 10, Batch 78, CE_loss: 0.16242341697216034, Dice_loss: 0.01378092635422945, Consistency_loss: 0.0008395792101509869\n",
      "[Training] Epoch: 10 [=========>     ] 63.5% Loss: 0.1827, Epoch 10, Batch 79, CE_loss: 0.1567218005657196, Dice_loss: 0.013346167281270027, Consistency_loss: 0.0005694099236279726\n",
      "[Training] Epoch: 10 [=========>     ] 64.3% Loss: 0.1826, Epoch 10, Batch 80, CE_loss: 0.15831974148750305, Dice_loss: 0.013482374139130116, Consistency_loss: 0.000798543740529567\n",
      "[Training] Epoch: 10 [=========>     ] 65.1% Loss: 0.1825, Epoch 10, Batch 81, CE_loss: 0.1576734334230423, Dice_loss: 0.01295474823564291, Consistency_loss: 0.0009956142166629434\n",
      "[Training] Epoch: 10 [=========>     ] 65.9% Loss: 0.1823, Epoch 10, Batch 82, CE_loss: 0.15602898597717285, Dice_loss: 0.012943384237587452, Consistency_loss: 0.0009734136401675642\n",
      "[Training] Epoch: 10 [==========>    ] 66.7% Loss: 0.1822, Epoch 10, Batch 83, CE_loss: 0.16128060221672058, Dice_loss: 0.013842398300766945, Consistency_loss: 0.0006037011626176536\n",
      "[Training] Epoch: 10 [==========>    ] 67.5% Loss: 0.1822, Epoch 10, Batch 84, CE_loss: 0.16603615880012512, Dice_loss: 0.01439697202295065, Consistency_loss: 0.00023400336795020849\n",
      "[Training] Epoch: 10 [==========>    ] 68.3% Loss: 0.1821, Epoch 10, Batch 85, CE_loss: 0.15813881158828735, Dice_loss: 0.013690111227333546, Consistency_loss: 0.00032121562981046736\n",
      "[Training] Epoch: 10 [==========>    ] 69.0% Loss: 0.1819, Epoch 10, Batch 86, CE_loss: 0.15475846827030182, Dice_loss: 0.012432334013283253, Consistency_loss: 0.0011745168594643474\n",
      "[Training] Epoch: 10 [==========>    ] 69.8% Loss: 0.1819, Epoch 10, Batch 87, CE_loss: 0.16105876863002777, Dice_loss: 0.01391046866774559, Consistency_loss: 0.0007601153338328004\n",
      "[Training] Epoch: 10 [==========>    ] 70.6% Loss: 0.1819, Epoch 10, Batch 88, CE_loss: 0.16513016819953918, Dice_loss: 0.01405452098697424, Consistency_loss: 0.00019039578910451382\n",
      "[Training] Epoch: 10 [==========>    ] 71.4% Loss: 0.1818, Epoch 10, Batch 89, CE_loss: 0.15975525975227356, Dice_loss: 0.013664898462593555, Consistency_loss: 0.00017939812096301466\n",
      "[Training] Epoch: 10 [==========>    ] 72.2% Loss: 0.1817, Epoch 10, Batch 90, CE_loss: 0.1618916094303131, Dice_loss: 0.013574276119470596, Consistency_loss: 0.0012217164039611816\n",
      "[Training] Epoch: 10 [==========>    ] 73.0% Loss: 0.1816, Epoch 10, Batch 91, CE_loss: 0.15567336976528168, Dice_loss: 0.012907514348626137, Consistency_loss: 0.00021809393365401775\n",
      "[Training] Epoch: 10 [===========>   ] 73.8% Loss: 0.1813, Epoch 10, Batch 92, CE_loss: 0.14876340329647064, Dice_loss: 0.011808796785771847, Consistency_loss: 0.0008587419288232923\n",
      "[Training] Epoch: 10 [===========>   ] 74.6% Loss: 0.1812, Epoch 10, Batch 93, CE_loss: 0.15864910185337067, Dice_loss: 0.013458024710416794, Consistency_loss: 0.00011735899897757918\n",
      "[Training] Epoch: 10 [===========>   ] 75.4% Loss: 0.1811, Epoch 10, Batch 94, CE_loss: 0.1536821871995926, Dice_loss: 0.012711306102573872, Consistency_loss: 0.0008565356838516891\n",
      "[Training] Epoch: 10 [===========>   ] 76.2% Loss: 0.1810, Epoch 10, Batch 95, CE_loss: 0.15465375781059265, Dice_loss: 0.012701851315796375, Consistency_loss: 0.0008340342319570482\n",
      "[Training] Epoch: 10 [===========>   ] 77.0% Loss: 0.1810, Epoch 10, Batch 96, CE_loss: 0.17295444011688232, Dice_loss: 0.014535834081470966, Consistency_loss: 0.0008565852767787874\n",
      "[Training] Epoch: 10 [===========>   ] 77.8% Loss: 0.1811, Epoch 10, Batch 97, CE_loss: 0.16785746812820435, Dice_loss: 0.014623059891164303, Consistency_loss: 0.0005632100510410964\n",
      "[Training] Epoch: 10 [===========>   ] 78.6% Loss: 0.1810, Epoch 10, Batch 98, CE_loss: 0.16274622082710266, Dice_loss: 0.01355118677020073, Consistency_loss: 0.0006567466771230102\n",
      "[Training] Epoch: 10 [===========>   ] 79.4% Loss: 0.1809, Epoch 10, Batch 99, CE_loss: 0.15367703139781952, Dice_loss: 0.012952369637787342, Consistency_loss: 0.0009404293377883732\n",
      "[Training] Epoch: 10 [============>  ] 80.2% Loss: 0.1810, Epoch 10, Batch 100, CE_loss: 0.17691853642463684, Dice_loss: 0.015988104045391083, Consistency_loss: 0.0007976596243679523\n",
      "[Training] Epoch: 10 [============>  ] 81.0% Loss: 0.1809, Epoch 10, Batch 101, CE_loss: 0.1523839235305786, Dice_loss: 0.012704279273748398, Consistency_loss: 0.0009713849285617471\n",
      "[Training] Epoch: 10 [============>  ] 81.7% Loss: 0.1807, Epoch 10, Batch 102, CE_loss: 0.15246684849262238, Dice_loss: 0.01290073711425066, Consistency_loss: 0.0011485641589388251\n",
      "[Training] Epoch: 10 [============>  ] 82.5% Loss: 0.1808, Epoch 10, Batch 103, CE_loss: 0.16894963383674622, Dice_loss: 0.014664915390312672, Consistency_loss: 0.0013833221746608615\n",
      "[Training] Epoch: 10 [============>  ] 83.3% Loss: 0.1807, Epoch 10, Batch 104, CE_loss: 0.16093428432941437, Dice_loss: 0.014227134175598621, Consistency_loss: 0.0008285758085548878\n",
      "[Training] Epoch: 10 [============>  ] 84.1% Loss: 0.1807, Epoch 10, Batch 105, CE_loss: 0.16581512987613678, Dice_loss: 0.014902014285326004, Consistency_loss: 0.00021741705131717026\n",
      "[Training] Epoch: 10 [============>  ] 84.9% Loss: 0.1806, Epoch 10, Batch 106, CE_loss: 0.15282556414604187, Dice_loss: 0.012824133969843388, Consistency_loss: 0.0009723302209749818\n",
      "[Training] Epoch: 10 [============>  ] 85.7% Loss: 0.1805, Epoch 10, Batch 107, CE_loss: 0.15936754643917084, Dice_loss: 0.013854620046913624, Consistency_loss: 0.0016098683699965477\n",
      "[Training] Epoch: 10 [============>  ] 86.5% Loss: 0.1806, Epoch 10, Batch 108, CE_loss: 0.16742201149463654, Dice_loss: 0.014997218735516071, Consistency_loss: 0.00022387155331671238\n",
      "[Training] Epoch: 10 [=============> ] 87.3% Loss: 0.1807, Epoch 10, Batch 109, CE_loss: 0.17564359307289124, Dice_loss: 0.015892572700977325, Consistency_loss: 0.00028103269869461656\n",
      "[Training] Epoch: 10 [=============> ] 88.1% Loss: 0.1804, Epoch 10, Batch 110, CE_loss: 0.1440432071685791, Dice_loss: 0.011467319913208485, Consistency_loss: 0.0009610294364392757\n",
      "[Training] Epoch: 10 [=============> ] 88.9% Loss: 0.1803, Epoch 10, Batch 111, CE_loss: 0.15094666182994843, Dice_loss: 0.01257318165153265, Consistency_loss: 0.00017017580103129148\n",
      "[Training] Epoch: 10 [=============> ] 89.7% Loss: 0.1801, Epoch 10, Batch 112, CE_loss: 0.14740905165672302, Dice_loss: 0.011846928857266903, Consistency_loss: 0.0006782390992157161\n",
      "[Training] Epoch: 10 [=============> ] 90.5% Loss: 0.1800, Epoch 10, Batch 113, CE_loss: 0.15616433322429657, Dice_loss: 0.013826032169163227, Consistency_loss: 0.0009491839446127415\n",
      "[Training] Epoch: 10 [=============> ] 91.3% Loss: 0.1800, Epoch 10, Batch 114, CE_loss: 0.15694710612297058, Dice_loss: 0.013790211640298367, Consistency_loss: 0.0013822114560753107\n",
      "[Training] Epoch: 10 [=============> ] 92.1% Loss: 0.1799, Epoch 10, Batch 115, CE_loss: 0.15426747500896454, Dice_loss: 0.01222823653370142, Consistency_loss: 0.001103831804357469\n",
      "[Training] Epoch: 10 [=============> ] 92.9% Loss: 0.1797, Epoch 10, Batch 116, CE_loss: 0.1497427374124527, Dice_loss: 0.012167842127382755, Consistency_loss: 0.001202601008117199\n",
      "[Training] Epoch: 10 [==============>] 93.7% Loss: 0.1797, Epoch 10, Batch 117, CE_loss: 0.16748788952827454, Dice_loss: 0.014518793672323227, Consistency_loss: 0.0013557770289480686\n",
      "[Training] Epoch: 10 [==============>] 94.4% Loss: 0.1797, Epoch 10, Batch 118, CE_loss: 0.1563129723072052, Dice_loss: 0.01319627184420824, Consistency_loss: 0.00041523590334691107\n",
      "[Training] Epoch: 10 [==============>] 95.2% Loss: 0.1796, Epoch 10, Batch 119, CE_loss: 0.1569681018590927, Dice_loss: 0.013562541455030441, Consistency_loss: 0.0008397395140491426\n",
      "[Training] Epoch: 10 [==============>] 96.0% Loss: 0.1795, Epoch 10, Batch 120, CE_loss: 0.15130971372127533, Dice_loss: 0.012560856528580189, Consistency_loss: 0.000986483646556735\n",
      "[Training] Epoch: 10 [==============>] 96.8% Loss: 0.1793, Epoch 10, Batch 121, CE_loss: 0.14776436984539032, Dice_loss: 0.011989344842731953, Consistency_loss: 0.00047233770601451397\n",
      "[Training] Epoch: 10 [==============>] 97.6% Loss: 0.1791, Epoch 10, Batch 122, CE_loss: 0.1441376954317093, Dice_loss: 0.011174606159329414, Consistency_loss: 0.0005507334135472775\n",
      "[Training] Epoch: 10 [==============>] 98.4% Loss: 0.1790, Epoch 10, Batch 123, CE_loss: 0.1536070853471756, Dice_loss: 0.013230966404080391, Consistency_loss: 0.0008762767538428307\n",
      "[Training] Epoch: 10 [==============>] 99.2% Loss: 0.1790, Epoch 10, Batch 124, CE_loss: 0.16466599702835083, Dice_loss: 0.014351562596857548, Consistency_loss: 0.00014528463361784816\n",
      "[Training] Epoch: 10 [DONE]                                 \n",
      "Epoch 10, Batch 125, CE_loss: 0.14485381543636322, Dice_loss: 0.011407341808080673, Consistency_loss: 0.00014727433153893799\n",
      "[Validation] Epoch: 10 [DONE]                                 \n",
      "[Epoch: 10, TrainLoss: 0.1789, TrainDice: 0.0140, ValLoss: 0.1999                                            \n",
      "Number of batches:  126\n",
      "[Training] Epoch: 11 [>              ] 0.8% Loss: 0.1721, Epoch 11, Batch 0, CE_loss: 0.1580333709716797, Dice_loss: 0.013444457203149796, Consistency_loss: 0.0006359016988426447\n",
      "[Training] Epoch: 11 [>              ] 1.6% Loss: 0.1651, Epoch 11, Batch 1, CE_loss: 0.14568468928337097, Dice_loss: 0.012100943364202976, Consistency_loss: 0.00021507698693312705\n",
      "[Training] Epoch: 11 [>              ] 2.4% Loss: 0.1671, Epoch 11, Batch 2, CE_loss: 0.15691347420215607, Dice_loss: 0.013691175729036331, Consistency_loss: 0.0005946008022874594\n",
      "[Training] Epoch: 11 [>              ] 3.2% Loss: 0.1698, Epoch 11, Batch 3, CE_loss: 0.1645243912935257, Dice_loss: 0.013149253092706203, Consistency_loss: 8.377576159546152e-05\n",
      "[Training] Epoch: 11 [>              ] 4.0% Loss: 0.1721, Epoch 11, Batch 4, CE_loss: 0.16655102372169495, Dice_loss: 0.014944602735340595, Consistency_loss: 0.00014478660887107253\n",
      "[Training] Epoch: 11 [>              ] 4.8% Loss: 0.1718, Epoch 11, Batch 5, CE_loss: 0.1559569090604782, Dice_loss: 0.01343406829982996, Consistency_loss: 0.00044811025145463645\n",
      "[Training] Epoch: 11 [>              ] 5.6% Loss: 0.1731, Epoch 11, Batch 6, CE_loss: 0.1655564159154892, Dice_loss: 0.014559066854417324, Consistency_loss: 0.0006913962424732745\n",
      "[Training] Epoch: 11 [>              ] 6.3% Loss: 0.1704, Epoch 11, Batch 7, CE_loss: 0.1402599960565567, Dice_loss: 0.01071056630462408, Consistency_loss: 0.0007748233038000762\n",
      "[Training] Epoch: 11 [=>             ] 7.1% Loss: 0.1694, Epoch 11, Batch 8, CE_loss: 0.14876116812229156, Dice_loss: 0.012537883594632149, Consistency_loss: 0.00041376519948244095\n",
      "[Training] Epoch: 11 [=>             ] 7.9% Loss: 0.1705, Epoch 11, Batch 9, CE_loss: 0.16533082723617554, Dice_loss: 0.014392510987818241, Consistency_loss: 0.000498006702400744\n",
      "[Training] Epoch: 11 [=>             ] 8.7% Loss: 0.1700, Epoch 11, Batch 10, CE_loss: 0.15146256983280182, Dice_loss: 0.012856284156441689, Consistency_loss: 0.0008523014257661998\n",
      "[Training] Epoch: 11 [=>             ] 9.5% Loss: 0.1708, Epoch 11, Batch 11, CE_loss: 0.16455793380737305, Dice_loss: 0.014527926221489906, Consistency_loss: 0.00021043371816631407\n",
      "[Training] Epoch: 11 [=>             ] 10.3% Loss: 0.1694, Epoch 11, Batch 12, CE_loss: 0.14154639840126038, Dice_loss: 0.010350917465984821, Consistency_loss: 0.0008468360756523907\n",
      "[Training] Epoch: 11 [=>             ] 11.1% Loss: 0.1679, Epoch 11, Batch 13, CE_loss: 0.13754723966121674, Dice_loss: 0.010636711493134499, Consistency_loss: 0.0007793765980750322\n",
      "[Training] Epoch: 11 [=>             ] 11.9% Loss: 0.1682, Epoch 11, Batch 14, CE_loss: 0.15770378708839417, Dice_loss: 0.013539765030145645, Consistency_loss: 0.00012048685312038288\n",
      "[Training] Epoch: 11 [=>             ] 12.7% Loss: 0.1681, Epoch 11, Batch 15, CE_loss: 0.15362827479839325, Dice_loss: 0.013098273426294327, Consistency_loss: 0.00024671267601661384\n",
      "[Training] Epoch: 11 [==>            ] 13.5% Loss: 0.1675, Epoch 11, Batch 16, CE_loss: 0.14475323259830475, Dice_loss: 0.011683103628456593, Consistency_loss: 0.001032202853821218\n",
      "[Training] Epoch: 11 [==>            ] 14.3% Loss: 0.1673, Epoch 11, Batch 17, CE_loss: 0.1507430225610733, Dice_loss: 0.013011204078793526, Consistency_loss: 0.0006256106426008046\n",
      "[Training] Epoch: 11 [==>            ] 15.1% Loss: 0.1671, Epoch 11, Batch 18, CE_loss: 0.1506044715642929, Dice_loss: 0.012963559478521347, Consistency_loss: 0.0002372162853134796\n",
      "[Training] Epoch: 11 [==>            ] 15.9% Loss: 0.1669, Epoch 11, Batch 19, CE_loss: 0.14907613396644592, Dice_loss: 0.012514744885265827, Consistency_loss: 0.0007709385827183723\n",
      "[Training] Epoch: 11 [==>            ] 16.7% Loss: 0.1665, Epoch 11, Batch 20, CE_loss: 0.14610321819782257, Dice_loss: 0.011893858201801777, Consistency_loss: 0.000951474707107991\n",
      "[Training] Epoch: 11 [==>            ] 17.5% Loss: 0.1668, Epoch 11, Batch 21, CE_loss: 0.15742288529872894, Dice_loss: 0.01384448166936636, Consistency_loss: 0.0008472615154460073\n",
      "[Training] Epoch: 11 [==>            ] 18.3% Loss: 0.1667, Epoch 11, Batch 22, CE_loss: 0.1519034057855606, Dice_loss: 0.013277770951390266, Consistency_loss: 0.0007729501812718809\n",
      "[Training] Epoch: 11 [==>            ] 19.0% Loss: 0.1668, Epoch 11, Batch 23, CE_loss: 0.15344439446926117, Dice_loss: 0.01313820667564869, Consistency_loss: 0.0009094054694287479\n",
      "[Training] Epoch: 11 [==>            ] 19.8% Loss: 0.1666, Epoch 11, Batch 24, CE_loss: 0.15001581609249115, Dice_loss: 0.012837079353630543, Consistency_loss: 0.0009686564444564283\n",
      "[Training] Epoch: 11 [===>           ] 20.6% Loss: 0.1675, Epoch 11, Batch 25, CE_loss: 0.17164482176303864, Dice_loss: 0.015386836603283882, Consistency_loss: 0.0009303438710048795\n",
      "[Training] Epoch: 11 [===>           ] 21.4% Loss: 0.1673, Epoch 11, Batch 26, CE_loss: 0.14824452996253967, Dice_loss: 0.012718790210783482, Consistency_loss: 0.001093876431696117\n",
      "[Training] Epoch: 11 [===>           ] 22.2% Loss: 0.1677, Epoch 11, Batch 27, CE_loss: 0.1633995622396469, Dice_loss: 0.014739619567990303, Consistency_loss: 0.0011498049134388566\n",
      "[Training] Epoch: 11 [===>           ] 23.0% Loss: 0.1672, Epoch 11, Batch 28, CE_loss: 0.14124733209609985, Dice_loss: 0.011697542853653431, Consistency_loss: 0.0009192040306515992\n",
      "[Training] Epoch: 11 [===>           ] 23.8% Loss: 0.1668, Epoch 11, Batch 29, CE_loss: 0.14274227619171143, Dice_loss: 0.011931945569813251, Consistency_loss: 0.0007560376543551683\n",
      "[Training] Epoch: 11 [===>           ] 24.6% Loss: 0.1670, Epoch 11, Batch 30, CE_loss: 0.15903712809085846, Dice_loss: 0.014149846509099007, Consistency_loss: 0.00020438361389096826\n",
      "[Training] Epoch: 11 [===>           ] 25.4% Loss: 0.1666, Epoch 11, Batch 31, CE_loss: 0.1412440836429596, Dice_loss: 0.010923519730567932, Consistency_loss: 0.00021467148326337337\n",
      "[Training] Epoch: 11 [===>           ] 26.2% Loss: 0.1670, Epoch 11, Batch 32, CE_loss: 0.1646021604537964, Dice_loss: 0.014479820616543293, Consistency_loss: 0.0001840194163378328\n",
      "[Training] Epoch: 11 [====>          ] 27.0% Loss: 0.1671, Epoch 11, Batch 33, CE_loss: 0.1559385508298874, Dice_loss: 0.013493295758962631, Consistency_loss: 0.0008263755589723587\n",
      "[Training] Epoch: 11 [====>          ] 27.8% Loss: 0.1670, Epoch 11, Batch 34, CE_loss: 0.1529383808374405, Dice_loss: 0.012934631668031216, Consistency_loss: 0.0007819854654371738\n",
      "[Training] Epoch: 11 [====>          ] 28.6% Loss: 0.1669, Epoch 11, Batch 35, CE_loss: 0.1495506465435028, Dice_loss: 0.01219748891890049, Consistency_loss: 0.001261210418306291\n",
      "[Training] Epoch: 11 [====>          ] 29.4% Loss: 0.1668, Epoch 11, Batch 36, CE_loss: 0.14834193885326385, Dice_loss: 0.012442585080862045, Consistency_loss: 0.0005016840877942741\n",
      "[Training] Epoch: 11 [====>          ] 30.2% Loss: 0.1665, Epoch 11, Batch 37, CE_loss: 0.14203155040740967, Dice_loss: 0.011305242776870728, Consistency_loss: 0.0011003542458638549\n",
      "[Training] Epoch: 11 [====>          ] 31.0% Loss: 0.1660, Epoch 11, Batch 38, CE_loss: 0.13789799809455872, Dice_loss: 0.010921512730419636, Consistency_loss: 0.0011686014477163553\n",
      "[Training] Epoch: 11 [====>          ] 31.7% Loss: 0.1658, Epoch 11, Batch 39, CE_loss: 0.1451220065355301, Dice_loss: 0.012031924910843372, Consistency_loss: 0.00016979913925752044\n",
      "[Training] Epoch: 11 [====>          ] 32.5% Loss: 0.1657, Epoch 11, Batch 40, CE_loss: 0.1476801484823227, Dice_loss: 0.012355448678135872, Consistency_loss: 0.0010187848238274455\n",
      "[Training] Epoch: 11 [=====>         ] 33.3% Loss: 0.1655, Epoch 11, Batch 41, CE_loss: 0.14350494742393494, Dice_loss: 0.011708298698067665, Consistency_loss: 0.0011330613633617759\n",
      "[Training] Epoch: 11 [=====>         ] 34.1% Loss: 0.1655, Epoch 11, Batch 42, CE_loss: 0.1512477993965149, Dice_loss: 0.012876981869339943, Consistency_loss: 0.000551324978005141\n",
      "[Training] Epoch: 11 [=====>         ] 34.9% Loss: 0.1658, Epoch 11, Batch 43, CE_loss: 0.16525782644748688, Dice_loss: 0.01487679686397314, Consistency_loss: 0.0009776140796020627\n",
      "[Training] Epoch: 11 [=====>         ] 35.7% Loss: 0.1657, Epoch 11, Batch 44, CE_loss: 0.1463804543018341, Dice_loss: 0.012487780302762985, Consistency_loss: 0.0011285619111731648\n",
      "[Training] Epoch: 11 [=====>         ] 36.5% Loss: 0.1659, Epoch 11, Batch 45, CE_loss: 0.16119280457496643, Dice_loss: 0.014270219951868057, Consistency_loss: 0.0007561204838566482\n",
      "[Training] Epoch: 11 [=====>         ] 37.3% Loss: 0.1656, Epoch 11, Batch 46, CE_loss: 0.13904017210006714, Dice_loss: 0.011120112612843513, Consistency_loss: 0.0007433832506649196\n",
      "[Training] Epoch: 11 [=====>         ] 38.1% Loss: 0.1655, Epoch 11, Batch 47, CE_loss: 0.1460542380809784, Dice_loss: 0.012357541359961033, Consistency_loss: 0.0010275939712300897\n",
      "[Training] Epoch: 11 [=====>         ] 38.9% Loss: 0.1652, Epoch 11, Batch 48, CE_loss: 0.14121747016906738, Dice_loss: 0.011825771071016788, Consistency_loss: 0.0015811367193236947\n",
      "[Training] Epoch: 11 [=====>         ] 39.7% Loss: 0.1651, Epoch 11, Batch 49, CE_loss: 0.14542599022388458, Dice_loss: 0.012127098627388477, Consistency_loss: 0.0009881557198241353\n",
      "[Training] Epoch: 11 [======>        ] 40.5% Loss: 0.1653, Epoch 11, Batch 50, CE_loss: 0.16110628843307495, Dice_loss: 0.013855242170393467, Consistency_loss: 0.00022269059263635427\n",
      "[Training] Epoch: 11 [======>        ] 41.3% Loss: 0.1651, Epoch 11, Batch 51, CE_loss: 0.14234559237957, Dice_loss: 0.01181797031313181, Consistency_loss: 0.0010699324775487185\n",
      "[Training] Epoch: 11 [======>        ] 42.1% Loss: 0.1650, Epoch 11, Batch 52, CE_loss: 0.14694075286388397, Dice_loss: 0.012529640458524227, Consistency_loss: 0.0006080687162466347\n",
      "[Training] Epoch: 11 [======>        ] 42.9% Loss: 0.1646, Epoch 11, Batch 53, CE_loss: 0.133253812789917, Dice_loss: 0.01053729560226202, Consistency_loss: 0.0008426904096268117\n",
      "[Training] Epoch: 11 [======>        ] 43.7% Loss: 0.1646, Epoch 11, Batch 54, CE_loss: 0.14983507990837097, Dice_loss: 0.01292738039046526, Consistency_loss: 0.00019567194976843894\n",
      "[Training] Epoch: 11 [======>        ] 44.4% Loss: 0.1645, Epoch 11, Batch 55, CE_loss: 0.14772894978523254, Dice_loss: 0.012586789205670357, Consistency_loss: 0.00019158651411999017\n",
      "[Training] Epoch: 11 [======>        ] 45.2% Loss: 0.1644, Epoch 11, Batch 56, CE_loss: 0.1457698792219162, Dice_loss: 0.011999081820249557, Consistency_loss: 0.0009243030217476189\n",
      "[Training] Epoch: 11 [======>        ] 46.0% Loss: 0.1642, Epoch 11, Batch 57, CE_loss: 0.13761603832244873, Dice_loss: 0.010886331088840961, Consistency_loss: 0.00021235198073554784\n",
      "[Training] Epoch: 11 [=======>       ] 46.8% Loss: 0.1642, Epoch 11, Batch 58, CE_loss: 0.15161727368831635, Dice_loss: 0.013340624049305916, Consistency_loss: 0.0008103276486508548\n",
      "[Training] Epoch: 11 [=======>       ] 47.6% Loss: 0.1644, Epoch 11, Batch 59, CE_loss: 0.16056743264198303, Dice_loss: 0.014094383455812931, Consistency_loss: 0.0007521898951381445\n",
      "[Training] Epoch: 11 [=======>       ] 48.4% Loss: 0.1645, Epoch 11, Batch 60, CE_loss: 0.15790331363677979, Dice_loss: 0.01336237695068121, Consistency_loss: 0.0007508504204452038\n",
      "[Training] Epoch: 11 [=======>       ] 49.2% Loss: 0.1643, Epoch 11, Batch 61, CE_loss: 0.13718336820602417, Dice_loss: 0.011176287196576595, Consistency_loss: 0.0009616840980015695\n",
      "[Training] Epoch: 11 [=======>       ] 50.0% Loss: 0.1640, Epoch 11, Batch 62, CE_loss: 0.13523723185062408, Dice_loss: 0.010347671806812286, Consistency_loss: 0.00021505959739442915\n",
      "[Training] Epoch: 11 [=======>       ] 50.8% Loss: 0.1640, Epoch 11, Batch 63, CE_loss: 0.15384024381637573, Dice_loss: 0.012662065215408802, Consistency_loss: 0.00028647625003941357\n",
      "[Training] Epoch: 11 [=======>       ] 51.6% Loss: 0.1637, Epoch 11, Batch 64, CE_loss: 0.13388276100158691, Dice_loss: 0.010217178612947464, Consistency_loss: 0.0012851684587076306\n",
      "[Training] Epoch: 11 [=======>       ] 52.4% Loss: 0.1637, Epoch 11, Batch 65, CE_loss: 0.1480027437210083, Dice_loss: 0.012013372965157032, Consistency_loss: 0.0011567085748538375\n",
      "[Training] Epoch: 11 [=======>       ] 53.2% Loss: 0.1638, Epoch 11, Batch 66, CE_loss: 0.15530529618263245, Dice_loss: 0.013802804984152317, Consistency_loss: 0.00019088636327069253\n",
      "[Training] Epoch: 11 [========>      ] 54.0% Loss: 0.1638, Epoch 11, Batch 67, CE_loss: 0.14995557069778442, Dice_loss: 0.012577155604958534, Consistency_loss: 0.0012740842066705227\n",
      "[Training] Epoch: 11 [========>      ] 54.8% Loss: 0.1639, Epoch 11, Batch 68, CE_loss: 0.1558513045310974, Dice_loss: 0.013365108519792557, Consistency_loss: 0.0007529177819378674\n",
      "[Training] Epoch: 11 [========>      ] 55.6% Loss: 0.1640, Epoch 11, Batch 69, CE_loss: 0.16089791059494019, Dice_loss: 0.013651554472744465, Consistency_loss: 0.0007757589337415993\n",
      "[Training] Epoch: 11 [========>      ] 56.3% Loss: 0.1638, Epoch 11, Batch 70, CE_loss: 0.13796404004096985, Dice_loss: 0.011121667921543121, Consistency_loss: 0.0001916157634695992\n",
      "[Training] Epoch: 11 [========>      ] 57.1% Loss: 0.1638, Epoch 11, Batch 71, CE_loss: 0.15008483827114105, Dice_loss: 0.01297307200729847, Consistency_loss: 0.00022025371436029673\n",
      "[Training] Epoch: 11 [========>      ] 57.9% Loss: 0.1637, Epoch 11, Batch 72, CE_loss: 0.1425955891609192, Dice_loss: 0.010822387412190437, Consistency_loss: 0.0008361442014575005\n",
      "[Training] Epoch: 11 [========>      ] 58.7% Loss: 0.1636, Epoch 11, Batch 73, CE_loss: 0.14651742577552795, Dice_loss: 0.012227422557771206, Consistency_loss: 0.0008855261839926243\n",
      "[Training] Epoch: 11 [========>      ] 59.5% Loss: 0.1635, Epoch 11, Batch 74, CE_loss: 0.13978637754917145, Dice_loss: 0.011679370887577534, Consistency_loss: 0.0007371422252617776\n",
      "[Training] Epoch: 11 [=========>     ] 60.3% Loss: 0.1634, Epoch 11, Batch 75, CE_loss: 0.1453431099653244, Dice_loss: 0.012474999763071537, Consistency_loss: 0.0010600037639960647\n",
      "[Training] Epoch: 11 [=========>     ] 61.1% Loss: 0.1634, Epoch 11, Batch 76, CE_loss: 0.14581111073493958, Dice_loss: 0.012370066717267036, Consistency_loss: 0.0009839290287345648\n",
      "[Training] Epoch: 11 [=========>     ] 61.9% Loss: 0.1632, Epoch 11, Batch 77, CE_loss: 0.13876879215240479, Dice_loss: 0.010949524119496346, Consistency_loss: 0.001321299816481769\n",
      "[Training] Epoch: 11 [=========>     ] 62.7% Loss: 0.1633, Epoch 11, Batch 78, CE_loss: 0.15654993057250977, Dice_loss: 0.013249433599412441, Consistency_loss: 0.0007259438280016184\n",
      "[Training] Epoch: 11 [=========>     ] 63.5% Loss: 0.1632, Epoch 11, Batch 79, CE_loss: 0.14443567395210266, Dice_loss: 0.012287861667573452, Consistency_loss: 0.000567930459510535\n",
      "[Training] Epoch: 11 [=========>     ] 64.3% Loss: 0.1631, Epoch 11, Batch 80, CE_loss: 0.14029517769813538, Dice_loss: 0.011440802365541458, Consistency_loss: 0.0006779705872759223\n",
      "[Training] Epoch: 11 [=========>     ] 65.1% Loss: 0.1630, Epoch 11, Batch 81, CE_loss: 0.14309845864772797, Dice_loss: 0.011071904562413692, Consistency_loss: 0.00012496812269091606\n",
      "[Training] Epoch: 11 [=========>     ] 65.9% Loss: 0.1629, Epoch 11, Batch 82, CE_loss: 0.14526712894439697, Dice_loss: 0.012008474208414555, Consistency_loss: 0.000492327322717756\n",
      "[Training] Epoch: 11 [==========>    ] 66.7% Loss: 0.1628, Epoch 11, Batch 83, CE_loss: 0.14212453365325928, Dice_loss: 0.012288822792470455, Consistency_loss: 0.0004040888452436775\n",
      "[Training] Epoch: 11 [==========>    ] 67.5% Loss: 0.1626, Epoch 11, Batch 84, CE_loss: 0.13623495399951935, Dice_loss: 0.01139003224670887, Consistency_loss: 0.0009171972051262856\n",
      "[Training] Epoch: 11 [==========>    ] 68.3% Loss: 0.1625, Epoch 11, Batch 85, CE_loss: 0.13617907464504242, Dice_loss: 0.011107617989182472, Consistency_loss: 0.0006686060805805027\n",
      "[Training] Epoch: 11 [==========>    ] 69.0% Loss: 0.1624, Epoch 11, Batch 86, CE_loss: 0.14051195979118347, Dice_loss: 0.01154657918959856, Consistency_loss: 0.000718333525583148\n",
      "[Training] Epoch: 11 [==========>    ] 69.8% Loss: 0.1625, Epoch 11, Batch 87, CE_loss: 0.163222536444664, Dice_loss: 0.013972298242151737, Consistency_loss: 0.0006984328501857817\n",
      "[Training] Epoch: 11 [==========>    ] 70.6% Loss: 0.1623, Epoch 11, Batch 88, CE_loss: 0.1282321810722351, Dice_loss: 0.010031408630311489, Consistency_loss: 0.0002780637005344033\n",
      "[Training] Epoch: 11 [==========>    ] 71.4% Loss: 0.1621, Epoch 11, Batch 89, CE_loss: 0.13603492081165314, Dice_loss: 0.011203475296497345, Consistency_loss: 0.001139383064582944\n",
      "[Training] Epoch: 11 [==========>    ] 72.2% Loss: 0.1623, Epoch 11, Batch 90, CE_loss: 0.16147108376026154, Dice_loss: 0.014433820731937885, Consistency_loss: 0.00022397752036340535\n",
      "[Training] Epoch: 11 [==========>    ] 73.0% Loss: 0.1623, Epoch 11, Batch 91, CE_loss: 0.1495637446641922, Dice_loss: 0.013184157200157642, Consistency_loss: 0.001244760351255536\n",
      "[Training] Epoch: 11 [===========>   ] 73.8% Loss: 0.1622, Epoch 11, Batch 92, CE_loss: 0.14017030596733093, Dice_loss: 0.010884051211178303, Consistency_loss: 0.0008903175476007164\n",
      "[Training] Epoch: 11 [===========>   ] 74.6% Loss: 0.1623, Epoch 11, Batch 93, CE_loss: 0.16247181594371796, Dice_loss: 0.01437765546143055, Consistency_loss: 0.0009428258053958416\n",
      "[Training] Epoch: 11 [===========>   ] 75.4% Loss: 0.1622, Epoch 11, Batch 94, CE_loss: 0.13471899926662445, Dice_loss: 0.01128186285495758, Consistency_loss: 0.0008758958429098129\n",
      "[Training] Epoch: 11 [===========>   ] 76.2% Loss: 0.1621, Epoch 11, Batch 95, CE_loss: 0.14531973004341125, Dice_loss: 0.012321335263550282, Consistency_loss: 0.0010931314900517464\n",
      "[Training] Epoch: 11 [===========>   ] 77.0% Loss: 0.1620, Epoch 11, Batch 96, CE_loss: 0.13364723324775696, Dice_loss: 0.010167374275624752, Consistency_loss: 0.0010483924997970462\n",
      "[Training] Epoch: 11 [===========>   ] 77.8% Loss: 0.1618, Epoch 11, Batch 97, CE_loss: 0.13302062451839447, Dice_loss: 0.010378070175647736, Consistency_loss: 0.0008867211872711778\n",
      "[Training] Epoch: 11 [===========>   ] 78.6% Loss: 0.1616, Epoch 11, Batch 98, CE_loss: 0.13598285615444183, Dice_loss: 0.011166519485414028, Consistency_loss: 0.000739476818125695\n",
      "[Training] Epoch: 11 [===========>   ] 79.4% Loss: 0.1616, Epoch 11, Batch 99, CE_loss: 0.14611046016216278, Dice_loss: 0.01193818636238575, Consistency_loss: 0.0010027606040239334\n",
      "[Training] Epoch: 11 [============>  ] 80.2% Loss: 0.1616, Epoch 11, Batch 100, CE_loss: 0.1495901346206665, Dice_loss: 0.012303713709115982, Consistency_loss: 0.0005131723592057824\n",
      "[Training] Epoch: 11 [============>  ] 81.0% Loss: 0.1616, Epoch 11, Batch 101, CE_loss: 0.14372491836547852, Dice_loss: 0.01225409284234047, Consistency_loss: 0.0008201474556699395\n",
      "[Training] Epoch: 11 [============>  ] 81.7% Loss: 0.1615, Epoch 11, Batch 102, CE_loss: 0.13748587667942047, Dice_loss: 0.011152013204991817, Consistency_loss: 0.0008600504952482879\n",
      "[Training] Epoch: 11 [============>  ] 82.5% Loss: 0.1614, Epoch 11, Batch 103, CE_loss: 0.13828983902931213, Dice_loss: 0.010825909674167633, Consistency_loss: 0.0009000563877634704\n",
      "[Training] Epoch: 11 [============>  ] 83.3% Loss: 0.1613, Epoch 11, Batch 104, CE_loss: 0.14206141233444214, Dice_loss: 0.011247549206018448, Consistency_loss: 0.0007570402231067419\n",
      "[Training] Epoch: 11 [============>  ] 84.1% Loss: 0.1612, Epoch 11, Batch 105, CE_loss: 0.14218191802501678, Dice_loss: 0.011952120810747147, Consistency_loss: 0.0009779119864106178\n",
      "[Training] Epoch: 11 [============>  ] 84.9% Loss: 0.1611, Epoch 11, Batch 106, CE_loss: 0.13381336629390717, Dice_loss: 0.010549865663051605, Consistency_loss: 0.0009285552660003304\n",
      "[Training] Epoch: 11 [============>  ] 85.7% Loss: 0.1612, Epoch 11, Batch 107, CE_loss: 0.15580788254737854, Dice_loss: 0.013790059834718704, Consistency_loss: 0.0011179535649716854\n",
      "[Training] Epoch: 11 [============>  ] 86.5% Loss: 0.1611, Epoch 11, Batch 108, CE_loss: 0.14053882658481598, Dice_loss: 0.011716479435563087, Consistency_loss: 0.0006871893419884145\n",
      "[Training] Epoch: 11 [=============> ] 87.3% Loss: 0.1610, Epoch 11, Batch 109, CE_loss: 0.14200367033481598, Dice_loss: 0.011467024683952332, Consistency_loss: 0.0009076534188352525\n",
      "[Training] Epoch: 11 [=============> ] 88.1% Loss: 0.1609, Epoch 11, Batch 110, CE_loss: 0.1359969675540924, Dice_loss: 0.010855834931135178, Consistency_loss: 0.0001167599912150763\n",
      "[Training] Epoch: 11 [=============> ] 88.9% Loss: 0.1609, Epoch 11, Batch 111, CE_loss: 0.15074706077575684, Dice_loss: 0.012436916120350361, Consistency_loss: 0.0006550473044626415\n",
      "[Training] Epoch: 11 [=============> ] 89.7% Loss: 0.1609, Epoch 11, Batch 112, CE_loss: 0.14242689311504364, Dice_loss: 0.011474794708192348, Consistency_loss: 0.0007107785204425454\n",
      "[Training] Epoch: 11 [=============> ] 90.5% Loss: 0.1608, Epoch 11, Batch 113, CE_loss: 0.14233604073524475, Dice_loss: 0.0110514797270298, Consistency_loss: 0.0007698297849856317\n",
      "[Training] Epoch: 11 [=============> ] 91.3% Loss: 0.1607, Epoch 11, Batch 114, CE_loss: 0.13105614483356476, Dice_loss: 0.01034692581743002, Consistency_loss: 0.0015455236425623298\n",
      "[Training] Epoch: 11 [=============> ] 92.1% Loss: 0.1607, Epoch 11, Batch 115, CE_loss: 0.14888086915016174, Dice_loss: 0.0131484754383564, Consistency_loss: 0.0012388188624754548\n",
      "[Training] Epoch: 11 [=============> ] 92.9% Loss: 0.1607, Epoch 11, Batch 116, CE_loss: 0.14896973967552185, Dice_loss: 0.012701726518571377, Consistency_loss: 0.001173405791632831\n",
      "[Training] Epoch: 11 [==============>] 93.7% Loss: 0.1607, Epoch 11, Batch 117, CE_loss: 0.1477513462305069, Dice_loss: 0.013184680603444576, Consistency_loss: 0.001171453739516437\n",
      "[Training] Epoch: 11 [==============>] 94.4% Loss: 0.1606, Epoch 11, Batch 118, CE_loss: 0.13817746937274933, Dice_loss: 0.011737154796719551, Consistency_loss: 0.0005929957260377705\n",
      "[Training] Epoch: 11 [==============>] 95.2% Loss: 0.1605, Epoch 11, Batch 119, CE_loss: 0.13129323720932007, Dice_loss: 0.010062530636787415, Consistency_loss: 0.00025007929070852697\n",
      "[Training] Epoch: 11 [==============>] 96.0% Loss: 0.1604, Epoch 11, Batch 120, CE_loss: 0.14033068716526031, Dice_loss: 0.011745640076696873, Consistency_loss: 0.0003618726332206279\n",
      "[Training] Epoch: 11 [==============>] 96.8% Loss: 0.1603, Epoch 11, Batch 121, CE_loss: 0.13990040123462677, Dice_loss: 0.011511903256177902, Consistency_loss: 0.0003064639458898455\n",
      "[Training] Epoch: 11 [==============>] 97.6% Loss: 0.1601, Epoch 11, Batch 122, CE_loss: 0.12407071143388748, Dice_loss: 0.009002642706036568, Consistency_loss: 0.00048533090739510953\n",
      "[Training] Epoch: 11 [==============>] 98.4% Loss: 0.1600, Epoch 11, Batch 123, CE_loss: 0.13955740630626678, Dice_loss: 0.0118165398016572, Consistency_loss: 0.0008548473124392331\n",
      "[Training] Epoch: 11 [==============>] 99.2% Loss: 0.1600, Epoch 11, Batch 124, CE_loss: 0.14073395729064941, Dice_loss: 0.011684605851769447, Consistency_loss: 0.0007877503521740437\n",
      "[Training] Epoch: 11 [DONE]                                 \n",
      "Epoch 11, Batch 125, CE_loss: 0.1428358107805252, Dice_loss: 0.012639928609132767, Consistency_loss: 0.0010542577365413308\n",
      "[Validation] Epoch: 11 [DONE]                                 \n",
      "[Epoch: 11, TrainLoss: 0.1600, TrainDice: 0.0123, ValLoss: 0.1926                                            \n",
      "Number of batches:  126\n",
      "[Training] Epoch: 12 [>              ] 0.8% Loss: 0.1506, Epoch 12, Batch 0, CE_loss: 0.1379808485507965, Dice_loss: 0.011617769487202168, Consistency_loss: 0.0010475927265360951\n",
      "[Training] Epoch: 12 [>              ] 1.6% Loss: 0.1470, Epoch 12, Batch 1, CE_loss: 0.13248823583126068, Dice_loss: 0.010555668734014034, Consistency_loss: 0.00039634117274545133\n",
      "[Training] Epoch: 12 [>              ] 2.4% Loss: 0.1500, Epoch 12, Batch 2, CE_loss: 0.14313669502735138, Dice_loss: 0.012161296792328358, Consistency_loss: 0.0005529021727852523\n",
      "[Training] Epoch: 12 [>              ] 3.2% Loss: 0.1535, Epoch 12, Batch 3, CE_loss: 0.14978237450122833, Dice_loss: 0.013396629132330418, Consistency_loss: 0.0008143685990944505\n",
      "[Training] Epoch: 12 [>              ] 4.0% Loss: 0.1531, Epoch 12, Batch 4, CE_loss: 0.1395915299654007, Dice_loss: 0.01189790852367878, Consistency_loss: 0.0002582902379799634\n",
      "[Training] Epoch: 12 [>              ] 4.8% Loss: 0.1524, Epoch 12, Batch 5, CE_loss: 0.13647526502609253, Dice_loss: 0.011485898867249489, Consistency_loss: 0.0004818782617803663\n",
      "[Training] Epoch: 12 [>              ] 5.6% Loss: 0.1531, Epoch 12, Batch 6, CE_loss: 0.14416131377220154, Dice_loss: 0.012988409958779812, Consistency_loss: 0.000661721162032336\n",
      "[Training] Epoch: 12 [>              ] 6.3% Loss: 0.1540, Epoch 12, Batch 7, CE_loss: 0.1464158594608307, Dice_loss: 0.012974887154996395, Consistency_loss: 0.0007606309955008328\n",
      "[Training] Epoch: 12 [=>             ] 7.1% Loss: 0.1523, Epoch 12, Batch 8, CE_loss: 0.12768059968948364, Dice_loss: 0.010201334953308105, Consistency_loss: 0.0004693481314461678\n",
      "[Training] Epoch: 12 [=>             ] 7.9% Loss: 0.1517, Epoch 12, Batch 9, CE_loss: 0.13514463603496552, Dice_loss: 0.010403498075902462, Consistency_loss: 0.0005739310290664434\n",
      "[Training] Epoch: 12 [=>             ] 8.7% Loss: 0.1525, Epoch 12, Batch 10, CE_loss: 0.14751185476779938, Dice_loss: 0.013020891696214676, Consistency_loss: 0.0005438616499304771\n",
      "[Training] Epoch: 12 [=>             ] 9.5% Loss: 0.1532, Epoch 12, Batch 11, CE_loss: 0.14766861498355865, Dice_loss: 0.012708695605397224, Consistency_loss: 0.0009800376137718558\n",
      "[Training] Epoch: 12 [=>             ] 10.3% Loss: 0.1534, Epoch 12, Batch 12, CE_loss: 0.14364877343177795, Dice_loss: 0.011310544796288013, Consistency_loss: 0.00014593085506930947\n",
      "[Training] Epoch: 12 [=>             ] 11.1% Loss: 0.1524, Epoch 12, Batch 13, CE_loss: 0.12871238589286804, Dice_loss: 0.010098325088620186, Consistency_loss: 0.0005913222557865083\n",
      "[Training] Epoch: 12 [=>             ] 11.9% Loss: 0.1523, Epoch 12, Batch 14, CE_loss: 0.13924267888069153, Dice_loss: 0.011746766045689583, Consistency_loss: 9.792447235668078e-05\n",
      "[Training] Epoch: 12 [=>             ] 12.7% Loss: 0.1524, Epoch 12, Batch 15, CE_loss: 0.14086642861366272, Dice_loss: 0.011781674809753895, Consistency_loss: 0.00071701779961586\n",
      "[Training] Epoch: 12 [==>            ] 13.5% Loss: 0.1527, Epoch 12, Batch 16, CE_loss: 0.14512529969215393, Dice_loss: 0.012264745309948921, Consistency_loss: 0.0006712795584462583\n",
      "[Training] Epoch: 12 [==>            ] 14.3% Loss: 0.1528, Epoch 12, Batch 17, CE_loss: 0.14236344397068024, Dice_loss: 0.011312131769955158, Consistency_loss: 0.0004971309681423008\n",
      "[Training] Epoch: 12 [==>            ] 15.1% Loss: 0.1528, Epoch 12, Batch 18, CE_loss: 0.1407536119222641, Dice_loss: 0.011985648423433304, Consistency_loss: 0.0009771183831617236\n",
      "[Training] Epoch: 12 [==>            ] 15.9% Loss: 0.1527, Epoch 12, Batch 19, CE_loss: 0.13762564957141876, Dice_loss: 0.011571063660085201, Consistency_loss: 0.0002217003348050639\n",
      "[Training] Epoch: 12 [==>            ] 16.7% Loss: 0.1529, Epoch 12, Batch 20, CE_loss: 0.14416958391666412, Dice_loss: 0.012383929453790188, Consistency_loss: 0.0008715816657058895\n",
      "[Training] Epoch: 12 [==>            ] 17.5% Loss: 0.1526, Epoch 12, Batch 21, CE_loss: 0.13521574437618256, Dice_loss: 0.011534459888935089, Consistency_loss: 0.00011634761904133484\n",
      "[Training] Epoch: 12 [==>            ] 18.3% Loss: 0.1526, Epoch 12, Batch 22, CE_loss: 0.14051519334316254, Dice_loss: 0.01201701257377863, Consistency_loss: 0.0004653861396946013\n",
      "[Training] Epoch: 12 [==>            ] 19.0% Loss: 0.1528, Epoch 12, Batch 23, CE_loss: 0.14499735832214355, Dice_loss: 0.012484029866755009, Consistency_loss: 0.00014933421334717423\n",
      "[Training] Epoch: 12 [==>            ] 19.8% Loss: 0.1523, Epoch 12, Batch 24, CE_loss: 0.12799084186553955, Dice_loss: 0.009767528623342514, Consistency_loss: 0.0007151043973863125\n",
      "[Training] Epoch: 12 [===>           ] 20.6% Loss: 0.1515, Epoch 12, Batch 25, CE_loss: 0.12297758460044861, Dice_loss: 0.009095531888306141, Consistency_loss: 0.0010963139357045293\n",
      "[Training] Epoch: 12 [===>           ] 21.4% Loss: 0.1518, Epoch 12, Batch 26, CE_loss: 0.1455410122871399, Dice_loss: 0.012226841412484646, Consistency_loss: 0.0011200192384421825\n",
      "[Training] Epoch: 12 [===>           ] 22.2% Loss: 0.1517, Epoch 12, Batch 27, CE_loss: 0.13538196682929993, Dice_loss: 0.010996874421834946, Consistency_loss: 0.0011751607526093721\n",
      "[Training] Epoch: 12 [===>           ] 23.0% Loss: 0.1516, Epoch 12, Batch 28, CE_loss: 0.1367531418800354, Dice_loss: 0.01150783896446228, Consistency_loss: 0.001018189243040979\n",
      "[Training] Epoch: 12 [===>           ] 23.8% Loss: 0.1512, Epoch 12, Batch 29, CE_loss: 0.12947770953178406, Dice_loss: 0.01016177237033844, Consistency_loss: 0.00016235439397860318\n",
      "[Training] Epoch: 12 [===>           ] 24.6% Loss: 0.1518, Epoch 12, Batch 30, CE_loss: 0.154170423746109, Dice_loss: 0.01417574379593134, Consistency_loss: 0.0010070184944197536\n",
      "[Training] Epoch: 12 [===>           ] 25.4% Loss: 0.1518, Epoch 12, Batch 31, CE_loss: 0.14161750674247742, Dice_loss: 0.0124441497027874, Consistency_loss: 0.00013318574929144233\n",
      "[Training] Epoch: 12 [===>           ] 26.2% Loss: 0.1512, Epoch 12, Batch 32, CE_loss: 0.12097270786762238, Dice_loss: 0.009100615046918392, Consistency_loss: 0.0008254479034803808\n",
      "[Training] Epoch: 12 [====>          ] 27.0% Loss: 0.1508, Epoch 12, Batch 33, CE_loss: 0.12805268168449402, Dice_loss: 0.009516352787613869, Consistency_loss: 0.0008715729345567524\n",
      "[Training] Epoch: 12 [====>          ] 27.8% Loss: 0.1509, Epoch 12, Batch 34, CE_loss: 0.1415068358182907, Dice_loss: 0.012144274078309536, Consistency_loss: 0.001081060734577477\n",
      "[Training] Epoch: 12 [====>          ] 28.6% Loss: 0.1508, Epoch 12, Batch 35, CE_loss: 0.13350069522857666, Dice_loss: 0.011328935623168945, Consistency_loss: 0.00021424198348540813\n",
      "[Training] Epoch: 12 [====>          ] 29.4% Loss: 0.1502, Epoch 12, Batch 36, CE_loss: 0.12075056880712509, Dice_loss: 0.009462708607316017, Consistency_loss: 0.00045615548151545227\n",
      "[Training] Epoch: 12 [====>          ] 30.2% Loss: 0.1502, Epoch 12, Batch 37, CE_loss: 0.13584861159324646, Dice_loss: 0.011207763105630875, Consistency_loss: 0.0001427626411896199\n",
      "[Training] Epoch: 12 [====>          ] 31.0% Loss: 0.1500, Epoch 12, Batch 38, CE_loss: 0.1330346316099167, Dice_loss: 0.010898132808506489, Consistency_loss: 0.0006170045235194266\n",
      "[Training] Epoch: 12 [====>          ] 31.7% Loss: 0.1499, Epoch 12, Batch 39, CE_loss: 0.13266173005104065, Dice_loss: 0.010597828775644302, Consistency_loss: 0.0008378556813113391\n",
      "[Training] Epoch: 12 [====>          ] 32.5% Loss: 0.1496, Epoch 12, Batch 40, CE_loss: 0.12825852632522583, Dice_loss: 0.010393112897872925, Consistency_loss: 0.000163497039466165\n",
      "[Training] Epoch: 12 [=====>         ] 33.3% Loss: 0.1492, Epoch 12, Batch 41, CE_loss: 0.12294523417949677, Dice_loss: 0.0088067427277565, Consistency_loss: 0.0005449982709251344\n",
      "[Training] Epoch: 12 [=====>         ] 34.1% Loss: 0.1489, Epoch 12, Batch 42, CE_loss: 0.12539851665496826, Dice_loss: 0.010035512037575245, Consistency_loss: 0.0008123657898977399\n",
      "[Training] Epoch: 12 [=====>         ] 34.9% Loss: 0.1487, Epoch 12, Batch 43, CE_loss: 0.12928836047649384, Dice_loss: 0.010789453983306885, Consistency_loss: 0.001012299326248467\n",
      "[Training] Epoch: 12 [=====>         ] 35.7% Loss: 0.1486, Epoch 12, Batch 44, CE_loss: 0.1332225203514099, Dice_loss: 0.011168517172336578, Consistency_loss: 0.0010060956701636314\n",
      "[Training] Epoch: 12 [=====>         ] 36.5% Loss: 0.1483, Epoch 12, Batch 45, CE_loss: 0.12274160236120224, Dice_loss: 0.009360297583043575, Consistency_loss: 0.0006290568853728473\n",
      "[Training] Epoch: 12 [=====>         ] 37.3% Loss: 0.1484, Epoch 12, Batch 46, CE_loss: 0.14009256660938263, Dice_loss: 0.012148940935730934, Consistency_loss: 0.00012425128079485148\n",
      "[Training] Epoch: 12 [=====>         ] 38.1% Loss: 0.1481, Epoch 12, Batch 47, CE_loss: 0.12589477002620697, Dice_loss: 0.010003138333559036, Consistency_loss: 0.00016921172209549695\n",
      "[Training] Epoch: 12 [=====>         ] 38.9% Loss: 0.1481, Epoch 12, Batch 48, CE_loss: 0.13645093142986298, Dice_loss: 0.010573957115411758, Consistency_loss: 0.0013282060390338302\n",
      "[Training] Epoch: 12 [=====>         ] 39.7% Loss: 0.1479, Epoch 12, Batch 49, CE_loss: 0.12694169580936432, Dice_loss: 0.010201111435890198, Consistency_loss: 0.0007728067575953901\n",
      "[Training] Epoch: 12 [======>        ] 40.5% Loss: 0.1479, Epoch 12, Batch 50, CE_loss: 0.1353275328874588, Dice_loss: 0.01110861450433731, Consistency_loss: 0.0009731335449032485\n",
      "[Training] Epoch: 12 [======>        ] 41.3% Loss: 0.1479, Epoch 12, Batch 51, CE_loss: 0.13615354895591736, Dice_loss: 0.011461763642728329, Consistency_loss: 0.0009699604706838727\n",
      "[Training] Epoch: 12 [======>        ] 42.1% Loss: 0.1482, Epoch 12, Batch 52, CE_loss: 0.14872412383556366, Dice_loss: 0.012771066278219223, Consistency_loss: 0.0005549664492718875\n",
      "[Training] Epoch: 12 [======>        ] 42.9% Loss: 0.1482, Epoch 12, Batch 53, CE_loss: 0.13725873827934265, Dice_loss: 0.01145942509174347, Consistency_loss: 0.0006582951173186302\n",
      "[Training] Epoch: 12 [======>        ] 43.7% Loss: 0.1481, Epoch 12, Batch 54, CE_loss: 0.13316845893859863, Dice_loss: 0.010689305141568184, Consistency_loss: 0.0009406086173839867\n",
      "[Training] Epoch: 12 [======>        ] 44.4% Loss: 0.1483, Epoch 12, Batch 55, CE_loss: 0.14103612303733826, Dice_loss: 0.012639615684747696, Consistency_loss: 0.0008410335867665708\n",
      "[Training] Epoch: 12 [======>        ] 45.2% Loss: 0.1480, Epoch 12, Batch 56, CE_loss: 0.1215074434876442, Dice_loss: 0.009853886440396309, Consistency_loss: 0.0008941045962274075\n",
      "[Training] Epoch: 12 [======>        ] 46.0% Loss: 0.1479, Epoch 12, Batch 57, CE_loss: 0.13083672523498535, Dice_loss: 0.010993275791406631, Consistency_loss: 0.0008815236506052315\n",
      "[Training] Epoch: 12 [=======>       ] 46.8% Loss: 0.1478, Epoch 12, Batch 58, CE_loss: 0.1300775706768036, Dice_loss: 0.010812087915837765, Consistency_loss: 0.0008382542291656137\n",
      "[Training] Epoch: 12 [=======>       ] 47.6% Loss: 0.1476, Epoch 12, Batch 59, CE_loss: 0.12338835746049881, Dice_loss: 0.009587078355252743, Consistency_loss: 0.0009294908377341926\n",
      "[Training] Epoch: 12 [=======>       ] 48.4% Loss: 0.1477, Epoch 12, Batch 60, CE_loss: 0.14568747580051422, Dice_loss: 0.012566180899739265, Consistency_loss: 0.0007479138439521194\n",
      "[Training] Epoch: 12 [=======>       ] 49.2% Loss: 0.1478, Epoch 12, Batch 61, CE_loss: 0.13863316178321838, Dice_loss: 0.011288135312497616, Consistency_loss: 0.0005522503633983433\n",
      "[Training] Epoch: 12 [=======>       ] 50.0% Loss: 0.1481, Epoch 12, Batch 62, CE_loss: 0.1543034464120865, Dice_loss: 0.01388716883957386, Consistency_loss: 0.0010058331536129117\n",
      "[Training] Epoch: 12 [=======>       ] 50.8% Loss: 0.1479, Epoch 12, Batch 63, CE_loss: 0.1230364441871643, Dice_loss: 0.009412484243512154, Consistency_loss: 0.0009463130845688283\n",
      "[Training] Epoch: 12 [=======>       ] 51.6% Loss: 0.1478, Epoch 12, Batch 64, CE_loss: 0.12896475195884705, Dice_loss: 0.010613425634801388, Consistency_loss: 0.0013169292360544205\n",
      "[Training] Epoch: 12 [=======>       ] 52.4% Loss: 0.1481, Epoch 12, Batch 65, CE_loss: 0.1559956967830658, Dice_loss: 0.013660991564393044, Consistency_loss: 0.0013436971930786967\n",
      "[Training] Epoch: 12 [=======>       ] 53.2% Loss: 0.1480, Epoch 12, Batch 66, CE_loss: 0.1252800077199936, Dice_loss: 0.010209636762738228, Consistency_loss: 0.0007534318719990551\n",
      "[Training] Epoch: 12 [========>      ] 54.0% Loss: 0.1481, Epoch 12, Batch 67, CE_loss: 0.14271505177021027, Dice_loss: 0.011991852894425392, Consistency_loss: 0.0013800542801618576\n",
      "[Training] Epoch: 12 [========>      ] 54.8% Loss: 0.1478, Epoch 12, Batch 68, CE_loss: 0.11926038563251495, Dice_loss: 0.008764457888901234, Consistency_loss: 0.0006271392339840531\n",
      "[Training] Epoch: 12 [========>      ] 55.6% Loss: 0.1476, Epoch 12, Batch 69, CE_loss: 0.12282322347164154, Dice_loss: 0.009714769199490547, Consistency_loss: 0.00042145774932578206\n",
      "[Training] Epoch: 12 [========>      ] 56.3% Loss: 0.1476, Epoch 12, Batch 70, CE_loss: 0.13872084021568298, Dice_loss: 0.011723020114004612, Consistency_loss: 0.000790202000644058\n",
      "[Training] Epoch: 12 [========>      ] 57.1% Loss: 0.1476, Epoch 12, Batch 71, CE_loss: 0.12975725531578064, Dice_loss: 0.01082032173871994, Consistency_loss: 0.001046541496179998\n",
      "[Training] Epoch: 12 [========>      ] 57.9% Loss: 0.1478, Epoch 12, Batch 72, CE_loss: 0.14832617342472076, Dice_loss: 0.012670496478676796, Consistency_loss: 0.0008154492825269699\n",
      "[Training] Epoch: 12 [========>      ] 58.7% Loss: 0.1476, Epoch 12, Batch 73, CE_loss: 0.12579387426376343, Dice_loss: 0.01022323127835989, Consistency_loss: 0.0009585827938281\n",
      "[Training] Epoch: 12 [========>      ] 59.5% Loss: 0.1478, Epoch 12, Batch 74, CE_loss: 0.14533837139606476, Dice_loss: 0.012598121538758278, Consistency_loss: 0.0007090784492902458\n",
      "[Training] Epoch: 12 [=========>     ] 60.3% Loss: 0.1477, Epoch 12, Batch 75, CE_loss: 0.13338753581047058, Dice_loss: 0.011551689356565475, Consistency_loss: 0.001108517055399716\n",
      "[Training] Epoch: 12 [=========>     ] 61.1% Loss: 0.1478, Epoch 12, Batch 76, CE_loss: 0.14342592656612396, Dice_loss: 0.01205360610038042, Consistency_loss: 0.0012862334260717034\n",
      "[Training] Epoch: 12 [=========>     ] 61.9% Loss: 0.1479, Epoch 12, Batch 77, CE_loss: 0.13982808589935303, Dice_loss: 0.01149675715714693, Consistency_loss: 0.00019962685473728925\n",
      "[Training] Epoch: 12 [=========>     ] 62.7% Loss: 0.1477, Epoch 12, Batch 78, CE_loss: 0.12405958026647568, Dice_loss: 0.010004626587033272, Consistency_loss: 0.0007675833767279983\n",
      "[Training] Epoch: 12 [=========>     ] 63.5% Loss: 0.1476, Epoch 12, Batch 79, CE_loss: 0.12757042050361633, Dice_loss: 0.010503253899514675, Consistency_loss: 0.0005337336915545166\n",
      "[Training] Epoch: 12 [=========>     ] 64.3% Loss: 0.1474, Epoch 12, Batch 80, CE_loss: 0.12019138783216476, Dice_loss: 0.008885403163731098, Consistency_loss: 0.000713008048478514\n",
      "[Training] Epoch: 12 [=========>     ] 65.1% Loss: 0.1472, Epoch 12, Batch 81, CE_loss: 0.11977371573448181, Dice_loss: 0.009389211423695087, Consistency_loss: 0.00011534879740793258\n",
      "[Training] Epoch: 12 [=========>     ] 65.9% Loss: 0.1471, Epoch 12, Batch 82, CE_loss: 0.13357001543045044, Dice_loss: 0.011125579476356506, Consistency_loss: 0.0001634169020690024\n",
      "[Training] Epoch: 12 [==========>    ] 66.7% Loss: 0.1470, Epoch 12, Batch 83, CE_loss: 0.12612779438495636, Dice_loss: 0.010050698183476925, Consistency_loss: 0.000407255778554827\n",
      "[Training] Epoch: 12 [==========>    ] 67.5% Loss: 0.1468, Epoch 12, Batch 84, CE_loss: 0.11875405162572861, Dice_loss: 0.009278763085603714, Consistency_loss: 0.0006481598829850554\n",
      "[Training] Epoch: 12 [==========>    ] 68.3% Loss: 0.1466, Epoch 12, Batch 85, CE_loss: 0.1192234605550766, Dice_loss: 0.008749540895223618, Consistency_loss: 0.00024545975611545146\n",
      "[Training] Epoch: 12 [==========>    ] 69.0% Loss: 0.1464, Epoch 12, Batch 86, CE_loss: 0.11867916584014893, Dice_loss: 0.009330055676400661, Consistency_loss: 0.0006311770994216204\n",
      "[Training] Epoch: 12 [==========>    ] 69.8% Loss: 0.1462, Epoch 12, Batch 87, CE_loss: 0.12399230897426605, Dice_loss: 0.00981705542653799, Consistency_loss: 0.0005756522295996547\n",
      "[Training] Epoch: 12 [==========>    ] 70.6% Loss: 0.1463, Epoch 12, Batch 88, CE_loss: 0.14047826826572418, Dice_loss: 0.012014593929052353, Consistency_loss: 0.00017416737682651728\n",
      "[Training] Epoch: 12 [==========>    ] 71.4% Loss: 0.1461, Epoch 12, Batch 89, CE_loss: 0.12010632455348969, Dice_loss: 0.00952380895614624, Consistency_loss: 0.000159110248205252\n",
      "[Training] Epoch: 12 [==========>    ] 72.2% Loss: 0.1459, Epoch 12, Batch 90, CE_loss: 0.11515852808952332, Dice_loss: 0.00860093254595995, Consistency_loss: 0.0009633251465857029\n",
      "[Training] Epoch: 12 [==========>    ] 73.0% Loss: 0.1460, Epoch 12, Batch 91, CE_loss: 0.1398306041955948, Dice_loss: 0.012004285119473934, Consistency_loss: 0.0010638448875397444\n",
      "[Training] Epoch: 12 [===========>   ] 73.8% Loss: 0.1457, Epoch 12, Batch 92, CE_loss: 0.11274160444736481, Dice_loss: 0.008179986849427223, Consistency_loss: 0.0008600021828897297\n",
      "[Training] Epoch: 12 [===========>   ] 74.6% Loss: 0.1458, Epoch 12, Batch 93, CE_loss: 0.1395999789237976, Dice_loss: 0.012567603029310703, Consistency_loss: 0.0007915465394034982\n",
      "[Training] Epoch: 12 [===========>   ] 75.4% Loss: 0.1456, Epoch 12, Batch 94, CE_loss: 0.121278315782547, Dice_loss: 0.009353699162602425, Consistency_loss: 0.0001499368663644418\n",
      "[Training] Epoch: 12 [===========>   ] 76.2% Loss: 0.1454, Epoch 12, Batch 95, CE_loss: 0.11728695034980774, Dice_loss: 0.008846363984048367, Consistency_loss: 0.0007842060294933617\n",
      "[Training] Epoch: 12 [===========>   ] 77.0% Loss: 0.1453, Epoch 12, Batch 96, CE_loss: 0.12096762657165527, Dice_loss: 0.009351061657071114, Consistency_loss: 0.0009716846980154514\n",
      "[Training] Epoch: 12 [===========>   ] 77.8% Loss: 0.1452, Epoch 12, Batch 97, CE_loss: 0.12326546013355255, Dice_loss: 0.009990781545639038, Consistency_loss: 0.0008730437839403749\n",
      "[Training] Epoch: 12 [===========>   ] 78.6% Loss: 0.1452, Epoch 12, Batch 98, CE_loss: 0.13222287595272064, Dice_loss: 0.010308816097676754, Consistency_loss: 0.0006780642434023321\n",
      "[Training] Epoch: 12 [===========>   ] 79.4% Loss: 0.1451, Epoch 12, Batch 99, CE_loss: 0.1296781301498413, Dice_loss: 0.010839213617146015, Consistency_loss: 0.0001809212553780526\n",
      "[Training] Epoch: 12 [============>  ] 80.2% Loss: 0.1450, Epoch 12, Batch 100, CE_loss: 0.1203317940235138, Dice_loss: 0.00938299298286438, Consistency_loss: 9.091535321203992e-05\n",
      "[Training] Epoch: 12 [============>  ] 81.0% Loss: 0.1448, Epoch 12, Batch 101, CE_loss: 0.12145805358886719, Dice_loss: 0.009896515868604183, Consistency_loss: 0.0006657041958533227\n",
      "[Training] Epoch: 12 [============>  ] 81.7% Loss: 0.1450, Epoch 12, Batch 102, CE_loss: 0.14504872262477875, Dice_loss: 0.012626388110220432, Consistency_loss: 0.0008234355482272804\n",
      "[Training] Epoch: 12 [============>  ] 82.5% Loss: 0.1448, Epoch 12, Batch 103, CE_loss: 0.12028250843286514, Dice_loss: 0.009396087378263474, Consistency_loss: 0.0008269274840131402\n",
      "[Training] Epoch: 12 [============>  ] 83.3% Loss: 0.1448, Epoch 12, Batch 104, CE_loss: 0.1307738572359085, Dice_loss: 0.010685071349143982, Consistency_loss: 0.0006678614881820977\n",
      "[Training] Epoch: 12 [============>  ] 84.1% Loss: 0.1448, Epoch 12, Batch 105, CE_loss: 0.1346968561410904, Dice_loss: 0.011313705705106258, Consistency_loss: 0.0008516056695953012\n",
      "[Training] Epoch: 12 [============>  ] 84.9% Loss: 0.1447, Epoch 12, Batch 106, CE_loss: 0.12361296266317368, Dice_loss: 0.00967406202107668, Consistency_loss: 0.000910711009055376\n",
      "[Training] Epoch: 12 [============>  ] 85.7% Loss: 0.1446, Epoch 12, Batch 107, CE_loss: 0.11870502680540085, Dice_loss: 0.009074091911315918, Consistency_loss: 0.00015303315012715757\n",
      "[Training] Epoch: 12 [============>  ] 86.5% Loss: 0.1445, Epoch 12, Batch 108, CE_loss: 0.12343313544988632, Dice_loss: 0.00911904126405716, Consistency_loss: 0.0008439520606771111\n",
      "[Training] Epoch: 12 [=============> ] 87.3% Loss: 0.1444, Epoch 12, Batch 109, CE_loss: 0.12595722079277039, Dice_loss: 0.010566571727395058, Consistency_loss: 0.00021155241120141\n",
      "[Training] Epoch: 12 [=============> ] 88.1% Loss: 0.1443, Epoch 12, Batch 110, CE_loss: 0.1193767786026001, Dice_loss: 0.009572209790349007, Consistency_loss: 0.0008011309546418488\n",
      "[Training] Epoch: 12 [=============> ] 88.9% Loss: 0.1442, Epoch 12, Batch 111, CE_loss: 0.12182042002677917, Dice_loss: 0.009914298541843891, Consistency_loss: 0.0007410460384562612\n",
      "[Training] Epoch: 12 [=============> ] 89.7% Loss: 0.1440, Epoch 12, Batch 112, CE_loss: 0.11509280651807785, Dice_loss: 0.008933518081903458, Consistency_loss: 0.0005770900170318782\n",
      "[Training] Epoch: 12 [=============> ] 90.5% Loss: 0.1439, Epoch 12, Batch 113, CE_loss: 0.12391117960214615, Dice_loss: 0.010007760487496853, Consistency_loss: 0.0009711615857668221\n",
      "[Training] Epoch: 12 [=============> ] 91.3% Loss: 0.1440, Epoch 12, Batch 114, CE_loss: 0.1397317498922348, Dice_loss: 0.012213082052767277, Consistency_loss: 0.0011010088492184877\n",
      "[Training] Epoch: 12 [=============> ] 92.1% Loss: 0.1439, Epoch 12, Batch 115, CE_loss: 0.11962845921516418, Dice_loss: 0.009511198848485947, Consistency_loss: 0.0009051239467225969\n",
      "[Training] Epoch: 12 [=============> ] 92.9% Loss: 0.1438, Epoch 12, Batch 116, CE_loss: 0.12047196179628372, Dice_loss: 0.009362108074128628, Consistency_loss: 0.0012259514769539237\n",
      "[Training] Epoch: 12 [==============>] 93.7% Loss: 0.1436, Epoch 12, Batch 117, CE_loss: 0.11386630684137344, Dice_loss: 0.009270595386624336, Consistency_loss: 0.0012037827400490642\n",
      "[Training] Epoch: 12 [==============>] 94.4% Loss: 0.1436, Epoch 12, Batch 118, CE_loss: 0.1342560350894928, Dice_loss: 0.011455326341092587, Consistency_loss: 0.00044391845585778356\n",
      "[Training] Epoch: 12 [==============>] 95.2% Loss: 0.1437, Epoch 12, Batch 119, CE_loss: 0.1381588727235794, Dice_loss: 0.01179876085370779, Consistency_loss: 0.0007205676520243287\n",
      "[Training] Epoch: 12 [==============>] 96.0% Loss: 0.1436, Epoch 12, Batch 120, CE_loss: 0.12886735796928406, Dice_loss: 0.010852937586605549, Consistency_loss: 0.0011655212147161365\n",
      "[Training] Epoch: 12 [==============>] 96.8% Loss: 0.1436, Epoch 12, Batch 121, CE_loss: 0.12777377665042877, Dice_loss: 0.010845248587429523, Consistency_loss: 0.00038164082798175514\n",
      "[Training] Epoch: 12 [==============>] 97.6% Loss: 0.1436, Epoch 12, Batch 122, CE_loss: 0.128264382481575, Dice_loss: 0.010610944591462612, Consistency_loss: 0.0005304819787852466\n",
      "[Training] Epoch: 12 [==============>] 98.4% Loss: 0.1435, Epoch 12, Batch 123, CE_loss: 0.12010403722524643, Dice_loss: 0.00988827645778656, Consistency_loss: 0.0010571532184258103\n",
      "[Training] Epoch: 12 [==============>] 99.2% Loss: 0.1433, Epoch 12, Batch 124, CE_loss: 0.11604198813438416, Dice_loss: 0.00962328352034092, Consistency_loss: 0.00019440543837845325\n",
      "[Training] Epoch: 12 [DONE]                                 \n",
      "Epoch 12, Batch 125, CE_loss: 0.12793539464473724, Dice_loss: 0.010162081569433212, Consistency_loss: 0.00025259863468818367\n",
      "[Validation] Epoch: 12 [DONE]                                 \n",
      "[Epoch: 12, TrainLoss: 0.1433, TrainDice: 0.0108, ValLoss: 0.1730                                            \n",
      "Number of batches:  126\n",
      "[Training] Epoch: 13 [>              ] 0.8% Loss: 0.1550, Epoch 13, Batch 0, CE_loss: 0.1414625346660614, Dice_loss: 0.012340857647359371, Consistency_loss: 0.001162225380539894\n",
      "[Training] Epoch: 13 [>              ] 1.6% Loss: 0.1445, Epoch 13, Batch 1, CE_loss: 0.12262696772813797, Dice_loss: 0.010105361230671406, Consistency_loss: 0.001387124415487051\n",
      "[Training] Epoch: 13 [>              ] 2.4% Loss: 0.1402, Epoch 13, Batch 2, CE_loss: 0.12111355364322662, Dice_loss: 0.00991186685860157, Consistency_loss: 0.000598614220507443\n",
      "[Training] Epoch: 13 [>              ] 3.2% Loss: 0.1363, Epoch 13, Batch 3, CE_loss: 0.11513912677764893, Dice_loss: 0.00898028165102005, Consistency_loss: 0.00024498908896930516\n",
      "[Training] Epoch: 13 [>              ] 4.0% Loss: 0.1336, Epoch 13, Batch 4, CE_loss: 0.11348836869001389, Dice_loss: 0.008428797125816345, Consistency_loss: 0.0011578688863664865\n",
      "[Training] Epoch: 13 [>              ] 4.8% Loss: 0.1337, Epoch 13, Batch 5, CE_loss: 0.12355832010507584, Dice_loss: 0.010299187153577805, Consistency_loss: 9.786124428501353e-05\n",
      "[Training] Epoch: 13 [>              ] 5.6% Loss: 0.1332, Epoch 13, Batch 6, CE_loss: 0.1196441575884819, Dice_loss: 0.009914044290781021, Consistency_loss: 0.0005537950783036649\n",
      "[Training] Epoch: 13 [>              ] 6.3% Loss: 0.1325, Epoch 13, Batch 7, CE_loss: 0.11749690771102905, Dice_loss: 0.009386610239744186, Consistency_loss: 0.000737745373044163\n",
      "[Training] Epoch: 13 [=>             ] 7.1% Loss: 0.1340, Epoch 13, Batch 8, CE_loss: 0.13389728963375092, Dice_loss: 0.011708714067935944, Consistency_loss: 0.0002800004440359771\n",
      "[Training] Epoch: 13 [=>             ] 7.9% Loss: 0.1339, Epoch 13, Batch 9, CE_loss: 0.12288282811641693, Dice_loss: 0.010204482823610306, Consistency_loss: 0.0004728288040496409\n",
      "[Training] Epoch: 13 [=>             ] 8.7% Loss: 0.1365, Epoch 13, Batch 10, CE_loss: 0.14770255982875824, Dice_loss: 0.013765879906713963, Consistency_loss: 0.00023231134400703013\n",
      "[Training] Epoch: 13 [=>             ] 9.5% Loss: 0.1365, Epoch 13, Batch 11, CE_loss: 0.12551137804985046, Dice_loss: 0.010402237065136433, Consistency_loss: 0.0005766851245425642\n",
      "[Training] Epoch: 13 [=>             ] 10.3% Loss: 0.1363, Epoch 13, Batch 12, CE_loss: 0.12408896535634995, Dice_loss: 0.009885670617222786, Consistency_loss: 0.0008869116427376866\n",
      "[Training] Epoch: 13 [=>             ] 11.1% Loss: 0.1350, Epoch 13, Batch 13, CE_loss: 0.10941565036773682, Dice_loss: 0.007685762830078602, Consistency_loss: 0.0006964399944990873\n",
      "[Training] Epoch: 13 [=>             ] 11.9% Loss: 0.1349, Epoch 13, Batch 14, CE_loss: 0.12334129214286804, Dice_loss: 0.009994774125516415, Consistency_loss: 0.0003916705900337547\n",
      "[Training] Epoch: 13 [=>             ] 12.7% Loss: 0.1350, Epoch 13, Batch 15, CE_loss: 0.12566505372524261, Dice_loss: 0.01017471868544817, Consistency_loss: 0.0004821699985768646\n",
      "[Training] Epoch: 13 [==>            ] 13.5% Loss: 0.1356, Epoch 13, Batch 16, CE_loss: 0.1328471153974533, Dice_loss: 0.011068668216466904, Consistency_loss: 0.0003414038219489157\n",
      "[Training] Epoch: 13 [==>            ] 14.3% Loss: 0.1351, Epoch 13, Batch 17, CE_loss: 0.11758757382631302, Dice_loss: 0.008750773966312408, Consistency_loss: 0.0005338307237252593\n",
      "[Training] Epoch: 13 [==>            ] 15.1% Loss: 0.1343, Epoch 13, Batch 18, CE_loss: 0.11193428188562393, Dice_loss: 0.008291799575090408, Consistency_loss: 0.0008895272621884942\n",
      "[Training] Epoch: 13 [==>            ] 15.9% Loss: 0.1343, Epoch 13, Batch 19, CE_loss: 0.12268223613500595, Dice_loss: 0.00973533745855093, Consistency_loss: 0.0006737287621945143\n",
      "[Training] Epoch: 13 [==>            ] 16.7% Loss: 0.1348, Epoch 13, Batch 20, CE_loss: 0.1331380307674408, Dice_loss: 0.010845007374882698, Consistency_loss: 0.0007980118389241397\n",
      "[Training] Epoch: 13 [==>            ] 17.5% Loss: 0.1348, Epoch 13, Batch 21, CE_loss: 0.12513169646263123, Dice_loss: 0.009936051443219185, Consistency_loss: 0.0005297993775457144\n",
      "[Training] Epoch: 13 [==>            ] 18.3% Loss: 0.1351, Epoch 13, Batch 22, CE_loss: 0.12931670248508453, Dice_loss: 0.01100383885204792, Consistency_loss: 0.0005725816590711474\n",
      "[Training] Epoch: 13 [==>            ] 19.0% Loss: 0.1350, Epoch 13, Batch 23, CE_loss: 0.12208152562379837, Dice_loss: 0.01009225845336914, Consistency_loss: 0.0006992998532950878\n",
      "[Training] Epoch: 13 [==>            ] 19.8% Loss: 0.1349, Epoch 13, Batch 24, CE_loss: 0.12259627133607864, Dice_loss: 0.01021395530551672, Consistency_loss: 0.0006403764709830284\n",
      "[Training] Epoch: 13 [===>           ] 20.6% Loss: 0.1347, Epoch 13, Batch 25, CE_loss: 0.11773496121168137, Dice_loss: 0.009757657535374165, Consistency_loss: 0.0009327337029390037\n",
      "[Training] Epoch: 13 [===>           ] 21.4% Loss: 0.1350, Epoch 13, Batch 26, CE_loss: 0.13204169273376465, Dice_loss: 0.011376285925507545, Consistency_loss: 0.0012298192596063018\n",
      "[Training] Epoch: 13 [===>           ] 22.2% Loss: 0.1346, Epoch 13, Batch 27, CE_loss: 0.11366519331932068, Dice_loss: 0.009101204574108124, Consistency_loss: 0.0011879629455506802\n",
      "[Training] Epoch: 13 [===>           ] 23.0% Loss: 0.1349, Epoch 13, Batch 28, CE_loss: 0.12968167662620544, Dice_loss: 0.011277987621724606, Consistency_loss: 0.0008546248427592218\n",
      "[Training] Epoch: 13 [===>           ] 23.8% Loss: 0.1347, Epoch 13, Batch 29, CE_loss: 0.1183745488524437, Dice_loss: 0.009502124041318893, Consistency_loss: 0.001037186710163951\n",
      "[Training] Epoch: 13 [===>           ] 24.6% Loss: 0.1346, Epoch 13, Batch 30, CE_loss: 0.12211833149194717, Dice_loss: 0.010249949991703033, Consistency_loss: 0.000843353511299938\n",
      "[Training] Epoch: 13 [===>           ] 25.4% Loss: 0.1341, Epoch 13, Batch 31, CE_loss: 0.10998119413852692, Dice_loss: 0.00853305496275425, Consistency_loss: 0.0001893504086183384\n",
      "[Training] Epoch: 13 [===>           ] 26.2% Loss: 0.1343, Epoch 13, Batch 32, CE_loss: 0.12621250748634338, Dice_loss: 0.01085575856268406, Consistency_loss: 0.0009970200480893254\n",
      "[Training] Epoch: 13 [====>          ] 27.0% Loss: 0.1341, Epoch 13, Batch 33, CE_loss: 0.11873964965343475, Dice_loss: 0.008596247993409634, Consistency_loss: 0.0005267552915029228\n",
      "[Training] Epoch: 13 [====>          ] 27.8% Loss: 0.1340, Epoch 13, Batch 34, CE_loss: 0.12253376841545105, Dice_loss: 0.009455377236008644, Consistency_loss: 0.00017319385369773954\n",
      "[Training] Epoch: 13 [====>          ] 28.6% Loss: 0.1335, Epoch 13, Batch 35, CE_loss: 0.10724354535341263, Dice_loss: 0.008011110126972198, Consistency_loss: 0.0008500083349645138\n",
      "[Training] Epoch: 13 [====>          ] 29.4% Loss: 0.1337, Epoch 13, Batch 36, CE_loss: 0.12883691489696503, Dice_loss: 0.011047715321183205, Consistency_loss: 0.0004963187384419143\n",
      "[Training] Epoch: 13 [====>          ] 30.2% Loss: 0.1339, Epoch 13, Batch 37, CE_loss: 0.12821850180625916, Dice_loss: 0.010793437249958515, Consistency_loss: 0.0009723143884912133\n",
      "[Training] Epoch: 13 [====>          ] 31.0% Loss: 0.1337, Epoch 13, Batch 38, CE_loss: 0.11615443229675293, Dice_loss: 0.009275306947529316, Consistency_loss: 0.00025000993628054857\n",
      "[Training] Epoch: 13 [====>          ] 31.7% Loss: 0.1331, Epoch 13, Batch 39, CE_loss: 0.10336044430732727, Dice_loss: 0.006962013430893421, Consistency_loss: 0.001387159456498921\n",
      "[Training] Epoch: 13 [====>          ] 32.5% Loss: 0.1334, Epoch 13, Batch 40, CE_loss: 0.13164357841014862, Dice_loss: 0.01137833297252655, Consistency_loss: 0.000536770501639694\n",
      "[Training] Epoch: 13 [=====>         ] 33.3% Loss: 0.1334, Epoch 13, Batch 41, CE_loss: 0.12290342152118683, Dice_loss: 0.010897815227508545, Consistency_loss: 0.0009501149179413915\n",
      "[Training] Epoch: 13 [=====>         ] 34.1% Loss: 0.1331, Epoch 13, Batch 42, CE_loss: 0.1113305389881134, Dice_loss: 0.008372457697987556, Consistency_loss: 0.0001149195377365686\n",
      "[Training] Epoch: 13 [=====>         ] 34.9% Loss: 0.1327, Epoch 13, Batch 43, CE_loss: 0.10941700637340546, Dice_loss: 0.00763936061412096, Consistency_loss: 0.0001803779450710863\n",
      "[Training] Epoch: 13 [=====>         ] 35.7% Loss: 0.1328, Epoch 13, Batch 44, CE_loss: 0.12320557981729507, Dice_loss: 0.010379921644926071, Consistency_loss: 0.0009813893120735884\n",
      "[Training] Epoch: 13 [=====>         ] 36.5% Loss: 0.1328, Epoch 13, Batch 45, CE_loss: 0.12349707633256912, Dice_loss: 0.010236642323434353, Consistency_loss: 0.00044929730938747525\n",
      "[Training] Epoch: 13 [=====>         ] 37.3% Loss: 0.1327, Epoch 13, Batch 46, CE_loss: 0.11949211359024048, Dice_loss: 0.00971154123544693, Consistency_loss: 0.0006496576825156808\n",
      "[Training] Epoch: 13 [=====>         ] 38.1% Loss: 0.1326, Epoch 13, Batch 47, CE_loss: 0.11616210639476776, Dice_loss: 0.008907218463718891, Consistency_loss: 0.0009062912431545556\n",
      "[Training] Epoch: 13 [=====>         ] 38.9% Loss: 0.1328, Epoch 13, Batch 48, CE_loss: 0.1286792904138565, Dice_loss: 0.010566839948296547, Consistency_loss: 0.001241033198311925\n",
      "[Training] Epoch: 13 [=====>         ] 39.7% Loss: 0.1330, Epoch 13, Batch 49, CE_loss: 0.1304359883069992, Dice_loss: 0.011498375795781612, Consistency_loss: 0.0009144592913798988\n",
      "[Training] Epoch: 13 [======>        ] 40.5% Loss: 0.1328, Epoch 13, Batch 50, CE_loss: 0.113112673163414, Dice_loss: 0.008622072637081146, Consistency_loss: 0.0007859594188630581\n",
      "[Training] Epoch: 13 [======>        ] 41.3% Loss: 0.1331, Epoch 13, Batch 51, CE_loss: 0.1378931701183319, Dice_loss: 0.01201952900737524, Consistency_loss: 0.0002787691482808441\n",
      "[Training] Epoch: 13 [======>        ] 42.1% Loss: 0.1330, Epoch 13, Batch 52, CE_loss: 0.11816713213920593, Dice_loss: 0.00994502380490303, Consistency_loss: 0.0004116075288038701\n",
      "[Training] Epoch: 13 [======>        ] 42.9% Loss: 0.1328, Epoch 13, Batch 53, CE_loss: 0.113615982234478, Dice_loss: 0.008791495114564896, Consistency_loss: 0.00018579223251435906\n",
      "[Training] Epoch: 13 [======>        ] 43.7% Loss: 0.1330, Epoch 13, Batch 54, CE_loss: 0.12945926189422607, Dice_loss: 0.010941683314740658, Consistency_loss: 0.0006911600357852876\n",
      "[Training] Epoch: 13 [======>        ] 44.4% Loss: 0.1328, Epoch 13, Batch 55, CE_loss: 0.11270783096551895, Dice_loss: 0.009266048669815063, Consistency_loss: 0.000818990811239928\n",
      "[Training] Epoch: 13 [======>        ] 45.2% Loss: 0.1325, Epoch 13, Batch 56, CE_loss: 0.10911611467599869, Dice_loss: 0.008853480219841003, Consistency_loss: 0.0009473013924434781\n",
      "[Training] Epoch: 13 [======>        ] 46.0% Loss: 0.1324, Epoch 13, Batch 57, CE_loss: 0.11338317394256592, Dice_loss: 0.008916521444916725, Consistency_loss: 0.0008094661170616746\n",
      "[Training] Epoch: 13 [=======>       ] 46.8% Loss: 0.1324, Epoch 13, Batch 58, CE_loss: 0.12481994181871414, Dice_loss: 0.010493923909962177, Consistency_loss: 0.0008179312571883202\n",
      "[Training] Epoch: 13 [=======>       ] 47.6% Loss: 0.1323, Epoch 13, Batch 59, CE_loss: 0.11287122219800949, Dice_loss: 0.009391192346811295, Consistency_loss: 0.0007618916570208967\n",
      "[Training] Epoch: 13 [=======>       ] 48.4% Loss: 0.1320, Epoch 13, Batch 60, CE_loss: 0.1072370782494545, Dice_loss: 0.00838908739387989, Consistency_loss: 0.0001352208637399599\n",
      "[Training] Epoch: 13 [=======>       ] 49.2% Loss: 0.1323, Epoch 13, Batch 61, CE_loss: 0.13541050255298615, Dice_loss: 0.012117608450353146, Consistency_loss: 0.0007737895357422531\n",
      "[Training] Epoch: 13 [=======>       ] 50.0% Loss: 0.1323, Epoch 13, Batch 62, CE_loss: 0.1247124895453453, Dice_loss: 0.010388508439064026, Consistency_loss: 0.0009005533647723496\n",
      "[Training] Epoch: 13 [=======>       ] 50.8% Loss: 0.1321, Epoch 13, Batch 63, CE_loss: 0.11041706800460815, Dice_loss: 0.008283703587949276, Consistency_loss: 0.00019685670849867165\n",
      "[Training] Epoch: 13 [=======>       ] 51.6% Loss: 0.1320, Epoch 13, Batch 64, CE_loss: 0.11495465785264969, Dice_loss: 0.009239951148629189, Consistency_loss: 0.001033702865242958\n",
      "[Training] Epoch: 13 [=======>       ] 52.4% Loss: 0.1319, Epoch 13, Batch 65, CE_loss: 0.11681642383337021, Dice_loss: 0.009261632338166237, Consistency_loss: 0.0002177815476898104\n",
      "[Training] Epoch: 13 [=======>       ] 53.2% Loss: 0.1319, Epoch 13, Batch 66, CE_loss: 0.11738362908363342, Dice_loss: 0.009665845893323421, Consistency_loss: 0.0006626515532843769\n",
      "[Training] Epoch: 13 [========>      ] 54.0% Loss: 0.1317, Epoch 13, Batch 67, CE_loss: 0.10904839634895325, Dice_loss: 0.008386168628931046, Consistency_loss: 0.0009226823458448052\n",
      "[Training] Epoch: 13 [========>      ] 54.8% Loss: 0.1315, Epoch 13, Batch 68, CE_loss: 0.11066694557666779, Dice_loss: 0.008371581323444843, Consistency_loss: 0.0005053873173892498\n",
      "[Training] Epoch: 13 [========>      ] 55.6% Loss: 0.1314, Epoch 13, Batch 69, CE_loss: 0.11606906354427338, Dice_loss: 0.008684344589710236, Consistency_loss: 0.0005075547378510237\n",
      "[Training] Epoch: 13 [========>      ] 56.3% Loss: 0.1315, Epoch 13, Batch 70, CE_loss: 0.129083514213562, Dice_loss: 0.010610662400722504, Consistency_loss: 0.000736227841116488\n",
      "[Training] Epoch: 13 [========>      ] 57.1% Loss: 0.1313, Epoch 13, Batch 71, CE_loss: 0.10875891149044037, Dice_loss: 0.008130120113492012, Consistency_loss: 0.0009658467024564743\n",
      "[Training] Epoch: 13 [========>      ] 57.9% Loss: 0.1312, Epoch 13, Batch 72, CE_loss: 0.10945078730583191, Dice_loss: 0.008282434195280075, Consistency_loss: 0.0007069478160701692\n",
      "[Training] Epoch: 13 [========>      ] 58.7% Loss: 0.1310, Epoch 13, Batch 73, CE_loss: 0.11218298226594925, Dice_loss: 0.008715704083442688, Consistency_loss: 0.0006503989570774138\n",
      "[Training] Epoch: 13 [========>      ] 59.5% Loss: 0.1309, Epoch 13, Batch 74, CE_loss: 0.11021367460489273, Dice_loss: 0.008661877363920212, Consistency_loss: 0.0008927892777137458\n",
      "[Training] Epoch: 13 [=========>     ] 60.3% Loss: 0.1308, Epoch 13, Batch 75, CE_loss: 0.11463933438062668, Dice_loss: 0.009222347289323807, Consistency_loss: 0.0008746871608309448\n",
      "[Training] Epoch: 13 [=========>     ] 61.1% Loss: 0.1306, Epoch 13, Batch 76, CE_loss: 0.10634748637676239, Dice_loss: 0.008007225580513477, Consistency_loss: 0.001147640054114163\n",
      "[Training] Epoch: 13 [=========>     ] 61.9% Loss: 0.1305, Epoch 13, Batch 77, CE_loss: 0.11119205504655838, Dice_loss: 0.008525066077709198, Consistency_loss: 0.0010428543901070952\n",
      "[Training] Epoch: 13 [=========>     ] 62.7% Loss: 0.1303, Epoch 13, Batch 78, CE_loss: 0.11040475964546204, Dice_loss: 0.009017332457005978, Consistency_loss: 0.00048612101818434894\n",
      "[Training] Epoch: 13 [=========>     ] 63.5% Loss: 0.1302, Epoch 13, Batch 79, CE_loss: 0.10757078230381012, Dice_loss: 0.0077357725240290165, Consistency_loss: 0.00015352485934272408\n",
      "[Training] Epoch: 13 [=========>     ] 64.3% Loss: 0.1301, Epoch 13, Batch 80, CE_loss: 0.11717450618743896, Dice_loss: 0.009077891707420349, Consistency_loss: 0.0006145752849988639\n",
      "[Training] Epoch: 13 [=========>     ] 65.1% Loss: 0.1302, Epoch 13, Batch 81, CE_loss: 0.12226552516222, Dice_loss: 0.010284055024385452, Consistency_loss: 0.0008376175537705421\n",
      "[Training] Epoch: 13 [=========>     ] 65.9% Loss: 0.1303, Epoch 13, Batch 82, CE_loss: 0.1289462000131607, Dice_loss: 0.011181343346834183, Consistency_loss: 0.0008308334508910775\n",
      "[Training] Epoch: 13 [==========>    ] 66.7% Loss: 0.1306, Epoch 13, Batch 83, CE_loss: 0.14328016340732574, Dice_loss: 0.012863289564847946, Consistency_loss: 0.000383066653739661\n",
      "[Training] Epoch: 13 [==========>    ] 67.5% Loss: 0.1307, Epoch 13, Batch 84, CE_loss: 0.12781915068626404, Dice_loss: 0.01049025822430849, Consistency_loss: 0.000731822510715574\n",
      "[Training] Epoch: 13 [==========>    ] 68.3% Loss: 0.1306, Epoch 13, Batch 85, CE_loss: 0.10917478799819946, Dice_loss: 0.008665278553962708, Consistency_loss: 0.00026372840511612594\n",
      "[Training] Epoch: 13 [==========>    ] 69.0% Loss: 0.1304, Epoch 13, Batch 86, CE_loss: 0.11176743358373642, Dice_loss: 0.008963804692029953, Consistency_loss: 0.0005981565336696804\n",
      "[Training] Epoch: 13 [==========>    ] 69.8% Loss: 0.1303, Epoch 13, Batch 87, CE_loss: 0.11070942133665085, Dice_loss: 0.008719880133867264, Consistency_loss: 0.0006449557258747518\n",
      "[Training] Epoch: 13 [==========>    ] 70.6% Loss: 0.1304, Epoch 13, Batch 88, CE_loss: 0.12330134212970734, Dice_loss: 0.011030660942196846, Consistency_loss: 0.0006586845847778022\n",
      "[Training] Epoch: 13 [==========>    ] 71.4% Loss: 0.1302, Epoch 13, Batch 89, CE_loss: 0.10829385370016098, Dice_loss: 0.008747457526624203, Consistency_loss: 0.0009327419102191925\n",
      "[Training] Epoch: 13 [==========>    ] 72.2% Loss: 0.1301, Epoch 13, Batch 90, CE_loss: 0.1103353425860405, Dice_loss: 0.009160075336694717, Consistency_loss: 0.0001858578179962933\n",
      "[Training] Epoch: 13 [==========>    ] 73.0% Loss: 0.1300, Epoch 13, Batch 91, CE_loss: 0.11179867386817932, Dice_loss: 0.009211944416165352, Consistency_loss: 0.0012660800712183118\n",
      "[Training] Epoch: 13 [===========>   ] 73.8% Loss: 0.1299, Epoch 13, Batch 92, CE_loss: 0.10580962896347046, Dice_loss: 0.008475879207253456, Consistency_loss: 0.0009457631385885179\n",
      "[Training] Epoch: 13 [===========>   ] 74.6% Loss: 0.1299, Epoch 13, Batch 93, CE_loss: 0.12133056670427322, Dice_loss: 0.01076001301407814, Consistency_loss: 0.0009771848563104868\n",
      "[Training] Epoch: 13 [===========>   ] 75.4% Loss: 0.1301, Epoch 13, Batch 94, CE_loss: 0.130981907248497, Dice_loss: 0.011787150986492634, Consistency_loss: 0.00016118962957989424\n",
      "[Training] Epoch: 13 [===========>   ] 76.2% Loss: 0.1301, Epoch 13, Batch 95, CE_loss: 0.11983786523342133, Dice_loss: 0.009910865686833858, Consistency_loss: 0.0007477634935639799\n",
      "[Training] Epoch: 13 [===========>   ] 77.0% Loss: 0.1302, Epoch 13, Batch 96, CE_loss: 0.12797513604164124, Dice_loss: 0.010775391012430191, Consistency_loss: 0.000805892632342875\n",
      "[Training] Epoch: 13 [===========>   ] 77.8% Loss: 0.1304, Epoch 13, Batch 97, CE_loss: 0.1409188210964203, Dice_loss: 0.013085135258734226, Consistency_loss: 0.000900043174624443\n",
      "[Training] Epoch: 13 [===========>   ] 78.6% Loss: 0.1304, Epoch 13, Batch 98, CE_loss: 0.12236978858709335, Dice_loss: 0.010117650032043457, Consistency_loss: 0.000755990797188133\n",
      "[Training] Epoch: 13 [===========>   ] 79.4% Loss: 0.1304, Epoch 13, Batch 99, CE_loss: 0.1166977733373642, Dice_loss: 0.009908978827297688, Consistency_loss: 0.0007349258521571755\n",
      "[Training] Epoch: 13 [============>  ] 80.2% Loss: 0.1304, Epoch 13, Batch 100, CE_loss: 0.1202184334397316, Dice_loss: 0.01027101930230856, Consistency_loss: 0.00016336147382389754\n",
      "[Training] Epoch: 13 [============>  ] 81.0% Loss: 0.1305, Epoch 13, Batch 101, CE_loss: 0.12696801126003265, Dice_loss: 0.011142052710056305, Consistency_loss: 0.0008136795950122178\n",
      "[Training] Epoch: 13 [============>  ] 81.7% Loss: 0.1304, Epoch 13, Batch 102, CE_loss: 0.10800030827522278, Dice_loss: 0.009069863706827164, Consistency_loss: 0.0007553601171821356\n",
      "[Training] Epoch: 13 [============>  ] 82.5% Loss: 0.1303, Epoch 13, Batch 103, CE_loss: 0.11506237834692001, Dice_loss: 0.009702314622700214, Consistency_loss: 0.0008545700693503022\n",
      "[Training] Epoch: 13 [============>  ] 83.3% Loss: 0.1302, Epoch 13, Batch 104, CE_loss: 0.10963640362024307, Dice_loss: 0.00878296047449112, Consistency_loss: 0.0007793541299179196\n",
      "[Training] Epoch: 13 [============>  ] 84.1% Loss: 0.1301, Epoch 13, Batch 105, CE_loss: 0.10678838938474655, Dice_loss: 0.008181489072740078, Consistency_loss: 0.0008611906669102609\n",
      "[Training] Epoch: 13 [============>  ] 84.9% Loss: 0.1300, Epoch 13, Batch 106, CE_loss: 0.1158779188990593, Dice_loss: 0.009725332260131836, Consistency_loss: 0.00010109566210303456\n",
      "[Training] Epoch: 13 [============>  ] 85.7% Loss: 0.1300, Epoch 13, Batch 107, CE_loss: 0.11398342251777649, Dice_loss: 0.009434237144887447, Consistency_loss: 0.0006061182939447463\n",
      "[Training] Epoch: 13 [============>  ] 86.5% Loss: 0.1299, Epoch 13, Batch 108, CE_loss: 0.11249342560768127, Dice_loss: 0.009068500250577927, Consistency_loss: 0.00022574308968614787\n",
      "[Training] Epoch: 13 [=============> ] 87.3% Loss: 0.1299, Epoch 13, Batch 109, CE_loss: 0.11506011337041855, Dice_loss: 0.009718760848045349, Consistency_loss: 0.0008885936113074422\n",
      "[Training] Epoch: 13 [=============> ] 88.1% Loss: 0.1297, Epoch 13, Batch 110, CE_loss: 0.10297761112451553, Dice_loss: 0.007733162026852369, Consistency_loss: 0.0008567425538785756\n",
      "[Training] Epoch: 13 [=============> ] 88.9% Loss: 0.1297, Epoch 13, Batch 111, CE_loss: 0.12251843512058258, Dice_loss: 0.01025294978171587, Consistency_loss: 0.0007030907436273992\n",
      "[Training] Epoch: 13 [=============> ] 89.7% Loss: 0.1298, Epoch 13, Batch 112, CE_loss: 0.12353136390447617, Dice_loss: 0.010192949324846268, Consistency_loss: 0.000647015287540853\n",
      "[Training] Epoch: 13 [=============> ] 90.5% Loss: 0.1299, Epoch 13, Batch 113, CE_loss: 0.12750692665576935, Dice_loss: 0.010899478569626808, Consistency_loss: 0.0007824774947948754\n",
      "[Training] Epoch: 13 [=============> ] 91.3% Loss: 0.1300, Epoch 13, Batch 114, CE_loss: 0.12869715690612793, Dice_loss: 0.010906501673161983, Consistency_loss: 0.001028045080602169\n",
      "[Training] Epoch: 13 [=============> ] 92.1% Loss: 0.1299, Epoch 13, Batch 115, CE_loss: 0.11272506415843964, Dice_loss: 0.009042290039360523, Consistency_loss: 0.0007365265628322959\n",
      "[Training] Epoch: 13 [=============> ] 92.9% Loss: 0.1299, Epoch 13, Batch 116, CE_loss: 0.11947157979011536, Dice_loss: 0.009846013970673084, Consistency_loss: 0.0003547262749634683\n",
      "[Training] Epoch: 13 [==============>] 93.7% Loss: 0.1298, Epoch 13, Batch 117, CE_loss: 0.10777515172958374, Dice_loss: 0.00827734638005495, Consistency_loss: 0.001119861495681107\n",
      "[Training] Epoch: 13 [==============>] 94.4% Loss: 0.1299, Epoch 13, Batch 118, CE_loss: 0.12824466824531555, Dice_loss: 0.011436223983764648, Consistency_loss: 0.0005777381593361497\n",
      "[Training] Epoch: 13 [==============>] 95.2% Loss: 0.1300, Epoch 13, Batch 119, CE_loss: 0.12814925611019135, Dice_loss: 0.011094797402620316, Consistency_loss: 0.00017308669339399785\n",
      "[Training] Epoch: 13 [==============>] 96.0% Loss: 0.1300, Epoch 13, Batch 120, CE_loss: 0.12260499596595764, Dice_loss: 0.010912854224443436, Consistency_loss: 0.0007885467493906617\n",
      "[Training] Epoch: 13 [==============>] 96.8% Loss: 0.1299, Epoch 13, Batch 121, CE_loss: 0.11453661322593689, Dice_loss: 0.009569872170686722, Consistency_loss: 0.00067835149820894\n",
      "[Training] Epoch: 13 [==============>] 97.6% Loss: 0.1301, Epoch 13, Batch 122, CE_loss: 0.137262761592865, Dice_loss: 0.012166071683168411, Consistency_loss: 0.0006173868896439672\n",
      "[Training] Epoch: 13 [==============>] 98.4% Loss: 0.1302, Epoch 13, Batch 123, CE_loss: 0.12399787455797195, Dice_loss: 0.011010866612195969, Consistency_loss: 0.0013153066392987967\n",
      "[Training] Epoch: 13 [==============>] 99.2% Loss: 0.1301, Epoch 13, Batch 124, CE_loss: 0.10948546230792999, Dice_loss: 0.009289969690144062, Consistency_loss: 0.00024626837694086134\n",
      "[Training] Epoch: 13 [DONE]                                 \n",
      "Epoch 13, Batch 125, CE_loss: 0.11989380419254303, Dice_loss: 0.010298427194356918, Consistency_loss: 0.001696425722911954\n",
      "[Validation] Epoch: 13 [DONE]                                 \n",
      "[Epoch: 13, TrainLoss: 0.1301, TrainDice: 0.0098, ValLoss: 0.1823                                            \n",
      "Number of batches:  126\n",
      "[Training] Epoch: 14 [>              ] 0.8% Loss: 0.1239, Epoch 14, Batch 0, CE_loss: 0.11276489496231079, Dice_loss: 0.009479065425693989, Consistency_loss: 0.0016074221348389983\n",
      "[Training] Epoch: 14 [>              ] 1.6% Loss: 0.1268, Epoch 14, Batch 1, CE_loss: 0.11764109134674072, Dice_loss: 0.010537872090935707, Consistency_loss: 0.0016047459794208407\n",
      "[Training] Epoch: 14 [>              ] 2.4% Loss: 0.1225, Epoch 14, Batch 2, CE_loss: 0.10545332729816437, Dice_loss: 0.00829790998250246, Consistency_loss: 0.00013404157652985305\n",
      "[Training] Epoch: 14 [>              ] 3.2% Loss: 0.1217, Epoch 14, Batch 3, CE_loss: 0.10944359004497528, Dice_loss: 0.008836654014885426, Consistency_loss: 0.0008712374838069081\n",
      "[Training] Epoch: 14 [>              ] 4.0% Loss: 0.1221, Epoch 14, Batch 4, CE_loss: 0.11390672624111176, Dice_loss: 0.009626738727092743, Consistency_loss: 0.0001375926221953705\n",
      "[Training] Epoch: 14 [>              ] 4.8% Loss: 0.1207, Epoch 14, Batch 5, CE_loss: 0.10571839660406113, Dice_loss: 0.00824798084795475, Consistency_loss: 9.512918768450618e-05\n",
      "[Training] Epoch: 14 [>              ] 5.6% Loss: 0.1223, Epoch 14, Batch 6, CE_loss: 0.12089034169912338, Dice_loss: 0.010441746562719345, Consistency_loss: 0.000616749282926321\n",
      "[Training] Epoch: 14 [>              ] 6.3% Loss: 0.1213, Epoch 14, Batch 7, CE_loss: 0.10508506745100021, Dice_loss: 0.008461274206638336, Consistency_loss: 0.0007247174507938325\n",
      "[Training] Epoch: 14 [=>             ] 7.1% Loss: 0.1227, Epoch 14, Batch 8, CE_loss: 0.12256155908107758, Dice_loss: 0.010712828487157822, Consistency_loss: 0.00035753054544329643\n",
      "[Training] Epoch: 14 [=>             ] 7.9% Loss: 0.1231, Epoch 14, Batch 9, CE_loss: 0.11701127141714096, Dice_loss: 0.00943200197070837, Consistency_loss: 0.0004964762483723462\n",
      "[Training] Epoch: 14 [=>             ] 8.7% Loss: 0.1220, Epoch 14, Batch 10, CE_loss: 0.10209304094314575, Dice_loss: 0.00782578345388174, Consistency_loss: 0.0006538187153637409\n",
      "[Training] Epoch: 14 [=>             ] 9.5% Loss: 0.1217, Epoch 14, Batch 11, CE_loss: 0.10883908718824387, Dice_loss: 0.008579913526773453, Consistency_loss: 0.000858968123793602\n",
      "[Training] Epoch: 14 [=>             ] 10.3% Loss: 0.1221, Epoch 14, Batch 12, CE_loss: 0.11653643846511841, Dice_loss: 0.009623181074857712, Consistency_loss: 0.0008903401321731508\n",
      "[Training] Epoch: 14 [=>             ] 11.1% Loss: 0.1237, Epoch 14, Batch 13, CE_loss: 0.13288353383541107, Dice_loss: 0.011440551839768887, Consistency_loss: 0.0008295048028230667\n",
      "[Training] Epoch: 14 [=>             ] 11.9% Loss: 0.1245, Epoch 14, Batch 14, CE_loss: 0.12471236288547516, Dice_loss: 0.010279834270477295, Consistency_loss: 0.0006619351916015148\n",
      "[Training] Epoch: 14 [=>             ] 12.7% Loss: 0.1237, Epoch 14, Batch 15, CE_loss: 0.10360638052225113, Dice_loss: 0.007471704855561256, Consistency_loss: 0.0005088392645120621\n",
      "[Training] Epoch: 14 [==>            ] 13.5% Loss: 0.1242, Epoch 14, Batch 16, CE_loss: 0.12144695222377777, Dice_loss: 0.01057373732328415, Consistency_loss: 0.000552365614566952\n",
      "[Training] Epoch: 14 [==>            ] 14.3% Loss: 0.1241, Epoch 14, Batch 17, CE_loss: 0.11221262812614441, Dice_loss: 0.008848062716424465, Consistency_loss: 0.00012452642840798944\n",
      "[Training] Epoch: 14 [==>            ] 15.1% Loss: 0.1233, Epoch 14, Batch 18, CE_loss: 0.10108816623687744, Dice_loss: 0.007976402528584003, Consistency_loss: 0.000755791028495878\n",
      "[Training] Epoch: 14 [==>            ] 15.9% Loss: 0.1230, Epoch 14, Batch 19, CE_loss: 0.10832332074642181, Dice_loss: 0.008565929718315601, Consistency_loss: 0.0005525136948563159\n",
      "[Training] Epoch: 14 [==>            ] 16.7% Loss: 0.1228, Epoch 14, Batch 20, CE_loss: 0.10944958031177521, Dice_loss: 0.008669968694448471, Consistency_loss: 0.0007173439371399581\n",
      "[Training] Epoch: 14 [==>            ] 17.5% Loss: 0.1224, Epoch 14, Batch 21, CE_loss: 0.10560458153486252, Dice_loss: 0.008175834082067013, Consistency_loss: 0.0005576371331699193\n",
      "[Training] Epoch: 14 [==>            ] 18.3% Loss: 0.1226, Epoch 14, Batch 22, CE_loss: 0.1156175285577774, Dice_loss: 0.009632532484829426, Consistency_loss: 0.0004999962984584272\n",
      "[Training] Epoch: 14 [==>            ] 19.0% Loss: 0.1225, Epoch 14, Batch 23, CE_loss: 0.11096048355102539, Dice_loss: 0.00964262243360281, Consistency_loss: 0.0006219797651283443\n",
      "[Training] Epoch: 14 [==>            ] 19.8% Loss: 0.1227, Epoch 14, Batch 24, CE_loss: 0.11666437238454819, Dice_loss: 0.009610019624233246, Consistency_loss: 0.00016306601173710078\n",
      "[Training] Epoch: 14 [===>           ] 20.6% Loss: 0.1229, Epoch 14, Batch 25, CE_loss: 0.11672131717205048, Dice_loss: 0.010178863070905209, Consistency_loss: 0.0007906144601292908\n",
      "[Training] Epoch: 14 [===>           ] 21.4% Loss: 0.1225, Epoch 14, Batch 26, CE_loss: 0.10408715903759003, Dice_loss: 0.008001302368938923, Consistency_loss: 0.001078035100363195\n",
      "[Training] Epoch: 14 [===>           ] 22.2% Loss: 0.1227, Epoch 14, Batch 27, CE_loss: 0.11566640436649323, Dice_loss: 0.009725555777549744, Consistency_loss: 0.0010927377734333277\n",
      "[Training] Epoch: 14 [===>           ] 23.0% Loss: 0.1227, Epoch 14, Batch 28, CE_loss: 0.11275932937860489, Dice_loss: 0.009486906230449677, Consistency_loss: 0.000564533460419625\n",
      "[Training] Epoch: 14 [===>           ] 23.8% Loss: 0.1226, Epoch 14, Batch 29, CE_loss: 0.1102222427725792, Dice_loss: 0.008709799498319626, Consistency_loss: 0.0006355687510222197\n",
      "[Training] Epoch: 14 [===>           ] 24.6% Loss: 0.1226, Epoch 14, Batch 30, CE_loss: 0.11332984268665314, Dice_loss: 0.00955626368522644, Consistency_loss: 0.0010376822901889682\n",
      "[Training] Epoch: 14 [===>           ] 25.4% Loss: 0.1236, Epoch 14, Batch 31, CE_loss: 0.1421063393354416, Dice_loss: 0.013057293370366096, Consistency_loss: 0.0006910906522534788\n",
      "[Training] Epoch: 14 [===>           ] 26.2% Loss: 0.1237, Epoch 14, Batch 32, CE_loss: 0.1144997626543045, Dice_loss: 0.009552679024636745, Consistency_loss: 0.0008942265994846821\n",
      "[Training] Epoch: 14 [====>          ] 27.0% Loss: 0.1236, Epoch 14, Batch 33, CE_loss: 0.11171717196702957, Dice_loss: 0.008978301659226418, Consistency_loss: 0.0004794053384102881\n",
      "[Training] Epoch: 14 [====>          ] 27.8% Loss: 0.1233, Epoch 14, Batch 34, CE_loss: 0.10567528009414673, Dice_loss: 0.008432029746472836, Consistency_loss: 0.00015629497647751123\n",
      "[Training] Epoch: 14 [====>          ] 28.6% Loss: 0.1231, Epoch 14, Batch 35, CE_loss: 0.10580983012914658, Dice_loss: 0.008364491164684296, Consistency_loss: 0.00020507792942225933\n",
      "[Training] Epoch: 14 [====>          ] 29.4% Loss: 0.1225, Epoch 14, Batch 36, CE_loss: 0.0938546359539032, Dice_loss: 0.006433126516640186, Consistency_loss: 0.0005505801527760923\n",
      "[Training] Epoch: 14 [====>          ] 30.2% Loss: 0.1227, Epoch 14, Batch 37, CE_loss: 0.11782533675432205, Dice_loss: 0.010104824788868427, Consistency_loss: 0.0006484456826001406\n",
      "[Training] Epoch: 14 [====>          ] 31.0% Loss: 0.1228, Epoch 14, Batch 38, CE_loss: 0.1162247583270073, Dice_loss: 0.009776419959962368, Consistency_loss: 0.000969564076513052\n",
      "[Training] Epoch: 14 [====>          ] 31.7% Loss: 0.1227, Epoch 14, Batch 39, CE_loss: 0.11098095774650574, Dice_loss: 0.00877389032393694, Consistency_loss: 0.0010933142621070147\n",
      "[Training] Epoch: 14 [====>          ] 32.5% Loss: 0.1227, Epoch 14, Batch 40, CE_loss: 0.11317773908376694, Dice_loss: 0.009540058672428131, Consistency_loss: 0.0007538446225225925\n",
      "[Training] Epoch: 14 [=====>         ] 33.3% Loss: 0.1225, Epoch 14, Batch 41, CE_loss: 0.10416719317436218, Dice_loss: 0.008063270710408688, Consistency_loss: 0.0009710010490380228\n",
      "[Training] Epoch: 14 [=====>         ] 34.1% Loss: 0.1227, Epoch 14, Batch 42, CE_loss: 0.1204889565706253, Dice_loss: 0.010468559339642525, Consistency_loss: 0.0001531666930532083\n",
      "[Training] Epoch: 14 [=====>         ] 34.9% Loss: 0.1229, Epoch 14, Batch 43, CE_loss: 0.12111373990774155, Dice_loss: 0.010064779780805111, Consistency_loss: 0.00014773111615795642\n",
      "[Training] Epoch: 14 [=====>         ] 35.7% Loss: 0.1233, Epoch 14, Batch 44, CE_loss: 0.13018247485160828, Dice_loss: 0.011323620565235615, Consistency_loss: 0.0011014395859092474\n",
      "[Training] Epoch: 14 [=====>         ] 36.5% Loss: 0.1235, Epoch 14, Batch 45, CE_loss: 0.1182890236377716, Dice_loss: 0.010070733726024628, Consistency_loss: 0.0005269217072054744\n",
      "[Training] Epoch: 14 [=====>         ] 37.3% Loss: 0.1232, Epoch 14, Batch 46, CE_loss: 0.10432928800582886, Dice_loss: 0.008540435694158077, Consistency_loss: 0.00035953085171058774\n",
      "[Training] Epoch: 14 [=====>         ] 38.1% Loss: 0.1232, Epoch 14, Batch 47, CE_loss: 0.10992935299873352, Dice_loss: 0.009322550147771835, Consistency_loss: 0.00015967246145009995\n",
      "[Training] Epoch: 14 [=====>         ] 38.9% Loss: 0.1231, Epoch 14, Batch 48, CE_loss: 0.1090749055147171, Dice_loss: 0.008989419788122177, Consistency_loss: 0.00039826822467148304\n",
      "[Training] Epoch: 14 [=====>         ] 39.7% Loss: 0.1228, Epoch 14, Batch 49, CE_loss: 0.09981825947761536, Dice_loss: 0.007646133191883564, Consistency_loss: 0.001045541255734861\n",
      "[Training] Epoch: 14 [======>        ] 40.5% Loss: 0.1233, Epoch 14, Batch 50, CE_loss: 0.13608238101005554, Dice_loss: 0.01248227246105671, Consistency_loss: 0.0014691752148792148\n",
      "[Training] Epoch: 14 [======>        ] 41.3% Loss: 0.1232, Epoch 14, Batch 51, CE_loss: 0.10914690792560577, Dice_loss: 0.00927271880209446, Consistency_loss: 0.0009369207546114922\n",
      "[Training] Epoch: 14 [======>        ] 42.1% Loss: 0.1232, Epoch 14, Batch 52, CE_loss: 0.11020328849554062, Dice_loss: 0.009169614873826504, Consistency_loss: 0.00038558366941288114\n",
      "[Training] Epoch: 14 [======>        ] 42.9% Loss: 0.1232, Epoch 14, Batch 53, CE_loss: 0.116530641913414, Dice_loss: 0.009763259440660477, Consistency_loss: 0.0006232200539670885\n",
      "[Training] Epoch: 14 [======>        ] 43.7% Loss: 0.1230, Epoch 14, Batch 54, CE_loss: 0.10233639925718307, Dice_loss: 0.0078203696757555, Consistency_loss: 0.0008034423226490617\n",
      "[Training] Epoch: 14 [======>        ] 44.4% Loss: 0.1230, Epoch 14, Batch 55, CE_loss: 0.11407113820314407, Dice_loss: 0.009695720858871937, Consistency_loss: 0.0007723835296928883\n",
      "[Training] Epoch: 14 [======>        ] 45.2% Loss: 0.1230, Epoch 14, Batch 56, CE_loss: 0.11097028851509094, Dice_loss: 0.00952465832233429, Consistency_loss: 0.00016127216804306954\n",
      "[Training] Epoch: 14 [======>        ] 46.0% Loss: 0.1228, Epoch 14, Batch 57, CE_loss: 0.10296252369880676, Dice_loss: 0.007875815033912659, Consistency_loss: 0.0006912704557180405\n",
      "[Training] Epoch: 14 [=======>       ] 46.8% Loss: 0.1228, Epoch 14, Batch 58, CE_loss: 0.11029797792434692, Dice_loss: 0.009167678654193878, Consistency_loss: 0.00073050003265962\n",
      "[Training] Epoch: 14 [=======>       ] 47.6% Loss: 0.1228, Epoch 14, Batch 59, CE_loss: 0.11444302648305893, Dice_loss: 0.009653368964791298, Consistency_loss: 9.238105121767148e-05\n",
      "[Training] Epoch: 14 [=======>       ] 48.4% Loss: 0.1227, Epoch 14, Batch 60, CE_loss: 0.11047188192605972, Dice_loss: 0.009207375347614288, Consistency_loss: 0.0006373251671902835\n",
      "[Training] Epoch: 14 [=======>       ] 49.2% Loss: 0.1227, Epoch 14, Batch 61, CE_loss: 0.10996963083744049, Dice_loss: 0.008141854777932167, Consistency_loss: 0.0006985415238887072\n",
      "[Training] Epoch: 14 [=======>       ] 50.0% Loss: 0.1228, Epoch 14, Batch 62, CE_loss: 0.11935322731733322, Dice_loss: 0.00990954227745533, Consistency_loss: 9.692991443444043e-05\n",
      "[Training] Epoch: 14 [=======>       ] 50.8% Loss: 0.1230, Epoch 14, Batch 63, CE_loss: 0.12362485378980637, Dice_loss: 0.010787863284349442, Consistency_loss: 0.0010156736243516207\n",
      "[Training] Epoch: 14 [=======>       ] 51.6% Loss: 0.1231, Epoch 14, Batch 64, CE_loss: 0.11724166572093964, Dice_loss: 0.01051362045109272, Consistency_loss: 0.0011704948265105486\n",
      "[Training] Epoch: 14 [=======>       ] 52.4% Loss: 0.1231, Epoch 14, Batch 65, CE_loss: 0.11408261209726334, Dice_loss: 0.009408791549503803, Consistency_loss: 0.00019914261065423489\n",
      "[Training] Epoch: 14 [=======>       ] 53.2% Loss: 0.1231, Epoch 14, Batch 66, CE_loss: 0.11223714053630829, Dice_loss: 0.009653190150856972, Consistency_loss: 0.0006946397479623556\n",
      "[Training] Epoch: 14 [========>      ] 54.0% Loss: 0.1229, Epoch 14, Batch 67, CE_loss: 0.10393839329481125, Dice_loss: 0.008594303391873837, Consistency_loss: 0.0011766141979023814\n",
      "[Training] Epoch: 14 [========>      ] 54.8% Loss: 0.1228, Epoch 14, Batch 68, CE_loss: 0.10521673411130905, Dice_loss: 0.008584888651967049, Consistency_loss: 0.00020973992650397122\n",
      "[Training] Epoch: 14 [========>      ] 55.6% Loss: 0.1227, Epoch 14, Batch 69, CE_loss: 0.10331401973962784, Dice_loss: 0.008294678293168545, Consistency_loss: 0.0007326347404159606\n",
      "[Training] Epoch: 14 [========>      ] 56.3% Loss: 0.1226, Epoch 14, Batch 70, CE_loss: 0.1095397099852562, Dice_loss: 0.009806433692574501, Consistency_loss: 0.00018280991935171187\n",
      "[Training] Epoch: 14 [========>      ] 57.1% Loss: 0.1224, Epoch 14, Batch 71, CE_loss: 0.10207685083150864, Dice_loss: 0.008265308104455471, Consistency_loss: 0.00019263860303908587\n",
      "[Training] Epoch: 14 [========>      ] 57.9% Loss: 0.1223, Epoch 14, Batch 72, CE_loss: 0.10014250129461288, Dice_loss: 0.008003953844308853, Consistency_loss: 0.0008173822425305843\n",
      "[Training] Epoch: 14 [========>      ] 58.7% Loss: 0.1222, Epoch 14, Batch 73, CE_loss: 0.10643596947193146, Dice_loss: 0.008831517770886421, Consistency_loss: 0.000877640675753355\n",
      "[Training] Epoch: 14 [========>      ] 59.5% Loss: 0.1221, Epoch 14, Batch 74, CE_loss: 0.1050201877951622, Dice_loss: 0.008695194497704506, Consistency_loss: 0.0009333773632533848\n",
      "[Training] Epoch: 14 [=========>     ] 60.3% Loss: 0.1220, Epoch 14, Batch 75, CE_loss: 0.10785990953445435, Dice_loss: 0.008871840313076973, Consistency_loss: 0.0008069652249105275\n",
      "[Training] Epoch: 14 [=========>     ] 61.1% Loss: 0.1219, Epoch 14, Batch 76, CE_loss: 0.10124373435974121, Dice_loss: 0.007782255299389362, Consistency_loss: 0.0009403264266438782\n",
      "[Training] Epoch: 14 [=========>     ] 61.9% Loss: 0.1219, Epoch 14, Batch 77, CE_loss: 0.11244088411331177, Dice_loss: 0.009801221080124378, Consistency_loss: 0.00023273219994734973\n",
      "[Training] Epoch: 14 [=========>     ] 62.7% Loss: 0.1219, Epoch 14, Batch 78, CE_loss: 0.11177009344100952, Dice_loss: 0.00937981903553009, Consistency_loss: 0.0007289797067642212\n",
      "[Training] Epoch: 14 [=========>     ] 63.5% Loss: 0.1219, Epoch 14, Batch 79, CE_loss: 0.11219742894172668, Dice_loss: 0.009821302257478237, Consistency_loss: 0.0008807624108158052\n",
      "[Training] Epoch: 14 [=========>     ] 64.3% Loss: 0.1217, Epoch 14, Batch 80, CE_loss: 0.10128175467252731, Dice_loss: 0.008183647878468037, Consistency_loss: 0.0007809838280081749\n",
      "[Training] Epoch: 14 [=========>     ] 65.1% Loss: 0.1218, Epoch 14, Batch 81, CE_loss: 0.1148112565279007, Dice_loss: 0.010115808807313442, Consistency_loss: 0.0010332049569115043\n",
      "[Training] Epoch: 14 [=========>     ] 65.9% Loss: 0.1216, Epoch 14, Batch 82, CE_loss: 0.10158083587884903, Dice_loss: 0.008042626082897186, Consistency_loss: 0.00018153121345676482\n",
      "[Training] Epoch: 14 [==========>    ] 66.7% Loss: 0.1217, Epoch 14, Batch 83, CE_loss: 0.11244465410709381, Dice_loss: 0.009957745671272278, Consistency_loss: 0.00047826473019085824\n",
      "[Training] Epoch: 14 [==========>    ] 67.5% Loss: 0.1217, Epoch 14, Batch 84, CE_loss: 0.11106239259243011, Dice_loss: 0.00948132760822773, Consistency_loss: 0.0007023426587693393\n",
      "[Training] Epoch: 14 [==========>    ] 68.3% Loss: 0.1215, Epoch 14, Batch 85, CE_loss: 0.10128431767225266, Dice_loss: 0.007986080832779408, Consistency_loss: 0.00017769960686564445\n",
      "[Training] Epoch: 14 [==========>    ] 69.0% Loss: 0.1216, Epoch 14, Batch 86, CE_loss: 0.11796578764915466, Dice_loss: 0.01057193148881197, Consistency_loss: 0.0002214425039710477\n",
      "[Training] Epoch: 14 [==========>    ] 69.8% Loss: 0.1215, Epoch 14, Batch 87, CE_loss: 0.10716967284679413, Dice_loss: 0.009339917451143265, Consistency_loss: 0.0001282547164009884\n",
      "[Training] Epoch: 14 [==========>    ] 70.6% Loss: 0.1216, Epoch 14, Batch 88, CE_loss: 0.11361612379550934, Dice_loss: 0.010038815438747406, Consistency_loss: 0.000755774904973805\n",
      "[Training] Epoch: 14 [==========>    ] 71.4% Loss: 0.1217, Epoch 14, Batch 89, CE_loss: 0.1174071803689003, Dice_loss: 0.010168097913265228, Consistency_loss: 0.0010383339831605554\n",
      "[Training] Epoch: 14 [==========>    ] 72.2% Loss: 0.1216, Epoch 14, Batch 90, CE_loss: 0.10471425950527191, Dice_loss: 0.008999294601380825, Consistency_loss: 0.0010372046381235123\n",
      "[Training] Epoch: 14 [==========>    ] 73.0% Loss: 0.1214, Epoch 14, Batch 91, CE_loss: 0.09479880332946777, Dice_loss: 0.007208776660263538, Consistency_loss: 0.0006996981683187187\n",
      "[Training] Epoch: 14 [===========>   ] 73.8% Loss: 0.1212, Epoch 14, Batch 92, CE_loss: 0.09966452419757843, Dice_loss: 0.007934671826660633, Consistency_loss: 0.0008191188680939376\n",
      "[Training] Epoch: 14 [===========>   ] 74.6% Loss: 0.1212, Epoch 14, Batch 93, CE_loss: 0.11036424338817596, Dice_loss: 0.008635264821350574, Consistency_loss: 0.0008380990475416183\n",
      "[Training] Epoch: 14 [===========>   ] 75.4% Loss: 0.1211, Epoch 14, Batch 94, CE_loss: 0.09858907759189606, Dice_loss: 0.007704779971390963, Consistency_loss: 0.0007143362308852375\n",
      "[Training] Epoch: 14 [===========>   ] 76.2% Loss: 0.1210, Epoch 14, Batch 95, CE_loss: 0.10407651215791702, Dice_loss: 0.008335219696164131, Consistency_loss: 0.0009391274652443826\n",
      "[Training] Epoch: 14 [===========>   ] 77.0% Loss: 0.1208, Epoch 14, Batch 96, CE_loss: 0.09799730777740479, Dice_loss: 0.007730345707386732, Consistency_loss: 0.0006505716592073441\n",
      "[Training] Epoch: 14 [===========>   ] 77.8% Loss: 0.1207, Epoch 14, Batch 97, CE_loss: 0.10081535577774048, Dice_loss: 0.008064433000981808, Consistency_loss: 0.0007122214883565903\n",
      "[Training] Epoch: 14 [===========>   ] 78.6% Loss: 0.1206, Epoch 14, Batch 98, CE_loss: 0.10167007148265839, Dice_loss: 0.008011732250452042, Consistency_loss: 0.00012298922229092568\n",
      "[Training] Epoch: 14 [===========>   ] 79.4% Loss: 0.1205, Epoch 14, Batch 99, CE_loss: 0.09980489313602448, Dice_loss: 0.00788811780512333, Consistency_loss: 0.0006413799128495157\n",
      "[Training] Epoch: 14 [============>  ] 80.2% Loss: 0.1203, Epoch 14, Batch 100, CE_loss: 0.0924140140414238, Dice_loss: 0.0066531081683933735, Consistency_loss: 0.000613841344602406\n",
      "[Training] Epoch: 14 [============>  ] 81.0% Loss: 0.1204, Epoch 14, Batch 101, CE_loss: 0.12235653400421143, Dice_loss: 0.010192783549427986, Consistency_loss: 0.000569594616536051\n",
      "[Training] Epoch: 14 [============>  ] 81.7% Loss: 0.1202, Epoch 14, Batch 102, CE_loss: 0.09062730520963669, Dice_loss: 0.0061356071382761, Consistency_loss: 0.00019969335698988289\n",
      "[Training] Epoch: 14 [============>  ] 82.5% Loss: 0.1202, Epoch 14, Batch 103, CE_loss: 0.11107131838798523, Dice_loss: 0.009281892329454422, Consistency_loss: 0.0006640661740675569\n",
      "[Training] Epoch: 14 [============>  ] 83.3% Loss: 0.1202, Epoch 14, Batch 104, CE_loss: 0.11059407889842987, Dice_loss: 0.009491194039583206, Consistency_loss: 0.0005724889342673123\n",
      "[Training] Epoch: 14 [============>  ] 84.1% Loss: 0.1200, Epoch 14, Batch 105, CE_loss: 0.09214729815721512, Dice_loss: 0.00693291611969471, Consistency_loss: 0.0007335520349442959\n",
      "[Training] Epoch: 14 [============>  ] 84.9% Loss: 0.1199, Epoch 14, Batch 106, CE_loss: 0.10011604428291321, Dice_loss: 0.008076444268226624, Consistency_loss: 0.0008405960979871452\n",
      "[Training] Epoch: 14 [============>  ] 85.7% Loss: 0.1198, Epoch 14, Batch 107, CE_loss: 0.09887925535440445, Dice_loss: 0.0075099351815879345, Consistency_loss: 0.00017367185500916094\n",
      "[Training] Epoch: 14 [============>  ] 86.5% Loss: 0.1197, Epoch 14, Batch 108, CE_loss: 0.10525970906019211, Dice_loss: 0.008643195033073425, Consistency_loss: 0.000710225198417902\n",
      "[Training] Epoch: 14 [=============> ] 87.3% Loss: 0.1196, Epoch 14, Batch 109, CE_loss: 0.09467855840921402, Dice_loss: 0.006676639895886183, Consistency_loss: 0.0005811327719129622\n",
      "[Training] Epoch: 14 [=============> ] 88.1% Loss: 0.1198, Epoch 14, Batch 110, CE_loss: 0.12969103455543518, Dice_loss: 0.011849382892251015, Consistency_loss: 0.0003284006379544735\n",
      "[Training] Epoch: 14 [=============> ] 88.9% Loss: 0.1196, Epoch 14, Batch 111, CE_loss: 0.09216277301311493, Dice_loss: 0.006738254800438881, Consistency_loss: 0.00014964203000999987\n",
      "[Training] Epoch: 14 [=============> ] 89.7% Loss: 0.1196, Epoch 14, Batch 112, CE_loss: 0.1079382449388504, Dice_loss: 0.008197877556085587, Consistency_loss: 0.0007148001459427178\n",
      "[Training] Epoch: 14 [=============> ] 90.5% Loss: 0.1195, Epoch 14, Batch 113, CE_loss: 0.1036238893866539, Dice_loss: 0.008757971227169037, Consistency_loss: 0.0009629350388422608\n",
      "[Training] Epoch: 14 [=============> ] 91.3% Loss: 0.1194, Epoch 14, Batch 114, CE_loss: 0.10226194560527802, Dice_loss: 0.008439897559583187, Consistency_loss: 0.0009036021656356752\n",
      "[Training] Epoch: 14 [=============> ] 92.1% Loss: 0.1192, Epoch 14, Batch 115, CE_loss: 0.08919546753168106, Dice_loss: 0.005982144270092249, Consistency_loss: 0.0008870853343978524\n",
      "[Training] Epoch: 14 [=============> ] 92.9% Loss: 0.1192, Epoch 14, Batch 116, CE_loss: 0.10264091938734055, Dice_loss: 0.00830466952174902, Consistency_loss: 0.0008922992274165154\n",
      "[Training] Epoch: 14 [==============>] 93.7% Loss: 0.1191, Epoch 14, Batch 117, CE_loss: 0.10366740077733994, Dice_loss: 0.008517498150467873, Consistency_loss: 0.0010251938365399837\n",
      "[Training] Epoch: 14 [==============>] 94.4% Loss: 0.1190, Epoch 14, Batch 118, CE_loss: 0.1003992035984993, Dice_loss: 0.008108009584248066, Consistency_loss: 0.00012503545440267771\n",
      "[Training] Epoch: 14 [==============>] 95.2% Loss: 0.1189, Epoch 14, Batch 119, CE_loss: 0.10001286119222641, Dice_loss: 0.00800432451069355, Consistency_loss: 0.0005217970465309918\n",
      "[Training] Epoch: 14 [==============>] 96.0% Loss: 0.1190, Epoch 14, Batch 120, CE_loss: 0.10977327078580856, Dice_loss: 0.009278306737542152, Consistency_loss: 0.0010425201617181301\n",
      "[Training] Epoch: 14 [==============>] 96.8% Loss: 0.1189, Epoch 14, Batch 121, CE_loss: 0.101754330098629, Dice_loss: 0.00810166634619236, Consistency_loss: 0.0003565125516615808\n",
      "[Training] Epoch: 14 [==============>] 97.6% Loss: 0.1188, Epoch 14, Batch 122, CE_loss: 0.10143613815307617, Dice_loss: 0.007760471198707819, Consistency_loss: 0.0005424924893304706\n",
      "[Training] Epoch: 14 [==============>] 98.4% Loss: 0.1188, Epoch 14, Batch 123, CE_loss: 0.10899513214826584, Dice_loss: 0.0090089812874794, Consistency_loss: 0.0005377130000852048\n",
      "[Training] Epoch: 14 [==============>] 99.2% Loss: 0.1187, Epoch 14, Batch 124, CE_loss: 0.097477987408638, Dice_loss: 0.007378118112683296, Consistency_loss: 0.0004292286466807127\n",
      "[Training] Epoch: 14 [DONE]                                 \n",
      "Epoch 14, Batch 125, CE_loss: 0.10500731319189072, Dice_loss: 0.008615667000412941, Consistency_loss: 0.0002554023521952331\n",
      "[Validation] Epoch: 14 [DONE]                                 \n",
      "[Epoch: 14, TrainLoss: 0.1187, TrainDice: 0.0090, ValLoss: 0.1647                                            \n",
      "Number of batches:  126\n",
      "[Training] Epoch: 15 [>              ] 0.8% Loss: 0.1021, Epoch 15, Batch 0, CE_loss: 0.09401137381792068, Dice_loss: 0.00736572640016675, Consistency_loss: 0.000764791329856962\n",
      "[Training] Epoch: 15 [>              ] 1.6% Loss: 0.1087, Epoch 15, Batch 1, CE_loss: 0.10552176088094711, Dice_loss: 0.009009907022118568, Consistency_loss: 0.0006517512374557555\n",
      "[Training] Epoch: 15 [>              ] 2.4% Loss: 0.1150, Epoch 15, Batch 2, CE_loss: 0.11706741154193878, Dice_loss: 0.01042648870497942, Consistency_loss: 0.00030300533398985863\n",
      "[Training] Epoch: 15 [>              ] 3.2% Loss: 0.1189, Epoch 15, Batch 3, CE_loss: 0.12027139961719513, Dice_loss: 0.010166162624955177, Consistency_loss: 0.00015967355284374207\n",
      "[Training] Epoch: 15 [>              ] 4.0% Loss: 0.1154, Epoch 15, Batch 4, CE_loss: 0.0941246822476387, Dice_loss: 0.007134609390050173, Consistency_loss: 0.00019861232431139797\n",
      "[Training] Epoch: 15 [>              ] 4.8% Loss: 0.1148, Epoch 15, Batch 5, CE_loss: 0.10295546799898148, Dice_loss: 0.008168100379407406, Consistency_loss: 0.00026658721617423\n",
      "[Training] Epoch: 15 [>              ] 5.6% Loss: 0.1147, Epoch 15, Batch 6, CE_loss: 0.10561307519674301, Dice_loss: 0.008610677905380726, Consistency_loss: 0.0004215584776829928\n",
      "[Training] Epoch: 15 [>              ] 6.3% Loss: 0.1137, Epoch 15, Batch 7, CE_loss: 0.0976356491446495, Dice_loss: 0.008102484047412872, Consistency_loss: 0.00047296719276346266\n",
      "[Training] Epoch: 15 [=>             ] 7.1% Loss: 0.1128, Epoch 15, Batch 8, CE_loss: 0.0976470485329628, Dice_loss: 0.007506153080612421, Consistency_loss: 0.0002465110446792096\n",
      "[Training] Epoch: 15 [=>             ] 7.9% Loss: 0.1126, Epoch 15, Batch 9, CE_loss: 0.10235241055488586, Dice_loss: 0.008207179605960846, Consistency_loss: 0.00040136254392564297\n",
      "[Training] Epoch: 15 [=>             ] 8.7% Loss: 0.1140, Epoch 15, Batch 10, CE_loss: 0.11744973808526993, Dice_loss: 0.010240263305604458, Consistency_loss: 0.0008175793918780982\n",
      "[Training] Epoch: 15 [=>             ] 9.5% Loss: 0.1144, Epoch 15, Batch 11, CE_loss: 0.1088239923119545, Dice_loss: 0.009194393642246723, Consistency_loss: 0.0006635794998146594\n",
      "[Training] Epoch: 15 [=>             ] 10.3% Loss: 0.1131, Epoch 15, Batch 12, CE_loss: 0.09050829708576202, Dice_loss: 0.006360939238220453, Consistency_loss: 0.0007948661223053932\n",
      "[Training] Epoch: 15 [=>             ] 11.1% Loss: 0.1150, Epoch 15, Batch 13, CE_loss: 0.1281515508890152, Dice_loss: 0.01071205921471119, Consistency_loss: 0.00014218063734006137\n",
      "[Training] Epoch: 15 [=>             ] 11.9% Loss: 0.1152, Epoch 15, Batch 14, CE_loss: 0.10861975699663162, Dice_loss: 0.009177491068840027, Consistency_loss: 0.00045150620280764997\n",
      "[Training] Epoch: 15 [=>             ] 12.7% Loss: 0.1152, Epoch 15, Batch 15, CE_loss: 0.10665231943130493, Dice_loss: 0.00889969989657402, Consistency_loss: 0.0003162938228342682\n",
      "[Training] Epoch: 15 [==>            ] 13.5% Loss: 0.1141, Epoch 15, Batch 16, CE_loss: 0.08950463682413101, Dice_loss: 0.006567635107785463, Consistency_loss: 0.00013115040201228112\n",
      "[Training] Epoch: 15 [==>            ] 14.3% Loss: 0.1135, Epoch 15, Batch 17, CE_loss: 0.0954718217253685, Dice_loss: 0.007340580690652132, Consistency_loss: 0.0005570959765464067\n",
      "[Training] Epoch: 15 [==>            ] 15.1% Loss: 0.1138, Epoch 15, Batch 18, CE_loss: 0.10825413465499878, Dice_loss: 0.009258386678993702, Consistency_loss: 0.0004835126455873251\n",
      "[Training] Epoch: 15 [==>            ] 15.9% Loss: 0.1139, Epoch 15, Batch 19, CE_loss: 0.10717040300369263, Dice_loss: 0.008907889015972614, Consistency_loss: 0.0007599390810355544\n",
      "[Training] Epoch: 15 [==>            ] 16.7% Loss: 0.1139, Epoch 15, Batch 20, CE_loss: 0.10494270920753479, Dice_loss: 0.00876135565340519, Consistency_loss: 0.0006560524343512952\n",
      "[Training] Epoch: 15 [==>            ] 17.5% Loss: 0.1152, Epoch 15, Batch 21, CE_loss: 0.1304686963558197, Dice_loss: 0.011800459586083889, Consistency_loss: 0.0005824289401061833\n",
      "[Training] Epoch: 15 [==>            ] 18.3% Loss: 0.1147, Epoch 15, Batch 22, CE_loss: 0.09418774396181107, Dice_loss: 0.0072490144520998, Consistency_loss: 0.0005873884074389935\n",
      "[Training] Epoch: 15 [==>            ] 19.0% Loss: 0.1140, Epoch 15, Batch 23, CE_loss: 0.09063949435949326, Dice_loss: 0.006619155872613192, Consistency_loss: 0.0005354825407266617\n",
      "[Training] Epoch: 15 [==>            ] 19.8% Loss: 0.1139, Epoch 15, Batch 24, CE_loss: 0.10280374437570572, Dice_loss: 0.008145954459905624, Consistency_loss: 0.000564530782867223\n",
      "[Training] Epoch: 15 [===>           ] 20.6% Loss: 0.1138, Epoch 15, Batch 25, CE_loss: 0.10163453221321106, Dice_loss: 0.008583641611039639, Consistency_loss: 0.0006409880588762462\n",
      "[Training] Epoch: 15 [===>           ] 21.4% Loss: 0.1135, Epoch 15, Batch 26, CE_loss: 0.0991138219833374, Dice_loss: 0.008171314373612404, Consistency_loss: 0.0007490998250432312\n",
      "[Training] Epoch: 15 [===>           ] 22.2% Loss: 0.1133, Epoch 15, Batch 27, CE_loss: 0.09775617718696594, Dice_loss: 0.0076820747926831245, Consistency_loss: 0.000391292676795274\n",
      "[Training] Epoch: 15 [===>           ] 23.0% Loss: 0.1130, Epoch 15, Batch 28, CE_loss: 0.09741430729627609, Dice_loss: 0.007694667670875788, Consistency_loss: 0.00046384046436287463\n",
      "[Training] Epoch: 15 [===>           ] 23.8% Loss: 0.1133, Epoch 15, Batch 29, CE_loss: 0.11174172908067703, Dice_loss: 0.010086818598210812, Consistency_loss: 0.0008847620338201523\n",
      "[Training] Epoch: 15 [===>           ] 24.6% Loss: 0.1134, Epoch 15, Batch 30, CE_loss: 0.10704229027032852, Dice_loss: 0.008870718069374561, Consistency_loss: 0.0009973658015951514\n",
      "[Training] Epoch: 15 [===>           ] 25.4% Loss: 0.1136, Epoch 15, Batch 31, CE_loss: 0.10949821025133133, Dice_loss: 0.008753961883485317, Consistency_loss: 0.0003954263811465353\n",
      "[Training] Epoch: 15 [===>           ] 26.2% Loss: 0.1135, Epoch 15, Batch 32, CE_loss: 0.10029023140668869, Dice_loss: 0.008170626126229763, Consistency_loss: 0.000804066308774054\n",
      "[Training] Epoch: 15 [====>          ] 27.0% Loss: 0.1130, Epoch 15, Batch 33, CE_loss: 0.09156051278114319, Dice_loss: 0.0065818908624351025, Consistency_loss: 0.0004705281462520361\n",
      "[Training] Epoch: 15 [====>          ] 27.8% Loss: 0.1124, Epoch 15, Batch 34, CE_loss: 0.08481678366661072, Dice_loss: 0.0062625291757285595, Consistency_loss: 0.0007530838483944535\n",
      "[Training] Epoch: 15 [====>          ] 28.6% Loss: 0.1122, Epoch 15, Batch 35, CE_loss: 0.095706045627594, Dice_loss: 0.007750676944851875, Consistency_loss: 0.0007735757390037179\n",
      "[Training] Epoch: 15 [====>          ] 29.4% Loss: 0.1126, Epoch 15, Batch 36, CE_loss: 0.11735767126083374, Dice_loss: 0.010592499747872353, Consistency_loss: 0.0004653906507883221\n",
      "[Training] Epoch: 15 [====>          ] 30.2% Loss: 0.1127, Epoch 15, Batch 37, CE_loss: 0.10713978111743927, Dice_loss: 0.008864633738994598, Consistency_loss: 0.000590287905652076\n",
      "[Training] Epoch: 15 [====>          ] 31.0% Loss: 0.1126, Epoch 15, Batch 38, CE_loss: 0.09666670858860016, Dice_loss: 0.007968571037054062, Consistency_loss: 0.001080564921721816\n",
      "[Training] Epoch: 15 [====>          ] 31.7% Loss: 0.1127, Epoch 15, Batch 39, CE_loss: 0.10570979118347168, Dice_loss: 0.009094749577343464, Consistency_loss: 0.0012889854842796922\n",
      "[Training] Epoch: 15 [====>          ] 32.5% Loss: 0.1127, Epoch 15, Batch 40, CE_loss: 0.10445131361484528, Dice_loss: 0.009436999447643757, Consistency_loss: 0.0007852513226680458\n",
      "[Training] Epoch: 15 [=====>         ] 33.3% Loss: 0.1138, Epoch 15, Batch 41, CE_loss: 0.14570720493793488, Dice_loss: 0.013375229202210903, Consistency_loss: 0.0007908016559667885\n",
      "[Training] Epoch: 15 [=====>         ] 34.1% Loss: 0.1138, Epoch 15, Batch 42, CE_loss: 0.10296813398599625, Dice_loss: 0.00878824945539236, Consistency_loss: 0.0007937589543871582\n",
      "[Training] Epoch: 15 [=====>         ] 34.9% Loss: 0.1135, Epoch 15, Batch 43, CE_loss: 0.09337040781974792, Dice_loss: 0.00730206398293376, Consistency_loss: 0.00069657270796597\n",
      "[Training] Epoch: 15 [=====>         ] 35.7% Loss: 0.1133, Epoch 15, Batch 44, CE_loss: 0.09676308184862137, Dice_loss: 0.00750723946839571, Consistency_loss: 0.0007617066730745137\n",
      "[Training] Epoch: 15 [=====>         ] 36.5% Loss: 0.1134, Epoch 15, Batch 45, CE_loss: 0.10577262192964554, Dice_loss: 0.009285275824368, Consistency_loss: 0.0003781867562793195\n",
      "[Training] Epoch: 15 [=====>         ] 37.3% Loss: 0.1133, Epoch 15, Batch 46, CE_loss: 0.10092145949602127, Dice_loss: 0.008097365498542786, Consistency_loss: 0.0004894487210549414\n",
      "[Training] Epoch: 15 [=====>         ] 38.1% Loss: 0.1138, Epoch 15, Batch 47, CE_loss: 0.1251424252986908, Dice_loss: 0.010864229872822762, Consistency_loss: 0.00040530363912694156\n",
      "[Training] Epoch: 15 [=====>         ] 38.9% Loss: 0.1137, Epoch 15, Batch 48, CE_loss: 0.09995909035205841, Dice_loss: 0.008200881071388721, Consistency_loss: 0.0013057668693363667\n",
      "[Training] Epoch: 15 [=====>         ] 39.7% Loss: 0.1134, Epoch 15, Batch 49, CE_loss: 0.09179821610450745, Dice_loss: 0.007012201938778162, Consistency_loss: 0.0009819230763241649\n",
      "[Training] Epoch: 15 [======>        ] 40.5% Loss: 0.1135, Epoch 15, Batch 50, CE_loss: 0.10795263200998306, Dice_loss: 0.009180057793855667, Consistency_loss: 0.00021723615645896643\n",
      "[Training] Epoch: 15 [======>        ] 41.3% Loss: 0.1134, Epoch 15, Batch 51, CE_loss: 0.10203668475151062, Dice_loss: 0.00851086899638176, Consistency_loss: 0.0009493770194239914\n",
      "[Training] Epoch: 15 [======>        ] 42.1% Loss: 0.1134, Epoch 15, Batch 52, CE_loss: 0.10331779718399048, Dice_loss: 0.00874300953000784, Consistency_loss: 0.0003853432135656476\n",
      "[Training] Epoch: 15 [======>        ] 42.9% Loss: 0.1130, Epoch 15, Batch 53, CE_loss: 0.0852338895201683, Dice_loss: 0.006370742805302143, Consistency_loss: 0.00013862938794773072\n",
      "[Training] Epoch: 15 [======>        ] 43.7% Loss: 0.1131, Epoch 15, Batch 54, CE_loss: 0.1085033193230629, Dice_loss: 0.009550027549266815, Consistency_loss: 0.0007927167462185025\n",
      "[Training] Epoch: 15 [======>        ] 44.4% Loss: 0.1131, Epoch 15, Batch 55, CE_loss: 0.10039537400007248, Dice_loss: 0.008613655343651772, Consistency_loss: 0.0005914936191402376\n",
      "[Training] Epoch: 15 [======>        ] 45.2% Loss: 0.1130, Epoch 15, Batch 56, CE_loss: 0.10075218975543976, Dice_loss: 0.007884742692112923, Consistency_loss: 0.00019171855819877237\n",
      "[Training] Epoch: 15 [======>        ] 46.0% Loss: 0.1130, Epoch 15, Batch 57, CE_loss: 0.10481321811676025, Dice_loss: 0.0090729258954525, Consistency_loss: 0.0008132436196319759\n",
      "[Training] Epoch: 15 [=======>       ] 46.8% Loss: 0.1129, Epoch 15, Batch 58, CE_loss: 0.09769769012928009, Dice_loss: 0.008021960034966469, Consistency_loss: 0.00014568281767424196\n",
      "[Training] Epoch: 15 [=======>       ] 47.6% Loss: 0.1126, Epoch 15, Batch 59, CE_loss: 0.08798279613256454, Dice_loss: 0.006333875935524702, Consistency_loss: 0.000743308977689594\n",
      "[Training] Epoch: 15 [=======>       ] 48.4% Loss: 0.1124, Epoch 15, Batch 60, CE_loss: 0.0935632511973381, Dice_loss: 0.007432481739670038, Consistency_loss: 0.0006446761544793844\n",
      "[Training] Epoch: 15 [=======>       ] 49.2% Loss: 0.1122, Epoch 15, Batch 61, CE_loss: 0.09299001842737198, Dice_loss: 0.007490525022149086, Consistency_loss: 0.00040910649113357067\n",
      "[Training] Epoch: 15 [=======>       ] 50.0% Loss: 0.1124, Epoch 15, Batch 62, CE_loss: 0.11266089230775833, Dice_loss: 0.010066116228699684, Consistency_loss: 0.0001292684901272878\n",
      "[Training] Epoch: 15 [=======>       ] 50.8% Loss: 0.1123, Epoch 15, Batch 63, CE_loss: 0.09812461584806442, Dice_loss: 0.008053475990891457, Consistency_loss: 0.0010664303554221988\n",
      "[Training] Epoch: 15 [=======>       ] 51.6% Loss: 0.1123, Epoch 15, Batch 64, CE_loss: 0.09944797307252884, Dice_loss: 0.0076816813088953495, Consistency_loss: 0.0011185485636815429\n",
      "[Training] Epoch: 15 [=======>       ] 52.4% Loss: 0.1121, Epoch 15, Batch 65, CE_loss: 0.09164582937955856, Dice_loss: 0.007104644551873207, Consistency_loss: 0.00091933534713462\n",
      "[Training] Epoch: 15 [=======>       ] 53.2% Loss: 0.1118, Epoch 15, Batch 66, CE_loss: 0.08906373381614685, Dice_loss: 0.0064797657541930676, Consistency_loss: 0.0004427465610206127\n",
      "[Training] Epoch: 15 [========>      ] 54.0% Loss: 0.1119, Epoch 15, Batch 67, CE_loss: 0.10608828067779541, Dice_loss: 0.009256210178136826, Consistency_loss: 0.0006806295714341104\n",
      "[Training] Epoch: 15 [========>      ] 54.8% Loss: 0.1119, Epoch 15, Batch 68, CE_loss: 0.10424899309873581, Dice_loss: 0.008665350265800953, Consistency_loss: 0.00021746607671957463\n",
      "[Training] Epoch: 15 [========>      ] 55.6% Loss: 0.1118, Epoch 15, Batch 69, CE_loss: 0.09501730650663376, Dice_loss: 0.007720515597611666, Consistency_loss: 0.0006302780820988119\n",
      "[Training] Epoch: 15 [========>      ] 56.3% Loss: 0.1118, Epoch 15, Batch 70, CE_loss: 0.10573751479387283, Dice_loss: 0.008872470818459988, Consistency_loss: 0.0006982082850299776\n",
      "[Training] Epoch: 15 [========>      ] 57.1% Loss: 0.1117, Epoch 15, Batch 71, CE_loss: 0.09316854923963547, Dice_loss: 0.0076470584608614445, Consistency_loss: 0.0009177422034554183\n",
      "[Training] Epoch: 15 [========>      ] 57.9% Loss: 0.1115, Epoch 15, Batch 72, CE_loss: 0.08778124302625656, Dice_loss: 0.006302824709564447, Consistency_loss: 0.0006925885681994259\n",
      "[Training] Epoch: 15 [========>      ] 58.7% Loss: 0.1114, Epoch 15, Batch 73, CE_loss: 0.09479717910289764, Dice_loss: 0.007590468507260084, Consistency_loss: 0.0008204705081880093\n",
      "[Training] Epoch: 15 [========>      ] 59.5% Loss: 0.1112, Epoch 15, Batch 74, CE_loss: 0.09472082555294037, Dice_loss: 0.007632865104824305, Consistency_loss: 0.0008622832829132676\n",
      "[Training] Epoch: 15 [=========>     ] 60.3% Loss: 0.1110, Epoch 15, Batch 75, CE_loss: 0.08532164245843887, Dice_loss: 0.0065779839642345905, Consistency_loss: 0.0007830571266822517\n",
      "[Training] Epoch: 15 [=========>     ] 61.1% Loss: 0.1109, Epoch 15, Batch 76, CE_loss: 0.09451177716255188, Dice_loss: 0.007698726840317249, Consistency_loss: 0.0008995619718916714\n",
      "[Training] Epoch: 15 [=========>     ] 61.9% Loss: 0.1111, Epoch 15, Batch 77, CE_loss: 0.11471964418888092, Dice_loss: 0.010459980927407742, Consistency_loss: 0.0010159224038943648\n",
      "[Training] Epoch: 15 [=========>     ] 62.7% Loss: 0.1112, Epoch 15, Batch 78, CE_loss: 0.10765501111745834, Dice_loss: 0.009179986082017422, Consistency_loss: 0.0006846803589724004\n",
      "[Training] Epoch: 15 [=========>     ] 63.5% Loss: 0.1114, Epoch 15, Batch 79, CE_loss: 0.11994396895170212, Dice_loss: 0.010959644801914692, Consistency_loss: 0.000570895557757467\n",
      "[Training] Epoch: 15 [=========>     ] 64.3% Loss: 0.1113, Epoch 15, Batch 80, CE_loss: 0.09547232836484909, Dice_loss: 0.007962191477417946, Consistency_loss: 0.0002044832071987912\n",
      "[Training] Epoch: 15 [=========>     ] 65.1% Loss: 0.1115, Epoch 15, Batch 81, CE_loss: 0.11368004232645035, Dice_loss: 0.010346491821110249, Consistency_loss: 0.0009305295534431934\n",
      "[Training] Epoch: 15 [=========>     ] 65.9% Loss: 0.1114, Epoch 15, Batch 82, CE_loss: 0.09716733545064926, Dice_loss: 0.007519148755818605, Consistency_loss: 0.0008415791089646518\n",
      "[Training] Epoch: 15 [==========>    ] 66.7% Loss: 0.1115, Epoch 15, Batch 83, CE_loss: 0.10443305969238281, Dice_loss: 0.008777757175266743, Consistency_loss: 0.0004788577207364142\n",
      "[Training] Epoch: 15 [==========>    ] 67.5% Loss: 0.1116, Epoch 15, Batch 84, CE_loss: 0.11353691667318344, Dice_loss: 0.010014139115810394, Consistency_loss: 0.0004948617424815893\n",
      "[Training] Epoch: 15 [==========>    ] 68.3% Loss: 0.1115, Epoch 15, Batch 85, CE_loss: 0.09508802741765976, Dice_loss: 0.007906508632004261, Consistency_loss: 0.00014602734881918877\n",
      "[Training] Epoch: 15 [==========>    ] 69.0% Loss: 0.1113, Epoch 15, Batch 86, CE_loss: 0.08849655836820602, Dice_loss: 0.006601958069950342, Consistency_loss: 0.0006034862599335611\n",
      "[Training] Epoch: 15 [==========>    ] 69.8% Loss: 0.1113, Epoch 15, Batch 87, CE_loss: 0.09861001372337341, Dice_loss: 0.00833534449338913, Consistency_loss: 0.0006056699785403907\n",
      "[Training] Epoch: 15 [==========>    ] 70.6% Loss: 0.1112, Epoch 15, Batch 88, CE_loss: 0.0968976691365242, Dice_loss: 0.008274641819298267, Consistency_loss: 0.0007740100263617933\n",
      "[Training] Epoch: 15 [==========>    ] 71.4% Loss: 0.1114, Epoch 15, Batch 89, CE_loss: 0.11758877336978912, Dice_loss: 0.010219650343060493, Consistency_loss: 0.0008353996090590954\n",
      "[Training] Epoch: 15 [==========>    ] 72.2% Loss: 0.1112, Epoch 15, Batch 90, CE_loss: 0.08852820843458176, Dice_loss: 0.007140022702515125, Consistency_loss: 0.0006870896904729307\n",
      "[Training] Epoch: 15 [==========>    ] 73.0% Loss: 0.1113, Epoch 15, Batch 91, CE_loss: 0.10244575887918472, Dice_loss: 0.00882385578006506, Consistency_loss: 0.0006926378118805587\n",
      "[Training] Epoch: 15 [===========>   ] 73.8% Loss: 0.1113, Epoch 15, Batch 92, CE_loss: 0.10577280074357986, Dice_loss: 0.00899739470332861, Consistency_loss: 0.0007206821464933455\n",
      "[Training] Epoch: 15 [===========>   ] 74.6% Loss: 0.1112, Epoch 15, Batch 93, CE_loss: 0.08952782303094864, Dice_loss: 0.006935289595276117, Consistency_loss: 0.0007300841971300542\n",
      "[Training] Epoch: 15 [===========>   ] 75.4% Loss: 0.1115, Epoch 15, Batch 94, CE_loss: 0.13079260289669037, Dice_loss: 0.011195902712643147, Consistency_loss: 0.0007452279678545892\n",
      "[Training] Epoch: 15 [===========>   ] 76.2% Loss: 0.1113, Epoch 15, Batch 95, CE_loss: 0.0829303041100502, Dice_loss: 0.005872164852917194, Consistency_loss: 0.0009289243607781827\n",
      "[Training] Epoch: 15 [===========>   ] 77.0% Loss: 0.1111, Epoch 15, Batch 96, CE_loss: 0.09249019622802734, Dice_loss: 0.007288692984730005, Consistency_loss: 0.00021462531003635377\n",
      "[Training] Epoch: 15 [===========>   ] 77.8% Loss: 0.1113, Epoch 15, Batch 97, CE_loss: 0.11235764622688293, Dice_loss: 0.009622309356927872, Consistency_loss: 0.0006355278892442584\n",
      "[Training] Epoch: 15 [===========>   ] 78.6% Loss: 0.1113, Epoch 15, Batch 98, CE_loss: 0.1045495867729187, Dice_loss: 0.008544816635549068, Consistency_loss: 0.0005451870965771377\n",
      "[Training] Epoch: 15 [===========>   ] 79.4% Loss: 0.1114, Epoch 15, Batch 99, CE_loss: 0.1122763529419899, Dice_loss: 0.009861253201961517, Consistency_loss: 0.0005430012824945152\n",
      "[Training] Epoch: 15 [============>  ] 80.2% Loss: 0.1113, Epoch 15, Batch 100, CE_loss: 0.09474474936723709, Dice_loss: 0.00751506257802248, Consistency_loss: 0.0007533338502980769\n",
      "[Training] Epoch: 15 [============>  ] 81.0% Loss: 0.1113, Epoch 15, Batch 101, CE_loss: 0.09667655825614929, Dice_loss: 0.00815044716000557, Consistency_loss: 0.0007251009228639305\n",
      "[Training] Epoch: 15 [============>  ] 81.7% Loss: 0.1112, Epoch 15, Batch 102, CE_loss: 0.09930755198001862, Dice_loss: 0.00792629923671484, Consistency_loss: 0.0005397946224547923\n",
      "[Training] Epoch: 15 [============>  ] 82.5% Loss: 0.1112, Epoch 15, Batch 103, CE_loss: 0.10133981704711914, Dice_loss: 0.008311839774250984, Consistency_loss: 0.0008856807835400105\n",
      "[Training] Epoch: 15 [============>  ] 83.3% Loss: 0.1111, Epoch 15, Batch 104, CE_loss: 0.08697722852230072, Dice_loss: 0.006558846216648817, Consistency_loss: 0.0007301486330106854\n",
      "[Training] Epoch: 15 [============>  ] 84.1% Loss: 0.1111, Epoch 15, Batch 105, CE_loss: 0.10218334197998047, Dice_loss: 0.00868268683552742, Consistency_loss: 0.0005877697258256376\n",
      "[Training] Epoch: 15 [============>  ] 84.9% Loss: 0.1109, Epoch 15, Batch 106, CE_loss: 0.08322975784540176, Dice_loss: 0.006160864606499672, Consistency_loss: 0.0008465605205856264\n",
      "[Training] Epoch: 15 [============>  ] 85.7% Loss: 0.1109, Epoch 15, Batch 107, CE_loss: 0.10293090343475342, Dice_loss: 0.008222803473472595, Consistency_loss: 0.00047602897393517196\n",
      "[Training] Epoch: 15 [============>  ] 86.5% Loss: 0.1110, Epoch 15, Batch 108, CE_loss: 0.1116100400686264, Dice_loss: 0.009550202637910843, Consistency_loss: 0.0006935375276952982\n",
      "[Training] Epoch: 15 [=============> ] 87.3% Loss: 0.1110, Epoch 15, Batch 109, CE_loss: 0.10707370936870575, Dice_loss: 0.009574636816978455, Consistency_loss: 0.00048575663822703063\n",
      "[Training] Epoch: 15 [=============> ] 88.1% Loss: 0.1112, Epoch 15, Batch 110, CE_loss: 0.11870662122964859, Dice_loss: 0.010816370137035847, Consistency_loss: 0.0007251158240251243\n",
      "[Training] Epoch: 15 [=============> ] 88.9% Loss: 0.1112, Epoch 15, Batch 111, CE_loss: 0.10013139247894287, Dice_loss: 0.00865959282964468, Consistency_loss: 0.00021179263421799988\n",
      "[Training] Epoch: 15 [=============> ] 89.7% Loss: 0.1111, Epoch 15, Batch 112, CE_loss: 0.08912909030914307, Dice_loss: 0.007012930698692799, Consistency_loss: 0.0007406653021462262\n",
      "[Training] Epoch: 15 [=============> ] 90.5% Loss: 0.1109, Epoch 15, Batch 113, CE_loss: 0.08856655657291412, Dice_loss: 0.007242362480610609, Consistency_loss: 0.00032476786873303354\n",
      "[Training] Epoch: 15 [=============> ] 91.3% Loss: 0.1108, Epoch 15, Batch 114, CE_loss: 0.08566679805517197, Dice_loss: 0.006565368268638849, Consistency_loss: 0.000770401326008141\n",
      "[Training] Epoch: 15 [=============> ] 92.1% Loss: 0.1108, Epoch 15, Batch 115, CE_loss: 0.10932335257530212, Dice_loss: 0.009250541217625141, Consistency_loss: 0.0009183752699755132\n",
      "[Training] Epoch: 15 [=============> ] 92.9% Loss: 0.1108, Epoch 15, Batch 116, CE_loss: 0.09250209480524063, Dice_loss: 0.007413795683532953, Consistency_loss: 0.0010117617202922702\n",
      "[Training] Epoch: 15 [==============>] 93.7% Loss: 0.1108, Epoch 15, Batch 117, CE_loss: 0.10073433071374893, Dice_loss: 0.008788567036390305, Consistency_loss: 0.0011308633256703615\n",
      "[Training] Epoch: 15 [==============>] 94.4% Loss: 0.1108, Epoch 15, Batch 118, CE_loss: 0.10430207848548889, Dice_loss: 0.009258480742573738, Consistency_loss: 0.0006416962714865804\n",
      "[Training] Epoch: 15 [==============>] 95.2% Loss: 0.1109, Epoch 15, Batch 119, CE_loss: 0.11022870987653732, Dice_loss: 0.009180714376270771, Consistency_loss: 0.0006067330250516534\n",
      "[Training] Epoch: 15 [==============>] 96.0% Loss: 0.1107, Epoch 15, Batch 120, CE_loss: 0.08566600829362869, Dice_loss: 0.0068057747557759285, Consistency_loss: 0.0004952940507791936\n",
      "[Training] Epoch: 15 [==============>] 96.8% Loss: 0.1107, Epoch 15, Batch 121, CE_loss: 0.09866946935653687, Dice_loss: 0.008757703006267548, Consistency_loss: 0.0001956772612174973\n",
      "[Training] Epoch: 15 [==============>] 97.6% Loss: 0.1106, Epoch 15, Batch 122, CE_loss: 0.09044396132230759, Dice_loss: 0.007283529732376337, Consistency_loss: 0.000586582173127681\n",
      "[Training] Epoch: 15 [==============>] 98.4% Loss: 0.1104, Epoch 15, Batch 123, CE_loss: 0.08047362416982651, Dice_loss: 0.006023472640663385, Consistency_loss: 0.0008106327732093632\n",
      "[Training] Epoch: 15 [==============>] 99.2% Loss: 0.1103, Epoch 15, Batch 124, CE_loss: 0.09407689422369003, Dice_loss: 0.007498294580727816, Consistency_loss: 0.0003330657200422138\n",
      "[Training] Epoch: 15 [DONE]                                 \n",
      "Epoch 15, Batch 125, CE_loss: 0.10064143687486649, Dice_loss: 0.008656512945890427, Consistency_loss: 0.0009808504255488515\n",
      "[Validation] Epoch: 15 [DONE]                                 \n",
      "[Epoch: 15, TrainLoss: 0.1103, TrainDice: 0.0084, ValLoss: 0.1570                                            \n",
      "Number of batches:  126\n",
      "[Training] Epoch: 16 [>              ] 0.8% Loss: 0.1047, Epoch 16, Batch 0, CE_loss: 0.0958365872502327, Dice_loss: 0.008212423883378506, Consistency_loss: 0.000613669166341424\n",
      "[Training] Epoch: 16 [>              ] 1.6% Loss: 0.1129, Epoch 16, Batch 1, CE_loss: 0.11078537255525589, Dice_loss: 0.009730696678161621, Consistency_loss: 0.0006215122411958873\n",
      "[Training] Epoch: 16 [>              ] 2.4% Loss: 0.1159, Epoch 16, Batch 2, CE_loss: 0.11143312603235245, Dice_loss: 0.00997399166226387, Consistency_loss: 0.00037340796552598476\n",
      "[Training] Epoch: 16 [>              ] 3.2% Loss: 0.1111, Epoch 16, Batch 3, CE_loss: 0.08905379474163055, Dice_loss: 0.007032072637230158, Consistency_loss: 0.0005862211110070348\n",
      "[Training] Epoch: 16 [>              ] 4.0% Loss: 0.1097, Epoch 16, Batch 4, CE_loss: 0.0959937646985054, Dice_loss: 0.007592127192765474, Consistency_loss: 0.0006252650637179613\n",
      "[Training] Epoch: 16 [>              ] 4.8% Loss: 0.1091, Epoch 16, Batch 5, CE_loss: 0.09750567376613617, Dice_loss: 0.008167876861989498, Consistency_loss: 0.00023661948216613382\n",
      "[Training] Epoch: 16 [>              ] 5.6% Loss: 0.1078, Epoch 16, Batch 6, CE_loss: 0.09254919737577438, Dice_loss: 0.007184359710663557, Consistency_loss: 0.00042072084033861756\n",
      "[Training] Epoch: 16 [>              ] 6.3% Loss: 0.1060, Epoch 16, Batch 7, CE_loss: 0.08647256344556808, Dice_loss: 0.006368605885654688, Consistency_loss: 0.0003680366789922118\n",
      "[Training] Epoch: 16 [=>             ] 7.1% Loss: 0.1055, Epoch 16, Batch 8, CE_loss: 0.09400749206542969, Dice_loss: 0.00752978352829814, Consistency_loss: 0.0002871283213607967\n",
      "[Training] Epoch: 16 [=>             ] 7.9% Loss: 0.1059, Epoch 16, Batch 9, CE_loss: 0.10078183561563492, Dice_loss: 0.008609949611127377, Consistency_loss: 0.0002432916808174923\n",
      "[Training] Epoch: 16 [=>             ] 8.7% Loss: 0.1047, Epoch 16, Batch 10, CE_loss: 0.08566303551197052, Dice_loss: 0.006600228138267994, Consistency_loss: 0.0007351759704761207\n",
      "[Training] Epoch: 16 [=>             ] 9.5% Loss: 0.1052, Epoch 16, Batch 11, CE_loss: 0.10139448940753937, Dice_loss: 0.008569908328354359, Consistency_loss: 0.0007907036924734712\n",
      "[Training] Epoch: 16 [=>             ] 10.3% Loss: 0.1066, Epoch 16, Batch 12, CE_loss: 0.11241886764764786, Dice_loss: 0.00996324885636568, Consistency_loss: 0.0004437596071511507\n",
      "[Training] Epoch: 16 [=>             ] 11.1% Loss: 0.1054, Epoch 16, Batch 13, CE_loss: 0.08374524861574173, Dice_loss: 0.006394288036972284, Consistency_loss: 0.0001256531832041219\n",
      "[Training] Epoch: 16 [=>             ] 11.9% Loss: 0.1049, Epoch 16, Batch 14, CE_loss: 0.09036888927221298, Dice_loss: 0.0073134321719408035, Consistency_loss: 0.00010288593330187723\n",
      "[Training] Epoch: 16 [=>             ] 12.7% Loss: 0.1051, Epoch 16, Batch 15, CE_loss: 0.09812518954277039, Dice_loss: 0.008230961859226227, Consistency_loss: 0.0007548489957116544\n",
      "[Training] Epoch: 16 [==>            ] 13.5% Loss: 0.1046, Epoch 16, Batch 16, CE_loss: 0.08981931954622269, Dice_loss: 0.007135422900319099, Consistency_loss: 0.000473882450023666\n",
      "[Training] Epoch: 16 [==>            ] 14.3% Loss: 0.1037, Epoch 16, Batch 17, CE_loss: 0.08161300420761108, Dice_loss: 0.006071122363209724, Consistency_loss: 0.0005842132377438247\n",
      "[Training] Epoch: 16 [==>            ] 15.1% Loss: 0.1029, Epoch 16, Batch 18, CE_loss: 0.0823434516787529, Dice_loss: 0.006271603982895613, Consistency_loss: 0.0005263022030703723\n",
      "[Training] Epoch: 16 [==>            ] 15.9% Loss: 0.1027, Epoch 16, Batch 19, CE_loss: 0.09080824255943298, Dice_loss: 0.007299256511032581, Consistency_loss: 0.0006009886274114251\n",
      "[Training] Epoch: 16 [==>            ] 16.7% Loss: 0.1034, Epoch 16, Batch 20, CE_loss: 0.10841173678636551, Dice_loss: 0.00911494717001915, Consistency_loss: 0.00042928862967528403\n",
      "[Training] Epoch: 16 [==>            ] 17.5% Loss: 0.1032, Epoch 16, Batch 21, CE_loss: 0.09044045209884644, Dice_loss: 0.007239796686917543, Consistency_loss: 0.00047005011583678424\n",
      "[Training] Epoch: 16 [==>            ] 18.3% Loss: 0.1025, Epoch 16, Batch 22, CE_loss: 0.08019045740365982, Dice_loss: 0.005922800395637751, Consistency_loss: 0.00012405186134856194\n",
      "[Training] Epoch: 16 [==>            ] 19.0% Loss: 0.1033, Epoch 16, Batch 23, CE_loss: 0.11274632811546326, Dice_loss: 0.009926444850862026, Consistency_loss: 0.0004330704396124929\n",
      "[Training] Epoch: 16 [==>            ] 19.8% Loss: 0.1035, Epoch 16, Batch 24, CE_loss: 0.09858633577823639, Dice_loss: 0.007889535278081894, Consistency_loss: 0.0005067889578640461\n",
      "[Training] Epoch: 16 [===>           ] 20.6% Loss: 0.1035, Epoch 16, Batch 25, CE_loss: 0.0947435274720192, Dice_loss: 0.007986197248101234, Consistency_loss: 0.0005844388506375253\n",
      "[Training] Epoch: 16 [===>           ] 21.4% Loss: 0.1035, Epoch 16, Batch 26, CE_loss: 0.09509436041116714, Dice_loss: 0.007607089355587959, Consistency_loss: 0.0007165215210989118\n",
      "[Training] Epoch: 16 [===>           ] 22.2% Loss: 0.1036, Epoch 16, Batch 27, CE_loss: 0.09897822141647339, Dice_loss: 0.008367326110601425, Consistency_loss: 0.0007416036678478122\n",
      "[Training] Epoch: 16 [===>           ] 23.0% Loss: 0.1031, Epoch 16, Batch 28, CE_loss: 0.0811123177409172, Dice_loss: 0.006025860086083412, Consistency_loss: 8.383407111978158e-05\n",
      "[Training] Epoch: 16 [===>           ] 23.8% Loss: 0.1034, Epoch 16, Batch 29, CE_loss: 0.10336390137672424, Dice_loss: 0.00861149188131094, Consistency_loss: 0.00016500431229360402\n",
      "[Training] Epoch: 16 [===>           ] 24.6% Loss: 0.1038, Epoch 16, Batch 30, CE_loss: 0.10857757180929184, Dice_loss: 0.008976772427558899, Consistency_loss: 0.00023865350522100925\n",
      "[Training] Epoch: 16 [===>           ] 25.4% Loss: 0.1034, Epoch 16, Batch 31, CE_loss: 0.08297724276781082, Dice_loss: 0.005803178530186415, Consistency_loss: 8.783969678916037e-05\n",
      "[Training] Epoch: 16 [===>           ] 26.2% Loss: 0.1032, Epoch 16, Batch 32, CE_loss: 0.09085102379322052, Dice_loss: 0.007316927891224623, Consistency_loss: 0.0005279806791804731\n",
      "[Training] Epoch: 16 [====>          ] 27.0% Loss: 0.1035, Epoch 16, Batch 33, CE_loss: 0.10302314162254333, Dice_loss: 0.008900593966245651, Consistency_loss: 0.00034964323276653886\n",
      "[Training] Epoch: 16 [====>          ] 27.8% Loss: 0.1041, Epoch 16, Batch 34, CE_loss: 0.11277713626623154, Dice_loss: 0.009690195322036743, Consistency_loss: 0.000738875416573137\n",
      "[Training] Epoch: 16 [====>          ] 28.6% Loss: 0.1042, Epoch 16, Batch 35, CE_loss: 0.09959815442562103, Dice_loss: 0.008239437825977802, Consistency_loss: 0.00020090244652237743\n",
      "[Training] Epoch: 16 [====>          ] 29.4% Loss: 0.1041, Epoch 16, Batch 36, CE_loss: 0.09370852261781693, Dice_loss: 0.00800589844584465, Consistency_loss: 0.00038200835115276277\n",
      "[Training] Epoch: 16 [====>          ] 30.2% Loss: 0.1043, Epoch 16, Batch 37, CE_loss: 0.10342947393655777, Dice_loss: 0.009012102149426937, Consistency_loss: 0.0005157370469532907\n",
      "[Training] Epoch: 16 [====>          ] 31.0% Loss: 0.1042, Epoch 16, Batch 38, CE_loss: 0.09140963107347488, Dice_loss: 0.007349217310547829, Consistency_loss: 0.0007645282312296331\n",
      "[Training] Epoch: 16 [====>          ] 31.7% Loss: 0.1045, Epoch 16, Batch 39, CE_loss: 0.1043725460767746, Dice_loss: 0.008943848311901093, Consistency_loss: 0.001039681606926024\n",
      "[Training] Epoch: 16 [====>          ] 32.5% Loss: 0.1043, Epoch 16, Batch 40, CE_loss: 0.08873745799064636, Dice_loss: 0.006853719241917133, Consistency_loss: 0.0007425753283314407\n",
      "[Training] Epoch: 16 [=====>         ] 33.3% Loss: 0.1041, Epoch 16, Batch 41, CE_loss: 0.0896911695599556, Dice_loss: 0.007310767658054829, Consistency_loss: 0.0008690235554240644\n",
      "[Training] Epoch: 16 [=====>         ] 34.1% Loss: 0.1040, Epoch 16, Batch 42, CE_loss: 0.09146969765424728, Dice_loss: 0.007613374385982752, Consistency_loss: 0.0006877082050777972\n",
      "[Training] Epoch: 16 [=====>         ] 34.9% Loss: 0.1039, Epoch 16, Batch 43, CE_loss: 0.089467853307724, Dice_loss: 0.007060687523335218, Consistency_loss: 0.0006858193664811552\n",
      "[Training] Epoch: 16 [=====>         ] 35.7% Loss: 0.1037, Epoch 16, Batch 44, CE_loss: 0.08932565897703171, Dice_loss: 0.007565224543213844, Consistency_loss: 0.0010929739801213145\n",
      "[Training] Epoch: 16 [=====>         ] 36.5% Loss: 0.1038, Epoch 16, Batch 45, CE_loss: 0.09852761030197144, Dice_loss: 0.008266192860901356, Consistency_loss: 0.0003663701645564288\n",
      "[Training] Epoch: 16 [=====>         ] 37.3% Loss: 0.1034, Epoch 16, Batch 46, CE_loss: 0.08048056066036224, Dice_loss: 0.005717097315937281, Consistency_loss: 0.0005646580248139799\n",
      "[Training] Epoch: 16 [=====>         ] 38.1% Loss: 0.1033, Epoch 16, Batch 47, CE_loss: 0.08942579478025436, Dice_loss: 0.007492559030652046, Consistency_loss: 0.00045996802509762347\n",
      "[Training] Epoch: 16 [=====>         ] 38.9% Loss: 0.1032, Epoch 16, Batch 48, CE_loss: 0.08812719583511353, Dice_loss: 0.0071009742096066475, Consistency_loss: 0.0009838304249569774\n",
      "[Training] Epoch: 16 [=====>         ] 39.7% Loss: 0.1031, Epoch 16, Batch 49, CE_loss: 0.09139266610145569, Dice_loss: 0.007487279362976551, Consistency_loss: 0.00016313385276589543\n",
      "[Training] Epoch: 16 [======>        ] 40.5% Loss: 0.1030, Epoch 16, Batch 50, CE_loss: 0.09174653142690659, Dice_loss: 0.00741833308711648, Consistency_loss: 0.0008386089466512203\n",
      "[Training] Epoch: 16 [======>        ] 41.3% Loss: 0.1030, Epoch 16, Batch 51, CE_loss: 0.09182383120059967, Dice_loss: 0.00723054725676775, Consistency_loss: 0.0009198749321512878\n",
      "[Training] Epoch: 16 [======>        ] 42.1% Loss: 0.1029, Epoch 16, Batch 52, CE_loss: 0.09370134770870209, Dice_loss: 0.007893670350313187, Consistency_loss: 9.905322076519951e-05\n",
      "[Training] Epoch: 16 [======>        ] 42.9% Loss: 0.1030, Epoch 16, Batch 53, CE_loss: 0.09670625627040863, Dice_loss: 0.008062135428190231, Consistency_loss: 0.0004978558863513172\n",
      "[Training] Epoch: 16 [======>        ] 43.7% Loss: 0.1031, Epoch 16, Batch 54, CE_loss: 0.10194534063339233, Dice_loss: 0.008964667096734047, Consistency_loss: 0.0007341366726905107\n",
      "[Training] Epoch: 16 [======>        ] 44.4% Loss: 0.1029, Epoch 16, Batch 55, CE_loss: 0.08487645536661148, Dice_loss: 0.006252622697502375, Consistency_loss: 0.0005205035558901727\n",
      "[Training] Epoch: 16 [======>        ] 45.2% Loss: 0.1031, Epoch 16, Batch 56, CE_loss: 0.10345876961946487, Dice_loss: 0.008695435710251331, Consistency_loss: 0.001099629676900804\n",
      "[Training] Epoch: 16 [======>        ] 46.0% Loss: 0.1030, Epoch 16, Batch 57, CE_loss: 0.08599217236042023, Dice_loss: 0.006799471564590931, Consistency_loss: 0.00048653711564838886\n",
      "[Training] Epoch: 16 [=======>       ] 46.8% Loss: 0.1031, Epoch 16, Batch 58, CE_loss: 0.10519711673259735, Dice_loss: 0.008481797762215137, Consistency_loss: 0.0006892468081787229\n",
      "[Training] Epoch: 16 [=======>       ] 47.6% Loss: 0.1036, Epoch 16, Batch 59, CE_loss: 0.1167888417840004, Dice_loss: 0.010074024088680744, Consistency_loss: 0.0006377955432981253\n",
      "[Training] Epoch: 16 [=======>       ] 48.4% Loss: 0.1035, Epoch 16, Batch 60, CE_loss: 0.09282432496547699, Dice_loss: 0.00769319711253047, Consistency_loss: 0.0002573926467448473\n",
      "[Training] Epoch: 16 [=======>       ] 49.2% Loss: 0.1036, Epoch 16, Batch 61, CE_loss: 0.09799560904502869, Dice_loss: 0.008631250821053982, Consistency_loss: 0.0003472115204203874\n",
      "[Training] Epoch: 16 [=======>       ] 50.0% Loss: 0.1035, Epoch 16, Batch 62, CE_loss: 0.08843962848186493, Dice_loss: 0.007330254185944796, Consistency_loss: 0.0008620391599833965\n",
      "[Training] Epoch: 16 [=======>       ] 50.8% Loss: 0.1040, Epoch 16, Batch 63, CE_loss: 0.12452143430709839, Dice_loss: 0.011264249682426453, Consistency_loss: 0.0008899748208932579\n",
      "[Training] Epoch: 16 [=======>       ] 51.6% Loss: 0.1040, Epoch 16, Batch 64, CE_loss: 0.09406653046607971, Dice_loss: 0.008010945282876492, Consistency_loss: 0.0011448514414951205\n",
      "[Training] Epoch: 16 [=======>       ] 52.4% Loss: 0.1039, Epoch 16, Batch 65, CE_loss: 0.09294082224369049, Dice_loss: 0.007486984599381685, Consistency_loss: 0.0009779632091522217\n",
      "[Training] Epoch: 16 [=======>       ] 53.2% Loss: 0.1039, Epoch 16, Batch 66, CE_loss: 0.09334681183099747, Dice_loss: 0.007725745905190706, Consistency_loss: 0.0004531262966338545\n",
      "[Training] Epoch: 16 [========>      ] 54.0% Loss: 0.1038, Epoch 16, Batch 67, CE_loss: 0.09261221438646317, Dice_loss: 0.007558067329227924, Consistency_loss: 0.0008044586866162717\n",
      "[Training] Epoch: 16 [========>      ] 54.8% Loss: 0.1037, Epoch 16, Batch 68, CE_loss: 0.08771354705095291, Dice_loss: 0.007022953126579523, Consistency_loss: 0.0005076923407614231\n",
      "[Training] Epoch: 16 [========>      ] 55.6% Loss: 0.1035, Epoch 16, Batch 69, CE_loss: 0.08239827305078506, Dice_loss: 0.0062109860591590405, Consistency_loss: 0.0005373363383114338\n",
      "[Training] Epoch: 16 [========>      ] 56.3% Loss: 0.1036, Epoch 16, Batch 70, CE_loss: 0.10135426372289658, Dice_loss: 0.00924414861947298, Consistency_loss: 0.00018454556993674487\n",
      "[Training] Epoch: 16 [========>      ] 57.1% Loss: 0.1034, Epoch 16, Batch 71, CE_loss: 0.0841563418507576, Dice_loss: 0.006559047382324934, Consistency_loss: 0.0008716959855519235\n",
      "[Training] Epoch: 16 [========>      ] 57.9% Loss: 0.1035, Epoch 16, Batch 72, CE_loss: 0.09700851887464523, Dice_loss: 0.007744083181023598, Consistency_loss: 0.0005847620777785778\n",
      "[Training] Epoch: 16 [========>      ] 58.7% Loss: 0.1034, Epoch 16, Batch 73, CE_loss: 0.08760879188776016, Dice_loss: 0.007054737303406, Consistency_loss: 0.0006735872011631727\n",
      "[Training] Epoch: 16 [========>      ] 59.5% Loss: 0.1034, Epoch 16, Batch 74, CE_loss: 0.10052067786455154, Dice_loss: 0.008915967307984829, Consistency_loss: 9.089573723031208e-05\n",
      "[Training] Epoch: 16 [=========>     ] 60.3% Loss: 0.1033, Epoch 16, Batch 75, CE_loss: 0.08657857030630112, Dice_loss: 0.006963435094803572, Consistency_loss: 0.0009717380744405091\n",
      "[Training] Epoch: 16 [=========>     ] 61.1% Loss: 0.1032, Epoch 16, Batch 76, CE_loss: 0.08783915638923645, Dice_loss: 0.006099884398281574, Consistency_loss: 0.0008764294325374067\n",
      "[Training] Epoch: 16 [=========>     ] 61.9% Loss: 0.1030, Epoch 16, Batch 77, CE_loss: 0.07610835134983063, Dice_loss: 0.0055155158042907715, Consistency_loss: 0.0007735795225016773\n",
      "[Training] Epoch: 16 [=========>     ] 62.7% Loss: 0.1027, Epoch 16, Batch 78, CE_loss: 0.07571948319673538, Dice_loss: 0.0053955004550516605, Consistency_loss: 0.0005898801027797163\n",
      "[Training] Epoch: 16 [=========>     ] 63.5% Loss: 0.1027, Epoch 16, Batch 79, CE_loss: 0.09469443559646606, Dice_loss: 0.008245517499744892, Consistency_loss: 0.0007154589402489364\n",
      "[Training] Epoch: 16 [=========>     ] 64.3% Loss: 0.1026, Epoch 16, Batch 80, CE_loss: 0.08504800498485565, Dice_loss: 0.006866625044494867, Consistency_loss: 0.0007009959663264453\n",
      "[Training] Epoch: 16 [=========>     ] 65.1% Loss: 0.1027, Epoch 16, Batch 81, CE_loss: 0.10311899334192276, Dice_loss: 0.008639024570584297, Consistency_loss: 0.000495788874104619\n",
      "[Training] Epoch: 16 [=========>     ] 65.9% Loss: 0.1029, Epoch 16, Batch 82, CE_loss: 0.10638780146837234, Dice_loss: 0.00954420305788517, Consistency_loss: 0.0007866203086450696\n",
      "[Training] Epoch: 16 [==========>    ] 66.7% Loss: 0.1028, Epoch 16, Batch 83, CE_loss: 0.08812543004751205, Dice_loss: 0.007132110185921192, Consistency_loss: 0.0003403311420697719\n",
      "[Training] Epoch: 16 [==========>    ] 67.5% Loss: 0.1027, Epoch 16, Batch 84, CE_loss: 0.08665064722299576, Dice_loss: 0.007002648897469044, Consistency_loss: 0.00033485746826045215\n",
      "[Training] Epoch: 16 [==========>    ] 68.3% Loss: 0.1027, Epoch 16, Batch 85, CE_loss: 0.09500154852867126, Dice_loss: 0.007619038689881563, Consistency_loss: 0.00013775116531178355\n",
      "[Training] Epoch: 16 [==========>    ] 69.0% Loss: 0.1026, Epoch 16, Batch 86, CE_loss: 0.09316449612379074, Dice_loss: 0.007073669228702784, Consistency_loss: 0.00010904939699685201\n",
      "[Training] Epoch: 16 [==========>    ] 69.8% Loss: 0.1026, Epoch 16, Batch 87, CE_loss: 0.08943183720111847, Dice_loss: 0.007348287384957075, Consistency_loss: 0.0004895944730378687\n",
      "[Training] Epoch: 16 [==========>    ] 70.6% Loss: 0.1025, Epoch 16, Batch 88, CE_loss: 0.08617235720157623, Dice_loss: 0.006919482722878456, Consistency_loss: 0.0006187683320604265\n",
      "[Training] Epoch: 16 [==========>    ] 71.4% Loss: 0.1025, Epoch 16, Batch 89, CE_loss: 0.095892995595932, Dice_loss: 0.008146628737449646, Consistency_loss: 0.0005540942656807601\n",
      "[Training] Epoch: 16 [==========>    ] 72.2% Loss: 0.1024, Epoch 16, Batch 90, CE_loss: 0.0840647965669632, Dice_loss: 0.006948718801140785, Consistency_loss: 0.0008336587925441563\n",
      "[Training] Epoch: 16 [==========>    ] 73.0% Loss: 0.1023, Epoch 16, Batch 91, CE_loss: 0.08965007960796356, Dice_loss: 0.007535380311310291, Consistency_loss: 0.0009719184599816799\n",
      "[Training] Epoch: 16 [===========>   ] 73.8% Loss: 0.1024, Epoch 16, Batch 92, CE_loss: 0.10160898417234421, Dice_loss: 0.008935672231018543, Consistency_loss: 0.00010541477240622044\n",
      "[Training] Epoch: 16 [===========>   ] 74.6% Loss: 0.1024, Epoch 16, Batch 93, CE_loss: 0.0930795893073082, Dice_loss: 0.008006300777196884, Consistency_loss: 0.00015620402700733393\n",
      "[Training] Epoch: 16 [===========>   ] 75.4% Loss: 0.1026, Epoch 16, Batch 94, CE_loss: 0.10636550188064575, Dice_loss: 0.009630534797906876, Consistency_loss: 0.0006862644222564995\n",
      "[Training] Epoch: 16 [===========>   ] 76.2% Loss: 0.1028, Epoch 16, Batch 95, CE_loss: 0.1100001260638237, Dice_loss: 0.009395653381943703, Consistency_loss: 0.0009460453875362873\n",
      "[Training] Epoch: 16 [===========>   ] 77.0% Loss: 0.1028, Epoch 16, Batch 96, CE_loss: 0.10242210328578949, Dice_loss: 0.008959655649960041, Consistency_loss: 0.00022347495541907847\n",
      "[Training] Epoch: 16 [===========>   ] 77.8% Loss: 0.1029, Epoch 16, Batch 97, CE_loss: 0.09556728601455688, Dice_loss: 0.007980157621204853, Consistency_loss: 0.0006771918851882219\n",
      "[Training] Epoch: 16 [===========>   ] 78.6% Loss: 0.1027, Epoch 16, Batch 98, CE_loss: 0.07957470417022705, Dice_loss: 0.0059516699984669685, Consistency_loss: 0.0004225105221848935\n",
      "[Training] Epoch: 16 [===========>   ] 79.4% Loss: 0.1026, Epoch 16, Batch 99, CE_loss: 0.08218573778867722, Dice_loss: 0.006688548717647791, Consistency_loss: 0.0001387767115375027\n",
      "[Training] Epoch: 16 [============>  ] 80.2% Loss: 0.1023, Epoch 16, Batch 100, CE_loss: 0.07482308149337769, Dice_loss: 0.004845594055950642, Consistency_loss: 0.0005184593610465527\n",
      "[Training] Epoch: 16 [============>  ] 81.0% Loss: 0.1022, Epoch 16, Batch 101, CE_loss: 0.08351028710603714, Dice_loss: 0.006657466758042574, Consistency_loss: 0.00015077002171892673\n",
      "[Training] Epoch: 16 [============>  ] 81.7% Loss: 0.1021, Epoch 16, Batch 102, CE_loss: 0.08487511426210403, Dice_loss: 0.006271282210946083, Consistency_loss: 0.0008280669571831822\n",
      "[Training] Epoch: 16 [============>  ] 82.5% Loss: 0.1019, Epoch 16, Batch 103, CE_loss: 0.07788846641778946, Dice_loss: 0.005798341706395149, Consistency_loss: 0.0007624057470820844\n",
      "[Training] Epoch: 16 [============>  ] 83.3% Loss: 0.1017, Epoch 16, Batch 104, CE_loss: 0.07523980736732483, Dice_loss: 0.00550418347120285, Consistency_loss: 0.0005293381400406361\n",
      "[Training] Epoch: 16 [============>  ] 84.1% Loss: 0.1017, Epoch 16, Batch 105, CE_loss: 0.08898437768220901, Dice_loss: 0.007303145714104176, Consistency_loss: 0.0005635854904539883\n",
      "[Training] Epoch: 16 [============>  ] 84.9% Loss: 0.1017, Epoch 16, Batch 106, CE_loss: 0.09122160822153091, Dice_loss: 0.007711351383477449, Consistency_loss: 0.0001232990325661376\n",
      "[Training] Epoch: 16 [============>  ] 85.7% Loss: 0.1017, Epoch 16, Batch 107, CE_loss: 0.09453297406435013, Dice_loss: 0.007896464318037033, Consistency_loss: 0.0009237696649506688\n",
      "[Training] Epoch: 16 [============>  ] 86.5% Loss: 0.1019, Epoch 16, Batch 108, CE_loss: 0.11417403072118759, Dice_loss: 0.010678218677639961, Consistency_loss: 0.0002343361993553117\n",
      "[Training] Epoch: 16 [=============> ] 87.3% Loss: 0.1021, Epoch 16, Batch 109, CE_loss: 0.10907446593046188, Dice_loss: 0.009354387409985065, Consistency_loss: 0.0004223782743792981\n",
      "[Training] Epoch: 16 [=============> ] 88.1% Loss: 0.1021, Epoch 16, Batch 110, CE_loss: 0.09745766222476959, Dice_loss: 0.008722776547074318, Consistency_loss: 0.0005813398747704923\n",
      "[Training] Epoch: 16 [=============> ] 88.9% Loss: 0.1020, Epoch 16, Batch 111, CE_loss: 0.08652656525373459, Dice_loss: 0.007316306699067354, Consistency_loss: 0.000582838780246675\n",
      "[Training] Epoch: 16 [=============> ] 89.7% Loss: 0.1020, Epoch 16, Batch 112, CE_loss: 0.08633670955896378, Dice_loss: 0.0068406169302761555, Consistency_loss: 0.0005255399155430496\n",
      "[Training] Epoch: 16 [=============> ] 90.5% Loss: 0.1018, Epoch 16, Batch 113, CE_loss: 0.07955659925937653, Dice_loss: 0.006109156180173159, Consistency_loss: 0.0007487016846425831\n",
      "[Training] Epoch: 16 [=============> ] 91.3% Loss: 0.1019, Epoch 16, Batch 114, CE_loss: 0.1004139706492424, Dice_loss: 0.009083658456802368, Consistency_loss: 0.0007577749784104526\n",
      "[Training] Epoch: 16 [=============> ] 92.1% Loss: 0.1017, Epoch 16, Batch 115, CE_loss: 0.07682808488607407, Dice_loss: 0.005736328661441803, Consistency_loss: 0.0008642968605272472\n",
      "[Training] Epoch: 16 [=============> ] 92.9% Loss: 0.1018, Epoch 16, Batch 116, CE_loss: 0.09630728513002396, Dice_loss: 0.008415739983320236, Consistency_loss: 0.001081919646821916\n",
      "[Training] Epoch: 16 [==============>] 93.7% Loss: 0.1016, Epoch 16, Batch 117, CE_loss: 0.07400445640087128, Dice_loss: 0.005011327564716339, Consistency_loss: 0.0009706755517981946\n",
      "[Training] Epoch: 16 [==============>] 94.4% Loss: 0.1015, Epoch 16, Batch 118, CE_loss: 0.08881298452615738, Dice_loss: 0.007646812591701746, Consistency_loss: 0.00035204432788304985\n",
      "[Training] Epoch: 16 [==============>] 95.2% Loss: 0.1014, Epoch 16, Batch 119, CE_loss: 0.0809374749660492, Dice_loss: 0.006301818881183863, Consistency_loss: 0.0003848959458991885\n",
      "[Training] Epoch: 16 [==============>] 96.0% Loss: 0.1013, Epoch 16, Batch 120, CE_loss: 0.07978600263595581, Dice_loss: 0.005925000179558992, Consistency_loss: 0.0005954491789452732\n",
      "[Training] Epoch: 16 [==============>] 96.8% Loss: 0.1012, Epoch 16, Batch 121, CE_loss: 0.07644451409578323, Dice_loss: 0.005641070194542408, Consistency_loss: 0.0003413778031244874\n",
      "[Training] Epoch: 16 [==============>] 97.6% Loss: 0.1013, Epoch 16, Batch 122, CE_loss: 0.11291027069091797, Dice_loss: 0.010338472202420235, Consistency_loss: 0.0004519467183854431\n",
      "[Training] Epoch: 16 [==============>] 98.4% Loss: 0.1014, Epoch 16, Batch 123, CE_loss: 0.09631484001874924, Dice_loss: 0.008244583383202553, Consistency_loss: 0.0006818045512773097\n",
      "[Training] Epoch: 16 [==============>] 99.2% Loss: 0.1012, Epoch 16, Batch 124, CE_loss: 0.07464241236448288, Dice_loss: 0.005241023376584053, Consistency_loss: 0.0005175500991754234\n",
      "[Training] Epoch: 16 [DONE]                                 \n",
      "Epoch 16, Batch 125, CE_loss: 0.07493061572313309, Dice_loss: 0.005500357132405043, Consistency_loss: 0.0008412033203057945\n",
      "[Validation] Epoch: 16 [DONE]                                 \n",
      "[Epoch: 16, TrainLoss: 0.1010, TrainDice: 0.0076, ValLoss: 0.2039                                            \n",
      "Number of batches:  126\n",
      "[Training] Epoch: 17 [>              ] 0.8% Loss: 0.0916, Epoch 17, Batch 0, CE_loss: 0.08447904139757156, Dice_loss: 0.006728093605488539, Consistency_loss: 0.0004397167358547449\n",
      "[Training] Epoch: 17 [>              ] 1.6% Loss: 0.0980, Epoch 17, Batch 1, CE_loss: 0.09533632546663284, Dice_loss: 0.008340275846421719, Consistency_loss: 0.0005838905344717205\n",
      "[Training] Epoch: 17 [>              ] 2.4% Loss: 0.1029, Epoch 17, Batch 2, CE_loss: 0.10304863005876541, Dice_loss: 0.00953135546296835, Consistency_loss: 0.0003323756391182542\n",
      "[Training] Epoch: 17 [>              ] 3.2% Loss: 0.0994, Epoch 17, Batch 3, CE_loss: 0.08181002736091614, Dice_loss: 0.006686760578304529, Consistency_loss: 9.947456419467926e-05\n",
      "[Training] Epoch: 17 [>              ] 4.0% Loss: 0.0990, Epoch 17, Batch 4, CE_loss: 0.08989288657903671, Dice_loss: 0.007527441252022982, Consistency_loss: 0.0001276122929994017\n",
      "[Training] Epoch: 17 [>              ] 4.8% Loss: 0.0995, Epoch 17, Batch 5, CE_loss: 0.09324470907449722, Dice_loss: 0.008343033492565155, Consistency_loss: 0.00017307954840362072\n",
      "[Training] Epoch: 17 [>              ] 5.6% Loss: 0.0983, Epoch 17, Batch 6, CE_loss: 0.08407212048768997, Dice_loss: 0.007048085797578096, Consistency_loss: 0.0004102245147805661\n",
      "[Training] Epoch: 17 [>              ] 6.3% Loss: 0.1009, Epoch 17, Batch 7, CE_loss: 0.10895262658596039, Dice_loss: 0.01009283121675253, Consistency_loss: 0.0001406762021360919\n",
      "[Training] Epoch: 17 [=>             ] 7.1% Loss: 0.0992, Epoch 17, Batch 8, CE_loss: 0.07889269292354584, Dice_loss: 0.006449819076806307, Consistency_loss: 0.00020433815370779485\n",
      "[Training] Epoch: 17 [=>             ] 7.9% Loss: 0.0977, Epoch 17, Batch 9, CE_loss: 0.07813823968172073, Dice_loss: 0.006048788316547871, Consistency_loss: 0.00024126713105943054\n",
      "[Training] Epoch: 17 [=>             ] 8.7% Loss: 0.0985, Epoch 17, Batch 10, CE_loss: 0.09659738838672638, Dice_loss: 0.008191194385290146, Consistency_loss: 0.0007481011562049389\n",
      "[Training] Epoch: 17 [=>             ] 9.5% Loss: 0.0996, Epoch 17, Batch 11, CE_loss: 0.1037096306681633, Dice_loss: 0.00801270641386509, Consistency_loss: 0.0006756258080713451\n",
      "[Training] Epoch: 17 [=>             ] 10.3% Loss: 0.0989, Epoch 17, Batch 12, CE_loss: 0.0828557088971138, Dice_loss: 0.006712715607136488, Consistency_loss: 0.0006112877745181322\n",
      "[Training] Epoch: 17 [=>             ] 11.1% Loss: 0.0980, Epoch 17, Batch 13, CE_loss: 0.0796118751168251, Dice_loss: 0.006323500070720911, Consistency_loss: 0.0007557249045930803\n",
      "[Training] Epoch: 17 [=>             ] 11.9% Loss: 0.0973, Epoch 17, Batch 14, CE_loss: 0.08042991161346436, Dice_loss: 0.0062833745032548904, Consistency_loss: 0.00042230868712067604\n",
      "[Training] Epoch: 17 [=>             ] 12.7% Loss: 0.0982, Epoch 17, Batch 15, CE_loss: 0.10184601694345474, Dice_loss: 0.009252481162548065, Consistency_loss: 0.0005666715442202985\n",
      "[Training] Epoch: 17 [==>            ] 13.5% Loss: 0.0979, Epoch 17, Batch 16, CE_loss: 0.08534269034862518, Dice_loss: 0.006881658919155598, Consistency_loss: 0.0005855788476765156\n",
      "[Training] Epoch: 17 [==>            ] 14.3% Loss: 0.0972, Epoch 17, Batch 17, CE_loss: 0.0800296813249588, Dice_loss: 0.006234312430024147, Consistency_loss: 0.0003978091408498585\n",
      "[Training] Epoch: 17 [==>            ] 15.1% Loss: 0.0978, Epoch 17, Batch 18, CE_loss: 0.09894799441099167, Dice_loss: 0.008348027244210243, Consistency_loss: 0.00047409298713319004\n",
      "[Training] Epoch: 17 [==>            ] 15.9% Loss: 0.0969, Epoch 17, Batch 19, CE_loss: 0.07386884838342667, Dice_loss: 0.005410100799053907, Consistency_loss: 0.000517826818395406\n",
      "[Training] Epoch: 17 [==>            ] 16.7% Loss: 0.0965, Epoch 17, Batch 20, CE_loss: 0.08203691989183426, Dice_loss: 0.006488312967121601, Consistency_loss: 0.0004532034508883953\n",
      "[Training] Epoch: 17 [==>            ] 17.5% Loss: 0.0961, Epoch 17, Batch 21, CE_loss: 0.08060970157384872, Dice_loss: 0.006391655188053846, Consistency_loss: 0.00043827309855259955\n",
      "[Training] Epoch: 17 [==>            ] 18.3% Loss: 0.0958, Epoch 17, Batch 22, CE_loss: 0.08305022865533829, Dice_loss: 0.006638793740421534, Consistency_loss: 0.0003568287647794932\n",
      "[Training] Epoch: 17 [==>            ] 19.0% Loss: 0.0965, Epoch 17, Batch 23, CE_loss: 0.10085415840148926, Dice_loss: 0.009073734283447266, Consistency_loss: 0.0005821228842251003\n",
      "[Training] Epoch: 17 [==>            ] 19.8% Loss: 0.0970, Epoch 17, Batch 24, CE_loss: 0.09972222149372101, Dice_loss: 0.009013460949063301, Consistency_loss: 0.0004359222948551178\n",
      "[Training] Epoch: 17 [===>           ] 20.6% Loss: 0.0971, Epoch 17, Batch 25, CE_loss: 0.0916331484913826, Dice_loss: 0.00770976860076189, Consistency_loss: 0.0005578260170295835\n",
      "[Training] Epoch: 17 [===>           ] 21.4% Loss: 0.0971, Epoch 17, Batch 26, CE_loss: 0.08948550373315811, Dice_loss: 0.007513690274208784, Consistency_loss: 0.0018654573941603303\n",
      "[Training] Epoch: 17 [===>           ] 22.2% Loss: 0.0970, Epoch 17, Batch 27, CE_loss: 0.08387844264507294, Dice_loss: 0.006836463697254658, Consistency_loss: 0.001310039428062737\n",
      "[Training] Epoch: 17 [===>           ] 23.0% Loss: 0.0964, Epoch 17, Batch 28, CE_loss: 0.07437697798013687, Dice_loss: 0.005536428187042475, Consistency_loss: 0.0009058592841029167\n",
      "[Training] Epoch: 17 [===>           ] 23.8% Loss: 0.0964, Epoch 17, Batch 29, CE_loss: 0.08905335515737534, Dice_loss: 0.0074018691666424274, Consistency_loss: 0.00043253504554741085\n",
      "[Training] Epoch: 17 [===>           ] 24.6% Loss: 0.0963, Epoch 17, Batch 30, CE_loss: 0.08403579145669937, Dice_loss: 0.006791411433368921, Consistency_loss: 0.0009327883017249405\n",
      "[Training] Epoch: 17 [===>           ] 25.4% Loss: 0.0961, Epoch 17, Batch 31, CE_loss: 0.08247383683919907, Dice_loss: 0.006775479298084974, Consistency_loss: 0.0002864064590539783\n",
      "[Training] Epoch: 17 [===>           ] 26.2% Loss: 0.0960, Epoch 17, Batch 32, CE_loss: 0.08468858897686005, Dice_loss: 0.007428279612213373, Consistency_loss: 0.00048073529615066946\n",
      "[Training] Epoch: 17 [====>          ] 27.0% Loss: 0.0957, Epoch 17, Batch 33, CE_loss: 0.08104174584150314, Dice_loss: 0.0062748584896326065, Consistency_loss: 0.00012414139928296208\n",
      "[Training] Epoch: 17 [====>          ] 27.8% Loss: 0.0963, Epoch 17, Batch 34, CE_loss: 0.10670185089111328, Dice_loss: 0.009842057712376118, Consistency_loss: 0.0008772753062658012\n",
      "[Training] Epoch: 17 [====>          ] 28.6% Loss: 0.0960, Epoch 17, Batch 35, CE_loss: 0.0792512372136116, Dice_loss: 0.0062782783061265945, Consistency_loss: 0.0006317015504464507\n",
      "[Training] Epoch: 17 [====>          ] 29.4% Loss: 0.0961, Epoch 17, Batch 36, CE_loss: 0.09124103933572769, Dice_loss: 0.008007623255252838, Consistency_loss: 0.00038442149525508285\n",
      "[Training] Epoch: 17 [====>          ] 30.2% Loss: 0.0960, Epoch 17, Batch 37, CE_loss: 0.08250347524881363, Dice_loss: 0.006709331646561623, Consistency_loss: 0.000543531496077776\n",
      "[Training] Epoch: 17 [====>          ] 31.0% Loss: 0.0963, Epoch 17, Batch 38, CE_loss: 0.10080047696828842, Dice_loss: 0.00877720769494772, Consistency_loss: 0.0008441870450042188\n",
      "[Training] Epoch: 17 [====>          ] 31.7% Loss: 0.0959, Epoch 17, Batch 39, CE_loss: 0.07151348888874054, Dice_loss: 0.005164276342839003, Consistency_loss: 0.0008559695561416447\n",
      "[Training] Epoch: 17 [====>          ] 32.5% Loss: 0.0957, Epoch 17, Batch 40, CE_loss: 0.0825316309928894, Dice_loss: 0.006904502399265766, Consistency_loss: 0.00011411788000259548\n",
      "[Training] Epoch: 17 [=====>         ] 33.3% Loss: 0.0957, Epoch 17, Batch 41, CE_loss: 0.08637648820877075, Dice_loss: 0.007175083737820387, Consistency_loss: 0.0008487837621942163\n",
      "[Training] Epoch: 17 [=====>         ] 34.1% Loss: 0.0959, Epoch 17, Batch 42, CE_loss: 0.0962253212928772, Dice_loss: 0.008404751308262348, Consistency_loss: 0.00016698923718649894\n",
      "[Training] Epoch: 17 [=====>         ] 34.9% Loss: 0.0960, Epoch 17, Batch 43, CE_loss: 0.09056691825389862, Dice_loss: 0.008284883573651314, Consistency_loss: 0.0006006137118674815\n",
      "[Training] Epoch: 17 [=====>         ] 35.7% Loss: 0.0965, Epoch 17, Batch 44, CE_loss: 0.10873118042945862, Dice_loss: 0.010250893421471119, Consistency_loss: 0.0009064074838533998\n",
      "[Training] Epoch: 17 [=====>         ] 36.5% Loss: 0.0965, Epoch 17, Batch 45, CE_loss: 0.0858093723654747, Dice_loss: 0.007151346188038588, Consistency_loss: 0.000740373448934406\n",
      "[Training] Epoch: 17 [=====>         ] 37.3% Loss: 0.0964, Epoch 17, Batch 46, CE_loss: 0.08832596987485886, Dice_loss: 0.007245639339089394, Consistency_loss: 9.411217615706846e-05\n",
      "[Training] Epoch: 17 [=====>         ] 38.1% Loss: 0.0965, Epoch 17, Batch 47, CE_loss: 0.09239273518323898, Dice_loss: 0.008324950933456421, Consistency_loss: 0.000796654203440994\n",
      "[Training] Epoch: 17 [=====>         ] 38.9% Loss: 0.0965, Epoch 17, Batch 48, CE_loss: 0.08585169911384583, Dice_loss: 0.007318979594856501, Consistency_loss: 0.0012317867949604988\n",
      "[Training] Epoch: 17 [=====>         ] 39.7% Loss: 0.0965, Epoch 17, Batch 49, CE_loss: 0.08657936006784439, Dice_loss: 0.007298443000763655, Consistency_loss: 0.0006921659805811942\n",
      "[Training] Epoch: 17 [======>        ] 40.5% Loss: 0.0964, Epoch 17, Batch 50, CE_loss: 0.0854664221405983, Dice_loss: 0.007142070215195417, Consistency_loss: 0.0009760448592714965\n",
      "[Training] Epoch: 17 [======>        ] 41.3% Loss: 0.0961, Epoch 17, Batch 51, CE_loss: 0.07484833151102066, Dice_loss: 0.005827184300869703, Consistency_loss: 0.0008183530881069601\n",
      "[Training] Epoch: 17 [======>        ] 42.1% Loss: 0.0964, Epoch 17, Batch 52, CE_loss: 0.10389689356088638, Dice_loss: 0.009309939108788967, Consistency_loss: 0.00029368544346652925\n",
      "[Training] Epoch: 17 [======>        ] 42.9% Loss: 0.0966, Epoch 17, Batch 53, CE_loss: 0.09664078056812286, Dice_loss: 0.008420594036579132, Consistency_loss: 0.0005143851740285754\n",
      "[Training] Epoch: 17 [======>        ] 43.7% Loss: 0.0965, Epoch 17, Batch 54, CE_loss: 0.08113469928503036, Dice_loss: 0.006201410666108131, Consistency_loss: 0.0007861460908316076\n",
      "[Training] Epoch: 17 [======>        ] 44.4% Loss: 0.0966, Epoch 17, Batch 55, CE_loss: 0.09288318455219269, Dice_loss: 0.008008924312889576, Consistency_loss: 0.0008392836316488683\n",
      "[Training] Epoch: 17 [======>        ] 45.2% Loss: 0.0963, Epoch 17, Batch 56, CE_loss: 0.07691643387079239, Dice_loss: 0.0062824939377605915, Consistency_loss: 0.0008154815877787769\n",
      "[Training] Epoch: 17 [======>        ] 46.0% Loss: 0.0961, Epoch 17, Batch 57, CE_loss: 0.07868800312280655, Dice_loss: 0.0063271974213421345, Consistency_loss: 0.0006185238598845899\n",
      "[Training] Epoch: 17 [=======>       ] 46.8% Loss: 0.0959, Epoch 17, Batch 58, CE_loss: 0.07517275959253311, Dice_loss: 0.006015412975102663, Consistency_loss: 0.0007324054604396224\n",
      "[Training] Epoch: 17 [=======>       ] 47.6% Loss: 0.0958, Epoch 17, Batch 59, CE_loss: 0.08459249138832092, Dice_loss: 0.006927515845745802, Consistency_loss: 0.0005664726486429572\n",
      "[Training] Epoch: 17 [=======>       ] 48.4% Loss: 0.0960, Epoch 17, Batch 60, CE_loss: 0.09381835907697678, Dice_loss: 0.008412646129727364, Consistency_loss: 0.0005340503412298858\n",
      "[Training] Epoch: 17 [=======>       ] 49.2% Loss: 0.0957, Epoch 17, Batch 61, CE_loss: 0.07505343854427338, Dice_loss: 0.006016431841999292, Consistency_loss: 0.0006340239779092371\n",
      "[Training] Epoch: 17 [=======>       ] 50.0% Loss: 0.0957, Epoch 17, Batch 62, CE_loss: 0.08797983825206757, Dice_loss: 0.007640174124389887, Consistency_loss: 0.0008428025175817311\n",
      "[Training] Epoch: 17 [=======>       ] 50.8% Loss: 0.0957, Epoch 17, Batch 63, CE_loss: 0.08267949521541595, Dice_loss: 0.006756676826626062, Consistency_loss: 0.0009973730193451047\n",
      "[Training] Epoch: 17 [=======>       ] 51.6% Loss: 0.0956, Epoch 17, Batch 64, CE_loss: 0.08501092344522476, Dice_loss: 0.007162195630371571, Consistency_loss: 0.0010569932637736201\n",
      "[Training] Epoch: 17 [=======>       ] 52.4% Loss: 0.0956, Epoch 17, Batch 65, CE_loss: 0.08526420593261719, Dice_loss: 0.007437506690621376, Consistency_loss: 0.001098030712455511\n",
      "[Training] Epoch: 17 [=======>       ] 53.2% Loss: 0.0956, Epoch 17, Batch 66, CE_loss: 0.09041722863912582, Dice_loss: 0.007745504844933748, Consistency_loss: 0.0005132399965077639\n",
      "[Training] Epoch: 17 [========>      ] 54.0% Loss: 0.0959, Epoch 17, Batch 67, CE_loss: 0.1044730395078659, Dice_loss: 0.009086497128009796, Consistency_loss: 0.0006323387497104704\n",
      "[Training] Epoch: 17 [========>      ] 54.8% Loss: 0.0959, Epoch 17, Batch 68, CE_loss: 0.08983243256807327, Dice_loss: 0.007446858566254377, Consistency_loss: 0.00038412437424995005\n",
      "[Training] Epoch: 17 [========>      ] 55.6% Loss: 0.0958, Epoch 17, Batch 69, CE_loss: 0.07704219222068787, Dice_loss: 0.006118981633335352, Consistency_loss: 0.0005436550127342343\n",
      "[Training] Epoch: 17 [========>      ] 56.3% Loss: 0.0959, Epoch 17, Batch 70, CE_loss: 0.0973537266254425, Dice_loss: 0.008796313777565956, Consistency_loss: 0.0005580083816312253\n",
      "[Training] Epoch: 17 [========>      ] 57.1% Loss: 0.0958, Epoch 17, Batch 71, CE_loss: 0.07958971709012985, Dice_loss: 0.006514929700642824, Consistency_loss: 0.0007944012177176774\n",
      "[Training] Epoch: 17 [========>      ] 57.9% Loss: 0.0961, Epoch 17, Batch 72, CE_loss: 0.10787400603294373, Dice_loss: 0.009369667619466782, Consistency_loss: 0.0007187425508163869\n",
      "[Training] Epoch: 17 [========>      ] 58.7% Loss: 0.0960, Epoch 17, Batch 73, CE_loss: 0.07957271486520767, Dice_loss: 0.00623588589951396, Consistency_loss: 0.00043326104059815407\n",
      "[Training] Epoch: 17 [========>      ] 59.5% Loss: 0.0959, Epoch 17, Batch 74, CE_loss: 0.08537708222866058, Dice_loss: 0.007256908807903528, Consistency_loss: 0.0006219483911991119\n",
      "[Training] Epoch: 17 [=========>     ] 60.3% Loss: 0.0966, Epoch 17, Batch 75, CE_loss: 0.13650213181972504, Dice_loss: 0.013254082761704922, Consistency_loss: 0.0007664989097975194\n",
      "[Training] Epoch: 17 [=========>     ] 61.1% Loss: 0.0964, Epoch 17, Batch 76, CE_loss: 0.07266902923583984, Dice_loss: 0.0055686235427856445, Consistency_loss: 0.00022073101717978716\n",
      "[Training] Epoch: 17 [=========>     ] 61.9% Loss: 0.0967, Epoch 17, Batch 77, CE_loss: 0.10904030501842499, Dice_loss: 0.009512919932603836, Consistency_loss: 0.0008346919785253704\n",
      "[Training] Epoch: 17 [=========>     ] 62.7% Loss: 0.0966, Epoch 17, Batch 78, CE_loss: 0.07851386070251465, Dice_loss: 0.006123697850853205, Consistency_loss: 0.00044363411143422127\n",
      "[Training] Epoch: 17 [=========>     ] 63.5% Loss: 0.0967, Epoch 17, Batch 79, CE_loss: 0.09507537633180618, Dice_loss: 0.008863297291100025, Consistency_loss: 0.0005985280149616301\n",
      "[Training] Epoch: 17 [=========>     ] 64.3% Loss: 0.0967, Epoch 17, Batch 80, CE_loss: 0.09367235749959946, Dice_loss: 0.008511485531926155, Consistency_loss: 0.0006890833028592169\n",
      "[Training] Epoch: 17 [=========>     ] 65.1% Loss: 0.0967, Epoch 17, Batch 81, CE_loss: 0.08516500890254974, Dice_loss: 0.006050326395779848, Consistency_loss: 0.00015670944412704557\n",
      "[Training] Epoch: 17 [=========>     ] 65.9% Loss: 0.0967, Epoch 17, Batch 82, CE_loss: 0.09034782648086548, Dice_loss: 0.007988901808857918, Consistency_loss: 0.0007397457375191152\n",
      "[Training] Epoch: 17 [==========>    ] 66.7% Loss: 0.0967, Epoch 17, Batch 83, CE_loss: 0.09197694808244705, Dice_loss: 0.008460434153676033, Consistency_loss: 0.00039793053292669356\n",
      "[Training] Epoch: 17 [==========>    ] 67.5% Loss: 0.0967, Epoch 17, Batch 84, CE_loss: 0.0858997106552124, Dice_loss: 0.007575246971100569, Consistency_loss: 0.0004384322674013674\n",
      "[Training] Epoch: 17 [==========>    ] 68.3% Loss: 0.0972, Epoch 17, Batch 85, CE_loss: 0.12292911857366562, Dice_loss: 0.01203023549169302, Consistency_loss: 0.0003678404027596116\n",
      "[Training] Epoch: 17 [==========>    ] 69.0% Loss: 0.0971, Epoch 17, Batch 86, CE_loss: 0.0821448564529419, Dice_loss: 0.006750794127583504, Consistency_loss: 0.0001422746863681823\n",
      "[Training] Epoch: 17 [==========>    ] 69.8% Loss: 0.0971, Epoch 17, Batch 87, CE_loss: 0.09078747779130936, Dice_loss: 0.008148944936692715, Consistency_loss: 0.0005384098622016609\n",
      "[Training] Epoch: 17 [==========>    ] 70.6% Loss: 0.0970, Epoch 17, Batch 88, CE_loss: 0.08464772254228592, Dice_loss: 0.0072167920880019665, Consistency_loss: 0.0006268768338486552\n",
      "[Training] Epoch: 17 [==========>    ] 71.4% Loss: 0.0969, Epoch 17, Batch 89, CE_loss: 0.0745774433016777, Dice_loss: 0.006156586576253176, Consistency_loss: 0.00043886611820198596\n",
      "[Training] Epoch: 17 [==========>    ] 72.2% Loss: 0.0967, Epoch 17, Batch 90, CE_loss: 0.07627497613430023, Dice_loss: 0.006326405797153711, Consistency_loss: 0.0008465567952953279\n",
      "[Training] Epoch: 17 [==========>    ] 73.0% Loss: 0.0969, Epoch 17, Batch 91, CE_loss: 0.10469642281532288, Dice_loss: 0.009650011546909809, Consistency_loss: 0.0008878777734935284\n",
      "[Training] Epoch: 17 [===========>   ] 73.8% Loss: 0.0970, Epoch 17, Batch 92, CE_loss: 0.09275444597005844, Dice_loss: 0.008092882111668587, Consistency_loss: 0.0007102119270712137\n",
      "[Training] Epoch: 17 [===========>   ] 74.6% Loss: 0.0969, Epoch 17, Batch 93, CE_loss: 0.0820673257112503, Dice_loss: 0.006510110571980476, Consistency_loss: 0.0007252992945723236\n",
      "[Training] Epoch: 17 [===========>   ] 75.4% Loss: 0.0972, Epoch 17, Batch 94, CE_loss: 0.11909922957420349, Dice_loss: 0.010731469839811325, Consistency_loss: 0.0006899292930029333\n",
      "[Training] Epoch: 17 [===========>   ] 76.2% Loss: 0.0973, Epoch 17, Batch 95, CE_loss: 0.09315957874059677, Dice_loss: 0.008496983908116817, Consistency_loss: 0.0007632345659658313\n",
      "[Training] Epoch: 17 [===========>   ] 77.0% Loss: 0.0972, Epoch 17, Batch 96, CE_loss: 0.08319403976202011, Dice_loss: 0.007029310334473848, Consistency_loss: 0.00016572349704802036\n",
      "[Training] Epoch: 17 [===========>   ] 77.8% Loss: 0.0972, Epoch 17, Batch 97, CE_loss: 0.083018958568573, Dice_loss: 0.006577013526111841, Consistency_loss: 0.00045242701889947057\n",
      "[Training] Epoch: 17 [===========>   ] 78.6% Loss: 0.0971, Epoch 17, Batch 98, CE_loss: 0.0805506706237793, Dice_loss: 0.006583272013813257, Consistency_loss: 0.0004701622237917036\n",
      "[Training] Epoch: 17 [===========>   ] 79.4% Loss: 0.0971, Epoch 17, Batch 99, CE_loss: 0.09086519479751587, Dice_loss: 0.007932275533676147, Consistency_loss: 0.0005840776138938963\n",
      "[Training] Epoch: 17 [============>  ] 80.2% Loss: 0.0969, Epoch 17, Batch 100, CE_loss: 0.07403525710105896, Dice_loss: 0.005741165950894356, Consistency_loss: 0.00016053716535679996\n",
      "[Training] Epoch: 17 [============>  ] 81.0% Loss: 0.0968, Epoch 17, Batch 101, CE_loss: 0.08211398869752884, Dice_loss: 0.007042613811790943, Consistency_loss: 0.00012980832252651453\n",
      "[Training] Epoch: 17 [============>  ] 81.7% Loss: 0.0969, Epoch 17, Batch 102, CE_loss: 0.09011482447385788, Dice_loss: 0.0081189488992095, Consistency_loss: 0.0008676155703142285\n",
      "[Training] Epoch: 17 [============>  ] 82.5% Loss: 0.0970, Epoch 17, Batch 103, CE_loss: 0.09930160641670227, Dice_loss: 0.008247283287346363, Consistency_loss: 0.0006955638527870178\n",
      "[Training] Epoch: 17 [============>  ] 83.3% Loss: 0.0968, Epoch 17, Batch 104, CE_loss: 0.07512019574642181, Dice_loss: 0.005716663785278797, Consistency_loss: 8.432111644651741e-05\n",
      "[Training] Epoch: 17 [============>  ] 84.1% Loss: 0.0967, Epoch 17, Batch 105, CE_loss: 0.07728814333677292, Dice_loss: 0.006295256782323122, Consistency_loss: 0.0008015450439415872\n",
      "[Training] Epoch: 17 [============>  ] 84.9% Loss: 0.0967, Epoch 17, Batch 106, CE_loss: 0.09114903211593628, Dice_loss: 0.008056672289967537, Consistency_loss: 0.0006855392712168396\n",
      "[Training] Epoch: 17 [============>  ] 85.7% Loss: 0.0966, Epoch 17, Batch 107, CE_loss: 0.07853388786315918, Dice_loss: 0.006728361826390028, Consistency_loss: 0.0008391037699766457\n",
      "[Training] Epoch: 17 [============>  ] 86.5% Loss: 0.0967, Epoch 17, Batch 108, CE_loss: 0.09865963459014893, Dice_loss: 0.008802894502878189, Consistency_loss: 0.0005824524560011923\n",
      "[Training] Epoch: 17 [=============> ] 87.3% Loss: 0.0966, Epoch 17, Batch 109, CE_loss: 0.07265638560056686, Dice_loss: 0.0055036828853189945, Consistency_loss: 0.0003854777314700186\n",
      "[Training] Epoch: 17 [=============> ] 88.1% Loss: 0.0966, Epoch 17, Batch 110, CE_loss: 0.0969322919845581, Dice_loss: 0.008463921025395393, Consistency_loss: 0.00027596516883932054\n",
      "[Training] Epoch: 17 [=============> ] 88.9% Loss: 0.0966, Epoch 17, Batch 111, CE_loss: 0.08049281686544418, Dice_loss: 0.006328967399895191, Consistency_loss: 0.0004756882262881845\n",
      "[Training] Epoch: 17 [=============> ] 89.7% Loss: 0.0966, Epoch 17, Batch 112, CE_loss: 0.08759720623493195, Dice_loss: 0.0072294073179364204, Consistency_loss: 0.0005828297580592334\n",
      "[Training] Epoch: 17 [=============> ] 90.5% Loss: 0.0967, Epoch 17, Batch 113, CE_loss: 0.0998668298125267, Dice_loss: 0.009024690836668015, Consistency_loss: 0.0005539173725992441\n",
      "[Training] Epoch: 17 [=============> ] 91.3% Loss: 0.0966, Epoch 17, Batch 114, CE_loss: 0.07952992618083954, Dice_loss: 0.006281854584813118, Consistency_loss: 0.0006889483192935586\n",
      "[Training] Epoch: 17 [=============> ] 92.1% Loss: 0.0965, Epoch 17, Batch 115, CE_loss: 0.08299225568771362, Dice_loss: 0.006355284247547388, Consistency_loss: 0.0007429147372022271\n",
      "[Training] Epoch: 17 [=============> ] 92.9% Loss: 0.0966, Epoch 17, Batch 116, CE_loss: 0.09230002015829086, Dice_loss: 0.007978977635502815, Consistency_loss: 0.0007162248366512358\n",
      "[Training] Epoch: 17 [==============>] 93.7% Loss: 0.0965, Epoch 17, Batch 117, CE_loss: 0.07977993786334991, Dice_loss: 0.006264934316277504, Consistency_loss: 0.0007290698122233152\n",
      "[Training] Epoch: 17 [==============>] 94.4% Loss: 0.0964, Epoch 17, Batch 118, CE_loss: 0.08358803391456604, Dice_loss: 0.007078081835061312, Consistency_loss: 0.0004575135244522244\n",
      "[Training] Epoch: 17 [==============>] 95.2% Loss: 0.0964, Epoch 17, Batch 119, CE_loss: 0.08520162105560303, Dice_loss: 0.007426549680531025, Consistency_loss: 0.00045925608719699085\n",
      "[Training] Epoch: 17 [==============>] 96.0% Loss: 0.0964, Epoch 17, Batch 120, CE_loss: 0.0847354605793953, Dice_loss: 0.007407760713249445, Consistency_loss: 0.0008503645658493042\n",
      "[Training] Epoch: 17 [==============>] 96.8% Loss: 0.0962, Epoch 17, Batch 121, CE_loss: 0.07327763736248016, Dice_loss: 0.005804179701954126, Consistency_loss: 0.00031529730767942965\n",
      "[Training] Epoch: 17 [==============>] 97.6% Loss: 0.0961, Epoch 17, Batch 122, CE_loss: 0.07594035565853119, Dice_loss: 0.006132822018116713, Consistency_loss: 0.00035180390113964677\n",
      "[Training] Epoch: 17 [==============>] 98.4% Loss: 0.0960, Epoch 17, Batch 123, CE_loss: 0.07347045093774796, Dice_loss: 0.005879634991288185, Consistency_loss: 0.0002835568448062986\n",
      "[Training] Epoch: 17 [==============>] 99.2% Loss: 0.0960, Epoch 17, Batch 124, CE_loss: 0.09216442704200745, Dice_loss: 0.008041557855904102, Consistency_loss: 0.0007392640109173954\n",
      "[Training] Epoch: 17 [DONE]                                 \n",
      "Epoch 17, Batch 125, CE_loss: 0.08247949182987213, Dice_loss: 0.006912370212376118, Consistency_loss: 0.0008737609605304897\n",
      "[Validation] Epoch: 17 [DONE]                                 \n",
      "[Epoch: 17, TrainLoss: 0.0960, TrainDice: 0.0074, ValLoss: 0.1597                                            \n",
      "Number of batches:  126\n",
      "[Training] Epoch: 18 [>              ] 0.8% Loss: 0.0816, Epoch 18, Batch 0, CE_loss: 0.07476869970560074, Dice_loss: 0.005785314831882715, Consistency_loss: 0.0010095045436173677\n",
      "[Training] Epoch: 18 [>              ] 1.6% Loss: 0.0763, Epoch 18, Batch 1, CE_loss: 0.06619326025247574, Dice_loss: 0.004562473390251398, Consistency_loss: 0.000364346633432433\n",
      "[Training] Epoch: 18 [>              ] 2.4% Loss: 0.0810, Epoch 18, Batch 2, CE_loss: 0.08326742798089981, Dice_loss: 0.007116182241588831, Consistency_loss: 5.7921057305065915e-05\n",
      "[Training] Epoch: 18 [>              ] 3.2% Loss: 0.0854, Epoch 18, Batch 3, CE_loss: 0.09047282487154007, Dice_loss: 0.007877697236835957, Consistency_loss: 0.00010455962183186784\n",
      "[Training] Epoch: 18 [>              ] 4.0% Loss: 0.0839, Epoch 18, Batch 4, CE_loss: 0.07214004546403885, Dice_loss: 0.005489583592861891, Consistency_loss: 0.0004457747272681445\n",
      "[Training] Epoch: 18 [>              ] 4.8% Loss: 0.0856, Epoch 18, Batch 5, CE_loss: 0.0860944613814354, Dice_loss: 0.007427841890603304, Consistency_loss: 0.00014531624037772417\n",
      "[Training] Epoch: 18 [>              ] 5.6% Loss: 0.0877, Epoch 18, Batch 6, CE_loss: 0.09214118123054504, Dice_loss: 0.007986152544617653, Consistency_loss: 0.0002108758344547823\n",
      "[Training] Epoch: 18 [>              ] 6.3% Loss: 0.0872, Epoch 18, Batch 7, CE_loss: 0.07707323879003525, Dice_loss: 0.006139268167316914, Consistency_loss: 0.00035997547092847526\n",
      "[Training] Epoch: 18 [=>             ] 7.1% Loss: 0.0870, Epoch 18, Batch 8, CE_loss: 0.07861676812171936, Dice_loss: 0.006686769891530275, Consistency_loss: 0.00025235756766051054\n",
      "[Training] Epoch: 18 [=>             ] 7.9% Loss: 0.0877, Epoch 18, Batch 9, CE_loss: 0.08643788844347, Dice_loss: 0.007295014336705208, Consistency_loss: 6.640774518018588e-05\n",
      "[Training] Epoch: 18 [=>             ] 8.7% Loss: 0.0886, Epoch 18, Batch 10, CE_loss: 0.08900120854377747, Dice_loss: 0.007993921637535095, Consistency_loss: 0.0006898302817717195\n",
      "[Training] Epoch: 18 [=>             ] 9.5% Loss: 0.0890, Epoch 18, Batch 11, CE_loss: 0.08597902208566666, Dice_loss: 0.0070641119964420795, Consistency_loss: 0.0004831852565985173\n",
      "[Training] Epoch: 18 [=>             ] 10.3% Loss: 0.0901, Epoch 18, Batch 12, CE_loss: 0.09545291215181351, Dice_loss: 0.0077920230105519295, Consistency_loss: 0.00045400625094771385\n",
      "[Training] Epoch: 18 [=>             ] 11.1% Loss: 0.0898, Epoch 18, Batch 13, CE_loss: 0.07893043756484985, Dice_loss: 0.006723095662891865, Consistency_loss: 7.405233918689191e-05\n",
      "[Training] Epoch: 18 [=>             ] 11.9% Loss: 0.0902, Epoch 18, Batch 14, CE_loss: 0.08825310319662094, Dice_loss: 0.007769810035824776, Consistency_loss: 0.0004175642679911107\n",
      "[Training] Epoch: 18 [=>             ] 12.7% Loss: 0.0902, Epoch 18, Batch 15, CE_loss: 0.08182916790246964, Dice_loss: 0.00694753834977746, Consistency_loss: 0.0004328492213971913\n",
      "[Training] Epoch: 18 [==>            ] 13.5% Loss: 0.0892, Epoch 18, Batch 16, CE_loss: 0.06860028207302094, Dice_loss: 0.004891464486718178, Consistency_loss: 0.000129026870126836\n",
      "[Training] Epoch: 18 [==>            ] 14.3% Loss: 0.0898, Epoch 18, Batch 17, CE_loss: 0.0916416123509407, Dice_loss: 0.007876226678490639, Consistency_loss: 0.00010128542635357007\n",
      "[Training] Epoch: 18 [==>            ] 15.1% Loss: 0.0898, Epoch 18, Batch 18, CE_loss: 0.08291983604431152, Dice_loss: 0.007110013160854578, Consistency_loss: 0.0007307835039682686\n",
      "[Training] Epoch: 18 [==>            ] 15.9% Loss: 0.0899, Epoch 18, Batch 19, CE_loss: 0.08498764783143997, Dice_loss: 0.006814143154770136, Consistency_loss: 0.00019958899065386504\n",
      "[Training] Epoch: 18 [==>            ] 16.7% Loss: 0.0901, Epoch 18, Batch 20, CE_loss: 0.08521228283643723, Dice_loss: 0.006901744287461042, Consistency_loss: 0.0003935749118681997\n",
      "[Training] Epoch: 18 [==>            ] 17.5% Loss: 0.0901, Epoch 18, Batch 21, CE_loss: 0.0838313177227974, Dice_loss: 0.007208459544926882, Consistency_loss: 0.00040207942947745323\n",
      "[Training] Epoch: 18 [==>            ] 18.3% Loss: 0.0903, Epoch 18, Batch 22, CE_loss: 0.08531428128480911, Dice_loss: 0.007267369423061609, Consistency_loss: 0.0005329294945113361\n",
      "[Training] Epoch: 18 [==>            ] 19.0% Loss: 0.0901, Epoch 18, Batch 23, CE_loss: 0.07938574254512787, Dice_loss: 0.006758053787052631, Consistency_loss: 0.0005720973131246865\n",
      "[Training] Epoch: 18 [==>            ] 19.8% Loss: 0.0899, Epoch 18, Batch 24, CE_loss: 0.0789242759346962, Dice_loss: 0.005974996369332075, Consistency_loss: 0.0003670618461910635\n",
      "[Training] Epoch: 18 [===>           ] 20.6% Loss: 0.0902, Epoch 18, Batch 25, CE_loss: 0.08903801441192627, Dice_loss: 0.007098810747265816, Consistency_loss: 0.00011734507279470563\n",
      "[Training] Epoch: 18 [===>           ] 21.4% Loss: 0.0904, Epoch 18, Batch 26, CE_loss: 0.08766201883554459, Dice_loss: 0.007692495360970497, Consistency_loss: 0.0008588282507844269\n",
      "[Training] Epoch: 18 [===>           ] 22.2% Loss: 0.0903, Epoch 18, Batch 27, CE_loss: 0.08164681494235992, Dice_loss: 0.00676294881850481, Consistency_loss: 0.0006275681662373245\n",
      "[Training] Epoch: 18 [===>           ] 23.0% Loss: 0.0899, Epoch 18, Batch 28, CE_loss: 0.07010860741138458, Dice_loss: 0.005472931545227766, Consistency_loss: 0.0006592620047740638\n",
      "[Training] Epoch: 18 [===>           ] 23.8% Loss: 0.0907, Epoch 18, Batch 29, CE_loss: 0.10603208839893341, Dice_loss: 0.00942374486476183, Consistency_loss: 0.0005632169777527452\n",
      "[Training] Epoch: 18 [===>           ] 24.6% Loss: 0.0911, Epoch 18, Batch 30, CE_loss: 0.09484345465898514, Dice_loss: 0.007951417937874794, Consistency_loss: 0.0011331880232319236\n",
      "[Training] Epoch: 18 [===>           ] 25.4% Loss: 0.0908, Epoch 18, Batch 31, CE_loss: 0.07446388900279999, Dice_loss: 0.006055368576198816, Consistency_loss: 6.866746844025329e-05\n",
      "[Training] Epoch: 18 [===>           ] 26.2% Loss: 0.0905, Epoch 18, Batch 32, CE_loss: 0.07485029101371765, Dice_loss: 0.006015721242874861, Consistency_loss: 0.00011155568063259125\n",
      "[Training] Epoch: 18 [====>          ] 27.0% Loss: 0.0905, Epoch 18, Batch 33, CE_loss: 0.08078726381063461, Dice_loss: 0.006818917579948902, Consistency_loss: 0.0007191527402028441\n",
      "[Training] Epoch: 18 [====>          ] 27.8% Loss: 0.0901, Epoch 18, Batch 34, CE_loss: 0.07141175121068954, Dice_loss: 0.005554752424359322, Consistency_loss: 0.0001136920545832254\n",
      "[Training] Epoch: 18 [====>          ] 28.6% Loss: 0.0900, Epoch 18, Batch 35, CE_loss: 0.08000847697257996, Dice_loss: 0.006541572976857424, Consistency_loss: 0.00030121146119199693\n",
      "[Training] Epoch: 18 [====>          ] 29.4% Loss: 0.0903, Epoch 18, Batch 36, CE_loss: 0.09176989644765854, Dice_loss: 0.008353816345334053, Consistency_loss: 0.00035821646451950073\n",
      "[Training] Epoch: 18 [====>          ] 30.2% Loss: 0.0901, Epoch 18, Batch 37, CE_loss: 0.07807237654924393, Dice_loss: 0.00664295582100749, Consistency_loss: 0.0005343483644537628\n",
      "[Training] Epoch: 18 [====>          ] 31.0% Loss: 0.0902, Epoch 18, Batch 38, CE_loss: 0.08350992947816849, Dice_loss: 0.007376611698418856, Consistency_loss: 0.0004895773017778993\n",
      "[Training] Epoch: 18 [====>          ] 31.7% Loss: 0.0897, Epoch 18, Batch 39, CE_loss: 0.06530335545539856, Dice_loss: 0.004733737092465162, Consistency_loss: 0.0002167328930227086\n",
      "[Training] Epoch: 18 [====>          ] 32.5% Loss: 0.0900, Epoch 18, Batch 40, CE_loss: 0.0934358611702919, Dice_loss: 0.00864536315202713, Consistency_loss: 0.0007013239664956927\n",
      "[Training] Epoch: 18 [=====>         ] 33.3% Loss: 0.0903, Epoch 18, Batch 41, CE_loss: 0.09294796735048294, Dice_loss: 0.008733934722840786, Consistency_loss: 0.0007826067740097642\n",
      "[Training] Epoch: 18 [=====>         ] 34.1% Loss: 0.0903, Epoch 18, Batch 42, CE_loss: 0.08340974152088165, Dice_loss: 0.0072984700091183186, Consistency_loss: 0.0007377114961855114\n",
      "[Training] Epoch: 18 [=====>         ] 34.9% Loss: 0.0906, Epoch 18, Batch 43, CE_loss: 0.09287098795175552, Dice_loss: 0.008448632434010506, Consistency_loss: 0.0006348637398332357\n",
      "[Training] Epoch: 18 [=====>         ] 35.7% Loss: 0.0903, Epoch 18, Batch 44, CE_loss: 0.07315473258495331, Dice_loss: 0.005750732496380806, Consistency_loss: 0.00018009245104622096\n",
      "[Training] Epoch: 18 [=====>         ] 36.5% Loss: 0.0902, Epoch 18, Batch 45, CE_loss: 0.07745787501335144, Dice_loss: 0.006733046844601631, Consistency_loss: 0.00042655333527363837\n",
      "[Training] Epoch: 18 [=====>         ] 37.3% Loss: 0.0907, Epoch 18, Batch 46, CE_loss: 0.10280358791351318, Dice_loss: 0.008800377137959003, Consistency_loss: 0.0005280208424665034\n",
      "[Training] Epoch: 18 [=====>         ] 38.1% Loss: 0.0910, Epoch 18, Batch 47, CE_loss: 0.09775552153587341, Dice_loss: 0.008570592850446701, Consistency_loss: 0.0004893200821243227\n",
      "[Training] Epoch: 18 [=====>         ] 38.9% Loss: 0.0908, Epoch 18, Batch 48, CE_loss: 0.07576290518045425, Dice_loss: 0.006020495668053627, Consistency_loss: 0.0010692962678149343\n",
      "[Training] Epoch: 18 [=====>         ] 39.7% Loss: 0.0906, Epoch 18, Batch 49, CE_loss: 0.07412053644657135, Dice_loss: 0.005794841330498457, Consistency_loss: 0.0005735682207159698\n",
      "[Training] Epoch: 18 [======>        ] 40.5% Loss: 0.0906, Epoch 18, Batch 50, CE_loss: 0.08154072612524033, Dice_loss: 0.007280042860656977, Consistency_loss: 0.000594542536418885\n",
      "[Training] Epoch: 18 [======>        ] 41.3% Loss: 0.0901, Epoch 18, Batch 51, CE_loss: 0.06019723787903786, Dice_loss: 0.004161054268479347, Consistency_loss: 0.0009097200236283243\n",
      "[Training] Epoch: 18 [======>        ] 42.1% Loss: 0.0902, Epoch 18, Batch 52, CE_loss: 0.08753625303506851, Dice_loss: 0.007859967648983002, Consistency_loss: 0.00020309699175413698\n",
      "[Training] Epoch: 18 [======>        ] 42.9% Loss: 0.0902, Epoch 18, Batch 53, CE_loss: 0.08412468433380127, Dice_loss: 0.006969666574150324, Consistency_loss: 0.00030478445114567876\n",
      "[Training] Epoch: 18 [======>        ] 43.7% Loss: 0.0902, Epoch 18, Batch 54, CE_loss: 0.08085808157920837, Dice_loss: 0.007272979710251093, Consistency_loss: 0.0007575023919343948\n",
      "[Training] Epoch: 18 [======>        ] 44.4% Loss: 0.0901, Epoch 18, Batch 55, CE_loss: 0.07508335262537003, Dice_loss: 0.005767688155174255, Consistency_loss: 0.0006468202918767929\n",
      "[Training] Epoch: 18 [======>        ] 45.2% Loss: 0.0903, Epoch 18, Batch 56, CE_loss: 0.09386976063251495, Dice_loss: 0.00860906857997179, Consistency_loss: 0.0010307688498869538\n",
      "[Training] Epoch: 18 [======>        ] 46.0% Loss: 0.0901, Epoch 18, Batch 57, CE_loss: 0.07331663370132446, Dice_loss: 0.00605589197948575, Consistency_loss: 0.0005036087241023779\n",
      "[Training] Epoch: 18 [=======>       ] 46.8% Loss: 0.0901, Epoch 18, Batch 58, CE_loss: 0.07919543981552124, Dice_loss: 0.006780168507248163, Consistency_loss: 0.0005586849874816835\n",
      "[Training] Epoch: 18 [=======>       ] 47.6% Loss: 0.0899, Epoch 18, Batch 59, CE_loss: 0.0720164105296135, Dice_loss: 0.0056986212730407715, Consistency_loss: 0.00011714768334059045\n",
      "[Training] Epoch: 18 [=======>       ] 48.4% Loss: 0.0899, Epoch 18, Batch 60, CE_loss: 0.083358533680439, Dice_loss: 0.007031469140201807, Consistency_loss: 0.00036529029603116214\n",
      "[Training] Epoch: 18 [=======>       ] 49.2% Loss: 0.0900, Epoch 18, Batch 61, CE_loss: 0.09003821015357971, Dice_loss: 0.00787905603647232, Consistency_loss: 0.00047405503573827446\n",
      "[Training] Epoch: 18 [=======>       ] 50.0% Loss: 0.0899, Epoch 18, Batch 62, CE_loss: 0.07529006153345108, Dice_loss: 0.006085248664021492, Consistency_loss: 0.000713961198925972\n",
      "[Training] Epoch: 18 [=======>       ] 50.8% Loss: 0.0897, Epoch 18, Batch 63, CE_loss: 0.0708247497677803, Dice_loss: 0.005643975920975208, Consistency_loss: 0.000770695332903415\n",
      "[Training] Epoch: 18 [=======>       ] 51.6% Loss: 0.0897, Epoch 18, Batch 64, CE_loss: 0.08211472630500793, Dice_loss: 0.006937797646969557, Consistency_loss: 0.00016756549302954227\n",
      "[Training] Epoch: 18 [=======>       ] 52.4% Loss: 0.0899, Epoch 18, Batch 65, CE_loss: 0.09641190618276596, Dice_loss: 0.008737752214074135, Consistency_loss: 0.00064008281333372\n",
      "[Training] Epoch: 18 [=======>       ] 53.2% Loss: 0.0901, Epoch 18, Batch 66, CE_loss: 0.09454705566167831, Dice_loss: 0.008616462349891663, Consistency_loss: 0.0002690186374820769\n",
      "[Training] Epoch: 18 [========>      ] 54.0% Loss: 0.0901, Epoch 18, Batch 67, CE_loss: 0.08402720838785172, Dice_loss: 0.007366199977695942, Consistency_loss: 0.00017319805920124054\n",
      "[Training] Epoch: 18 [========>      ] 54.8% Loss: 0.0899, Epoch 18, Batch 68, CE_loss: 0.06698623299598694, Dice_loss: 0.0049976082518696785, Consistency_loss: 0.00027347009745426476\n",
      "[Training] Epoch: 18 [========>      ] 55.6% Loss: 0.0899, Epoch 18, Batch 69, CE_loss: 0.08297719061374664, Dice_loss: 0.007169316988438368, Consistency_loss: 0.00017525952716823667\n",
      "[Training] Epoch: 18 [========>      ] 56.3% Loss: 0.0898, Epoch 18, Batch 70, CE_loss: 0.07485725730657578, Dice_loss: 0.006072137039154768, Consistency_loss: 0.000481033930554986\n",
      "[Training] Epoch: 18 [========>      ] 57.1% Loss: 0.0899, Epoch 18, Batch 71, CE_loss: 0.09041040390729904, Dice_loss: 0.00787133164703846, Consistency_loss: 0.000633730145636946\n",
      "[Training] Epoch: 18 [========>      ] 57.9% Loss: 0.0902, Epoch 18, Batch 72, CE_loss: 0.10243623703718185, Dice_loss: 0.009084919467568398, Consistency_loss: 0.0005101824062876403\n",
      "[Training] Epoch: 18 [========>      ] 58.7% Loss: 0.0900, Epoch 18, Batch 73, CE_loss: 0.07093676924705505, Dice_loss: 0.005531694274395704, Consistency_loss: 0.00015192589489743114\n",
      "[Training] Epoch: 18 [========>      ] 59.5% Loss: 0.0900, Epoch 18, Batch 74, CE_loss: 0.08402902632951736, Dice_loss: 0.007401082199066877, Consistency_loss: 0.00011662710312521085\n",
      "[Training] Epoch: 18 [=========>     ] 60.3% Loss: 0.0899, Epoch 18, Batch 75, CE_loss: 0.07042762637138367, Dice_loss: 0.005574529059231281, Consistency_loss: 0.0007028126274235547\n",
      "[Training] Epoch: 18 [=========>     ] 61.1% Loss: 0.0898, Epoch 18, Batch 76, CE_loss: 0.07802022248506546, Dice_loss: 0.006330643780529499, Consistency_loss: 0.0006971688126213849\n",
      "[Training] Epoch: 18 [=========>     ] 61.9% Loss: 0.0898, Epoch 18, Batch 77, CE_loss: 0.08117813616991043, Dice_loss: 0.007239148486405611, Consistency_loss: 0.0001945172989508137\n",
      "[Training] Epoch: 18 [=========>     ] 62.7% Loss: 0.0896, Epoch 18, Batch 78, CE_loss: 0.06967484205961227, Dice_loss: 0.005364275071769953, Consistency_loss: 9.756063809618354e-05\n",
      "[Training] Epoch: 18 [=========>     ] 63.5% Loss: 0.0898, Epoch 18, Batch 79, CE_loss: 0.09798893332481384, Dice_loss: 0.008914988487958908, Consistency_loss: 0.0005018151714466512\n",
      "[Training] Epoch: 18 [=========>     ] 64.3% Loss: 0.0896, Epoch 18, Batch 80, CE_loss: 0.06908734887838364, Dice_loss: 0.005491107702255249, Consistency_loss: 0.0005402045790106058\n",
      "[Training] Epoch: 18 [=========>     ] 65.1% Loss: 0.0897, Epoch 18, Batch 81, CE_loss: 0.0845450758934021, Dice_loss: 0.007749483454972506, Consistency_loss: 0.0007368542719632387\n",
      "[Training] Epoch: 18 [=========>     ] 65.9% Loss: 0.0897, Epoch 18, Batch 82, CE_loss: 0.08358414471149445, Dice_loss: 0.006802788469940424, Consistency_loss: 0.0006643155938945711\n",
      "[Training] Epoch: 18 [==========>    ] 66.7% Loss: 0.0897, Epoch 18, Batch 83, CE_loss: 0.07970193773508072, Dice_loss: 0.0070702629163861275, Consistency_loss: 0.0003452096716500819\n",
      "[Training] Epoch: 18 [==========>    ] 67.5% Loss: 0.0896, Epoch 18, Batch 84, CE_loss: 0.07779674232006073, Dice_loss: 0.006827049423009157, Consistency_loss: 0.0004540949303191155\n",
      "[Training] Epoch: 18 [==========>    ] 68.3% Loss: 0.0897, Epoch 18, Batch 85, CE_loss: 0.09052376449108124, Dice_loss: 0.007745991926640272, Consistency_loss: 0.0004709916247520596\n",
      "[Training] Epoch: 18 [==========>    ] 69.0% Loss: 0.0897, Epoch 18, Batch 86, CE_loss: 0.08442346006631851, Dice_loss: 0.007316400296986103, Consistency_loss: 0.00013813884288538247\n",
      "[Training] Epoch: 18 [==========>    ] 69.8% Loss: 0.0898, Epoch 18, Batch 87, CE_loss: 0.0891449972987175, Dice_loss: 0.008231762796640396, Consistency_loss: 0.0006057162536308169\n",
      "[Training] Epoch: 18 [==========>    ] 70.6% Loss: 0.0898, Epoch 18, Batch 88, CE_loss: 0.07515799254179001, Dice_loss: 0.006503083277493715, Consistency_loss: 0.0008136965334415436\n",
      "[Training] Epoch: 18 [==========>    ] 71.4% Loss: 0.0899, Epoch 18, Batch 89, CE_loss: 0.09461420029401779, Dice_loss: 0.009087060578167439, Consistency_loss: 0.0008436599746346474\n",
      "[Training] Epoch: 18 [==========>    ] 72.2% Loss: 0.0897, Epoch 18, Batch 90, CE_loss: 0.06811118125915527, Dice_loss: 0.005058489739894867, Consistency_loss: 0.0005238747107796371\n",
      "[Training] Epoch: 18 [==========>    ] 73.0% Loss: 0.0897, Epoch 18, Batch 91, CE_loss: 0.08045462518930435, Dice_loss: 0.007059373427182436, Consistency_loss: 0.00011458423978183419\n",
      "[Training] Epoch: 18 [===========>   ] 73.8% Loss: 0.0896, Epoch 18, Batch 92, CE_loss: 0.07415611296892166, Dice_loss: 0.005902116186916828, Consistency_loss: 0.0006627402035519481\n",
      "[Training] Epoch: 18 [===========>   ] 74.6% Loss: 0.0897, Epoch 18, Batch 93, CE_loss: 0.09277564287185669, Dice_loss: 0.007855001837015152, Consistency_loss: 0.0001144157286034897\n",
      "[Training] Epoch: 18 [===========>   ] 75.4% Loss: 0.0896, Epoch 18, Batch 94, CE_loss: 0.06869480013847351, Dice_loss: 0.0055004688911139965, Consistency_loss: 0.0005622586468234658\n",
      "[Training] Epoch: 18 [===========>   ] 76.2% Loss: 0.0896, Epoch 18, Batch 95, CE_loss: 0.08312071859836578, Dice_loss: 0.007344492245465517, Consistency_loss: 0.0004142129037063569\n",
      "[Training] Epoch: 18 [===========>   ] 77.0% Loss: 0.0897, Epoch 18, Batch 96, CE_loss: 0.08873548358678818, Dice_loss: 0.00825272873044014, Consistency_loss: 0.0008927643648348749\n",
      "[Training] Epoch: 18 [===========>   ] 77.8% Loss: 0.0897, Epoch 18, Batch 97, CE_loss: 0.0801166221499443, Dice_loss: 0.007159969303756952, Consistency_loss: 0.0009016058756969869\n",
      "[Training] Epoch: 18 [===========>   ] 78.6% Loss: 0.0898, Epoch 18, Batch 98, CE_loss: 0.09725344181060791, Dice_loss: 0.008740175515413284, Consistency_loss: 0.0006744330748915672\n",
      "[Training] Epoch: 18 [===========>   ] 79.4% Loss: 0.0897, Epoch 18, Batch 99, CE_loss: 0.06844962388277054, Dice_loss: 0.005122339818626642, Consistency_loss: 0.0005028527230024338\n",
      "[Training] Epoch: 18 [============>  ] 80.2% Loss: 0.0896, Epoch 18, Batch 100, CE_loss: 0.07221333682537079, Dice_loss: 0.005691285710781813, Consistency_loss: 0.0004967410932295024\n",
      "[Training] Epoch: 18 [============>  ] 81.0% Loss: 0.0893, Epoch 18, Batch 101, CE_loss: 0.06128627061843872, Dice_loss: 0.004296952858567238, Consistency_loss: 0.0006618633633479476\n",
      "[Training] Epoch: 18 [============>  ] 81.7% Loss: 0.0892, Epoch 18, Batch 102, CE_loss: 0.06710604578256607, Dice_loss: 0.005276495590806007, Consistency_loss: 0.0008241577888838947\n",
      "[Training] Epoch: 18 [============>  ] 82.5% Loss: 0.0891, Epoch 18, Batch 103, CE_loss: 0.07461044192314148, Dice_loss: 0.0063847932033240795, Consistency_loss: 0.0007891887216828763\n",
      "[Training] Epoch: 18 [============>  ] 83.3% Loss: 0.0890, Epoch 18, Batch 104, CE_loss: 0.07286708801984787, Dice_loss: 0.005685451906174421, Consistency_loss: 0.0005144310416653752\n",
      "[Training] Epoch: 18 [============>  ] 84.1% Loss: 0.0890, Epoch 18, Batch 105, CE_loss: 0.08295797556638718, Dice_loss: 0.0075682238675653934, Consistency_loss: 0.0005114391096867621\n",
      "[Training] Epoch: 18 [============>  ] 84.9% Loss: 0.0890, Epoch 18, Batch 106, CE_loss: 0.07311858981847763, Dice_loss: 0.006113608367741108, Consistency_loss: 0.0007357351132668555\n",
      "[Training] Epoch: 18 [============>  ] 85.7% Loss: 0.0890, Epoch 18, Batch 107, CE_loss: 0.08781033754348755, Dice_loss: 0.008081827312707901, Consistency_loss: 0.0006808504112996161\n",
      "[Training] Epoch: 18 [============>  ] 86.5% Loss: 0.0891, Epoch 18, Batch 108, CE_loss: 0.08980049192905426, Dice_loss: 0.007232375908643007, Consistency_loss: 0.00024158151063602418\n",
      "[Training] Epoch: 18 [=============> ] 87.3% Loss: 0.0890, Epoch 18, Batch 109, CE_loss: 0.07308104634284973, Dice_loss: 0.005974459927529097, Consistency_loss: 0.0003473468532320112\n",
      "[Training] Epoch: 18 [=============> ] 88.1% Loss: 0.0891, Epoch 18, Batch 110, CE_loss: 0.09276056289672852, Dice_loss: 0.008500336669385433, Consistency_loss: 0.0001562922989251092\n",
      "[Training] Epoch: 18 [=============> ] 88.9% Loss: 0.0892, Epoch 18, Batch 111, CE_loss: 0.08511493355035782, Dice_loss: 0.007568009663373232, Consistency_loss: 0.0004077896592207253\n",
      "[Training] Epoch: 18 [=============> ] 89.7% Loss: 0.0891, Epoch 18, Batch 112, CE_loss: 0.07396993786096573, Dice_loss: 0.006350179202854633, Consistency_loss: 0.0006927559734322131\n",
      "[Training] Epoch: 18 [=============> ] 90.5% Loss: 0.0890, Epoch 18, Batch 113, CE_loss: 0.07104071974754333, Dice_loss: 0.005488738417625427, Consistency_loss: 0.0008138438570313156\n",
      "[Training] Epoch: 18 [=============> ] 91.3% Loss: 0.0889, Epoch 18, Batch 114, CE_loss: 0.07020094245672226, Dice_loss: 0.005312410183250904, Consistency_loss: 0.0005425265408121049\n",
      "[Training] Epoch: 18 [=============> ] 92.1% Loss: 0.0889, Epoch 18, Batch 115, CE_loss: 0.08243036270141602, Dice_loss: 0.006521907635033131, Consistency_loss: 0.0006373030482791364\n",
      "[Training] Epoch: 18 [=============> ] 92.9% Loss: 0.0888, Epoch 18, Batch 116, CE_loss: 0.07250747829675674, Dice_loss: 0.005791725590825081, Consistency_loss: 0.0007922360091470182\n",
      "[Training] Epoch: 18 [==============>] 93.7% Loss: 0.0888, Epoch 18, Batch 117, CE_loss: 0.07880645245313644, Dice_loss: 0.006880778353661299, Consistency_loss: 0.0008493263158015907\n",
      "[Training] Epoch: 18 [==============>] 94.4% Loss: 0.0887, Epoch 18, Batch 118, CE_loss: 0.07560016959905624, Dice_loss: 0.006358882877975702, Consistency_loss: 0.0005769188283011317\n",
      "[Training] Epoch: 18 [==============>] 95.2% Loss: 0.0886, Epoch 18, Batch 119, CE_loss: 0.07035496830940247, Dice_loss: 0.00576480058953166, Consistency_loss: 0.0004261163994669914\n",
      "[Training] Epoch: 18 [==============>] 96.0% Loss: 0.0886, Epoch 18, Batch 120, CE_loss: 0.08234082907438278, Dice_loss: 0.007396991830319166, Consistency_loss: 0.0007158223888836801\n",
      "[Training] Epoch: 18 [==============>] 96.8% Loss: 0.0887, Epoch 18, Batch 121, CE_loss: 0.08802458643913269, Dice_loss: 0.00788621325045824, Consistency_loss: 0.0005505708395503461\n",
      "[Training] Epoch: 18 [==============>] 97.6% Loss: 0.0889, Epoch 18, Batch 122, CE_loss: 0.09971221536397934, Dice_loss: 0.00900494959205389, Consistency_loss: 0.00025176620692946017\n",
      "[Training] Epoch: 18 [==============>] 98.4% Loss: 0.0888, Epoch 18, Batch 123, CE_loss: 0.07893092930316925, Dice_loss: 0.006619312334805727, Consistency_loss: 0.00018700104556046426\n",
      "[Training] Epoch: 18 [==============>] 99.2% Loss: 0.0887, Epoch 18, Batch 124, CE_loss: 0.0714322105050087, Dice_loss: 0.0055852532386779785, Consistency_loss: 0.0002805218973662704\n",
      "[Training] Epoch: 18 [DONE]                                 \n",
      "Epoch 18, Batch 125, CE_loss: 0.07896421104669571, Dice_loss: 0.006927605252712965, Consistency_loss: 0.00013025262160226703\n",
      "[Validation] Epoch: 18 [DONE]                                 \n",
      "[Epoch: 18, TrainLoss: 0.0887, TrainDice: 0.0069, ValLoss: 0.1394                                            \n",
      "Number of batches:  126\n",
      "[Training] Epoch: 19 [>              ] 0.8% Loss: 0.0796, Epoch 19, Batch 0, CE_loss: 0.07303151488304138, Dice_loss: 0.006053098011761904, Consistency_loss: 0.000506120384670794\n",
      "[Training] Epoch: 19 [>              ] 1.6% Loss: 0.0816, Epoch 19, Batch 1, CE_loss: 0.07662136107683182, Dice_loss: 0.006633456330746412, Consistency_loss: 0.00028654877678491175\n",
      "[Training] Epoch: 19 [>              ] 2.4% Loss: 0.0821, Epoch 19, Batch 2, CE_loss: 0.07603304088115692, Dice_loss: 0.006784169469028711, Consistency_loss: 0.0002486139419488609\n",
      "[Training] Epoch: 19 [>              ] 3.2% Loss: 0.0846, Epoch 19, Batch 3, CE_loss: 0.08511407673358917, Dice_loss: 0.0066084000281989574, Consistency_loss: 0.0005159859429113567\n",
      "[Training] Epoch: 19 [>              ] 4.0% Loss: 0.0849, Epoch 19, Batch 4, CE_loss: 0.07904418557882309, Dice_loss: 0.006577129941433668, Consistency_loss: 0.0006427948828786612\n",
      "[Training] Epoch: 19 [>              ] 4.8% Loss: 0.0848, Epoch 19, Batch 5, CE_loss: 0.07761231064796448, Dice_loss: 0.0063325571827590466, Consistency_loss: 0.0001460212079109624\n",
      "[Training] Epoch: 19 [>              ] 5.6% Loss: 0.0841, Epoch 19, Batch 6, CE_loss: 0.07366011291742325, Dice_loss: 0.006199175491929054, Consistency_loss: 0.00017257286526728421\n",
      "[Training] Epoch: 19 [>              ] 6.3% Loss: 0.0879, Epoch 19, Batch 7, CE_loss: 0.10458877682685852, Dice_loss: 0.009767688810825348, Consistency_loss: 0.0003376519016455859\n",
      "[Training] Epoch: 19 [=>             ] 7.1% Loss: 0.0874, Epoch 19, Batch 8, CE_loss: 0.07574377208948135, Dice_loss: 0.00679700868204236, Consistency_loss: 0.0002476448134984821\n",
      "[Training] Epoch: 19 [=>             ] 7.9% Loss: 0.0866, Epoch 19, Batch 9, CE_loss: 0.07356826215982437, Dice_loss: 0.00614703306928277, Consistency_loss: 0.0002128837222699076\n",
      "[Training] Epoch: 19 [=>             ] 8.7% Loss: 0.0868, Epoch 19, Batch 10, CE_loss: 0.08122750371694565, Dice_loss: 0.006911539006978273, Consistency_loss: 0.0004527878190856427\n",
      "[Training] Epoch: 19 [=>             ] 9.5% Loss: 0.0874, Epoch 19, Batch 11, CE_loss: 0.08588136732578278, Dice_loss: 0.007539515383541584, Consistency_loss: 0.000598556303884834\n",
      "[Training] Epoch: 19 [=>             ] 10.3% Loss: 0.0864, Epoch 19, Batch 12, CE_loss: 0.06837547570466995, Dice_loss: 0.005729368422180414, Consistency_loss: 0.0007559111691080034\n",
      "[Training] Epoch: 19 [=>             ] 11.1% Loss: 0.0871, Epoch 19, Batch 13, CE_loss: 0.08709981292486191, Dice_loss: 0.008061062544584274, Consistency_loss: 0.0003295640635769814\n",
      "[Training] Epoch: 19 [=>             ] 11.9% Loss: 0.0869, Epoch 19, Batch 14, CE_loss: 0.07691452652215958, Dice_loss: 0.0068584042601287365, Consistency_loss: 0.0005074811051599681\n",
      "[Training] Epoch: 19 [=>             ] 12.7% Loss: 0.0878, Epoch 19, Batch 15, CE_loss: 0.0922660157084465, Dice_loss: 0.008495490998029709, Consistency_loss: 0.0008689733222126961\n",
      "[Training] Epoch: 19 [==>            ] 13.5% Loss: 0.0876, Epoch 19, Batch 16, CE_loss: 0.07733770459890366, Dice_loss: 0.006373626179993153, Consistency_loss: 0.00032068221480585635\n",
      "[Training] Epoch: 19 [==>            ] 14.3% Loss: 0.0874, Epoch 19, Batch 17, CE_loss: 0.07759073376655579, Dice_loss: 0.006850996986031532, Consistency_loss: 0.00044242615695111454\n",
      "[Training] Epoch: 19 [==>            ] 15.1% Loss: 0.0869, Epoch 19, Batch 18, CE_loss: 0.07009758800268173, Dice_loss: 0.005822195205837488, Consistency_loss: 0.00032504997216165066\n",
      "[Training] Epoch: 19 [==>            ] 15.9% Loss: 0.0861, Epoch 19, Batch 19, CE_loss: 0.06661390513181686, Dice_loss: 0.00534507492557168, Consistency_loss: 0.00022074727166909724\n",
      "[Training] Epoch: 19 [==>            ] 16.7% Loss: 0.0863, Epoch 19, Batch 20, CE_loss: 0.08336911350488663, Dice_loss: 0.006533883977681398, Consistency_loss: 0.000553312711417675\n",
      "[Training] Epoch: 19 [==>            ] 17.5% Loss: 0.0859, Epoch 19, Batch 21, CE_loss: 0.07067427039146423, Dice_loss: 0.005948411300778389, Consistency_loss: 0.0004146442806813866\n",
      "[Training] Epoch: 19 [==>            ] 18.3% Loss: 0.0866, Epoch 19, Batch 22, CE_loss: 0.09244668483734131, Dice_loss: 0.008614531718194485, Consistency_loss: 0.0005404722178354859\n",
      "[Training] Epoch: 19 [==>            ] 19.0% Loss: 0.0869, Epoch 19, Batch 23, CE_loss: 0.0853075161576271, Dice_loss: 0.00799390859901905, Consistency_loss: 9.165723895421252e-05\n",
      "[Training] Epoch: 19 [==>            ] 19.8% Loss: 0.0873, Epoch 19, Batch 24, CE_loss: 0.0890752300620079, Dice_loss: 0.00814215000718832, Consistency_loss: 0.0002892322954721749\n",
      "[Training] Epoch: 19 [===>           ] 20.6% Loss: 0.0868, Epoch 19, Batch 25, CE_loss: 0.06788088381290436, Dice_loss: 0.005355330184102058, Consistency_loss: 0.00020532452617771924\n",
      "[Training] Epoch: 19 [===>           ] 21.4% Loss: 0.0869, Epoch 19, Batch 26, CE_loss: 0.08239300549030304, Dice_loss: 0.00739855645224452, Consistency_loss: 0.0002008824812946841\n",
      "[Training] Epoch: 19 [===>           ] 22.2% Loss: 0.0870, Epoch 19, Batch 27, CE_loss: 0.08137161284685135, Dice_loss: 0.007466277573257685, Consistency_loss: 0.0007085358374752104\n",
      "[Training] Epoch: 19 [===>           ] 23.0% Loss: 0.0868, Epoch 19, Batch 28, CE_loss: 0.0758904293179512, Dice_loss: 0.0064326259307563305, Consistency_loss: 0.0003474226105026901\n",
      "[Training] Epoch: 19 [===>           ] 23.8% Loss: 0.0867, Epoch 19, Batch 29, CE_loss: 0.07561609894037247, Dice_loss: 0.006330670788884163, Consistency_loss: 0.0004309633222874254\n",
      "[Training] Epoch: 19 [===>           ] 24.6% Loss: 0.0865, Epoch 19, Batch 30, CE_loss: 0.07417381554841995, Dice_loss: 0.006487865932285786, Consistency_loss: 0.0008315964951179922\n",
      "[Training] Epoch: 19 [===>           ] 25.4% Loss: 0.0865, Epoch 19, Batch 31, CE_loss: 0.07781323045492172, Dice_loss: 0.006927900481969118, Consistency_loss: 0.0003061355964746326\n",
      "[Training] Epoch: 19 [===>           ] 26.2% Loss: 0.0863, Epoch 19, Batch 32, CE_loss: 0.07465649396181107, Dice_loss: 0.006287916097790003, Consistency_loss: 0.00010312711674487218\n",
      "[Training] Epoch: 19 [====>          ] 27.0% Loss: 0.0864, Epoch 19, Batch 33, CE_loss: 0.08044146001338959, Dice_loss: 0.007131287828087807, Consistency_loss: 0.0005036668153479695\n",
      "[Training] Epoch: 19 [====>          ] 27.8% Loss: 0.0859, Epoch 19, Batch 34, CE_loss: 0.06483683735132217, Dice_loss: 0.005266392603516579, Consistency_loss: 0.0007282511214725673\n",
      "[Training] Epoch: 19 [====>          ] 28.6% Loss: 0.0862, Epoch 19, Batch 35, CE_loss: 0.0866025909781456, Dice_loss: 0.00763383973389864, Consistency_loss: 0.0004965653060935438\n",
      "[Training] Epoch: 19 [====>          ] 29.4% Loss: 0.0863, Epoch 19, Batch 36, CE_loss: 0.08331242203712463, Dice_loss: 0.007455043960362673, Consistency_loss: 0.00019186094868928194\n",
      "[Training] Epoch: 19 [====>          ] 30.2% Loss: 0.0861, Epoch 19, Batch 37, CE_loss: 0.0731307789683342, Dice_loss: 0.006210069637745619, Consistency_loss: 0.000593335076700896\n",
      "[Training] Epoch: 19 [====>          ] 31.0% Loss: 0.0857, Epoch 19, Batch 38, CE_loss: 0.06542454659938812, Dice_loss: 0.004907391965389252, Consistency_loss: 0.0005714195431210101\n",
      "[Training] Epoch: 19 [====>          ] 31.7% Loss: 0.0855, Epoch 19, Batch 39, CE_loss: 0.0711674690246582, Dice_loss: 0.005881329067051411, Consistency_loss: 0.0001927058183355257\n",
      "[Training] Epoch: 19 [====>          ] 32.5% Loss: 0.0854, Epoch 19, Batch 40, CE_loss: 0.07314448058605194, Dice_loss: 0.006169925909489393, Consistency_loss: 0.0007644006400369108\n",
      "[Training] Epoch: 19 [=====>         ] 33.3% Loss: 0.0851, Epoch 19, Batch 41, CE_loss: 0.06750094145536423, Dice_loss: 0.005512914154678583, Consistency_loss: 0.000645138556137681\n",
      "[Training] Epoch: 19 [=====>         ] 34.1% Loss: 0.0850, Epoch 19, Batch 42, CE_loss: 0.07249125838279724, Dice_loss: 0.006213744170963764, Consistency_loss: 0.0008464662241749465\n",
      "[Training] Epoch: 19 [=====>         ] 34.9% Loss: 0.0852, Epoch 19, Batch 43, CE_loss: 0.08686277270317078, Dice_loss: 0.007917318493127823, Consistency_loss: 0.00012551041436381638\n",
      "[Training] Epoch: 19 [=====>         ] 35.7% Loss: 0.0849, Epoch 19, Batch 44, CE_loss: 0.06599082797765732, Dice_loss: 0.005293281748890877, Consistency_loss: 0.0007371359970420599\n",
      "[Training] Epoch: 19 [=====>         ] 36.5% Loss: 0.0847, Epoch 19, Batch 45, CE_loss: 0.06786739081144333, Dice_loss: 0.005578364711254835, Consistency_loss: 0.00033657706808298826\n",
      "[Training] Epoch: 19 [=====>         ] 37.3% Loss: 0.0850, Epoch 19, Batch 46, CE_loss: 0.09192991256713867, Dice_loss: 0.008776254951953888, Consistency_loss: 0.0003950907557737082\n",
      "[Training] Epoch: 19 [=====>         ] 38.1% Loss: 0.0852, Epoch 19, Batch 47, CE_loss: 0.08421619236469269, Dice_loss: 0.007763086352497339, Consistency_loss: 0.000604872708208859\n",
      "[Training] Epoch: 19 [=====>         ] 38.9% Loss: 0.0850, Epoch 19, Batch 48, CE_loss: 0.07092985510826111, Dice_loss: 0.005847734399139881, Consistency_loss: 0.0002757918555289507\n",
      "[Training] Epoch: 19 [=====>         ] 39.7% Loss: 0.0851, Epoch 19, Batch 49, CE_loss: 0.07972262054681778, Dice_loss: 0.007122637704014778, Consistency_loss: 0.0006992594571784139\n",
      "[Training] Epoch: 19 [======>        ] 40.5% Loss: 0.0850, Epoch 19, Batch 50, CE_loss: 0.07696397602558136, Dice_loss: 0.006304577458649874, Consistency_loss: 0.00020033189503010362\n",
      "[Training] Epoch: 19 [======>        ] 41.3% Loss: 0.0850, Epoch 19, Batch 51, CE_loss: 0.07805490493774414, Dice_loss: 0.0068377600982785225, Consistency_loss: 0.00087869813432917\n",
      "[Training] Epoch: 19 [======>        ] 42.1% Loss: 0.0851, Epoch 19, Batch 52, CE_loss: 0.08106737583875656, Dice_loss: 0.007440944202244282, Consistency_loss: 0.00018640719645190984\n",
      "[Training] Epoch: 19 [======>        ] 42.9% Loss: 0.0853, Epoch 19, Batch 53, CE_loss: 0.08597239851951599, Dice_loss: 0.008122922852635384, Consistency_loss: 0.00020671238598879427\n",
      "[Training] Epoch: 19 [======>        ] 43.7% Loss: 0.0851, Epoch 19, Batch 54, CE_loss: 0.06720709800720215, Dice_loss: 0.005630524829030037, Consistency_loss: 0.0005685309297405183\n",
      "[Training] Epoch: 19 [======>        ] 44.4% Loss: 0.0853, Epoch 19, Batch 55, CE_loss: 0.08931824564933777, Dice_loss: 0.0075267706997692585, Consistency_loss: 0.0006278710789047182\n",
      "[Training] Epoch: 19 [======>        ] 45.2% Loss: 0.0856, Epoch 19, Batch 56, CE_loss: 0.09446167945861816, Dice_loss: 0.008985002525150776, Consistency_loss: 0.0005426438874565065\n",
      "[Training] Epoch: 19 [======>        ] 46.0% Loss: 0.0853, Epoch 19, Batch 57, CE_loss: 0.059757161885499954, Dice_loss: 0.0043641687370836735, Consistency_loss: 0.00033826695289462805\n",
      "[Training] Epoch: 19 [=======>       ] 46.8% Loss: 0.0849, Epoch 19, Batch 58, CE_loss: 0.061898816376924515, Dice_loss: 0.0047103301621973515, Consistency_loss: 0.0005609182990156114\n",
      "[Training] Epoch: 19 [=======>       ] 47.6% Loss: 0.0849, Epoch 19, Batch 59, CE_loss: 0.07513576745986938, Dice_loss: 0.006714190822094679, Consistency_loss: 0.0005241994513198733\n",
      "[Training] Epoch: 19 [=======>       ] 48.4% Loss: 0.0849, Epoch 19, Batch 60, CE_loss: 0.07888268679380417, Dice_loss: 0.006345369387418032, Consistency_loss: 0.00048168966895900667\n",
      "[Training] Epoch: 19 [=======>       ] 49.2% Loss: 0.0849, Epoch 19, Batch 61, CE_loss: 0.07719532400369644, Dice_loss: 0.006801166106015444, Consistency_loss: 0.00047187693417072296\n",
      "[Training] Epoch: 19 [=======>       ] 50.0% Loss: 0.0848, Epoch 19, Batch 62, CE_loss: 0.07088064402341843, Dice_loss: 0.005590904038399458, Consistency_loss: 0.0007137690554372966\n",
      "[Training] Epoch: 19 [=======>       ] 50.8% Loss: 0.0846, Epoch 19, Batch 63, CE_loss: 0.06639157235622406, Dice_loss: 0.005383332259953022, Consistency_loss: 0.0008482292178086936\n",
      "[Training] Epoch: 19 [=======>       ] 51.6% Loss: 0.0847, Epoch 19, Batch 64, CE_loss: 0.08188994973897934, Dice_loss: 0.006323898211121559, Consistency_loss: 0.0008362222579307854\n",
      "[Training] Epoch: 19 [=======>       ] 52.4% Loss: 0.0851, Epoch 19, Batch 65, CE_loss: 0.10619023442268372, Dice_loss: 0.009678371250629425, Consistency_loss: 0.00017481546092312783\n",
      "[Training] Epoch: 19 [=======>       ] 53.2% Loss: 0.0851, Epoch 19, Batch 66, CE_loss: 0.07305417209863663, Dice_loss: 0.006289337761700153, Consistency_loss: 0.00033465109299868345\n",
      "[Training] Epoch: 19 [========>      ] 54.0% Loss: 0.0852, Epoch 19, Batch 67, CE_loss: 0.08385850489139557, Dice_loss: 0.00694655068218708, Consistency_loss: 0.0005145111936144531\n",
      "[Training] Epoch: 19 [========>      ] 54.8% Loss: 0.0851, Epoch 19, Batch 68, CE_loss: 0.07343331724405289, Dice_loss: 0.006261912174522877, Consistency_loss: 0.0002658717567101121\n",
      "[Training] Epoch: 19 [========>      ] 55.6% Loss: 0.0848, Epoch 19, Batch 69, CE_loss: 0.06323940306901932, Dice_loss: 0.004966467618942261, Consistency_loss: 7.490836287615821e-05\n",
      "[Training] Epoch: 19 [========>      ] 56.3% Loss: 0.0852, Epoch 19, Batch 70, CE_loss: 0.09786609560251236, Dice_loss: 0.008754073642194271, Consistency_loss: 0.0007949714781716466\n",
      "[Training] Epoch: 19 [========>      ] 57.1% Loss: 0.0852, Epoch 19, Batch 71, CE_loss: 0.07938000559806824, Dice_loss: 0.006683059502393007, Consistency_loss: 0.0006954888813197613\n",
      "[Training] Epoch: 19 [========>      ] 57.9% Loss: 0.0853, Epoch 19, Batch 72, CE_loss: 0.08487431704998016, Dice_loss: 0.007679401431232691, Consistency_loss: 0.000518278160598129\n",
      "[Training] Epoch: 19 [========>      ] 58.7% Loss: 0.0855, Epoch 19, Batch 73, CE_loss: 0.08929227292537689, Dice_loss: 0.008447613567113876, Consistency_loss: 0.000599548511672765\n",
      "[Training] Epoch: 19 [========>      ] 59.5% Loss: 0.0853, Epoch 19, Batch 74, CE_loss: 0.06774309277534485, Dice_loss: 0.005652693100273609, Consistency_loss: 0.0007525770924985409\n",
      "[Training] Epoch: 19 [=========>     ] 60.3% Loss: 0.0853, Epoch 19, Batch 75, CE_loss: 0.07830963283777237, Dice_loss: 0.006786780431866646, Consistency_loss: 0.000719742791261524\n",
      "[Training] Epoch: 19 [=========>     ] 61.1% Loss: 0.0855, Epoch 19, Batch 76, CE_loss: 0.08791793882846832, Dice_loss: 0.008070386946201324, Consistency_loss: 0.0007187047740444541\n",
      "[Training] Epoch: 19 [=========>     ] 61.9% Loss: 0.0856, Epoch 19, Batch 77, CE_loss: 0.08632263541221619, Dice_loss: 0.008115408010780811, Consistency_loss: 0.0008384037064388394\n",
      "[Training] Epoch: 19 [=========>     ] 62.7% Loss: 0.0856, Epoch 19, Batch 78, CE_loss: 0.08071737736463547, Dice_loss: 0.007312703412026167, Consistency_loss: 0.00047254329547286034\n",
      "[Training] Epoch: 19 [=========>     ] 63.5% Loss: 0.0854, Epoch 19, Batch 79, CE_loss: 0.05917517468333244, Dice_loss: 0.004486996214836836, Consistency_loss: 0.0004269347118679434\n",
      "[Training] Epoch: 19 [=========>     ] 64.3% Loss: 0.0853, Epoch 19, Batch 80, CE_loss: 0.0728115662932396, Dice_loss: 0.006087023299187422, Consistency_loss: 0.0005462851258926094\n",
      "[Training] Epoch: 19 [=========>     ] 65.1% Loss: 0.0855, Epoch 19, Batch 81, CE_loss: 0.09083560854196548, Dice_loss: 0.008943920023739338, Consistency_loss: 0.0001502761006122455\n",
      "[Training] Epoch: 19 [=========>     ] 65.9% Loss: 0.0852, Epoch 19, Batch 82, CE_loss: 0.06197074055671692, Dice_loss: 0.004795481450855732, Consistency_loss: 0.0007289383793249726\n",
      "[Training] Epoch: 19 [==========>    ] 66.7% Loss: 0.0853, Epoch 19, Batch 83, CE_loss: 0.08112815022468567, Dice_loss: 0.007342095952481031, Consistency_loss: 0.00025562624796293676\n",
      "[Training] Epoch: 19 [==========>    ] 67.5% Loss: 0.0851, Epoch 19, Batch 84, CE_loss: 0.06522655487060547, Dice_loss: 0.0052871438674628735, Consistency_loss: 0.0004451365675777197\n",
      "[Training] Epoch: 19 [==========>    ] 68.3% Loss: 0.0850, Epoch 19, Batch 85, CE_loss: 0.06835287064313889, Dice_loss: 0.005522704217582941, Consistency_loss: 0.00023101230908650905\n",
      "[Training] Epoch: 19 [==========>    ] 69.0% Loss: 0.0850, Epoch 19, Batch 86, CE_loss: 0.07830674201250076, Dice_loss: 0.006869101896882057, Consistency_loss: 0.0007799140294082463\n",
      "[Training] Epoch: 19 [==========>    ] 69.8% Loss: 0.0848, Epoch 19, Batch 87, CE_loss: 0.06182175874710083, Dice_loss: 0.004952350631356239, Consistency_loss: 0.00038583515561185777\n",
      "[Training] Epoch: 19 [==========>    ] 70.6% Loss: 0.0848, Epoch 19, Batch 88, CE_loss: 0.07840856164693832, Dice_loss: 0.007334389258176088, Consistency_loss: 0.0003012435045093298\n",
      "[Training] Epoch: 19 [==========>    ] 71.4% Loss: 0.0849, Epoch 19, Batch 89, CE_loss: 0.0804540142416954, Dice_loss: 0.007333951070904732, Consistency_loss: 0.0008366590482182801\n",
      "[Training] Epoch: 19 [==========>    ] 72.2% Loss: 0.0850, Epoch 19, Batch 90, CE_loss: 0.09213680773973465, Dice_loss: 0.008416763506829739, Consistency_loss: 0.0007730798679403961\n",
      "[Training] Epoch: 19 [==========>    ] 73.0% Loss: 0.0849, Epoch 19, Batch 91, CE_loss: 0.06984302401542664, Dice_loss: 0.0056289914064109325, Consistency_loss: 0.0008326409733854234\n",
      "[Training] Epoch: 19 [===========>   ] 73.8% Loss: 0.0849, Epoch 19, Batch 92, CE_loss: 0.07327146083116531, Dice_loss: 0.00615844177082181, Consistency_loss: 0.0005996472900733352\n",
      "[Training] Epoch: 19 [===========>   ] 74.6% Loss: 0.0847, Epoch 19, Batch 93, CE_loss: 0.0645512044429779, Dice_loss: 0.00545661011710763, Consistency_loss: 0.0007551272283308208\n",
      "[Training] Epoch: 19 [===========>   ] 75.4% Loss: 0.0848, Epoch 19, Batch 94, CE_loss: 0.07838065922260284, Dice_loss: 0.007192088756710291, Consistency_loss: 0.0007589321467094123\n",
      "[Training] Epoch: 19 [===========>   ] 76.2% Loss: 0.0851, Epoch 19, Batch 95, CE_loss: 0.11108054220676422, Dice_loss: 0.01107538677752018, Consistency_loss: 0.00026711911777965724\n",
      "[Training] Epoch: 19 [===========>   ] 77.0% Loss: 0.0851, Epoch 19, Batch 96, CE_loss: 0.07208902388811111, Dice_loss: 0.0063452888280153275, Consistency_loss: 0.0006206974503584206\n",
      "[Training] Epoch: 19 [===========>   ] 77.8% Loss: 0.0854, Epoch 19, Batch 97, CE_loss: 0.10797891765832901, Dice_loss: 0.011103697121143341, Consistency_loss: 0.0006158867618069053\n",
      "[Training] Epoch: 19 [===========>   ] 78.6% Loss: 0.0853, Epoch 19, Batch 98, CE_loss: 0.06482566893100739, Dice_loss: 0.005558596923947334, Consistency_loss: 0.0006660411017946899\n",
      "[Training] Epoch: 19 [===========>   ] 79.4% Loss: 0.0853, Epoch 19, Batch 99, CE_loss: 0.08192525804042816, Dice_loss: 0.007483837194740772, Consistency_loss: 0.00012663700908888131\n",
      "[Training] Epoch: 19 [============>  ] 80.2% Loss: 0.0852, Epoch 19, Batch 100, CE_loss: 0.0646788701415062, Dice_loss: 0.005310514941811562, Consistency_loss: 0.0006727626896463335\n",
      "[Training] Epoch: 19 [============>  ] 81.0% Loss: 0.0851, Epoch 19, Batch 101, CE_loss: 0.07112379372119904, Dice_loss: 0.006411262322217226, Consistency_loss: 0.000879512750543654\n",
      "[Training] Epoch: 19 [============>  ] 81.7% Loss: 0.0852, Epoch 19, Batch 102, CE_loss: 0.08368366211652756, Dice_loss: 0.007812036667019129, Consistency_loss: 0.0009196197497658432\n",
      "[Training] Epoch: 19 [============>  ] 82.5% Loss: 0.0853, Epoch 19, Batch 103, CE_loss: 0.08707943558692932, Dice_loss: 0.007797816768288612, Consistency_loss: 0.0005948501056991518\n",
      "[Training] Epoch: 19 [============>  ] 83.3% Loss: 0.0852, Epoch 19, Batch 104, CE_loss: 0.07147622853517532, Dice_loss: 0.006116898730397224, Consistency_loss: 0.00043701688991859555\n",
      "[Training] Epoch: 19 [============>  ] 84.1% Loss: 0.0853, Epoch 19, Batch 105, CE_loss: 0.08236084133386612, Dice_loss: 0.007345381658524275, Consistency_loss: 0.0005168537609279156\n",
      "[Training] Epoch: 19 [============>  ] 84.9% Loss: 0.0852, Epoch 19, Batch 106, CE_loss: 0.0720011293888092, Dice_loss: 0.006405665073543787, Consistency_loss: 0.0008270105463452637\n",
      "[Training] Epoch: 19 [============>  ] 85.7% Loss: 0.0853, Epoch 19, Batch 107, CE_loss: 0.08330758661031723, Dice_loss: 0.007744337897747755, Consistency_loss: 0.0007566585554741323\n",
      "[Training] Epoch: 19 [============>  ] 86.5% Loss: 0.0852, Epoch 19, Batch 108, CE_loss: 0.07165685296058655, Dice_loss: 0.006249940488487482, Consistency_loss: 0.0005581000586971641\n",
      "[Training] Epoch: 19 [=============> ] 87.3% Loss: 0.0850, Epoch 19, Batch 109, CE_loss: 0.05867552384734154, Dice_loss: 0.004614821169525385, Consistency_loss: 9.929070802172646e-05\n",
      "[Training] Epoch: 19 [=============> ] 88.1% Loss: 0.0853, Epoch 19, Batch 110, CE_loss: 0.10168670862913132, Dice_loss: 0.009883668273687363, Consistency_loss: 0.00010797227878356352\n",
      "[Training] Epoch: 19 [=============> ] 88.9% Loss: 0.0851, Epoch 19, Batch 111, CE_loss: 0.06522534042596817, Dice_loss: 0.005458952859044075, Consistency_loss: 0.0005665794597007334\n",
      "[Training] Epoch: 19 [=============> ] 89.7% Loss: 0.0852, Epoch 19, Batch 112, CE_loss: 0.07950786501169205, Dice_loss: 0.007394993677735329, Consistency_loss: 0.0009033445385284722\n",
      "[Training] Epoch: 19 [=============> ] 90.5% Loss: 0.0852, Epoch 19, Batch 113, CE_loss: 0.07809915393590927, Dice_loss: 0.006709188688546419, Consistency_loss: 0.0003605056263040751\n",
      "[Training] Epoch: 19 [=============> ] 91.3% Loss: 0.0851, Epoch 19, Batch 114, CE_loss: 0.06861627101898193, Dice_loss: 0.0059034754522144794, Consistency_loss: 0.0008843305404298007\n",
      "[Training] Epoch: 19 [=============> ] 92.1% Loss: 0.0850, Epoch 19, Batch 115, CE_loss: 0.07326255738735199, Dice_loss: 0.006299024913460016, Consistency_loss: 0.0007898417534306645\n",
      "[Training] Epoch: 19 [=============> ] 92.9% Loss: 0.0851, Epoch 19, Batch 116, CE_loss: 0.08078259974718094, Dice_loss: 0.007510127499699593, Consistency_loss: 0.0008815653854981065\n",
      "[Training] Epoch: 19 [==============>] 93.7% Loss: 0.0850, Epoch 19, Batch 117, CE_loss: 0.07469850778579712, Dice_loss: 0.006546145770698786, Consistency_loss: 0.0008277659653685987\n",
      "[Training] Epoch: 19 [==============>] 94.4% Loss: 0.0851, Epoch 19, Batch 118, CE_loss: 0.0805896520614624, Dice_loss: 0.007468821480870247, Consistency_loss: 0.0004884042427875102\n",
      "[Training] Epoch: 19 [==============>] 95.2% Loss: 0.0849, Epoch 19, Batch 119, CE_loss: 0.0616433322429657, Dice_loss: 0.00474820751696825, Consistency_loss: 0.0004945091786794364\n",
      "[Training] Epoch: 19 [==============>] 96.0% Loss: 0.0848, Epoch 19, Batch 120, CE_loss: 0.06779297441244125, Dice_loss: 0.005781332030892372, Consistency_loss: 0.0006130802212283015\n",
      "[Training] Epoch: 19 [==============>] 96.8% Loss: 0.0848, Epoch 19, Batch 121, CE_loss: 0.07100403308868408, Dice_loss: 0.0062987301498651505, Consistency_loss: 0.00048658516607247293\n",
      "[Training] Epoch: 19 [==============>] 97.6% Loss: 0.0847, Epoch 19, Batch 122, CE_loss: 0.06734256446361542, Dice_loss: 0.00589526304975152, Consistency_loss: 0.0006434947135858238\n",
      "[Training] Epoch: 19 [==============>] 98.4% Loss: 0.0847, Epoch 19, Batch 123, CE_loss: 0.07543661445379257, Dice_loss: 0.006401297636330128, Consistency_loss: 0.0004212435451336205\n",
      "[Training] Epoch: 19 [==============>] 99.2% Loss: 0.0846, Epoch 19, Batch 124, CE_loss: 0.07356977462768555, Dice_loss: 0.006086822133511305, Consistency_loss: 0.000669380184262991\n",
      "[Training] Epoch: 19 [DONE]                                 \n",
      "Epoch 19, Batch 125, CE_loss: 0.060312628746032715, Dice_loss: 0.004763223230838776, Consistency_loss: 7.567655120510608e-05\n",
      "[Validation] Epoch: 19 [DONE]                                 \n",
      "[Epoch: 19, TrainLoss: 0.0845, TrainDice: 0.0067, ValLoss: 0.1464                                            \n",
      "Number of batches:  126\n",
      "[Training] Epoch: 20 [>              ] 0.8% Loss: 0.0929, Epoch 20, Batch 0, CE_loss: 0.08432979136705399, Dice_loss: 0.008059967309236526, Consistency_loss: 0.0004921346553601325\n",
      "[Training] Epoch: 20 [>              ] 1.6% Loss: 0.0782, Epoch 20, Batch 1, CE_loss: 0.058375004678964615, Dice_loss: 0.00448666512966156, Consistency_loss: 0.0006800582050345838\n",
      "[Training] Epoch: 20 [>              ] 2.4% Loss: 0.0769, Epoch 20, Batch 2, CE_loss: 0.06798116117715836, Dice_loss: 0.005797487683594227, Consistency_loss: 0.00043073977576568723\n",
      "[Training] Epoch: 20 [>              ] 3.2% Loss: 0.0818, Epoch 20, Batch 3, CE_loss: 0.08816627413034439, Dice_loss: 0.008279715664684772, Consistency_loss: 8.095715747913346e-05\n",
      "[Training] Epoch: 20 [>              ] 4.0% Loss: 0.0824, Epoch 20, Batch 4, CE_loss: 0.07750353217124939, Dice_loss: 0.0069592599757015705, Consistency_loss: 0.00046364107402041554\n",
      "[Training] Epoch: 20 [>              ] 4.8% Loss: 0.0832, Epoch 20, Batch 5, CE_loss: 0.08032162487506866, Dice_loss: 0.006966756656765938, Consistency_loss: 8.527594764018431e-05\n",
      "[Training] Epoch: 20 [>              ] 5.6% Loss: 0.0804, Epoch 20, Batch 6, CE_loss: 0.05856625363230705, Dice_loss: 0.004336474929004908, Consistency_loss: 0.00016988902643788606\n",
      "[Training] Epoch: 20 [>              ] 6.3% Loss: 0.0796, Epoch 20, Batch 7, CE_loss: 0.06836903095245361, Dice_loss: 0.005764536559581757, Consistency_loss: 0.00021130584354978055\n",
      "[Training] Epoch: 20 [=>             ] 7.1% Loss: 0.0788, Epoch 20, Batch 8, CE_loss: 0.06612730771303177, Dice_loss: 0.005618253722786903, Consistency_loss: 0.00021239901252556592\n",
      "[Training] Epoch: 20 [=>             ] 7.9% Loss: 0.0794, Epoch 20, Batch 9, CE_loss: 0.07791510969400406, Dice_loss: 0.007321107666939497, Consistency_loss: 0.0002580262953415513\n",
      "[Training] Epoch: 20 [=>             ] 8.7% Loss: 0.0786, Epoch 20, Batch 10, CE_loss: 0.06439685076475143, Dice_loss: 0.005473982077091932, Consistency_loss: 0.0007760759326629341\n",
      "[Training] Epoch: 20 [=>             ] 9.5% Loss: 0.0809, Epoch 20, Batch 11, CE_loss: 0.0963054895401001, Dice_loss: 0.009160436689853668, Consistency_loss: 0.0007272519869729877\n",
      "[Training] Epoch: 20 [=>             ] 10.3% Loss: 0.0804, Epoch 20, Batch 12, CE_loss: 0.06795155256986618, Dice_loss: 0.005554506555199623, Consistency_loss: 0.0003570189292076975\n",
      "[Training] Epoch: 20 [=>             ] 11.1% Loss: 0.0803, Epoch 20, Batch 13, CE_loss: 0.07252471148967743, Dice_loss: 0.006309244316071272, Consistency_loss: 0.00046471116365864873\n",
      "[Training] Epoch: 20 [=>             ] 11.9% Loss: 0.0814, Epoch 20, Batch 14, CE_loss: 0.08744611591100693, Dice_loss: 0.008423558436334133, Consistency_loss: 0.0005876222858205438\n",
      "[Training] Epoch: 20 [=>             ] 12.7% Loss: 0.0820, Epoch 20, Batch 15, CE_loss: 0.0828365832567215, Dice_loss: 0.007846847176551819, Consistency_loss: 0.0007215830846689641\n",
      "[Training] Epoch: 20 [==>            ] 13.5% Loss: 0.0815, Epoch 20, Batch 16, CE_loss: 0.06620445847511292, Dice_loss: 0.005646519362926483, Consistency_loss: 0.0006558552267961204\n",
      "[Training] Epoch: 20 [==>            ] 14.3% Loss: 0.0811, Epoch 20, Batch 17, CE_loss: 0.0680801272392273, Dice_loss: 0.005681138020008802, Consistency_loss: 0.0004965928383171558\n",
      "[Training] Epoch: 20 [==>            ] 15.1% Loss: 0.0815, Epoch 20, Batch 18, CE_loss: 0.0811646580696106, Dice_loss: 0.007785317488014698, Consistency_loss: 0.00012240263458807021\n",
      "[Training] Epoch: 20 [==>            ] 15.9% Loss: 0.0812, Epoch 20, Batch 19, CE_loss: 0.06946015357971191, Dice_loss: 0.006112267263233662, Consistency_loss: 0.0005649055237881839\n",
      "[Training] Epoch: 20 [==>            ] 16.7% Loss: 0.0810, Epoch 20, Batch 20, CE_loss: 0.07109721004962921, Dice_loss: 0.006075740326195955, Consistency_loss: 0.00012786769366357476\n",
      "[Training] Epoch: 20 [==>            ] 17.5% Loss: 0.0813, Epoch 20, Batch 21, CE_loss: 0.0786522775888443, Dice_loss: 0.007151060272008181, Consistency_loss: 0.0004708269552793354\n",
      "[Training] Epoch: 20 [==>            ] 18.3% Loss: 0.0813, Epoch 20, Batch 22, CE_loss: 0.07481864094734192, Dice_loss: 0.006976922042667866, Consistency_loss: 0.0005560399731621146\n",
      "[Training] Epoch: 20 [==>            ] 19.0% Loss: 0.0817, Epoch 20, Batch 23, CE_loss: 0.08196474611759186, Dice_loss: 0.007817575708031654, Consistency_loss: 0.0005498450482264161\n",
      "[Training] Epoch: 20 [==>            ] 19.8% Loss: 0.0824, Epoch 20, Batch 24, CE_loss: 0.08990210294723511, Dice_loss: 0.008392020128667355, Consistency_loss: 8.13891165307723e-05\n",
      "[Training] Epoch: 20 [===>           ] 20.6% Loss: 0.0819, Epoch 20, Batch 25, CE_loss: 0.06520979106426239, Dice_loss: 0.005589030683040619, Consistency_loss: 0.00043091518455184996\n",
      "[Training] Epoch: 20 [===>           ] 21.4% Loss: 0.0816, Epoch 20, Batch 26, CE_loss: 0.06746064126491547, Dice_loss: 0.0059656486846506596, Consistency_loss: 0.0009463059832341969\n",
      "[Training] Epoch: 20 [===>           ] 22.2% Loss: 0.0816, Epoch 20, Batch 27, CE_loss: 0.07390662282705307, Dice_loss: 0.006057840771973133, Consistency_loss: 0.0006711249588988721\n",
      "[Training] Epoch: 20 [===>           ] 23.0% Loss: 0.0817, Epoch 20, Batch 28, CE_loss: 0.07557719945907593, Dice_loss: 0.007019618526101112, Consistency_loss: 0.0007004994549788535\n",
      "[Training] Epoch: 20 [===>           ] 23.8% Loss: 0.0812, Epoch 20, Batch 29, CE_loss: 0.06190460920333862, Dice_loss: 0.0050307647325098515, Consistency_loss: 0.0006077995058149099\n",
      "[Training] Epoch: 20 [===>           ] 24.6% Loss: 0.0813, Epoch 20, Batch 30, CE_loss: 0.07635416090488434, Dice_loss: 0.007075099740177393, Consistency_loss: 0.0008724238141439855\n",
      "[Training] Epoch: 20 [===>           ] 25.4% Loss: 0.0814, Epoch 20, Batch 31, CE_loss: 0.07732252031564713, Dice_loss: 0.006973734591156244, Consistency_loss: 0.0003004051686730236\n",
      "[Training] Epoch: 20 [===>           ] 26.2% Loss: 0.0811, Epoch 20, Batch 32, CE_loss: 0.06429222971200943, Dice_loss: 0.00550325820222497, Consistency_loss: 0.0002950431371573359\n",
      "[Training] Epoch: 20 [====>          ] 27.0% Loss: 0.0812, Epoch 20, Batch 33, CE_loss: 0.07775639742612839, Dice_loss: 0.007432933431118727, Consistency_loss: 0.0006589939002878964\n",
      "[Training] Epoch: 20 [====>          ] 27.8% Loss: 0.0809, Epoch 20, Batch 34, CE_loss: 0.06594904512166977, Dice_loss: 0.005285865161567926, Consistency_loss: 0.0003469589864835143\n",
      "[Training] Epoch: 20 [====>          ] 28.6% Loss: 0.0810, Epoch 20, Batch 35, CE_loss: 0.07566096633672714, Dice_loss: 0.006936648860573769, Consistency_loss: 0.00019554949540179223\n",
      "[Training] Epoch: 20 [====>          ] 29.4% Loss: 0.0812, Epoch 20, Batch 36, CE_loss: 0.0831732526421547, Dice_loss: 0.00769924558699131, Consistency_loss: 0.00019500269263517112\n",
      "[Training] Epoch: 20 [====>          ] 30.2% Loss: 0.0812, Epoch 20, Batch 37, CE_loss: 0.07320050895214081, Dice_loss: 0.006723287981003523, Consistency_loss: 9.05626147869043e-05\n",
      "[Training] Epoch: 20 [====>          ] 31.0% Loss: 0.0807, Epoch 20, Batch 38, CE_loss: 0.05587506666779518, Dice_loss: 0.004262897651642561, Consistency_loss: 0.0007182979607023299\n",
      "[Training] Epoch: 20 [====>          ] 31.7% Loss: 0.0807, Epoch 20, Batch 39, CE_loss: 0.07399360090494156, Dice_loss: 0.006507330108433962, Consistency_loss: 0.0008487002342008054\n",
      "[Training] Epoch: 20 [====>          ] 32.5% Loss: 0.0802, Epoch 20, Batch 40, CE_loss: 0.05460118502378464, Dice_loss: 0.004153829999268055, Consistency_loss: 0.0006531300605274737\n",
      "[Training] Epoch: 20 [=====>         ] 33.3% Loss: 0.0803, Epoch 20, Batch 41, CE_loss: 0.07646000385284424, Dice_loss: 0.00699611334130168, Consistency_loss: 0.0006888724747113883\n",
      "[Training] Epoch: 20 [=====>         ] 34.1% Loss: 0.0799, Epoch 20, Batch 42, CE_loss: 0.05956215783953667, Dice_loss: 0.0047455476596951485, Consistency_loss: 0.000794326129835099\n",
      "[Training] Epoch: 20 [=====>         ] 34.9% Loss: 0.0801, Epoch 20, Batch 43, CE_loss: 0.08015843480825424, Dice_loss: 0.007229501381516457, Consistency_loss: 0.00011966947204200551\n",
      "[Training] Epoch: 20 [=====>         ] 35.7% Loss: 0.0804, Epoch 20, Batch 44, CE_loss: 0.08388788998126984, Dice_loss: 0.007877491414546967, Consistency_loss: 0.0006070726085454226\n",
      "[Training] Epoch: 20 [=====>         ] 36.5% Loss: 0.0801, Epoch 20, Batch 45, CE_loss: 0.0631142109632492, Dice_loss: 0.005091436207294464, Consistency_loss: 0.0003110714606009424\n",
      "[Training] Epoch: 20 [=====>         ] 37.3% Loss: 0.0803, Epoch 20, Batch 46, CE_loss: 0.08289554715156555, Dice_loss: 0.006857049651443958, Consistency_loss: 0.0003696386411320418\n",
      "[Training] Epoch: 20 [=====>         ] 38.1% Loss: 0.0800, Epoch 20, Batch 47, CE_loss: 0.060298141092061996, Dice_loss: 0.005022293422371149, Consistency_loss: 0.0007603860576637089\n",
      "[Training] Epoch: 20 [=====>         ] 38.9% Loss: 0.0803, Epoch 20, Batch 48, CE_loss: 0.0859951302409172, Dice_loss: 0.008080432191491127, Consistency_loss: 0.0008164743194356561\n",
      "[Training] Epoch: 20 [=====>         ] 39.7% Loss: 0.0807, Epoch 20, Batch 49, CE_loss: 0.09048329293727875, Dice_loss: 0.008130080066621304, Consistency_loss: 0.00038508453872054815\n",
      "[Training] Epoch: 20 [======>        ] 40.5% Loss: 0.0804, Epoch 20, Batch 50, CE_loss: 0.06109100207686424, Dice_loss: 0.004924768581986427, Consistency_loss: 0.0008639988373033702\n",
      "[Training] Epoch: 20 [======>        ] 41.3% Loss: 0.0806, Epoch 20, Batch 51, CE_loss: 0.0809144601225853, Dice_loss: 0.007589409127831459, Consistency_loss: 0.0009641377255320549\n",
      "[Training] Epoch: 20 [======>        ] 42.1% Loss: 0.0805, Epoch 20, Batch 52, CE_loss: 0.06723477691411972, Dice_loss: 0.005926207173615694, Consistency_loss: 0.0002105034509440884\n",
      "[Training] Epoch: 20 [======>        ] 42.9% Loss: 0.0803, Epoch 20, Batch 53, CE_loss: 0.06438851356506348, Dice_loss: 0.00556919164955616, Consistency_loss: 0.00020902040705550462\n",
      "[Training] Epoch: 20 [======>        ] 43.7% Loss: 0.0803, Epoch 20, Batch 54, CE_loss: 0.0758831799030304, Dice_loss: 0.0069319638423621655, Consistency_loss: 0.0005711567355319858\n",
      "[Training] Epoch: 20 [======>        ] 44.4% Loss: 0.0804, Epoch 20, Batch 55, CE_loss: 0.07433917373418808, Dice_loss: 0.006756735034286976, Consistency_loss: 0.0002025454305112362\n",
      "[Training] Epoch: 20 [======>        ] 45.2% Loss: 0.0803, Epoch 20, Batch 56, CE_loss: 0.07173360884189606, Dice_loss: 0.0065480503253638744, Consistency_loss: 0.0011058029485866427\n",
      "[Training] Epoch: 20 [======>        ] 46.0% Loss: 0.0805, Epoch 20, Batch 57, CE_loss: 0.07950598001480103, Dice_loss: 0.007453345227986574, Consistency_loss: 0.0004620285762939602\n",
      "[Training] Epoch: 20 [=======>       ] 46.8% Loss: 0.0804, Epoch 20, Batch 58, CE_loss: 0.06896085292100906, Dice_loss: 0.005945934448391199, Consistency_loss: 0.0005511503550224006\n",
      "[Training] Epoch: 20 [=======>       ] 47.6% Loss: 0.0806, Epoch 20, Batch 59, CE_loss: 0.08311526477336884, Dice_loss: 0.008060382679104805, Consistency_loss: 0.0005950810736976564\n",
      "[Training] Epoch: 20 [=======>       ] 48.4% Loss: 0.0805, Epoch 20, Batch 60, CE_loss: 0.06957099586725235, Dice_loss: 0.006127229426056147, Consistency_loss: 8.154248644132167e-05\n",
      "[Training] Epoch: 20 [=======>       ] 49.2% Loss: 0.0805, Epoch 20, Batch 61, CE_loss: 0.07610619068145752, Dice_loss: 0.006926827598363161, Consistency_loss: 6.71424058964476e-05\n",
      "[Training] Epoch: 20 [=======>       ] 50.0% Loss: 0.0806, Epoch 20, Batch 62, CE_loss: 0.079587422311306, Dice_loss: 0.007522009778767824, Consistency_loss: 0.00018147038645111024\n",
      "[Training] Epoch: 20 [=======>       ] 50.8% Loss: 0.0808, Epoch 20, Batch 63, CE_loss: 0.08224678784608841, Dice_loss: 0.007397139444947243, Consistency_loss: 0.00017613664385862648\n",
      "[Training] Epoch: 20 [=======>       ] 51.6% Loss: 0.0807, Epoch 20, Batch 64, CE_loss: 0.06844279915094376, Dice_loss: 0.005556017160415649, Consistency_loss: 0.0007563168182969093\n",
      "[Training] Epoch: 20 [=======>       ] 52.4% Loss: 0.0806, Epoch 20, Batch 65, CE_loss: 0.06843278557062149, Dice_loss: 0.006252917926758528, Consistency_loss: 0.0008776813629083335\n",
      "[Training] Epoch: 20 [=======>       ] 53.2% Loss: 0.0804, Epoch 20, Batch 66, CE_loss: 0.058531489223241806, Dice_loss: 0.004487139172852039, Consistency_loss: 0.00030754870385862887\n",
      "[Training] Epoch: 20 [========>      ] 54.0% Loss: 0.0804, Epoch 20, Batch 67, CE_loss: 0.07783716171979904, Dice_loss: 0.007336481008678675, Consistency_loss: 0.0004570653836708516\n",
      "[Training] Epoch: 20 [========>      ] 54.8% Loss: 0.0804, Epoch 20, Batch 68, CE_loss: 0.07073923945426941, Dice_loss: 0.00614482956007123, Consistency_loss: 0.00040490576066076756\n",
      "[Training] Epoch: 20 [========>      ] 55.6% Loss: 0.0801, Epoch 20, Batch 69, CE_loss: 0.05740881338715553, Dice_loss: 0.0043935030698776245, Consistency_loss: 0.0003210378054063767\n",
      "[Training] Epoch: 20 [========>      ] 56.3% Loss: 0.0803, Epoch 20, Batch 70, CE_loss: 0.08324515074491501, Dice_loss: 0.00783146545290947, Consistency_loss: 0.0005941585986874998\n",
      "[Training] Epoch: 20 [========>      ] 57.1% Loss: 0.0805, Epoch 20, Batch 71, CE_loss: 0.08583775162696838, Dice_loss: 0.007814155891537666, Consistency_loss: 0.0007943615200929344\n",
      "[Training] Epoch: 20 [========>      ] 57.9% Loss: 0.0807, Epoch 20, Batch 72, CE_loss: 0.08941736072301865, Dice_loss: 0.008499518036842346, Consistency_loss: 0.0005530347116291523\n",
      "[Training] Epoch: 20 [========>      ] 58.7% Loss: 0.0807, Epoch 20, Batch 73, CE_loss: 0.07124876230955124, Dice_loss: 0.006043607369065285, Consistency_loss: 0.0001238697295775637\n",
      "[Training] Epoch: 20 [========>      ] 59.5% Loss: 0.0804, Epoch 20, Batch 74, CE_loss: 0.05463046953082085, Dice_loss: 0.004131719470024109, Consistency_loss: 0.0006442908779717982\n",
      "[Training] Epoch: 20 [=========>     ] 60.3% Loss: 0.0802, Epoch 20, Batch 75, CE_loss: 0.05812196433544159, Dice_loss: 0.004351647570729256, Consistency_loss: 0.0007390864193439484\n",
      "[Training] Epoch: 20 [=========>     ] 61.1% Loss: 0.0801, Epoch 20, Batch 76, CE_loss: 0.06702303141355515, Dice_loss: 0.0059461090713739395, Consistency_loss: 0.000747213838621974\n",
      "[Training] Epoch: 20 [=========>     ] 61.9% Loss: 0.0800, Epoch 20, Batch 77, CE_loss: 0.06410430371761322, Dice_loss: 0.005288574378937483, Consistency_loss: 0.0008669893140904605\n",
      "[Training] Epoch: 20 [=========>     ] 62.7% Loss: 0.0801, Epoch 20, Batch 78, CE_loss: 0.0789012536406517, Dice_loss: 0.0074894786812365055, Consistency_loss: 0.00040828375495038927\n",
      "[Training] Epoch: 20 [=========>     ] 63.5% Loss: 0.0800, Epoch 20, Batch 79, CE_loss: 0.06754450500011444, Dice_loss: 0.0059030731208622456, Consistency_loss: 0.0005287511157803237\n",
      "[Training] Epoch: 20 [=========>     ] 64.3% Loss: 0.0800, Epoch 20, Batch 80, CE_loss: 0.07236333936452866, Dice_loss: 0.006637564394623041, Consistency_loss: 9.545779175823554e-05\n",
      "[Training] Epoch: 20 [=========>     ] 65.1% Loss: 0.0798, Epoch 20, Batch 81, CE_loss: 0.062127240002155304, Dice_loss: 0.005215662997215986, Consistency_loss: 0.0006981421611271799\n",
      "[Training] Epoch: 20 [=========>     ] 65.9% Loss: 0.0797, Epoch 20, Batch 82, CE_loss: 0.06504032760858536, Dice_loss: 0.005483298096805811, Consistency_loss: 0.0006228410638868809\n",
      "[Training] Epoch: 20 [==========>    ] 66.7% Loss: 0.0798, Epoch 20, Batch 83, CE_loss: 0.0831948071718216, Dice_loss: 0.007056141272187233, Consistency_loss: 0.0002797632187139243\n",
      "[Training] Epoch: 20 [==========>    ] 67.5% Loss: 0.0796, Epoch 20, Batch 84, CE_loss: 0.05564217269420624, Dice_loss: 0.004250876605510712, Consistency_loss: 0.0003166247042827308\n",
      "[Training] Epoch: 20 [==========>    ] 68.3% Loss: 0.0795, Epoch 20, Batch 85, CE_loss: 0.0634402334690094, Dice_loss: 0.005601257085800171, Consistency_loss: 9.867397602647543e-05\n",
      "[Training] Epoch: 20 [==========>    ] 69.0% Loss: 0.0796, Epoch 20, Batch 86, CE_loss: 0.08246369659900665, Dice_loss: 0.007522666826844215, Consistency_loss: 0.0006513707339763641\n",
      "[Training] Epoch: 20 [==========>    ] 69.8% Loss: 0.0796, Epoch 20, Batch 87, CE_loss: 0.07228795439004898, Dice_loss: 0.006277603097259998, Consistency_loss: 0.000458343856735155\n",
      "[Training] Epoch: 20 [==========>    ] 70.6% Loss: 0.0794, Epoch 20, Batch 88, CE_loss: 0.05626052990555763, Dice_loss: 0.004297886975109577, Consistency_loss: 0.0004890027339570224\n",
      "[Training] Epoch: 20 [==========>    ] 71.4% Loss: 0.0792, Epoch 20, Batch 89, CE_loss: 0.057789042592048645, Dice_loss: 0.00434134341776371, Consistency_loss: 0.00038798022433184087\n",
      "[Training] Epoch: 20 [==========>    ] 72.2% Loss: 0.0792, Epoch 20, Batch 90, CE_loss: 0.06938721239566803, Dice_loss: 0.0055191102437675, Consistency_loss: 0.0003744619607459754\n",
      "[Training] Epoch: 20 [==========>    ] 73.0% Loss: 0.0793, Epoch 20, Batch 91, CE_loss: 0.08160527795553207, Dice_loss: 0.007750538177788258, Consistency_loss: 0.0006219565984793007\n",
      "[Training] Epoch: 20 [===========>   ] 73.8% Loss: 0.0791, Epoch 20, Batch 92, CE_loss: 0.057389549911022186, Dice_loss: 0.004629001021385193, Consistency_loss: 8.560060814488679e-05\n",
      "[Training] Epoch: 20 [===========>   ] 74.6% Loss: 0.0792, Epoch 20, Batch 93, CE_loss: 0.07731444388628006, Dice_loss: 0.007048318162560463, Consistency_loss: 0.0006127011147327721\n",
      "[Training] Epoch: 20 [===========>   ] 75.4% Loss: 0.0790, Epoch 20, Batch 94, CE_loss: 0.05881207063794136, Dice_loss: 0.004344132728874683, Consistency_loss: 0.0003905594057869166\n",
      "[Training] Epoch: 20 [===========>   ] 76.2% Loss: 0.0791, Epoch 20, Batch 95, CE_loss: 0.07642341405153275, Dice_loss: 0.006694624200463295, Consistency_loss: 0.0005937210517004132\n",
      "[Training] Epoch: 20 [===========>   ] 77.0% Loss: 0.0790, Epoch 20, Batch 96, CE_loss: 0.07003322243690491, Dice_loss: 0.006034179124981165, Consistency_loss: 0.0005799791542813182\n",
      "[Training] Epoch: 20 [===========>   ] 77.8% Loss: 0.0790, Epoch 20, Batch 97, CE_loss: 0.06770329922437668, Dice_loss: 0.005753695964813232, Consistency_loss: 0.0005835722549818456\n",
      "[Training] Epoch: 20 [===========>   ] 78.6% Loss: 0.0791, Epoch 20, Batch 98, CE_loss: 0.07947060465812683, Dice_loss: 0.007535773795098066, Consistency_loss: 0.00034356521791778505\n",
      "[Training] Epoch: 20 [===========>   ] 79.4% Loss: 0.0794, Epoch 20, Batch 99, CE_loss: 0.10298338532447815, Dice_loss: 0.009315017610788345, Consistency_loss: 0.0003264487022534013\n",
      "[Training] Epoch: 20 [============>  ] 80.2% Loss: 0.0794, Epoch 20, Batch 100, CE_loss: 0.07342661917209625, Dice_loss: 0.006690636742860079, Consistency_loss: 0.00043081780313514173\n",
      "[Training] Epoch: 20 [============>  ] 81.0% Loss: 0.0797, Epoch 20, Batch 101, CE_loss: 0.09818299859762192, Dice_loss: 0.00932349730283022, Consistency_loss: 0.0005254567367956042\n",
      "[Training] Epoch: 20 [============>  ] 81.7% Loss: 0.0798, Epoch 20, Batch 102, CE_loss: 0.07934661209583282, Dice_loss: 0.007373093161731958, Consistency_loss: 0.0001834547583712265\n",
      "[Training] Epoch: 20 [============>  ] 82.5% Loss: 0.0799, Epoch 20, Batch 103, CE_loss: 0.08751215040683746, Dice_loss: 0.008118774741888046, Consistency_loss: 0.0007585991988889873\n",
      "[Training] Epoch: 20 [============>  ] 83.3% Loss: 0.0799, Epoch 20, Batch 104, CE_loss: 0.07316937297582626, Dice_loss: 0.006609808187931776, Consistency_loss: 7.055929017951712e-05\n",
      "[Training] Epoch: 20 [============>  ] 84.1% Loss: 0.0799, Epoch 20, Batch 105, CE_loss: 0.0664282888174057, Dice_loss: 0.0055958884768188, Consistency_loss: 0.0005740319611504674\n",
      "[Training] Epoch: 20 [============>  ] 84.9% Loss: 0.0798, Epoch 20, Batch 106, CE_loss: 0.07144041359424591, Dice_loss: 0.006390045862644911, Consistency_loss: 0.0007408316596411169\n",
      "[Training] Epoch: 20 [============>  ] 85.7% Loss: 0.0799, Epoch 20, Batch 107, CE_loss: 0.07609617710113525, Dice_loss: 0.007245728746056557, Consistency_loss: 8.878471999196336e-05\n",
      "[Training] Epoch: 20 [============>  ] 86.5% Loss: 0.0798, Epoch 20, Batch 108, CE_loss: 0.06676694005727768, Dice_loss: 0.005745913367718458, Consistency_loss: 0.00013725146709475666\n",
      "[Training] Epoch: 20 [=============> ] 87.3% Loss: 0.0799, Epoch 20, Batch 109, CE_loss: 0.0795140415430069, Dice_loss: 0.0076304334215819836, Consistency_loss: 0.00031994777964428067\n",
      "[Training] Epoch: 20 [=============> ] 88.1% Loss: 0.0799, Epoch 20, Batch 110, CE_loss: 0.07875947654247284, Dice_loss: 0.00716825295239687, Consistency_loss: 0.00044109183363616467\n",
      "[Training] Epoch: 20 [=============> ] 88.9% Loss: 0.0799, Epoch 20, Batch 111, CE_loss: 0.06660228222608566, Dice_loss: 0.006069276016205549, Consistency_loss: 0.0005033598863519728\n",
      "[Training] Epoch: 20 [=============> ] 89.7% Loss: 0.0797, Epoch 20, Batch 112, CE_loss: 0.05803665518760681, Dice_loss: 0.004842366557568312, Consistency_loss: 0.0004877254832535982\n",
      "[Training] Epoch: 20 [=============> ] 90.5% Loss: 0.0797, Epoch 20, Batch 113, CE_loss: 0.07366086542606354, Dice_loss: 0.006546937394887209, Consistency_loss: 0.0005856023053638637\n",
      "[Training] Epoch: 20 [=============> ] 91.3% Loss: 0.0797, Epoch 20, Batch 114, CE_loss: 0.06817550212144852, Dice_loss: 0.005489802453666925, Consistency_loss: 0.000546265859156847\n",
      "[Training] Epoch: 20 [=============> ] 92.1% Loss: 0.0798, Epoch 20, Batch 115, CE_loss: 0.0882306769490242, Dice_loss: 0.008622104302048683, Consistency_loss: 0.0004393478448037058\n",
      "[Training] Epoch: 20 [=============> ] 92.9% Loss: 0.0798, Epoch 20, Batch 116, CE_loss: 0.06758993864059448, Dice_loss: 0.005997321102768183, Consistency_loss: 0.0006442166632041335\n",
      "[Training] Epoch: 20 [==============>] 93.7% Loss: 0.0797, Epoch 20, Batch 117, CE_loss: 0.06668039411306381, Dice_loss: 0.0054899947717785835, Consistency_loss: 0.0005592384841293097\n",
      "[Training] Epoch: 20 [==============>] 94.4% Loss: 0.0797, Epoch 20, Batch 118, CE_loss: 0.07307234406471252, Dice_loss: 0.006402053404599428, Consistency_loss: 0.0003621347714215517\n",
      "[Training] Epoch: 20 [==============>] 95.2% Loss: 0.0797, Epoch 20, Batch 119, CE_loss: 0.06401826441287994, Dice_loss: 0.005530205555260181, Consistency_loss: 0.00018172313866671175\n",
      "[Training] Epoch: 20 [==============>] 96.0% Loss: 0.0796, Epoch 20, Batch 120, CE_loss: 0.06613807380199432, Dice_loss: 0.005802905652672052, Consistency_loss: 0.0007290904759429395\n",
      "[Training] Epoch: 20 [==============>] 96.8% Loss: 0.0797, Epoch 20, Batch 121, CE_loss: 0.0843842551112175, Dice_loss: 0.007890965789556503, Consistency_loss: 0.0001805491920094937\n",
      "[Training] Epoch: 20 [==============>] 97.6% Loss: 0.0796, Epoch 20, Batch 122, CE_loss: 0.06258594244718552, Dice_loss: 0.005230303388088942, Consistency_loss: 0.00047992743202485144\n",
      "[Training] Epoch: 20 [==============>] 98.4% Loss: 0.0796, Epoch 20, Batch 123, CE_loss: 0.06669862568378448, Dice_loss: 0.005805963650345802, Consistency_loss: 0.00047968243598006666\n",
      "[Training] Epoch: 20 [==============>] 99.2% Loss: 0.0796, Epoch 20, Batch 124, CE_loss: 0.07886183261871338, Dice_loss: 0.007601121440529823, Consistency_loss: 0.00031129043782129884\n",
      "[Training] Epoch: 20 [DONE]                                 \n",
      "Epoch 20, Batch 125, CE_loss: 0.06899076700210571, Dice_loss: 0.006175415590405464, Consistency_loss: 0.00039028123137541115\n",
      "[Validation] Epoch: 20 [DONE]                                 \n",
      "[Epoch: 20, TrainLoss: 0.0796, TrainDice: 0.0064, ValLoss: 0.1461                                            \n",
      "Number of batches:  126\n",
      "[Training] Epoch: 21 [>              ] 0.8% Loss: 0.0697, Epoch 21, Batch 0, CE_loss: 0.06352803111076355, Dice_loss: 0.005491031799465418, Consistency_loss: 0.0006507204379886389\n",
      "[Training] Epoch: 21 [>              ] 1.6% Loss: 0.0735, Epoch 21, Batch 1, CE_loss: 0.07069441676139832, Dice_loss: 0.005950212944298983, Consistency_loss: 0.000762693234719336\n",
      "[Training] Epoch: 21 [>              ] 2.4% Loss: 0.0764, Epoch 21, Batch 2, CE_loss: 0.07530901581048965, Dice_loss: 0.006766806822270155, Consistency_loss: 5.182658424018882e-05\n",
      "[Training] Epoch: 21 [>              ] 3.2% Loss: 0.0738, Epoch 21, Batch 3, CE_loss: 0.06097625568509102, Dice_loss: 0.00476595014333725, Consistency_loss: 0.0003718146763276309\n",
      "[Training] Epoch: 21 [>              ] 4.0% Loss: 0.0815, Epoch 21, Batch 4, CE_loss: 0.10247022658586502, Dice_loss: 0.009621808305382729, Consistency_loss: 5.565980609389953e-05\n",
      "[Training] Epoch: 21 [>              ] 4.8% Loss: 0.0811, Epoch 21, Batch 5, CE_loss: 0.07270701974630356, Dice_loss: 0.006546338088810444, Consistency_loss: 3.886037666234188e-05\n",
      "[Training] Epoch: 21 [>              ] 5.6% Loss: 0.0803, Epoch 21, Batch 6, CE_loss: 0.06875196099281311, Dice_loss: 0.00605856953188777, Consistency_loss: 0.0002239100431324914\n",
      "[Training] Epoch: 21 [>              ] 6.3% Loss: 0.0804, Epoch 21, Batch 7, CE_loss: 0.07407760620117188, Dice_loss: 0.006665973458439112, Consistency_loss: 0.0004222397692501545\n",
      "[Training] Epoch: 21 [=>             ] 7.1% Loss: 0.0809, Epoch 21, Batch 8, CE_loss: 0.07715672999620438, Dice_loss: 0.007422919850796461, Consistency_loss: 0.0001828908280003816\n",
      "[Training] Epoch: 21 [=>             ] 7.9% Loss: 0.0802, Epoch 21, Batch 9, CE_loss: 0.06794792413711548, Dice_loss: 0.006087045650929213, Consistency_loss: 5.2129536925349385e-05\n",
      "[Training] Epoch: 21 [=>             ] 8.7% Loss: 0.0804, Epoch 21, Batch 10, CE_loss: 0.07549261301755905, Dice_loss: 0.007023194804787636, Consistency_loss: 0.0005636698915623128\n",
      "[Training] Epoch: 21 [=>             ] 9.5% Loss: 0.0818, Epoch 21, Batch 11, CE_loss: 0.08886060118675232, Dice_loss: 0.0076913912780582905, Consistency_loss: 0.0005784569657407701\n",
      "[Training] Epoch: 21 [=>             ] 10.3% Loss: 0.0822, Epoch 21, Batch 12, CE_loss: 0.07970009744167328, Dice_loss: 0.0070476653054356575, Consistency_loss: 0.00038254642277024686\n",
      "[Training] Epoch: 21 [=>             ] 11.1% Loss: 0.0817, Epoch 21, Batch 13, CE_loss: 0.0674586296081543, Dice_loss: 0.006092383060604334, Consistency_loss: 0.0006057646824046969\n",
      "[Training] Epoch: 21 [=>             ] 11.9% Loss: 0.0812, Epoch 21, Batch 14, CE_loss: 0.0685633197426796, Dice_loss: 0.0059727211482822895, Consistency_loss: 0.0005271937698125839\n",
      "[Training] Epoch: 21 [=>             ] 12.7% Loss: 0.0810, Epoch 21, Batch 15, CE_loss: 0.07071301341056824, Dice_loss: 0.006602172739803791, Consistency_loss: 0.00041111238533630967\n",
      "[Training] Epoch: 21 [==>            ] 13.5% Loss: 0.0806, Epoch 21, Batch 16, CE_loss: 0.06784344464540482, Dice_loss: 0.006128423381596804, Consistency_loss: 0.00042754458263516426\n",
      "[Training] Epoch: 21 [==>            ] 14.3% Loss: 0.0800, Epoch 21, Batch 17, CE_loss: 0.06362389773130417, Dice_loss: 0.005522440653294325, Consistency_loss: 0.0003417549014557153\n",
      "[Training] Epoch: 21 [==>            ] 15.1% Loss: 0.0803, Epoch 21, Batch 18, CE_loss: 0.078189916908741, Dice_loss: 0.007318233139812946, Consistency_loss: 0.00015841001004446298\n",
      "[Training] Epoch: 21 [==>            ] 15.9% Loss: 0.0798, Epoch 21, Batch 19, CE_loss: 0.06464032828807831, Dice_loss: 0.005624176934361458, Consistency_loss: 0.00037009772495366633\n",
      "[Training] Epoch: 21 [==>            ] 16.7% Loss: 0.0798, Epoch 21, Batch 20, CE_loss: 0.07234130054712296, Dice_loss: 0.006718397606164217, Consistency_loss: 0.0001076848857337609\n",
      "[Training] Epoch: 21 [==>            ] 17.5% Loss: 0.0799, Epoch 21, Batch 21, CE_loss: 0.07564648240804672, Dice_loss: 0.007360983174294233, Consistency_loss: 7.416321022901684e-05\n",
      "[Training] Epoch: 21 [==>            ] 18.3% Loss: 0.0795, Epoch 21, Batch 22, CE_loss: 0.06372460722923279, Dice_loss: 0.005605477374047041, Consistency_loss: 0.00025825281045399606\n",
      "[Training] Epoch: 21 [==>            ] 19.0% Loss: 0.0790, Epoch 21, Batch 23, CE_loss: 0.061830587685108185, Dice_loss: 0.005252838134765625, Consistency_loss: 0.0005112402723170817\n",
      "[Training] Epoch: 21 [==>            ] 19.8% Loss: 0.0799, Epoch 21, Batch 24, CE_loss: 0.09172374755144119, Dice_loss: 0.009345893748104572, Consistency_loss: 0.00028196294442750514\n",
      "[Training] Epoch: 21 [===>           ] 20.6% Loss: 0.0797, Epoch 21, Batch 25, CE_loss: 0.06809676438570023, Dice_loss: 0.006095838733017445, Consistency_loss: 0.00016765156760811806\n",
      "[Training] Epoch: 21 [===>           ] 21.4% Loss: 0.0802, Epoch 21, Batch 26, CE_loss: 0.08472824841737747, Dice_loss: 0.008404751308262348, Consistency_loss: 0.0006801272975280881\n",
      "[Training] Epoch: 21 [===>           ] 22.2% Loss: 0.0797, Epoch 21, Batch 27, CE_loss: 0.061210907995700836, Dice_loss: 0.005293361842632294, Consistency_loss: 0.00046587057295255363\n",
      "[Training] Epoch: 21 [===>           ] 23.0% Loss: 0.0793, Epoch 21, Batch 28, CE_loss: 0.06297491490840912, Dice_loss: 0.005121767520904541, Consistency_loss: 0.00039183415356092155\n",
      "[Training] Epoch: 21 [===>           ] 23.8% Loss: 0.0791, Epoch 21, Batch 29, CE_loss: 0.06559884548187256, Dice_loss: 0.0052085816860198975, Consistency_loss: 0.00013321038568392396\n",
      "[Training] Epoch: 21 [===>           ] 24.6% Loss: 0.0796, Epoch 21, Batch 30, CE_loss: 0.0869264006614685, Dice_loss: 0.008730863220989704, Consistency_loss: 0.0007831567781977355\n",
      "[Training] Epoch: 21 [===>           ] 25.4% Loss: 0.0794, Epoch 21, Batch 31, CE_loss: 0.06681177020072937, Dice_loss: 0.005742658860981464, Consistency_loss: 3.8153670175233856e-05\n",
      "[Training] Epoch: 21 [===>           ] 26.2% Loss: 0.0788, Epoch 21, Batch 32, CE_loss: 0.05666368082165718, Dice_loss: 0.004178385715931654, Consistency_loss: 7.017039752099663e-05\n",
      "[Training] Epoch: 21 [====>          ] 27.0% Loss: 0.0784, Epoch 21, Batch 33, CE_loss: 0.05918992683291435, Dice_loss: 0.004739096853882074, Consistency_loss: 0.0005079097463749349\n",
      "[Training] Epoch: 21 [====>          ] 27.8% Loss: 0.0778, Epoch 21, Batch 34, CE_loss: 0.052129264920949936, Dice_loss: 0.003884397679939866, Consistency_loss: 0.0006638352642767131\n",
      "[Training] Epoch: 21 [====>          ] 28.6% Loss: 0.0773, Epoch 21, Batch 35, CE_loss: 0.05541757866740227, Dice_loss: 0.004575992003083229, Consistency_loss: 0.00043474967242218554\n",
      "[Training] Epoch: 21 [====>          ] 29.4% Loss: 0.0773, Epoch 21, Batch 36, CE_loss: 0.07213364541530609, Dice_loss: 0.006612642202526331, Consistency_loss: 4.896007521892898e-05\n",
      "[Training] Epoch: 21 [====>          ] 30.2% Loss: 0.0773, Epoch 21, Batch 37, CE_loss: 0.07007312774658203, Dice_loss: 0.006420421879738569, Consistency_loss: 0.0005029496969655156\n",
      "[Training] Epoch: 21 [====>          ] 31.0% Loss: 0.0776, Epoch 21, Batch 38, CE_loss: 0.07931103557348251, Dice_loss: 0.007315103895962238, Consistency_loss: 6.058724829927087e-05\n",
      "[Training] Epoch: 21 [====>          ] 31.7% Loss: 0.0779, Epoch 21, Batch 39, CE_loss: 0.08123373985290527, Dice_loss: 0.007394291926175356, Consistency_loss: 0.00011294276919215918\n",
      "[Training] Epoch: 21 [====>          ] 32.5% Loss: 0.0779, Epoch 21, Batch 40, CE_loss: 0.07126025855541229, Dice_loss: 0.006404230371117592, Consistency_loss: 0.00011330400593578815\n",
      "[Training] Epoch: 21 [=====>         ] 33.3% Loss: 0.0779, Epoch 21, Batch 41, CE_loss: 0.07115113735198975, Dice_loss: 0.006361681502312422, Consistency_loss: 0.0005419246153905988\n",
      "[Training] Epoch: 21 [=====>         ] 34.1% Loss: 0.0776, Epoch 21, Batch 42, CE_loss: 0.060255955904722214, Dice_loss: 0.005101253278553486, Consistency_loss: 0.0006613588193431497\n",
      "[Training] Epoch: 21 [=====>         ] 34.9% Loss: 0.0781, Epoch 21, Batch 43, CE_loss: 0.09118686616420746, Dice_loss: 0.007470090873539448, Consistency_loss: 0.0004042913787998259\n",
      "[Training] Epoch: 21 [=====>         ] 35.7% Loss: 0.0778, Epoch 21, Batch 44, CE_loss: 0.061656393110752106, Dice_loss: 0.00511101633310318, Consistency_loss: 0.0001711021177470684\n",
      "[Training] Epoch: 21 [=====>         ] 36.5% Loss: 0.0776, Epoch 21, Batch 45, CE_loss: 0.06007539480924606, Dice_loss: 0.004931916482746601, Consistency_loss: 0.00037349091144278646\n",
      "[Training] Epoch: 21 [=====>         ] 37.3% Loss: 0.0776, Epoch 21, Batch 46, CE_loss: 0.07115387171506882, Dice_loss: 0.006732309237122536, Consistency_loss: 0.00015964903286658227\n",
      "[Training] Epoch: 21 [=====>         ] 38.1% Loss: 0.0782, Epoch 21, Batch 47, CE_loss: 0.09860635548830032, Dice_loss: 0.009305965155363083, Consistency_loss: 0.0006470612133853137\n",
      "[Training] Epoch: 21 [=====>         ] 38.9% Loss: 0.0783, Epoch 21, Batch 48, CE_loss: 0.07684099674224854, Dice_loss: 0.006677502766251564, Consistency_loss: 0.0008028377196751535\n",
      "[Training] Epoch: 21 [=====>         ] 39.7% Loss: 0.0784, Epoch 21, Batch 49, CE_loss: 0.07484374940395355, Dice_loss: 0.007069042418152094, Consistency_loss: 0.00035177735844627023\n",
      "[Training] Epoch: 21 [======>        ] 40.5% Loss: 0.0781, Epoch 21, Batch 50, CE_loss: 0.05536947771906853, Dice_loss: 0.004206374287605286, Consistency_loss: 0.0006970090325921774\n",
      "[Training] Epoch: 21 [======>        ] 41.3% Loss: 0.0779, Epoch 21, Batch 51, CE_loss: 0.06342282891273499, Dice_loss: 0.005320613272488117, Consistency_loss: 0.0007849590037949383\n",
      "[Training] Epoch: 21 [======>        ] 42.1% Loss: 0.0779, Epoch 21, Batch 52, CE_loss: 0.0718638226389885, Dice_loss: 0.006663224194198847, Consistency_loss: 0.00015821080887690187\n",
      "[Training] Epoch: 21 [======>        ] 42.9% Loss: 0.0779, Epoch 21, Batch 53, CE_loss: 0.0687842071056366, Dice_loss: 0.006296620238572359, Consistency_loss: 0.0001864741207100451\n",
      "[Training] Epoch: 21 [======>        ] 43.7% Loss: 0.0777, Epoch 21, Batch 54, CE_loss: 0.06441685557365417, Dice_loss: 0.005886376369744539, Consistency_loss: 0.0004117710923310369\n",
      "[Training] Epoch: 21 [======>        ] 44.4% Loss: 0.0775, Epoch 21, Batch 55, CE_loss: 0.059367116540670395, Dice_loss: 0.004763169679790735, Consistency_loss: 0.000526897085364908\n",
      "[Training] Epoch: 21 [======>        ] 45.2% Loss: 0.0774, Epoch 21, Batch 56, CE_loss: 0.06414194405078888, Dice_loss: 0.005336567759513855, Consistency_loss: 0.0002126018953276798\n",
      "[Training] Epoch: 21 [======>        ] 46.0% Loss: 0.0774, Epoch 21, Batch 57, CE_loss: 0.07146240025758743, Dice_loss: 0.006781201343983412, Consistency_loss: 0.0001663650036789477\n",
      "[Training] Epoch: 21 [=======>       ] 46.8% Loss: 0.0773, Epoch 21, Batch 58, CE_loss: 0.06747841835021973, Dice_loss: 0.0062849391251802444, Consistency_loss: 0.0005134521634317935\n",
      "[Training] Epoch: 21 [=======>       ] 47.6% Loss: 0.0772, Epoch 21, Batch 59, CE_loss: 0.06586329638957977, Dice_loss: 0.005381499417126179, Consistency_loss: 0.0005699180765077472\n",
      "[Training] Epoch: 21 [=======>       ] 48.4% Loss: 0.0772, Epoch 21, Batch 60, CE_loss: 0.07032056152820587, Dice_loss: 0.006365570705384016, Consistency_loss: 0.0004858955799136311\n",
      "[Training] Epoch: 21 [=======>       ] 49.2% Loss: 0.0777, Epoch 21, Batch 61, CE_loss: 0.09698109328746796, Dice_loss: 0.009821458719670773, Consistency_loss: 0.0005220578168518841\n",
      "[Training] Epoch: 21 [=======>       ] 50.0% Loss: 0.0776, Epoch 21, Batch 62, CE_loss: 0.06272488832473755, Dice_loss: 0.00570177286863327, Consistency_loss: 0.0007080238428898156\n",
      "[Training] Epoch: 21 [=======>       ] 50.8% Loss: 0.0777, Epoch 21, Batch 63, CE_loss: 0.075873002409935, Dice_loss: 0.007506510708481073, Consistency_loss: 0.00021280864893924445\n",
      "[Training] Epoch: 21 [=======>       ] 51.6% Loss: 0.0780, Epoch 21, Batch 64, CE_loss: 0.08942146599292755, Dice_loss: 0.008762960322201252, Consistency_loss: 0.0007583321421407163\n",
      "[Training] Epoch: 21 [=======>       ] 52.4% Loss: 0.0781, Epoch 21, Batch 65, CE_loss: 0.07727722823619843, Dice_loss: 0.007478910963982344, Consistency_loss: 0.0006838813424110413\n",
      "[Training] Epoch: 21 [=======>       ] 53.2% Loss: 0.0780, Epoch 21, Batch 66, CE_loss: 0.06262964010238647, Dice_loss: 0.005469042342156172, Consistency_loss: 0.000285236572381109\n",
      "[Training] Epoch: 21 [========>      ] 54.0% Loss: 0.0779, Epoch 21, Batch 67, CE_loss: 0.06557271629571915, Dice_loss: 0.005874136462807655, Consistency_loss: 0.00014312622079160064\n",
      "[Training] Epoch: 21 [========>      ] 54.8% Loss: 0.0778, Epoch 21, Batch 68, CE_loss: 0.0649789422750473, Dice_loss: 0.006005886476486921, Consistency_loss: 0.0002871045144274831\n",
      "[Training] Epoch: 21 [========>      ] 55.6% Loss: 0.0778, Epoch 21, Batch 69, CE_loss: 0.06965379416942596, Dice_loss: 0.006449568551033735, Consistency_loss: 9.899451833916828e-05\n",
      "[Training] Epoch: 21 [========>      ] 56.3% Loss: 0.0777, Epoch 21, Batch 70, CE_loss: 0.06744881719350815, Dice_loss: 0.005825516767799854, Consistency_loss: 0.0008694012649357319\n",
      "[Training] Epoch: 21 [========>      ] 57.1% Loss: 0.0775, Epoch 21, Batch 71, CE_loss: 0.05851161107420921, Dice_loss: 0.005077041685581207, Consistency_loss: 0.0007604174898006022\n",
      "[Training] Epoch: 21 [========>      ] 57.9% Loss: 0.0773, Epoch 21, Batch 72, CE_loss: 0.05820384994149208, Dice_loss: 0.005010979250073433, Consistency_loss: 0.0006894217221997678\n",
      "[Training] Epoch: 21 [========>      ] 58.7% Loss: 0.0772, Epoch 21, Batch 73, CE_loss: 0.05926167219877243, Dice_loss: 0.005023406818509102, Consistency_loss: 0.00046993824071250856\n",
      "[Training] Epoch: 21 [========>      ] 59.5% Loss: 0.0770, Epoch 21, Batch 74, CE_loss: 0.061670709401369095, Dice_loss: 0.0053351866081357, Consistency_loss: 0.0006405149470083416\n",
      "[Training] Epoch: 21 [=========>     ] 60.3% Loss: 0.0768, Epoch 21, Batch 75, CE_loss: 0.05341687053442001, Dice_loss: 0.004007390234619379, Consistency_loss: 0.0006803722935728729\n",
      "[Training] Epoch: 21 [=========>     ] 61.1% Loss: 0.0768, Epoch 21, Batch 76, CE_loss: 0.068677619099617, Dice_loss: 0.0064591215923428535, Consistency_loss: 0.0006202244549058378\n",
      "[Training] Epoch: 21 [=========>     ] 61.9% Loss: 0.0767, Epoch 21, Batch 77, CE_loss: 0.06817292422056198, Dice_loss: 0.006215049419552088, Consistency_loss: 0.00016493446310050786\n",
      "[Training] Epoch: 21 [=========>     ] 62.7% Loss: 0.0768, Epoch 21, Batch 78, CE_loss: 0.07327179610729218, Dice_loss: 0.006735813803970814, Consistency_loss: 0.000382592057576403\n",
      "[Training] Epoch: 21 [=========>     ] 63.5% Loss: 0.0765, Epoch 21, Batch 79, CE_loss: 0.05002669245004654, Dice_loss: 0.0038293050602078438, Consistency_loss: 0.0004144568520132452\n",
      "[Training] Epoch: 21 [=========>     ] 64.3% Loss: 0.0763, Epoch 21, Batch 80, CE_loss: 0.05477458983659744, Dice_loss: 0.004381473641842604, Consistency_loss: 0.0004293005622457713\n",
      "[Training] Epoch: 21 [=========>     ] 65.1% Loss: 0.0763, Epoch 21, Batch 81, CE_loss: 0.0679536759853363, Dice_loss: 0.0057249427773058414, Consistency_loss: 0.0006131487316451967\n",
      "[Training] Epoch: 21 [=========>     ] 65.9% Loss: 0.0767, Epoch 21, Batch 82, CE_loss: 0.10271703451871872, Dice_loss: 0.01047498732805252, Consistency_loss: 0.0006031982484273612\n",
      "[Training] Epoch: 21 [==========>    ] 66.7% Loss: 0.0767, Epoch 21, Batch 83, CE_loss: 0.06792252510786057, Dice_loss: 0.006195889785885811, Consistency_loss: 0.0002422337420284748\n",
      "[Training] Epoch: 21 [==========>    ] 67.5% Loss: 0.0766, Epoch 21, Batch 84, CE_loss: 0.06120890751481056, Dice_loss: 0.005105450749397278, Consistency_loss: 0.00022033492859918624\n",
      "[Training] Epoch: 21 [==========>    ] 68.3% Loss: 0.0765, Epoch 21, Batch 85, CE_loss: 0.06350385397672653, Dice_loss: 0.005213253200054169, Consistency_loss: 0.0005595281254500151\n",
      "[Training] Epoch: 21 [==========>    ] 69.0% Loss: 0.0763, Epoch 21, Batch 86, CE_loss: 0.054378919303417206, Dice_loss: 0.004108782391995192, Consistency_loss: 0.0008047252777032554\n",
      "[Training] Epoch: 21 [==========>    ] 69.8% Loss: 0.0763, Epoch 21, Batch 87, CE_loss: 0.06646284461021423, Dice_loss: 0.005950753577053547, Consistency_loss: 0.0003673745959531516\n",
      "[Training] Epoch: 21 [==========>    ] 70.6% Loss: 0.0765, Epoch 21, Batch 88, CE_loss: 0.0919075459241867, Dice_loss: 0.008530368097126484, Consistency_loss: 0.000372930895537138\n",
      "[Training] Epoch: 21 [==========>    ] 71.4% Loss: 0.0766, Epoch 21, Batch 89, CE_loss: 0.0718783438205719, Dice_loss: 0.006802810821682215, Consistency_loss: 0.0004927406553179026\n",
      "[Training] Epoch: 21 [==========>    ] 72.2% Loss: 0.0767, Epoch 21, Batch 90, CE_loss: 0.08103273063898087, Dice_loss: 0.007225884590297937, Consistency_loss: 0.00045730816782452166\n",
      "[Training] Epoch: 21 [==========>    ] 73.0% Loss: 0.0768, Epoch 21, Batch 91, CE_loss: 0.07657843828201294, Dice_loss: 0.00732093770056963, Consistency_loss: 0.0004745363839901984\n",
      "[Training] Epoch: 21 [===========>   ] 73.8% Loss: 0.0768, Epoch 21, Batch 92, CE_loss: 0.06756032258272171, Dice_loss: 0.006310733035206795, Consistency_loss: 0.00046205587568692863\n",
      "[Training] Epoch: 21 [===========>   ] 74.6% Loss: 0.0767, Epoch 21, Batch 93, CE_loss: 0.06118188053369522, Dice_loss: 0.005111615639179945, Consistency_loss: 0.0004971832386218011\n",
      "[Training] Epoch: 21 [===========>   ] 75.4% Loss: 0.0766, Epoch 21, Batch 94, CE_loss: 0.06413029134273529, Dice_loss: 0.0056368280202150345, Consistency_loss: 0.000339752557920292\n",
      "[Training] Epoch: 21 [===========>   ] 76.2% Loss: 0.0765, Epoch 21, Batch 95, CE_loss: 0.06406727433204651, Dice_loss: 0.0057790204882621765, Consistency_loss: 0.0006470206426456571\n",
      "[Training] Epoch: 21 [===========>   ] 77.0% Loss: 0.0765, Epoch 21, Batch 96, CE_loss: 0.06668293476104736, Dice_loss: 0.005788028240203857, Consistency_loss: 0.00022071963758207858\n",
      "[Training] Epoch: 21 [===========>   ] 77.8% Loss: 0.0764, Epoch 21, Batch 97, CE_loss: 0.05883282423019409, Dice_loss: 0.004964187741279602, Consistency_loss: 0.00037845486076548696\n",
      "[Training] Epoch: 21 [===========>   ] 78.6% Loss: 0.0765, Epoch 21, Batch 98, CE_loss: 0.08190249651670456, Dice_loss: 0.007848264649510384, Consistency_loss: 0.0004287347837816924\n",
      "[Training] Epoch: 21 [===========>   ] 79.4% Loss: 0.0768, Epoch 21, Batch 99, CE_loss: 0.09355026483535767, Dice_loss: 0.009031346999108791, Consistency_loss: 0.00044020023779012263\n",
      "[Training] Epoch: 21 [============>  ] 80.2% Loss: 0.0767, Epoch 21, Batch 100, CE_loss: 0.0670473650097847, Dice_loss: 0.006077085621654987, Consistency_loss: 0.0005257026059553027\n",
      "[Training] Epoch: 21 [============>  ] 81.0% Loss: 0.0770, Epoch 21, Batch 101, CE_loss: 0.09677901118993759, Dice_loss: 0.00962282344698906, Consistency_loss: 0.0006152362329885364\n",
      "[Training] Epoch: 21 [============>  ] 81.7% Loss: 0.0769, Epoch 21, Batch 102, CE_loss: 0.057515017688274384, Dice_loss: 0.004788230638951063, Consistency_loss: 0.00027998824953101575\n",
      "[Training] Epoch: 21 [============>  ] 82.5% Loss: 0.0768, Epoch 21, Batch 103, CE_loss: 0.05925420671701431, Dice_loss: 0.005023598670959473, Consistency_loss: 0.0006640273495577276\n",
      "[Training] Epoch: 21 [============>  ] 83.3% Loss: 0.0768, Epoch 21, Batch 104, CE_loss: 0.07024909555912018, Dice_loss: 0.006785448174923658, Consistency_loss: 0.0005114499945193529\n",
      "[Training] Epoch: 21 [============>  ] 84.1% Loss: 0.0767, Epoch 21, Batch 105, CE_loss: 0.0630713552236557, Dice_loss: 0.0057790339924395084, Consistency_loss: 0.00034379304270260036\n",
      "[Training] Epoch: 21 [============>  ] 84.9% Loss: 0.0766, Epoch 21, Batch 106, CE_loss: 0.06351789087057114, Dice_loss: 0.005798730533570051, Consistency_loss: 0.0006030267104506493\n",
      "[Training] Epoch: 21 [============>  ] 85.7% Loss: 0.0765, Epoch 21, Batch 107, CE_loss: 0.057336702942848206, Dice_loss: 0.0049468744546175, Consistency_loss: 0.0007803753251209855\n",
      "[Training] Epoch: 21 [============>  ] 86.5% Loss: 0.0766, Epoch 21, Batch 108, CE_loss: 0.08261828124523163, Dice_loss: 0.007621693890541792, Consistency_loss: 0.0005283464561216533\n",
      "[Training] Epoch: 21 [=============> ] 87.3% Loss: 0.0766, Epoch 21, Batch 109, CE_loss: 0.06564559042453766, Dice_loss: 0.006036343052983284, Consistency_loss: 9.17444922379218e-05\n",
      "[Training] Epoch: 21 [=============> ] 88.1% Loss: 0.0766, Epoch 21, Batch 110, CE_loss: 0.06634607911109924, Dice_loss: 0.0056230234913527966, Consistency_loss: 4.9424637836636975e-05\n",
      "[Training] Epoch: 21 [=============> ] 88.9% Loss: 0.0765, Epoch 21, Batch 111, CE_loss: 0.06199188902974129, Dice_loss: 0.0054679871536791325, Consistency_loss: 0.0006072275573387742\n",
      "[Training] Epoch: 21 [=============> ] 89.7% Loss: 0.0765, Epoch 21, Batch 112, CE_loss: 0.0727524384856224, Dice_loss: 0.006074497476220131, Consistency_loss: 0.0008197698625735939\n",
      "[Training] Epoch: 21 [=============> ] 90.5% Loss: 0.0765, Epoch 21, Batch 113, CE_loss: 0.06876295059919357, Dice_loss: 0.006246181204915047, Consistency_loss: 0.0014697619481012225\n",
      "[Training] Epoch: 21 [=============> ] 91.3% Loss: 0.0765, Epoch 21, Batch 114, CE_loss: 0.06614623963832855, Dice_loss: 0.00599592225626111, Consistency_loss: 0.0004647869209293276\n",
      "[Training] Epoch: 21 [=============> ] 92.1% Loss: 0.0765, Epoch 21, Batch 115, CE_loss: 0.06915293633937836, Dice_loss: 0.006515832617878914, Consistency_loss: 0.000497976376209408\n",
      "[Training] Epoch: 21 [=============> ] 92.9% Loss: 0.0765, Epoch 21, Batch 116, CE_loss: 0.07086563855409622, Dice_loss: 0.006672487128525972, Consistency_loss: 0.0005784407258033752\n",
      "[Training] Epoch: 21 [==============>] 93.7% Loss: 0.0765, Epoch 21, Batch 117, CE_loss: 0.06888771802186966, Dice_loss: 0.006249793339520693, Consistency_loss: 0.0001848188112489879\n",
      "[Training] Epoch: 21 [==============>] 94.4% Loss: 0.0764, Epoch 21, Batch 118, CE_loss: 0.06067291274666786, Dice_loss: 0.005211009178310633, Consistency_loss: 0.00012508562940638512\n",
      "[Training] Epoch: 21 [==============>] 95.2% Loss: 0.0764, Epoch 21, Batch 119, CE_loss: 0.06830844283103943, Dice_loss: 0.006401096470654011, Consistency_loss: 0.00045785229303874075\n",
      "[Training] Epoch: 21 [==============>] 96.0% Loss: 0.0763, Epoch 21, Batch 120, CE_loss: 0.06226114556193352, Dice_loss: 0.005284841638058424, Consistency_loss: 0.0012142463820055127\n",
      "[Training] Epoch: 21 [==============>] 96.8% Loss: 0.0763, Epoch 21, Batch 121, CE_loss: 0.07251784205436707, Dice_loss: 0.006797822192311287, Consistency_loss: 0.00014592467050533742\n",
      "[Training] Epoch: 21 [==============>] 97.6% Loss: 0.0764, Epoch 21, Batch 122, CE_loss: 0.0806671679019928, Dice_loss: 0.00801656860858202, Consistency_loss: 0.00024527354980818927\n",
      "[Training] Epoch: 21 [==============>] 98.4% Loss: 0.0764, Epoch 21, Batch 123, CE_loss: 0.06563897430896759, Dice_loss: 0.006132223177701235, Consistency_loss: 0.00012795710063073784\n",
      "[Training] Epoch: 21 [==============>] 99.2% Loss: 0.0764, Epoch 21, Batch 124, CE_loss: 0.07196362316608429, Dice_loss: 0.006381815765053034, Consistency_loss: 0.00048792336019687355\n",
      "[Training] Epoch: 21 [DONE]                                 \n",
      "Epoch 21, Batch 125, CE_loss: 0.0716819316148758, Dice_loss: 0.006183238700032234, Consistency_loss: 0.0004653104697354138\n",
      "[Validation] Epoch: 21 [DONE]                                 \n",
      "[Epoch: 21, TrainLoss: 0.0764, TrainDice: 0.0063, ValLoss: 0.1496                                            \n",
      "Number of batches:  126\n",
      "[Training] Epoch: 22 [>              ] 0.8% Loss: 0.0658, Epoch 22, Batch 0, CE_loss: 0.06020025163888931, Dice_loss: 0.005309240892529488, Consistency_loss: 0.00030556393903680146\n",
      "[Training] Epoch: 22 [>              ] 1.6% Loss: 0.0734, Epoch 22, Batch 1, CE_loss: 0.07339398562908173, Dice_loss: 0.007227717433124781, Consistency_loss: 0.00032049426226876676\n",
      "[Training] Epoch: 22 [>              ] 2.4% Loss: 0.0773, Epoch 22, Batch 2, CE_loss: 0.0777372270822525, Dice_loss: 0.007175950799137354, Consistency_loss: 0.0003498453588690609\n",
      "[Training] Epoch: 22 [>              ] 3.2% Loss: 0.0724, Epoch 22, Batch 3, CE_loss: 0.05294607952237129, Dice_loss: 0.004379309713840485, Consistency_loss: 0.0003979857137892395\n",
      "[Training] Epoch: 22 [>              ] 4.0% Loss: 0.0735, Epoch 22, Batch 4, CE_loss: 0.0709536001086235, Dice_loss: 0.006374024320393801, Consistency_loss: 0.00042059863335452974\n",
      "[Training] Epoch: 22 [>              ] 4.8% Loss: 0.0735, Epoch 22, Batch 5, CE_loss: 0.06703516840934753, Dice_loss: 0.006292534060776234, Consistency_loss: 0.00019851706747431308\n",
      "[Training] Epoch: 22 [>              ] 5.6% Loss: 0.0759, Epoch 22, Batch 6, CE_loss: 0.08235595375299454, Dice_loss: 0.007733908481895924, Consistency_loss: 0.0001360364112770185\n",
      "[Training] Epoch: 22 [>              ] 6.3% Loss: 0.0736, Epoch 22, Batch 7, CE_loss: 0.05313286930322647, Dice_loss: 0.004265686962753534, Consistency_loss: 0.00028354147798381746\n",
      "[Training] Epoch: 22 [=>             ] 7.1% Loss: 0.0736, Epoch 22, Batch 8, CE_loss: 0.06716382503509521, Dice_loss: 0.006248299963772297, Consistency_loss: 5.723294088966213e-05\n",
      "[Training] Epoch: 22 [=>             ] 7.9% Loss: 0.0732, Epoch 22, Batch 9, CE_loss: 0.06383021920919418, Dice_loss: 0.005652170162647963, Consistency_loss: 0.00018276945047546178\n",
      "[Training] Epoch: 22 [=>             ] 8.7% Loss: 0.0759, Epoch 22, Batch 10, CE_loss: 0.09260188788175583, Dice_loss: 0.009308374486863613, Consistency_loss: 0.0005946527235209942\n",
      "[Training] Epoch: 22 [=>             ] 9.5% Loss: 0.0755, Epoch 22, Batch 11, CE_loss: 0.06476734578609467, Dice_loss: 0.006037813611328602, Consistency_loss: 0.0005962745635770261\n",
      "[Training] Epoch: 22 [=>             ] 10.3% Loss: 0.0751, Epoch 22, Batch 12, CE_loss: 0.06433691829442978, Dice_loss: 0.005908812861889601, Consistency_loss: 0.0006480056326836348\n",
      "[Training] Epoch: 22 [=>             ] 11.1% Loss: 0.0743, Epoch 22, Batch 13, CE_loss: 0.05747886374592781, Dice_loss: 0.00498433131724596, Consistency_loss: 0.0006196207250468433\n",
      "[Training] Epoch: 22 [=>             ] 11.9% Loss: 0.0751, Epoch 22, Batch 14, CE_loss: 0.0789133831858635, Dice_loss: 0.007843200117349625, Consistency_loss: 0.0005007820436730981\n",
      "[Training] Epoch: 22 [=>             ] 12.7% Loss: 0.0742, Epoch 22, Batch 15, CE_loss: 0.055158521980047226, Dice_loss: 0.004795968532562256, Consistency_loss: 0.0004752700333483517\n",
      "[Training] Epoch: 22 [==>            ] 13.5% Loss: 0.0738, Epoch 22, Batch 16, CE_loss: 0.061457399278879166, Dice_loss: 0.0052223727107048035, Consistency_loss: 0.00020729620882775635\n",
      "[Training] Epoch: 22 [==>            ] 14.3% Loss: 0.0755, Epoch 22, Batch 17, CE_loss: 0.09574724733829498, Dice_loss: 0.009011762216687202, Consistency_loss: 0.0002988712803926319\n",
      "[Training] Epoch: 22 [==>            ] 15.1% Loss: 0.0761, Epoch 22, Batch 18, CE_loss: 0.07787257432937622, Dice_loss: 0.007516940124332905, Consistency_loss: 0.0005587117630057037\n",
      "[Training] Epoch: 22 [==>            ] 15.9% Loss: 0.0764, Epoch 22, Batch 19, CE_loss: 0.07407596707344055, Dice_loss: 0.0072836861945688725, Consistency_loss: 0.0005443485570140183\n",
      "[Training] Epoch: 22 [==>            ] 16.7% Loss: 0.0758, Epoch 22, Batch 20, CE_loss: 0.05860339477658272, Dice_loss: 0.004957965109497309, Consistency_loss: 0.00036335529875941575\n",
      "[Training] Epoch: 22 [==>            ] 17.5% Loss: 0.0757, Epoch 22, Batch 21, CE_loss: 0.0669594407081604, Dice_loss: 0.006380211096256971, Consistency_loss: 0.00026765940128825605\n",
      "[Training] Epoch: 22 [==>            ] 18.3% Loss: 0.0763, Epoch 22, Batch 22, CE_loss: 0.08190696686506271, Dice_loss: 0.008104813285171986, Consistency_loss: 0.0004895533202216029\n",
      "[Training] Epoch: 22 [==>            ] 19.0% Loss: 0.0763, Epoch 22, Batch 23, CE_loss: 0.06793119758367538, Dice_loss: 0.006176130846142769, Consistency_loss: 0.0004755344707518816\n",
      "[Training] Epoch: 22 [==>            ] 19.8% Loss: 0.0759, Epoch 22, Batch 24, CE_loss: 0.061121851205825806, Dice_loss: 0.005465819034725428, Consistency_loss: 0.00033839524257928133\n",
      "[Training] Epoch: 22 [===>           ] 20.6% Loss: 0.0754, Epoch 22, Batch 25, CE_loss: 0.05736605450510979, Dice_loss: 0.004824887495487928, Consistency_loss: 7.410273974528536e-05\n",
      "[Training] Epoch: 22 [===>           ] 21.4% Loss: 0.0755, Epoch 22, Batch 26, CE_loss: 0.07270652055740356, Dice_loss: 0.006699291057884693, Consistency_loss: 0.000746529723983258\n",
      "[Training] Epoch: 22 [===>           ] 22.2% Loss: 0.0752, Epoch 22, Batch 27, CE_loss: 0.05966871976852417, Dice_loss: 0.005357015412300825, Consistency_loss: 0.0006683053798042238\n",
      "[Training] Epoch: 22 [===>           ] 23.0% Loss: 0.0751, Epoch 22, Batch 28, CE_loss: 0.0652620941400528, Dice_loss: 0.0060185822658240795, Consistency_loss: 0.0005023997509852052\n",
      "[Training] Epoch: 22 [===>           ] 23.8% Loss: 0.0747, Epoch 22, Batch 29, CE_loss: 0.05798445641994476, Dice_loss: 0.0050566974096000195, Consistency_loss: 0.0005092198844067752\n",
      "[Training] Epoch: 22 [===>           ] 24.6% Loss: 0.0746, Epoch 22, Batch 30, CE_loss: 0.06417436897754669, Dice_loss: 0.005823889747262001, Consistency_loss: 0.0006935725104995072\n",
      "[Training] Epoch: 22 [===>           ] 25.4% Loss: 0.0747, Epoch 22, Batch 31, CE_loss: 0.0732913464307785, Dice_loss: 0.0070196096785366535, Consistency_loss: 5.754309313488193e-05\n",
      "[Training] Epoch: 22 [===>           ] 26.2% Loss: 0.0747, Epoch 22, Batch 32, CE_loss: 0.0665869265794754, Dice_loss: 0.006295368541032076, Consistency_loss: 0.0002734620065893978\n",
      "[Training] Epoch: 22 [====>          ] 27.0% Loss: 0.0747, Epoch 22, Batch 33, CE_loss: 0.06710028648376465, Dice_loss: 0.006314385216683149, Consistency_loss: 0.0005149340140633285\n",
      "[Training] Epoch: 22 [====>          ] 27.8% Loss: 0.0748, Epoch 22, Batch 34, CE_loss: 0.07180871069431305, Dice_loss: 0.006797191686928272, Consistency_loss: 0.0005658554146066308\n",
      "[Training] Epoch: 22 [====>          ] 28.6% Loss: 0.0748, Epoch 22, Batch 35, CE_loss: 0.06979411095380783, Dice_loss: 0.006658007390797138, Consistency_loss: 0.0003546260413713753\n",
      "[Training] Epoch: 22 [====>          ] 29.4% Loss: 0.0748, Epoch 22, Batch 36, CE_loss: 0.0686057060956955, Dice_loss: 0.006073880475014448, Consistency_loss: 5.0910497520817444e-05\n",
      "[Training] Epoch: 22 [====>          ] 30.2% Loss: 0.0747, Epoch 22, Batch 37, CE_loss: 0.06322149932384491, Dice_loss: 0.005860287230461836, Consistency_loss: 0.00045009213499724865\n",
      "[Training] Epoch: 22 [====>          ] 31.0% Loss: 0.0745, Epoch 22, Batch 38, CE_loss: 0.061522241681814194, Dice_loss: 0.005287514999508858, Consistency_loss: 0.00035164059954695404\n",
      "[Training] Epoch: 22 [====>          ] 31.7% Loss: 0.0748, Epoch 22, Batch 39, CE_loss: 0.0795743316411972, Dice_loss: 0.007043682504445314, Consistency_loss: 0.0008234530105255544\n",
      "[Training] Epoch: 22 [====>          ] 32.5% Loss: 0.0743, Epoch 22, Batch 40, CE_loss: 0.04708946496248245, Dice_loss: 0.003604111261665821, Consistency_loss: 0.0005475211655721068\n",
      "[Training] Epoch: 22 [=====>         ] 33.3% Loss: 0.0744, Epoch 22, Batch 41, CE_loss: 0.07192191481590271, Dice_loss: 0.00624859519302845, Consistency_loss: 0.00012416046229191124\n",
      "[Training] Epoch: 22 [=====>         ] 34.1% Loss: 0.0750, Epoch 22, Batch 42, CE_loss: 0.09279121458530426, Dice_loss: 0.009029929526150227, Consistency_loss: 0.0007991960155777633\n",
      "[Training] Epoch: 22 [=====>         ] 34.9% Loss: 0.0748, Epoch 22, Batch 43, CE_loss: 0.05821583792567253, Dice_loss: 0.005090837366878986, Consistency_loss: 0.00038451675209216774\n",
      "[Training] Epoch: 22 [=====>         ] 35.7% Loss: 0.0744, Epoch 22, Batch 44, CE_loss: 0.05189359188079834, Dice_loss: 0.0043022409081459045, Consistency_loss: 0.00044209492625668645\n",
      "[Training] Epoch: 22 [=====>         ] 36.5% Loss: 0.0741, Epoch 22, Batch 45, CE_loss: 0.05856863781809807, Dice_loss: 0.005000326316803694, Consistency_loss: 0.00034546953975223005\n",
      "[Training] Epoch: 22 [=====>         ] 37.3% Loss: 0.0741, Epoch 22, Batch 46, CE_loss: 0.06672584265470505, Dice_loss: 0.006407717242836952, Consistency_loss: 0.00033311464358121157\n",
      "[Training] Epoch: 22 [=====>         ] 38.1% Loss: 0.0739, Epoch 22, Batch 47, CE_loss: 0.060291923582553864, Dice_loss: 0.005306182894855738, Consistency_loss: 0.00020564952865242958\n",
      "[Training] Epoch: 22 [=====>         ] 38.9% Loss: 0.0736, Epoch 22, Batch 48, CE_loss: 0.05328381434082985, Dice_loss: 0.004221439361572266, Consistency_loss: 0.0007409010431729257\n",
      "[Training] Epoch: 22 [=====>         ] 39.7% Loss: 0.0735, Epoch 22, Batch 49, CE_loss: 0.061254795640707016, Dice_loss: 0.005224107299000025, Consistency_loss: 0.0004926410038024187\n",
      "[Training] Epoch: 22 [======>        ] 40.5% Loss: 0.0732, Epoch 22, Batch 50, CE_loss: 0.05310126021504402, Dice_loss: 0.004569049458950758, Consistency_loss: 0.00018581286713015288\n",
      "[Training] Epoch: 22 [======>        ] 41.3% Loss: 0.0730, Epoch 22, Batch 51, CE_loss: 0.056370098143815994, Dice_loss: 0.004885259550064802, Consistency_loss: 0.0009399425471201539\n",
      "[Training] Epoch: 22 [======>        ] 42.1% Loss: 0.0727, Epoch 22, Batch 52, CE_loss: 0.053682439029216766, Dice_loss: 0.004671554546803236, Consistency_loss: 0.00010656454833224416\n",
      "[Training] Epoch: 22 [======>        ] 42.9% Loss: 0.0728, Epoch 22, Batch 53, CE_loss: 0.07084251940250397, Dice_loss: 0.006247642915695906, Consistency_loss: 0.0001854974398156628\n",
      "[Training] Epoch: 22 [======>        ] 43.7% Loss: 0.0726, Epoch 22, Batch 54, CE_loss: 0.05541751906275749, Dice_loss: 0.004762713797390461, Consistency_loss: 0.0008966819732449949\n",
      "[Training] Epoch: 22 [======>        ] 44.4% Loss: 0.0727, Epoch 22, Batch 55, CE_loss: 0.07252229005098343, Dice_loss: 0.006778845563530922, Consistency_loss: 0.0003641842631623149\n",
      "[Training] Epoch: 22 [======>        ] 45.2% Loss: 0.0728, Epoch 22, Batch 56, CE_loss: 0.07008444517850876, Dice_loss: 0.006659460254013538, Consistency_loss: 0.00031685104477219284\n",
      "[Training] Epoch: 22 [======>        ] 46.0% Loss: 0.0726, Epoch 22, Batch 57, CE_loss: 0.0594949945807457, Dice_loss: 0.005464911460876465, Consistency_loss: 0.00039699027547612786\n",
      "[Training] Epoch: 22 [=======>       ] 46.8% Loss: 0.0729, Epoch 22, Batch 58, CE_loss: 0.07750684022903442, Dice_loss: 0.007469237316399813, Consistency_loss: 0.0004602307453751564\n",
      "[Training] Epoch: 22 [=======>       ] 47.6% Loss: 0.0729, Epoch 22, Batch 59, CE_loss: 0.06605572998523712, Dice_loss: 0.006200708914548159, Consistency_loss: 0.0001234958035638556\n",
      "[Training] Epoch: 22 [=======>       ] 48.4% Loss: 0.0728, Epoch 22, Batch 60, CE_loss: 0.0659981220960617, Dice_loss: 0.006267504766583443, Consistency_loss: 0.0004311641678214073\n",
      "[Training] Epoch: 22 [=======>       ] 49.2% Loss: 0.0732, Epoch 22, Batch 61, CE_loss: 0.08709979802370071, Dice_loss: 0.008749620988965034, Consistency_loss: 0.0004750276857521385\n",
      "[Training] Epoch: 22 [=======>       ] 50.0% Loss: 0.0732, Epoch 22, Batch 62, CE_loss: 0.06602887809276581, Dice_loss: 0.006040089298039675, Consistency_loss: 0.0006029855576343834\n",
      "[Training] Epoch: 22 [=======>       ] 50.8% Loss: 0.0731, Epoch 22, Batch 63, CE_loss: 0.06175617501139641, Dice_loss: 0.005649134516716003, Consistency_loss: 0.0006609167321585119\n",
      "[Training] Epoch: 22 [=======>       ] 51.6% Loss: 0.0731, Epoch 22, Batch 64, CE_loss: 0.06163572520017624, Dice_loss: 0.005534644704312086, Consistency_loss: 0.0006371721974574029\n",
      "[Training] Epoch: 22 [=======>       ] 52.4% Loss: 0.0730, Epoch 22, Batch 65, CE_loss: 0.06300393491983414, Dice_loss: 0.0055139511823654175, Consistency_loss: 0.0006897532730363309\n",
      "[Training] Epoch: 22 [=======>       ] 53.2% Loss: 0.0728, Epoch 22, Batch 66, CE_loss: 0.0561879500746727, Dice_loss: 0.00476877111941576, Consistency_loss: 0.0002562470326665789\n",
      "[Training] Epoch: 22 [========>      ] 54.0% Loss: 0.0728, Epoch 22, Batch 67, CE_loss: 0.06708049029111862, Dice_loss: 0.006190891843289137, Consistency_loss: 6.324894638964906e-05\n",
      "[Training] Epoch: 22 [========>      ] 54.8% Loss: 0.0727, Epoch 22, Batch 68, CE_loss: 0.05749903991818428, Dice_loss: 0.005140569992363453, Consistency_loss: 0.0002007986477110535\n",
      "[Training] Epoch: 22 [========>      ] 55.6% Loss: 0.0730, Epoch 22, Batch 69, CE_loss: 0.08629318326711655, Dice_loss: 0.008168578147888184, Consistency_loss: 0.0002854682388715446\n",
      "[Training] Epoch: 22 [========>      ] 56.3% Loss: 0.0729, Epoch 22, Batch 70, CE_loss: 0.058933861553668976, Dice_loss: 0.00498808640986681, Consistency_loss: 0.00010389094677520916\n",
      "[Training] Epoch: 22 [========>      ] 57.1% Loss: 0.0726, Epoch 22, Batch 71, CE_loss: 0.045672688633203506, Dice_loss: 0.0035286250058561563, Consistency_loss: 0.0006233285530470312\n",
      "[Training] Epoch: 22 [========>      ] 57.9% Loss: 0.0728, Epoch 22, Batch 72, CE_loss: 0.0804985910654068, Dice_loss: 0.008046824485063553, Consistency_loss: 0.00043473043479025364\n",
      "[Training] Epoch: 22 [========>      ] 58.7% Loss: 0.0729, Epoch 22, Batch 73, CE_loss: 0.07081907242536545, Dice_loss: 0.006798367481678724, Consistency_loss: 0.0005641750758513808\n",
      "[Training] Epoch: 22 [========>      ] 59.5% Loss: 0.0730, Epoch 22, Batch 74, CE_loss: 0.07669387757778168, Dice_loss: 0.006746632046997547, Consistency_loss: 0.0005536260432563722\n",
      "[Training] Epoch: 22 [=========>     ] 60.3% Loss: 0.0729, Epoch 22, Batch 75, CE_loss: 0.06198439002037048, Dice_loss: 0.005874815862625837, Consistency_loss: 0.0006171264103613794\n",
      "[Training] Epoch: 22 [=========>     ] 61.1% Loss: 0.0729, Epoch 22, Batch 76, CE_loss: 0.06203470379114151, Dice_loss: 0.005820469930768013, Consistency_loss: 9.658702037995681e-05\n",
      "[Training] Epoch: 22 [=========>     ] 61.9% Loss: 0.0729, Epoch 22, Batch 77, CE_loss: 0.06552068889141083, Dice_loss: 0.006220427341759205, Consistency_loss: 0.0006347544840537012\n",
      "[Training] Epoch: 22 [=========>     ] 62.7% Loss: 0.0731, Epoch 22, Batch 78, CE_loss: 0.07980974018573761, Dice_loss: 0.008245646953582764, Consistency_loss: 0.0004256970714777708\n",
      "[Training] Epoch: 22 [=========>     ] 63.5% Loss: 0.0731, Epoch 22, Batch 79, CE_loss: 0.06574543565511703, Dice_loss: 0.005981965456157923, Consistency_loss: 0.00046573817962780595\n",
      "[Training] Epoch: 22 [=========>     ] 64.3% Loss: 0.0730, Epoch 22, Batch 80, CE_loss: 0.06406325846910477, Dice_loss: 0.0060834335163235664, Consistency_loss: 0.00016471375420223922\n",
      "[Training] Epoch: 22 [=========>     ] 65.1% Loss: 0.0728, Epoch 22, Batch 81, CE_loss: 0.04669189453125, Dice_loss: 0.0035857066977769136, Consistency_loss: 0.0007411555270664394\n",
      "[Training] Epoch: 22 [=========>     ] 65.9% Loss: 0.0729, Epoch 22, Batch 82, CE_loss: 0.07730724662542343, Dice_loss: 0.007900205440819263, Consistency_loss: 0.000673299131449312\n",
      "[Training] Epoch: 22 [==========>    ] 66.7% Loss: 0.0729, Epoch 22, Batch 83, CE_loss: 0.061631035059690475, Dice_loss: 0.005811376962810755, Consistency_loss: 0.00030427760793827474\n",
      "[Training] Epoch: 22 [==========>    ] 67.5% Loss: 0.0731, Epoch 22, Batch 84, CE_loss: 0.08832645416259766, Dice_loss: 0.00832714606076479, Consistency_loss: 8.35944592836313e-05\n",
      "[Training] Epoch: 22 [==========>    ] 68.3% Loss: 0.0733, Epoch 22, Batch 85, CE_loss: 0.08172572404146194, Dice_loss: 0.008094473741948605, Consistency_loss: 0.00011102082498837262\n",
      "[Training] Epoch: 22 [==========>    ] 69.0% Loss: 0.0734, Epoch 22, Batch 86, CE_loss: 0.07460001856088638, Dice_loss: 0.006934033706784248, Consistency_loss: 0.0005468931049108505\n",
      "[Training] Epoch: 22 [==========>    ] 69.8% Loss: 0.0734, Epoch 22, Batch 87, CE_loss: 0.06229507550597191, Dice_loss: 0.005529968533664942, Consistency_loss: 0.00039436185033991933\n",
      "[Training] Epoch: 22 [==========>    ] 70.6% Loss: 0.0732, Epoch 22, Batch 88, CE_loss: 0.053693655878305435, Dice_loss: 0.004626292269676924, Consistency_loss: 0.0004240740672685206\n",
      "[Training] Epoch: 22 [==========>    ] 71.4% Loss: 0.0732, Epoch 22, Batch 89, CE_loss: 0.06833471357822418, Dice_loss: 0.0056698680855333805, Consistency_loss: 0.00013964984100311995\n",
      "[Training] Epoch: 22 [==========>    ] 72.2% Loss: 0.0732, Epoch 22, Batch 90, CE_loss: 0.06674988567829132, Dice_loss: 0.006173926871269941, Consistency_loss: 0.00037373774102889\n",
      "[Training] Epoch: 22 [==========>    ] 73.0% Loss: 0.0730, Epoch 22, Batch 91, CE_loss: 0.050364281982183456, Dice_loss: 0.004226021468639374, Consistency_loss: 0.000136028669658117\n",
      "[Training] Epoch: 22 [===========>   ] 73.8% Loss: 0.0729, Epoch 22, Batch 92, CE_loss: 0.055526282638311386, Dice_loss: 0.004702940583229065, Consistency_loss: 0.0005658245063386858\n",
      "[Training] Epoch: 22 [===========>   ] 74.6% Loss: 0.0730, Epoch 22, Batch 93, CE_loss: 0.07342315465211868, Dice_loss: 0.00690833805128932, Consistency_loss: 0.0005602290038950741\n",
      "[Training] Epoch: 22 [===========>   ] 75.4% Loss: 0.0729, Epoch 22, Batch 94, CE_loss: 0.05879729613661766, Dice_loss: 0.005388629622757435, Consistency_loss: 0.0004145338316448033\n",
      "[Training] Epoch: 22 [===========>   ] 76.2% Loss: 0.0728, Epoch 22, Batch 95, CE_loss: 0.05763806402683258, Dice_loss: 0.0048437342047691345, Consistency_loss: 0.0005837823264300823\n",
      "[Training] Epoch: 22 [===========>   ] 77.0% Loss: 0.0727, Epoch 22, Batch 96, CE_loss: 0.0614854171872139, Dice_loss: 0.005476628430187702, Consistency_loss: 0.0001407246309099719\n",
      "[Training] Epoch: 22 [===========>   ] 77.8% Loss: 0.0728, Epoch 22, Batch 97, CE_loss: 0.07228482514619827, Dice_loss: 0.0069240243174135685, Consistency_loss: 0.0004432186542544514\n",
      "[Training] Epoch: 22 [===========>   ] 78.6% Loss: 0.0727, Epoch 22, Batch 98, CE_loss: 0.06092657148838043, Dice_loss: 0.0051152631640434265, Consistency_loss: 0.00035429614945314825\n",
      "[Training] Epoch: 22 [===========>   ] 79.4% Loss: 0.0729, Epoch 22, Batch 99, CE_loss: 0.07921517640352249, Dice_loss: 0.008160553872585297, Consistency_loss: 0.0003146692761220038\n",
      "[Training] Epoch: 22 [============>  ] 80.2% Loss: 0.0729, Epoch 22, Batch 100, CE_loss: 0.06931234896183014, Dice_loss: 0.006798819173127413, Consistency_loss: 7.701178401475772e-05\n",
      "[Training] Epoch: 22 [============>  ] 81.0% Loss: 0.0728, Epoch 22, Batch 101, CE_loss: 0.052584510296583176, Dice_loss: 0.004314851947128773, Consistency_loss: 0.0006150942645035684\n",
      "[Training] Epoch: 22 [============>  ] 81.7% Loss: 0.0728, Epoch 22, Batch 102, CE_loss: 0.07302289456129074, Dice_loss: 0.006771134212613106, Consistency_loss: 0.0006407582550309598\n",
      "[Training] Epoch: 22 [============>  ] 82.5% Loss: 0.0730, Epoch 22, Batch 103, CE_loss: 0.07861911505460739, Dice_loss: 0.00779597507789731, Consistency_loss: 0.0006920090527273715\n",
      "[Training] Epoch: 22 [============>  ] 83.3% Loss: 0.0728, Epoch 22, Batch 104, CE_loss: 0.055173132568597794, Dice_loss: 0.004696923773735762, Consistency_loss: 0.0003887107304763049\n",
      "[Training] Epoch: 22 [============>  ] 84.1% Loss: 0.0728, Epoch 22, Batch 105, CE_loss: 0.06544291228055954, Dice_loss: 0.006062816362828016, Consistency_loss: 0.00044329316006042063\n",
      "[Training] Epoch: 22 [============>  ] 84.9% Loss: 0.0728, Epoch 22, Batch 106, CE_loss: 0.061820369213819504, Dice_loss: 0.005509736016392708, Consistency_loss: 0.0006208010017871857\n",
      "[Training] Epoch: 22 [============>  ] 85.7% Loss: 0.0729, Epoch 22, Batch 107, CE_loss: 0.07284481823444366, Dice_loss: 0.006490928120911121, Consistency_loss: 6.681579543510452e-05\n",
      "[Training] Epoch: 22 [============>  ] 86.5% Loss: 0.0728, Epoch 22, Batch 108, CE_loss: 0.060642678290605545, Dice_loss: 0.0056040287017822266, Consistency_loss: 0.0003490768722258508\n",
      "[Training] Epoch: 22 [=============> ] 87.3% Loss: 0.0729, Epoch 22, Batch 109, CE_loss: 0.07808570563793182, Dice_loss: 0.0076000262051820755, Consistency_loss: 0.00020408850105013698\n",
      "[Training] Epoch: 22 [=============> ] 88.1% Loss: 0.0729, Epoch 22, Batch 110, CE_loss: 0.06106169521808624, Dice_loss: 0.005350962281227112, Consistency_loss: 4.5198183215688914e-05\n",
      "[Training] Epoch: 22 [=============> ] 88.9% Loss: 0.0729, Epoch 22, Batch 111, CE_loss: 0.06618677079677582, Dice_loss: 0.005973029416054487, Consistency_loss: 0.00039183811168186367\n",
      "[Training] Epoch: 22 [=============> ] 89.7% Loss: 0.0727, Epoch 22, Batch 112, CE_loss: 0.04621262103319168, Dice_loss: 0.003443643683567643, Consistency_loss: 0.00012006586621282622\n",
      "[Training] Epoch: 22 [=============> ] 90.5% Loss: 0.0727, Epoch 22, Batch 113, CE_loss: 0.06923709064722061, Dice_loss: 0.0064652906730771065, Consistency_loss: 0.0001851249544415623\n",
      "[Training] Epoch: 22 [=============> ] 91.3% Loss: 0.0727, Epoch 22, Batch 114, CE_loss: 0.07117144018411636, Dice_loss: 0.006720878649502993, Consistency_loss: 0.00045492537901736796\n",
      "[Training] Epoch: 22 [=============> ] 92.1% Loss: 0.0730, Epoch 22, Batch 115, CE_loss: 0.09132466465234756, Dice_loss: 0.008516720496118069, Consistency_loss: 0.00035531417233869433\n",
      "[Training] Epoch: 22 [=============> ] 92.9% Loss: 0.0731, Epoch 22, Batch 116, CE_loss: 0.08527150750160217, Dice_loss: 0.008185865357518196, Consistency_loss: 0.0005433968035504222\n",
      "[Training] Epoch: 22 [==============>] 93.7% Loss: 0.0731, Epoch 22, Batch 117, CE_loss: 0.05977144464850426, Dice_loss: 0.005607917904853821, Consistency_loss: 0.000470387953100726\n",
      "[Training] Epoch: 22 [==============>] 94.4% Loss: 0.0731, Epoch 22, Batch 118, CE_loss: 0.0698757916688919, Dice_loss: 0.006725737825036049, Consistency_loss: 0.00034379796124994755\n",
      "[Training] Epoch: 22 [==============>] 95.2% Loss: 0.0732, Epoch 22, Batch 119, CE_loss: 0.07712358981370926, Dice_loss: 0.007526296656578779, Consistency_loss: 0.00034184809192083776\n",
      "[Training] Epoch: 22 [==============>] 96.0% Loss: 0.0730, Epoch 22, Batch 120, CE_loss: 0.047639425843954086, Dice_loss: 0.0038374767173081636, Consistency_loss: 0.0003595353045966476\n",
      "[Training] Epoch: 22 [==============>] 96.8% Loss: 0.0730, Epoch 22, Batch 121, CE_loss: 0.058478452265262604, Dice_loss: 0.0053712353110313416, Consistency_loss: 0.0003828647022601217\n",
      "[Training] Epoch: 22 [==============>] 97.6% Loss: 0.0730, Epoch 22, Batch 122, CE_loss: 0.06616261601448059, Dice_loss: 0.006379008758813143, Consistency_loss: 0.0001365909556625411\n",
      "[Training] Epoch: 22 [==============>] 98.4% Loss: 0.0729, Epoch 22, Batch 123, CE_loss: 0.06181430071592331, Dice_loss: 0.005492118187248707, Consistency_loss: 0.0006481882883235812\n",
      "[Training] Epoch: 22 [==============>] 99.2% Loss: 0.0728, Epoch 22, Batch 124, CE_loss: 0.05626332759857178, Dice_loss: 0.004589090123772621, Consistency_loss: 0.0006759531679563224\n",
      "[Training] Epoch: 22 [DONE]                                 \n",
      "Epoch 22, Batch 125, CE_loss: 0.060313403606414795, Dice_loss: 0.005667395889759064, Consistency_loss: 0.0005951942293904722\n",
      "[Validation] Epoch: 22 [DONE]                                 \n",
      "[Epoch: 22, TrainLoss: 0.0728, TrainDice: 0.0061, ValLoss: 0.1266                                            \n",
      "Number of batches:  126\n",
      "[Training] Epoch: 23 [>              ] 0.8% Loss: 0.0826, Epoch 23, Batch 0, CE_loss: 0.07478378713130951, Dice_loss: 0.007364827673882246, Consistency_loss: 0.0004704625753220171\n",
      "[Training] Epoch: 23 [>              ] 1.6% Loss: 0.0731, Epoch 23, Batch 1, CE_loss: 0.05833815783262253, Dice_loss: 0.005104159004986286, Consistency_loss: 0.00017093768110498786\n",
      "[Training] Epoch: 23 [>              ] 2.4% Loss: 0.0664, Epoch 23, Batch 2, CE_loss: 0.04877237230539322, Dice_loss: 0.0038910985458642244, Consistency_loss: 0.00033106841146945953\n",
      "[Training] Epoch: 23 [>              ] 3.2% Loss: 0.0663, Epoch 23, Batch 3, CE_loss: 0.06030263006687164, Dice_loss: 0.005388102028518915, Consistency_loss: 0.0002135398390237242\n",
      "[Training] Epoch: 23 [>              ] 4.0% Loss: 0.0668, Epoch 23, Batch 4, CE_loss: 0.06260169297456741, Dice_loss: 0.005879411473870277, Consistency_loss: 0.0005623276229016483\n",
      "[Training] Epoch: 23 [>              ] 4.8% Loss: 0.0650, Epoch 23, Batch 5, CE_loss: 0.051236752420663834, Dice_loss: 0.004292821977287531, Consistency_loss: 0.00015811090997885913\n",
      "[Training] Epoch: 23 [>              ] 5.6% Loss: 0.0641, Epoch 23, Batch 6, CE_loss: 0.054039131850004196, Dice_loss: 0.0047095525078475475, Consistency_loss: 0.0001963245013030246\n",
      "[Training] Epoch: 23 [>              ] 6.3% Loss: 0.0691, Epoch 23, Batch 7, CE_loss: 0.09395743161439896, Dice_loss: 0.00959824025630951, Consistency_loss: 0.0002678964228834957\n",
      "[Training] Epoch: 23 [=>             ] 7.1% Loss: 0.0677, Epoch 23, Batch 8, CE_loss: 0.05183710902929306, Dice_loss: 0.004418327007442713, Consistency_loss: 3.4763990697683766e-05\n",
      "[Training] Epoch: 23 [=>             ] 7.9% Loss: 0.0686, Epoch 23, Batch 9, CE_loss: 0.07048644870519638, Dice_loss: 0.006500329356640577, Consistency_loss: 7.144530536606908e-05\n",
      "[Training] Epoch: 23 [=>             ] 8.7% Loss: 0.0704, Epoch 23, Batch 10, CE_loss: 0.08008992671966553, Dice_loss: 0.008124643936753273, Consistency_loss: 0.0006130848196335137\n",
      "[Training] Epoch: 23 [=>             ] 9.5% Loss: 0.0701, Epoch 23, Batch 11, CE_loss: 0.06082511320710182, Dice_loss: 0.005565722472965717, Consistency_loss: 0.000539055501576513\n",
      "[Training] Epoch: 23 [=>             ] 10.3% Loss: 0.0695, Epoch 23, Batch 12, CE_loss: 0.05551372841000557, Dice_loss: 0.005102674942463636, Consistency_loss: 0.0005575146642513573\n",
      "[Training] Epoch: 23 [=>             ] 11.1% Loss: 0.0685, Epoch 23, Batch 13, CE_loss: 0.05144626647233963, Dice_loss: 0.0043621123768389225, Consistency_loss: 0.0005898985546082258\n",
      "[Training] Epoch: 23 [=>             ] 11.9% Loss: 0.0680, Epoch 23, Batch 14, CE_loss: 0.05565493181347847, Dice_loss: 0.004753129556775093, Consistency_loss: 7.319718133658171e-05\n",
      "[Training] Epoch: 23 [=>             ] 12.7% Loss: 0.0700, Epoch 23, Batch 15, CE_loss: 0.09069192409515381, Dice_loss: 0.009177683852612972, Consistency_loss: 0.0002560157736297697\n",
      "[Training] Epoch: 23 [==>            ] 13.5% Loss: 0.0694, Epoch 23, Batch 16, CE_loss: 0.05375462397933006, Dice_loss: 0.004812759347259998, Consistency_loss: 0.0006339767132885754\n",
      "[Training] Epoch: 23 [==>            ] 14.3% Loss: 0.0701, Epoch 23, Batch 17, CE_loss: 0.0750725120306015, Dice_loss: 0.007463242392987013, Consistency_loss: 0.0004133188631385565\n",
      "[Training] Epoch: 23 [==>            ] 15.1% Loss: 0.0709, Epoch 23, Batch 18, CE_loss: 0.07744821906089783, Dice_loss: 0.007930089719593525, Consistency_loss: 0.0005484443390741944\n",
      "[Training] Epoch: 23 [==>            ] 15.9% Loss: 0.0701, Epoch 23, Batch 19, CE_loss: 0.04875095188617706, Dice_loss: 0.004073917865753174, Consistency_loss: 0.00030539455474354327\n",
      "[Training] Epoch: 23 [==>            ] 16.7% Loss: 0.0703, Epoch 23, Batch 20, CE_loss: 0.06909230351448059, Dice_loss: 0.0066464738920331, Consistency_loss: 6.664197280770168e-05\n",
      "[Training] Epoch: 23 [==>            ] 17.5% Loss: 0.0707, Epoch 23, Batch 21, CE_loss: 0.07121027261018753, Dice_loss: 0.006808792240917683, Consistency_loss: 0.00030723874806426466\n",
      "[Training] Epoch: 23 [==>            ] 18.3% Loss: 0.0701, Epoch 23, Batch 22, CE_loss: 0.05234641954302788, Dice_loss: 0.004485775716602802, Consistency_loss: 0.0002970519126392901\n",
      "[Training] Epoch: 23 [==>            ] 19.0% Loss: 0.0711, Epoch 23, Batch 23, CE_loss: 0.084964819252491, Dice_loss: 0.008688404224812984, Consistency_loss: 0.000466115860035643\n",
      "[Training] Epoch: 23 [==>            ] 19.8% Loss: 0.0712, Epoch 23, Batch 24, CE_loss: 0.06858101487159729, Dice_loss: 0.005518381483852863, Consistency_loss: 0.00019417832663748413\n",
      "[Training] Epoch: 23 [===>           ] 20.6% Loss: 0.0713, Epoch 23, Batch 25, CE_loss: 0.06667269766330719, Dice_loss: 0.006061783526092768, Consistency_loss: 0.0006073326803743839\n",
      "[Training] Epoch: 23 [===>           ] 21.4% Loss: 0.0710, Epoch 23, Batch 26, CE_loss: 0.056048713624477386, Dice_loss: 0.004947870969772339, Consistency_loss: 0.0005320375203154981\n",
      "[Training] Epoch: 23 [===>           ] 22.2% Loss: 0.0716, Epoch 23, Batch 27, CE_loss: 0.08065623790025711, Dice_loss: 0.008242969401180744, Consistency_loss: 0.0005938920076005161\n",
      "[Training] Epoch: 23 [===>           ] 23.0% Loss: 0.0712, Epoch 23, Batch 28, CE_loss: 0.05544218048453331, Dice_loss: 0.004336868412792683, Consistency_loss: 0.0002581717853900045\n",
      "[Training] Epoch: 23 [===>           ] 23.8% Loss: 0.0711, Epoch 23, Batch 29, CE_loss: 0.06291525065898895, Dice_loss: 0.005747973918914795, Consistency_loss: 0.0005443519330583513\n",
      "[Training] Epoch: 23 [===>           ] 24.6% Loss: 0.0713, Epoch 23, Batch 30, CE_loss: 0.06950600445270538, Dice_loss: 0.006549561396241188, Consistency_loss: 0.0007667187019251287\n",
      "[Training] Epoch: 23 [===>           ] 25.4% Loss: 0.0711, Epoch 23, Batch 31, CE_loss: 0.05869486182928085, Dice_loss: 0.005367203149944544, Consistency_loss: 0.00014478745288215578\n",
      "[Training] Epoch: 23 [===>           ] 26.2% Loss: 0.0707, Epoch 23, Batch 32, CE_loss: 0.05155167728662491, Dice_loss: 0.004212623927742243, Consistency_loss: 0.0002633212134242058\n",
      "[Training] Epoch: 23 [====>          ] 27.0% Loss: 0.0701, Epoch 23, Batch 33, CE_loss: 0.04869939759373665, Dice_loss: 0.003918524365872145, Consistency_loss: 0.0003162998182233423\n",
      "[Training] Epoch: 23 [====>          ] 27.8% Loss: 0.0701, Epoch 23, Batch 34, CE_loss: 0.0629609152674675, Dice_loss: 0.005956989713013172, Consistency_loss: 0.0006319463718682528\n",
      "[Training] Epoch: 23 [====>          ] 28.6% Loss: 0.0701, Epoch 23, Batch 35, CE_loss: 0.06278161704540253, Dice_loss: 0.005598557181656361, Consistency_loss: 0.00020955040236003697\n",
      "[Training] Epoch: 23 [====>          ] 29.4% Loss: 0.0701, Epoch 23, Batch 36, CE_loss: 0.06357941776514053, Dice_loss: 0.005757773295044899, Consistency_loss: 0.00025080351042561233\n",
      "[Training] Epoch: 23 [====>          ] 30.2% Loss: 0.0700, Epoch 23, Batch 37, CE_loss: 0.06251160800457001, Dice_loss: 0.0057901786640286446, Consistency_loss: 0.00039200717583298683\n",
      "[Training] Epoch: 23 [====>          ] 31.0% Loss: 0.0699, Epoch 23, Batch 38, CE_loss: 0.05991068854928017, Dice_loss: 0.005334203131496906, Consistency_loss: 0.0007813018164597452\n",
      "[Training] Epoch: 23 [====>          ] 31.7% Loss: 0.0699, Epoch 23, Batch 39, CE_loss: 0.0641145408153534, Dice_loss: 0.006153743248432875, Consistency_loss: 0.0007864332874305546\n",
      "[Training] Epoch: 23 [====>          ] 32.5% Loss: 0.0701, Epoch 23, Batch 40, CE_loss: 0.06900277733802795, Dice_loss: 0.006830831058323383, Consistency_loss: 0.0005858919466845691\n",
      "[Training] Epoch: 23 [=====>         ] 33.3% Loss: 0.0700, Epoch 23, Batch 41, CE_loss: 0.06129513308405876, Dice_loss: 0.005723539274185896, Consistency_loss: 0.00010588904842734337\n",
      "[Training] Epoch: 23 [=====>         ] 34.1% Loss: 0.0702, Epoch 23, Batch 42, CE_loss: 0.06786353886127472, Dice_loss: 0.0068467590026557446, Consistency_loss: 0.0007093957392498851\n",
      "[Training] Epoch: 23 [=====>         ] 34.9% Loss: 0.0699, Epoch 23, Batch 43, CE_loss: 0.054178137332201004, Dice_loss: 0.004361468832939863, Consistency_loss: 0.00017070017929654568\n",
      "[Training] Epoch: 23 [=====>         ] 35.7% Loss: 0.0701, Epoch 23, Batch 44, CE_loss: 0.07130947709083557, Dice_loss: 0.006969724781811237, Consistency_loss: 0.000161477699293755\n",
      "[Training] Epoch: 23 [=====>         ] 36.5% Loss: 0.0701, Epoch 23, Batch 45, CE_loss: 0.06435737013816833, Dice_loss: 0.006082070060074329, Consistency_loss: 0.00018763575644697994\n",
      "[Training] Epoch: 23 [=====>         ] 37.3% Loss: 0.0704, Epoch 23, Batch 46, CE_loss: 0.0762501060962677, Dice_loss: 0.007572005968540907, Consistency_loss: 3.132842175546102e-05\n",
      "[Training] Epoch: 23 [=====>         ] 38.1% Loss: 0.0707, Epoch 23, Batch 47, CE_loss: 0.07516098767518997, Dice_loss: 0.007625279016792774, Consistency_loss: 0.000490805774461478\n",
      "[Training] Epoch: 23 [=====>         ] 38.9% Loss: 0.0703, Epoch 23, Batch 48, CE_loss: 0.04992828518152237, Dice_loss: 0.004204206168651581, Consistency_loss: 0.0009617848554626107\n",
      "[Training] Epoch: 23 [=====>         ] 39.7% Loss: 0.0702, Epoch 23, Batch 49, CE_loss: 0.05785636603832245, Dice_loss: 0.005457736551761627, Consistency_loss: 0.0005621413583867252\n",
      "[Training] Epoch: 23 [======>        ] 40.5% Loss: 0.0704, Epoch 23, Batch 50, CE_loss: 0.07020159810781479, Dice_loss: 0.007100907154381275, Consistency_loss: 0.0006652746233157814\n",
      "[Training] Epoch: 23 [======>        ] 41.3% Loss: 0.0700, Epoch 23, Batch 51, CE_loss: 0.04798230528831482, Dice_loss: 0.0038106145802885294, Consistency_loss: 0.0006852343212813139\n",
      "[Training] Epoch: 23 [======>        ] 42.1% Loss: 0.0701, Epoch 23, Batch 52, CE_loss: 0.06654087454080582, Dice_loss: 0.006467923987656832, Consistency_loss: 0.00012633878213819116\n",
      "[Training] Epoch: 23 [======>        ] 42.9% Loss: 0.0702, Epoch 23, Batch 53, CE_loss: 0.07139377295970917, Dice_loss: 0.0067267571575939655, Consistency_loss: 5.392341336118989e-05\n",
      "[Training] Epoch: 23 [======>        ] 43.7% Loss: 0.0702, Epoch 23, Batch 54, CE_loss: 0.06268934905529022, Dice_loss: 0.006080416031181812, Consistency_loss: 0.00040903204353526235\n",
      "[Training] Epoch: 23 [======>        ] 44.4% Loss: 0.0705, Epoch 23, Batch 55, CE_loss: 0.0789172574877739, Dice_loss: 0.008027655072510242, Consistency_loss: 0.0004600873216986656\n",
      "[Training] Epoch: 23 [======>        ] 45.2% Loss: 0.0705, Epoch 23, Batch 56, CE_loss: 0.060899730771780014, Dice_loss: 0.005719296634197235, Consistency_loss: 0.00044541372335515916\n",
      "[Training] Epoch: 23 [======>        ] 46.0% Loss: 0.0705, Epoch 23, Batch 57, CE_loss: 0.06596256792545319, Dice_loss: 0.0062842415645718575, Consistency_loss: 0.0003871172957587987\n",
      "[Training] Epoch: 23 [=======>       ] 46.8% Loss: 0.0705, Epoch 23, Batch 58, CE_loss: 0.06569572538137436, Dice_loss: 0.005949640646576881, Consistency_loss: 0.00013606173160951585\n",
      "[Training] Epoch: 23 [=======>       ] 47.6% Loss: 0.0708, Epoch 23, Batch 59, CE_loss: 0.07806287705898285, Dice_loss: 0.007790713105350733, Consistency_loss: 0.0005160031723789871\n",
      "[Training] Epoch: 23 [=======>       ] 48.4% Loss: 0.0708, Epoch 23, Batch 60, CE_loss: 0.06344200670719147, Dice_loss: 0.00590120442211628, Consistency_loss: 0.00018258774071000516\n",
      "[Training] Epoch: 23 [=======>       ] 49.2% Loss: 0.0707, Epoch 23, Batch 61, CE_loss: 0.058379750698804855, Dice_loss: 0.005513522308319807, Consistency_loss: 0.0005700270994566381\n",
      "[Training] Epoch: 23 [=======>       ] 50.0% Loss: 0.0707, Epoch 23, Batch 62, CE_loss: 0.06661853194236755, Dice_loss: 0.006300334818661213, Consistency_loss: 0.00041754962876439095\n",
      "[Training] Epoch: 23 [=======>       ] 50.8% Loss: 0.0705, Epoch 23, Batch 63, CE_loss: 0.05037454143166542, Dice_loss: 0.00424490449950099, Consistency_loss: 0.0009255042532458901\n",
      "[Training] Epoch: 23 [=======>       ] 51.6% Loss: 0.0703, Epoch 23, Batch 64, CE_loss: 0.05250481516122818, Dice_loss: 0.00472648162394762, Consistency_loss: 0.0006077284342609346\n",
      "[Training] Epoch: 23 [=======>       ] 52.4% Loss: 0.0701, Epoch 23, Batch 65, CE_loss: 0.051437798887491226, Dice_loss: 0.004286241717636585, Consistency_loss: 0.0006216386682353914\n",
      "[Training] Epoch: 23 [=======>       ] 53.2% Loss: 0.0699, Epoch 23, Batch 66, CE_loss: 0.05290727689862251, Dice_loss: 0.004790666978806257, Consistency_loss: 6.491186650237069e-05\n",
      "[Training] Epoch: 23 [========>      ] 54.0% Loss: 0.0699, Epoch 23, Batch 67, CE_loss: 0.06780581921339035, Dice_loss: 0.006789806764572859, Consistency_loss: 0.00012092816177755594\n",
      "[Training] Epoch: 23 [========>      ] 54.8% Loss: 0.0697, Epoch 23, Batch 68, CE_loss: 0.04886465519666672, Dice_loss: 0.004260671325027943, Consistency_loss: 5.8701931266114116e-05\n",
      "[Training] Epoch: 23 [========>      ] 55.6% Loss: 0.0697, Epoch 23, Batch 69, CE_loss: 0.06105596572160721, Dice_loss: 0.005757938604801893, Consistency_loss: 0.00023046480782795697\n",
      "[Training] Epoch: 23 [========>      ] 56.3% Loss: 0.0699, Epoch 23, Batch 70, CE_loss: 0.07755155116319656, Dice_loss: 0.007588197477161884, Consistency_loss: 0.0007051764405332506\n",
      "[Training] Epoch: 23 [========>      ] 57.1% Loss: 0.0699, Epoch 23, Batch 71, CE_loss: 0.06411914527416229, Dice_loss: 0.006201670039445162, Consistency_loss: 0.0005709677352569997\n",
      "[Training] Epoch: 23 [========>      ] 57.9% Loss: 0.0700, Epoch 23, Batch 72, CE_loss: 0.06720222532749176, Dice_loss: 0.0066018421202898026, Consistency_loss: 0.0005956710665486753\n",
      "[Training] Epoch: 23 [========>      ] 58.7% Loss: 0.0700, Epoch 23, Batch 73, CE_loss: 0.0665217787027359, Dice_loss: 0.005693610291928053, Consistency_loss: 0.00039385963464155793\n",
      "[Training] Epoch: 23 [========>      ] 59.5% Loss: 0.0699, Epoch 23, Batch 74, CE_loss: 0.056186046451330185, Dice_loss: 0.004972713068127632, Consistency_loss: 0.0005776465404778719\n",
      "[Training] Epoch: 23 [=========>     ] 60.3% Loss: 0.0704, Epoch 23, Batch 75, CE_loss: 0.09589782357215881, Dice_loss: 0.009524193592369556, Consistency_loss: 0.0005163300666026771\n",
      "[Training] Epoch: 23 [=========>     ] 61.1% Loss: 0.0704, Epoch 23, Batch 76, CE_loss: 0.0635341927409172, Dice_loss: 0.005617797374725342, Consistency_loss: 0.000312639691401273\n",
      "[Training] Epoch: 23 [=========>     ] 61.9% Loss: 0.0704, Epoch 23, Batch 77, CE_loss: 0.0680568516254425, Dice_loss: 0.006616611965000629, Consistency_loss: 0.00018349598394706845\n",
      "[Training] Epoch: 23 [=========>     ] 62.7% Loss: 0.0705, Epoch 23, Batch 78, CE_loss: 0.06677349656820297, Dice_loss: 0.006332780700176954, Consistency_loss: 0.00035413121804594994\n",
      "[Training] Epoch: 23 [=========>     ] 63.5% Loss: 0.0706, Epoch 23, Batch 79, CE_loss: 0.07703487575054169, Dice_loss: 0.00796338077634573, Consistency_loss: 0.00015882382285781205\n",
      "[Training] Epoch: 23 [=========>     ] 64.3% Loss: 0.0707, Epoch 23, Batch 80, CE_loss: 0.0682777687907219, Dice_loss: 0.00639110105112195, Consistency_loss: 0.000400233460823074\n",
      "[Training] Epoch: 23 [=========>     ] 65.1% Loss: 0.0711, Epoch 23, Batch 81, CE_loss: 0.09371926635503769, Dice_loss: 0.009375943802297115, Consistency_loss: 0.00013087665138300508\n",
      "[Training] Epoch: 23 [=========>     ] 65.9% Loss: 0.0711, Epoch 23, Batch 82, CE_loss: 0.06272478401660919, Dice_loss: 0.005947526078671217, Consistency_loss: 0.0006191806751303375\n",
      "[Training] Epoch: 23 [==========>    ] 66.7% Loss: 0.0710, Epoch 23, Batch 83, CE_loss: 0.06006777659058571, Dice_loss: 0.0055020647123456, Consistency_loss: 8.752656140131876e-05\n",
      "[Training] Epoch: 23 [==========>    ] 67.5% Loss: 0.0710, Epoch 23, Batch 84, CE_loss: 0.061067577451467514, Dice_loss: 0.005859661381691694, Consistency_loss: 0.00020484857668634504\n",
      "[Training] Epoch: 23 [==========>    ] 68.3% Loss: 0.0711, Epoch 23, Batch 85, CE_loss: 0.07766493409872055, Dice_loss: 0.007723698392510414, Consistency_loss: 0.00012817404058296233\n",
      "[Training] Epoch: 23 [==========>    ] 69.0% Loss: 0.0709, Epoch 23, Batch 86, CE_loss: 0.04903334751725197, Dice_loss: 0.003988632932305336, Consistency_loss: 0.0005129569326527417\n",
      "[Training] Epoch: 23 [==========>    ] 69.8% Loss: 0.0711, Epoch 23, Batch 87, CE_loss: 0.07547210156917572, Dice_loss: 0.007631528656929731, Consistency_loss: 0.0002594961260911077\n",
      "[Training] Epoch: 23 [==========>    ] 70.6% Loss: 0.0711, Epoch 23, Batch 88, CE_loss: 0.06861215084791183, Dice_loss: 0.006630769465118647, Consistency_loss: 0.00038822670467197895\n",
      "[Training] Epoch: 23 [==========>    ] 71.4% Loss: 0.0710, Epoch 23, Batch 89, CE_loss: 0.05908265337347984, Dice_loss: 0.005534452386200428, Consistency_loss: 0.0003997040039394051\n",
      "[Training] Epoch: 23 [==========>    ] 72.2% Loss: 0.0710, Epoch 23, Batch 90, CE_loss: 0.05700618028640747, Dice_loss: 0.005435183644294739, Consistency_loss: 0.00041421246714890003\n",
      "[Training] Epoch: 23 [==========>    ] 73.0% Loss: 0.0709, Epoch 23, Batch 91, CE_loss: 0.06342433393001556, Dice_loss: 0.006174834445118904, Consistency_loss: 0.00011777272447943687\n",
      "[Training] Epoch: 23 [===========>   ] 73.8% Loss: 0.0709, Epoch 23, Batch 92, CE_loss: 0.06202559545636177, Dice_loss: 0.006070371251553297, Consistency_loss: 0.0005266880616545677\n",
      "[Training] Epoch: 23 [===========>   ] 74.6% Loss: 0.0709, Epoch 23, Batch 93, CE_loss: 0.058421261608600616, Dice_loss: 0.005464924965053797, Consistency_loss: 0.0004513080639299005\n",
      "[Training] Epoch: 23 [===========>   ] 75.4% Loss: 0.0707, Epoch 23, Batch 94, CE_loss: 0.04976143315434456, Dice_loss: 0.004224041476845741, Consistency_loss: 0.00047787409857846797\n",
      "[Training] Epoch: 23 [===========>   ] 76.2% Loss: 0.0706, Epoch 23, Batch 95, CE_loss: 0.058542974293231964, Dice_loss: 0.005615025758743286, Consistency_loss: 0.00010664160799933597\n",
      "[Training] Epoch: 23 [===========>   ] 77.0% Loss: 0.0706, Epoch 23, Batch 96, CE_loss: 0.06045373156666756, Dice_loss: 0.005762355402112007, Consistency_loss: 0.00034457375295460224\n",
      "[Training] Epoch: 23 [===========>   ] 77.8% Loss: 0.0706, Epoch 23, Batch 97, CE_loss: 0.06733572483062744, Dice_loss: 0.0067800660617649555, Consistency_loss: 0.00042704129009507596\n",
      "[Training] Epoch: 23 [===========>   ] 78.6% Loss: 0.0705, Epoch 23, Batch 98, CE_loss: 0.05472740903496742, Dice_loss: 0.004860310349613428, Consistency_loss: 0.0003257912176195532\n",
      "[Training] Epoch: 23 [===========>   ] 79.4% Loss: 0.0703, Epoch 23, Batch 99, CE_loss: 0.04881700500845909, Dice_loss: 0.00397009402513504, Consistency_loss: 0.00037626372068189085\n",
      "[Training] Epoch: 23 [============>  ] 80.2% Loss: 0.0702, Epoch 23, Batch 100, CE_loss: 0.05289571359753609, Dice_loss: 0.00445151049643755, Consistency_loss: 0.0002743230143096298\n",
      "[Training] Epoch: 23 [============>  ] 81.0% Loss: 0.0702, Epoch 23, Batch 101, CE_loss: 0.06144866719841957, Dice_loss: 0.0057334452867507935, Consistency_loss: 0.0006045266636647284\n",
      "[Training] Epoch: 23 [============>  ] 81.7% Loss: 0.0702, Epoch 23, Batch 102, CE_loss: 0.06684169173240662, Dice_loss: 0.006258818786591291, Consistency_loss: 0.00012447312474250793\n",
      "[Training] Epoch: 23 [============>  ] 82.5% Loss: 0.0702, Epoch 23, Batch 103, CE_loss: 0.06505639851093292, Dice_loss: 0.005843447521328926, Consistency_loss: 0.00010831082909135148\n",
      "[Training] Epoch: 23 [============>  ] 83.3% Loss: 0.0701, Epoch 23, Batch 104, CE_loss: 0.05002289265394211, Dice_loss: 0.004136207979172468, Consistency_loss: 0.0004854708386119455\n",
      "[Training] Epoch: 23 [============>  ] 84.1% Loss: 0.0701, Epoch 23, Batch 105, CE_loss: 0.06464866548776627, Dice_loss: 0.00628982950001955, Consistency_loss: 0.000268193514784798\n",
      "[Training] Epoch: 23 [============>  ] 84.9% Loss: 0.0699, Epoch 23, Batch 106, CE_loss: 0.043094124644994736, Dice_loss: 0.0032104612328112125, Consistency_loss: 0.0006294827908277512\n",
      "[Training] Epoch: 23 [============>  ] 85.7% Loss: 0.0698, Epoch 23, Batch 107, CE_loss: 0.057426948100328445, Dice_loss: 0.005500200670212507, Consistency_loss: 0.000620753038674593\n",
      "[Training] Epoch: 23 [============>  ] 86.5% Loss: 0.0699, Epoch 23, Batch 108, CE_loss: 0.07104611396789551, Dice_loss: 0.0068049924448132515, Consistency_loss: 0.00040412528323940933\n",
      "[Training] Epoch: 23 [=============> ] 87.3% Loss: 0.0699, Epoch 23, Batch 109, CE_loss: 0.06212339550256729, Dice_loss: 0.006102392449975014, Consistency_loss: 0.00029022592934779823\n",
      "[Training] Epoch: 23 [=============> ] 88.1% Loss: 0.0699, Epoch 23, Batch 110, CE_loss: 0.06286317855119705, Dice_loss: 0.005871507804840803, Consistency_loss: 0.0004017213359475136\n",
      "[Training] Epoch: 23 [=============> ] 88.9% Loss: 0.0700, Epoch 23, Batch 111, CE_loss: 0.08046855032444, Dice_loss: 0.007000538986176252, Consistency_loss: 0.0004899633931927383\n",
      "[Training] Epoch: 23 [=============> ] 89.7% Loss: 0.0698, Epoch 23, Batch 112, CE_loss: 0.04211406409740448, Dice_loss: 0.003298902651295066, Consistency_loss: 0.0001979528897209093\n",
      "[Training] Epoch: 23 [=============> ] 90.5% Loss: 0.0697, Epoch 23, Batch 113, CE_loss: 0.0539921410381794, Dice_loss: 0.004849309101700783, Consistency_loss: 0.0012899780413135886\n",
      "[Training] Epoch: 23 [=============> ] 91.3% Loss: 0.0698, Epoch 23, Batch 114, CE_loss: 0.07348083704710007, Dice_loss: 0.007388618774712086, Consistency_loss: 0.0005455833743326366\n",
      "[Training] Epoch: 23 [=============> ] 92.1% Loss: 0.0698, Epoch 23, Batch 115, CE_loss: 0.0579027459025383, Dice_loss: 0.005290523171424866, Consistency_loss: 0.00013941011275164783\n",
      "[Training] Epoch: 23 [=============> ] 92.9% Loss: 0.0697, Epoch 23, Batch 116, CE_loss: 0.05894211679697037, Dice_loss: 0.005350385792553425, Consistency_loss: 0.0004970908048562706\n",
      "[Training] Epoch: 23 [==============>] 93.7% Loss: 0.0696, Epoch 23, Batch 117, CE_loss: 0.04641011729836464, Dice_loss: 0.003923937678337097, Consistency_loss: 0.00046629394637420774\n",
      "[Training] Epoch: 23 [==============>] 94.4% Loss: 0.0698, Epoch 23, Batch 118, CE_loss: 0.08446770161390305, Dice_loss: 0.008405868895351887, Consistency_loss: 0.0003533865965437144\n",
      "[Training] Epoch: 23 [==============>] 95.2% Loss: 0.0696, Epoch 23, Batch 119, CE_loss: 0.049102045595645905, Dice_loss: 0.004302379675209522, Consistency_loss: 0.00025524842203594744\n",
      "[Training] Epoch: 23 [==============>] 96.0% Loss: 0.0697, Epoch 23, Batch 120, CE_loss: 0.07224074751138687, Dice_loss: 0.007460461929440498, Consistency_loss: 0.0004242859431542456\n",
      "[Training] Epoch: 23 [==============>] 96.8% Loss: 0.0697, Epoch 23, Batch 121, CE_loss: 0.05900336802005768, Dice_loss: 0.005209323950111866, Consistency_loss: 0.0002732893917709589\n",
      "[Training] Epoch: 23 [==============>] 97.6% Loss: 0.0698, Epoch 23, Batch 122, CE_loss: 0.07253950834274292, Dice_loss: 0.007248276844620705, Consistency_loss: 0.00010119655780727044\n",
      "[Training] Epoch: 23 [==============>] 98.4% Loss: 0.0697, Epoch 23, Batch 123, CE_loss: 0.05420081317424774, Dice_loss: 0.0050249891355633736, Consistency_loss: 0.00059012311976403\n",
      "[Training] Epoch: 23 [==============>] 99.2% Loss: 0.0697, Epoch 23, Batch 124, CE_loss: 0.060810163617134094, Dice_loss: 0.005992497783154249, Consistency_loss: 0.000557257269974798\n",
      "[Training] Epoch: 23 [DONE]                                 \n",
      "Epoch 23, Batch 125, CE_loss: 0.06058245152235031, Dice_loss: 0.00553996441885829, Consistency_loss: 6.006376497680321e-05\n",
      "[Validation] Epoch: 23 [DONE]                                 \n",
      "[Epoch: 23, TrainLoss: 0.0696, TrainDice: 0.0059, ValLoss: 0.1588                                            \n",
      "Number of batches:  126\n",
      "[Training] Epoch: 24 [>              ] 0.8% Loss: 0.0534, Epoch 24, Batch 0, CE_loss: 0.04887045919895172, Dice_loss: 0.004175810609012842, Consistency_loss: 0.00031111130374483764\n",
      "[Training] Epoch: 24 [>              ] 1.6% Loss: 0.0722, Epoch 24, Batch 1, CE_loss: 0.0826556533575058, Dice_loss: 0.007906249724328518, Consistency_loss: 0.0004122214450035244\n",
      "[Training] Epoch: 24 [>              ] 2.4% Loss: 0.0687, Epoch 24, Batch 2, CE_loss: 0.05643773078918457, Dice_loss: 0.005025977268815041, Consistency_loss: 0.000241360321524553\n",
      "[Training] Epoch: 24 [>              ] 3.2% Loss: 0.0732, Epoch 24, Batch 3, CE_loss: 0.07857216894626617, Dice_loss: 0.007997055537998676, Consistency_loss: 7.372715481324121e-05\n",
      "[Training] Epoch: 24 [>              ] 4.0% Loss: 0.0680, Epoch 24, Batch 4, CE_loss: 0.04339750111103058, Dice_loss: 0.0034964473452419043, Consistency_loss: 0.0003877155249938369\n",
      "[Training] Epoch: 24 [>              ] 4.8% Loss: 0.0684, Epoch 24, Batch 5, CE_loss: 0.06429963558912277, Dice_loss: 0.0063495757058262825, Consistency_loss: 6.536267028423026e-05\n",
      "[Training] Epoch: 24 [>              ] 5.6% Loss: 0.0669, Epoch 24, Batch 6, CE_loss: 0.052997030317783356, Dice_loss: 0.004466883838176727, Consistency_loss: 0.0001668128970777616\n",
      "[Training] Epoch: 24 [>              ] 6.3% Loss: 0.0657, Epoch 24, Batch 7, CE_loss: 0.05207189545035362, Dice_loss: 0.0047916145995259285, Consistency_loss: 0.00015212950529530644\n",
      "[Training] Epoch: 24 [=>             ] 7.1% Loss: 0.0659, Epoch 24, Batch 8, CE_loss: 0.061607494950294495, Dice_loss: 0.006018966902047396, Consistency_loss: 0.0001519914949312806\n",
      "[Training] Epoch: 24 [=>             ] 7.9% Loss: 0.0664, Epoch 24, Batch 9, CE_loss: 0.06444071978330612, Dice_loss: 0.006417368538677692, Consistency_loss: 0.00012444384628906846\n",
      "[Training] Epoch: 24 [=>             ] 8.7% Loss: 0.0649, Epoch 24, Batch 10, CE_loss: 0.04558681324124336, Dice_loss: 0.0038592428900301456, Consistency_loss: 0.000101304474810604\n",
      "[Training] Epoch: 24 [=>             ] 9.5% Loss: 0.0655, Epoch 24, Batch 11, CE_loss: 0.06549550592899323, Dice_loss: 0.006200963631272316, Consistency_loss: 0.0005122261354699731\n",
      "[Training] Epoch: 24 [=>             ] 10.3% Loss: 0.0665, Epoch 24, Batch 12, CE_loss: 0.07198663055896759, Dice_loss: 0.00642044423148036, Consistency_loss: 5.870255336049013e-05\n",
      "[Training] Epoch: 24 [=>             ] 11.1% Loss: 0.0662, Epoch 24, Batch 13, CE_loss: 0.05617957562208176, Dice_loss: 0.005170105490833521, Consistency_loss: 0.0006362204439938068\n",
      "[Training] Epoch: 24 [=>             ] 11.9% Loss: 0.0677, Epoch 24, Batch 14, CE_loss: 0.08040907233953476, Dice_loss: 0.008127263747155666, Consistency_loss: 0.00032709469087421894\n",
      "[Training] Epoch: 24 [=>             ] 12.7% Loss: 0.0669, Epoch 24, Batch 15, CE_loss: 0.05130912736058235, Dice_loss: 0.00446799723431468, Consistency_loss: 0.00017061886319424957\n",
      "[Training] Epoch: 24 [==>            ] 13.5% Loss: 0.0666, Epoch 24, Batch 16, CE_loss: 0.054879702627658844, Dice_loss: 0.005164589267224073, Consistency_loss: 0.000205847347388044\n",
      "[Training] Epoch: 24 [==>            ] 14.3% Loss: 0.0654, Epoch 24, Batch 17, CE_loss: 0.042847391217947006, Dice_loss: 0.0033713357988744974, Consistency_loss: 0.00014723023923579603\n",
      "[Training] Epoch: 24 [==>            ] 15.1% Loss: 0.0658, Epoch 24, Batch 18, CE_loss: 0.06587308645248413, Dice_loss: 0.006422115955501795, Consistency_loss: 0.0005197506980039179\n",
      "[Training] Epoch: 24 [==>            ] 15.9% Loss: 0.0663, Epoch 24, Batch 19, CE_loss: 0.06926287710666656, Dice_loss: 0.006923850160092115, Consistency_loss: 0.00025730699417181313\n",
      "[Training] Epoch: 24 [==>            ] 16.7% Loss: 0.0659, Epoch 24, Batch 20, CE_loss: 0.05213100090622902, Dice_loss: 0.0047569964081048965, Consistency_loss: 0.0003086946962866932\n",
      "[Training] Epoch: 24 [==>            ] 17.5% Loss: 0.0674, Epoch 24, Batch 21, CE_loss: 0.08917059004306793, Dice_loss: 0.009557658806443214, Consistency_loss: 0.00029838597401976585\n",
      "[Training] Epoch: 24 [==>            ] 18.3% Loss: 0.0670, Epoch 24, Batch 22, CE_loss: 0.053127873688936234, Dice_loss: 0.004951979499310255, Consistency_loss: 0.00028109963750466704\n",
      "[Training] Epoch: 24 [==>            ] 19.0% Loss: 0.0670, Epoch 24, Batch 23, CE_loss: 0.059415075927972794, Dice_loss: 0.0056100101210176945, Consistency_loss: 0.0004451512068044394\n",
      "[Training] Epoch: 24 [==>            ] 19.8% Loss: 0.0668, Epoch 24, Batch 24, CE_loss: 0.05810033529996872, Dice_loss: 0.005535511765629053, Consistency_loss: 0.0002588885836303234\n",
      "[Training] Epoch: 24 [===>           ] 20.6% Loss: 0.0662, Epoch 24, Batch 25, CE_loss: 0.047233644872903824, Dice_loss: 0.0038480402436107397, Consistency_loss: 0.000207652963581495\n",
      "[Training] Epoch: 24 [===>           ] 21.4% Loss: 0.0663, Epoch 24, Batch 26, CE_loss: 0.06104332208633423, Dice_loss: 0.0057680862955749035, Consistency_loss: 0.0006722675752826035\n",
      "[Training] Epoch: 24 [===>           ] 22.2% Loss: 0.0663, Epoch 24, Batch 27, CE_loss: 0.06120160594582558, Dice_loss: 0.005492525175213814, Consistency_loss: 0.0006431734072975814\n",
      "[Training] Epoch: 24 [===>           ] 23.0% Loss: 0.0663, Epoch 24, Batch 28, CE_loss: 0.06058201566338539, Dice_loss: 0.00592062808573246, Consistency_loss: 0.00020908312581013888\n",
      "[Training] Epoch: 24 [===>           ] 23.8% Loss: 0.0665, Epoch 24, Batch 29, CE_loss: 0.06386251747608185, Dice_loss: 0.005993378348648548, Consistency_loss: 0.00045803861576132476\n",
      "[Training] Epoch: 24 [===>           ] 24.6% Loss: 0.0677, Epoch 24, Batch 30, CE_loss: 0.09296362847089767, Dice_loss: 0.009701792150735855, Consistency_loss: 0.000647420238237828\n",
      "[Training] Epoch: 24 [===>           ] 25.4% Loss: 0.0681, Epoch 24, Batch 31, CE_loss: 0.07444563508033752, Dice_loss: 0.007426116149872541, Consistency_loss: 0.0002876086800824851\n",
      "[Training] Epoch: 24 [===>           ] 26.2% Loss: 0.0677, Epoch 24, Batch 32, CE_loss: 0.05053495243191719, Dice_loss: 0.004567364230751991, Consistency_loss: 0.00033882600837387145\n",
      "[Training] Epoch: 24 [====>          ] 27.0% Loss: 0.0676, Epoch 24, Batch 33, CE_loss: 0.05697707459330559, Dice_loss: 0.005268082022666931, Consistency_loss: 0.0005054857465438545\n",
      "[Training] Epoch: 24 [====>          ] 27.8% Loss: 0.0677, Epoch 24, Batch 34, CE_loss: 0.06530506163835526, Dice_loss: 0.0065338704735040665, Consistency_loss: 0.0004857666790485382\n",
      "[Training] Epoch: 24 [====>          ] 28.6% Loss: 0.0679, Epoch 24, Batch 35, CE_loss: 0.0677148625254631, Dice_loss: 0.006693180184811354, Consistency_loss: 0.00036659836769104004\n",
      "[Training] Epoch: 24 [====>          ] 29.4% Loss: 0.0683, Epoch 24, Batch 36, CE_loss: 0.07507894933223724, Dice_loss: 0.007652427535504103, Consistency_loss: 0.00031759843113832176\n",
      "[Training] Epoch: 24 [====>          ] 30.2% Loss: 0.0682, Epoch 24, Batch 37, CE_loss: 0.05909261479973793, Dice_loss: 0.005265489220619202, Consistency_loss: 7.06149367033504e-05\n",
      "[Training] Epoch: 24 [====>          ] 31.0% Loss: 0.0681, Epoch 24, Batch 38, CE_loss: 0.0589328333735466, Dice_loss: 0.005491219460964203, Consistency_loss: 0.0006964209605939686\n",
      "[Training] Epoch: 24 [====>          ] 31.7% Loss: 0.0678, Epoch 24, Batch 39, CE_loss: 0.05123800411820412, Dice_loss: 0.00454718479886651, Consistency_loss: 0.000712064967956394\n",
      "[Training] Epoch: 24 [====>          ] 32.5% Loss: 0.0678, Epoch 24, Batch 40, CE_loss: 0.05948111414909363, Dice_loss: 0.005724424496293068, Consistency_loss: 0.00012892672384623438\n",
      "[Training] Epoch: 24 [=====>         ] 33.3% Loss: 0.0680, Epoch 24, Batch 41, CE_loss: 0.07077573984861374, Dice_loss: 0.007406111340969801, Consistency_loss: 0.0005695546860806644\n",
      "[Training] Epoch: 24 [=====>         ] 34.1% Loss: 0.0679, Epoch 24, Batch 42, CE_loss: 0.054814793169498444, Dice_loss: 0.004877194762229919, Consistency_loss: 0.0001499549689469859\n",
      "[Training] Epoch: 24 [=====>         ] 34.9% Loss: 0.0682, Epoch 24, Batch 43, CE_loss: 0.07321549952030182, Dice_loss: 0.00738265085965395, Consistency_loss: 0.00042794650653377175\n",
      "[Training] Epoch: 24 [=====>         ] 35.7% Loss: 0.0682, Epoch 24, Batch 44, CE_loss: 0.06303292512893677, Dice_loss: 0.006208174396306276, Consistency_loss: 0.000540535373147577\n",
      "[Training] Epoch: 24 [=====>         ] 36.5% Loss: 0.0682, Epoch 24, Batch 45, CE_loss: 0.06475885212421417, Dice_loss: 0.005237299483269453, Consistency_loss: 0.0002908515452872962\n",
      "[Training] Epoch: 24 [=====>         ] 37.3% Loss: 0.0682, Epoch 24, Batch 46, CE_loss: 0.060705769807100296, Dice_loss: 0.0059246825985610485, Consistency_loss: 0.0002818748471327126\n",
      "[Training] Epoch: 24 [=====>         ] 38.1% Loss: 0.0680, Epoch 24, Batch 47, CE_loss: 0.05157100036740303, Dice_loss: 0.004713325295597315, Consistency_loss: 0.0002513403014745563\n",
      "[Training] Epoch: 24 [=====>         ] 38.9% Loss: 0.0677, Epoch 24, Batch 48, CE_loss: 0.0505918450653553, Dice_loss: 0.0045793624594807625, Consistency_loss: 0.0007720876019448042\n",
      "[Training] Epoch: 24 [=====>         ] 39.7% Loss: 0.0676, Epoch 24, Batch 49, CE_loss: 0.054256752133369446, Dice_loss: 0.005149300675839186, Consistency_loss: 0.00040816314867697656\n",
      "[Training] Epoch: 24 [======>        ] 40.5% Loss: 0.0674, Epoch 24, Batch 50, CE_loss: 0.052188266068696976, Dice_loss: 0.0047195078805089, Consistency_loss: 0.00012990389950573444\n",
      "[Training] Epoch: 24 [======>        ] 41.3% Loss: 0.0676, Epoch 24, Batch 51, CE_loss: 0.07266819477081299, Dice_loss: 0.0071182833053171635, Consistency_loss: 0.0007506911642849445\n",
      "[Training] Epoch: 24 [======>        ] 42.1% Loss: 0.0673, Epoch 24, Batch 52, CE_loss: 0.04847896099090576, Dice_loss: 0.004283478949218988, Consistency_loss: 0.0001455119054298848\n",
      "[Training] Epoch: 24 [======>        ] 42.9% Loss: 0.0673, Epoch 24, Batch 53, CE_loss: 0.05736434832215309, Dice_loss: 0.005384047515690327, Consistency_loss: 0.00019640808750409633\n",
      "[Training] Epoch: 24 [======>        ] 43.7% Loss: 0.0671, Epoch 24, Batch 54, CE_loss: 0.05142567306756973, Dice_loss: 0.004538709297776222, Consistency_loss: 0.0003627680125646293\n",
      "[Training] Epoch: 24 [======>        ] 44.4% Loss: 0.0672, Epoch 24, Batch 55, CE_loss: 0.06772074848413467, Dice_loss: 0.006218152120709419, Consistency_loss: 0.00014760099293198436\n",
      "[Training] Epoch: 24 [======>        ] 45.2% Loss: 0.0677, Epoch 24, Batch 56, CE_loss: 0.08805214613676071, Dice_loss: 0.008896454237401485, Consistency_loss: 0.0005089195328764617\n",
      "[Training] Epoch: 24 [======>        ] 46.0% Loss: 0.0676, Epoch 24, Batch 57, CE_loss: 0.053255245089530945, Dice_loss: 0.005072464235126972, Consistency_loss: 0.0004692139627877623\n",
      "[Training] Epoch: 24 [=======>       ] 46.8% Loss: 0.0675, Epoch 24, Batch 58, CE_loss: 0.05577365309000015, Dice_loss: 0.005320250988006592, Consistency_loss: 0.000500850030221045\n",
      "[Training] Epoch: 24 [=======>       ] 47.6% Loss: 0.0675, Epoch 24, Batch 59, CE_loss: 0.06075115129351616, Dice_loss: 0.006014433689415455, Consistency_loss: 0.0005249591777101159\n",
      "[Training] Epoch: 24 [=======>       ] 48.4% Loss: 0.0674, Epoch 24, Batch 60, CE_loss: 0.05999854952096939, Dice_loss: 0.005867368075996637, Consistency_loss: 0.0004577802028506994\n",
      "[Training] Epoch: 24 [=======>       ] 49.2% Loss: 0.0673, Epoch 24, Batch 61, CE_loss: 0.05434265732765198, Dice_loss: 0.005081690847873688, Consistency_loss: 0.0003270041779614985\n",
      "[Training] Epoch: 24 [=======>       ] 50.0% Loss: 0.0672, Epoch 24, Batch 62, CE_loss: 0.05596113204956055, Dice_loss: 0.005094592459499836, Consistency_loss: 0.0008080938714556396\n",
      "[Training] Epoch: 24 [=======>       ] 50.8% Loss: 0.0672, Epoch 24, Batch 63, CE_loss: 0.05836137384176254, Dice_loss: 0.005506852641701698, Consistency_loss: 0.0009178681648336351\n",
      "[Training] Epoch: 24 [=======>       ] 51.6% Loss: 0.0671, Epoch 24, Batch 64, CE_loss: 0.05310824140906334, Dice_loss: 0.005002020392566919, Consistency_loss: 0.0006883137975819409\n",
      "[Training] Epoch: 24 [=======>       ] 52.4% Loss: 0.0672, Epoch 24, Batch 65, CE_loss: 0.07120570540428162, Dice_loss: 0.007241575513035059, Consistency_loss: 0.0007701142458245158\n",
      "[Training] Epoch: 24 [=======>       ] 53.2% Loss: 0.0672, Epoch 24, Batch 66, CE_loss: 0.0557745136320591, Dice_loss: 0.005403873510658741, Consistency_loss: 0.00016822149336803705\n",
      "[Training] Epoch: 24 [========>      ] 54.0% Loss: 0.0670, Epoch 24, Batch 67, CE_loss: 0.05172893404960632, Dice_loss: 0.004474157467484474, Consistency_loss: 0.00038227063487283885\n",
      "[Training] Epoch: 24 [========>      ] 54.8% Loss: 0.0669, Epoch 24, Batch 68, CE_loss: 0.05711542069911957, Dice_loss: 0.0052747298032045364, Consistency_loss: 0.0002952518407255411\n",
      "[Training] Epoch: 24 [========>      ] 55.6% Loss: 0.0673, Epoch 24, Batch 69, CE_loss: 0.08159255236387253, Dice_loss: 0.008318048901855946, Consistency_loss: 0.0003654648899100721\n",
      "[Training] Epoch: 24 [========>      ] 56.3% Loss: 0.0672, Epoch 24, Batch 70, CE_loss: 0.05351328104734421, Dice_loss: 0.005070725455880165, Consistency_loss: 0.0007463741931132972\n",
      "[Training] Epoch: 24 [========>      ] 57.1% Loss: 0.0673, Epoch 24, Batch 71, CE_loss: 0.07159943133592606, Dice_loss: 0.007233837619423866, Consistency_loss: 0.000711423228494823\n",
      "[Training] Epoch: 24 [========>      ] 57.9% Loss: 0.0674, Epoch 24, Batch 72, CE_loss: 0.06287505477666855, Dice_loss: 0.0061730192974209785, Consistency_loss: 0.0005460823304019868\n",
      "[Training] Epoch: 24 [========>      ] 58.7% Loss: 0.0673, Epoch 24, Batch 73, CE_loss: 0.053827401250600815, Dice_loss: 0.005056527443230152, Consistency_loss: 0.00059179263189435\n",
      "[Training] Epoch: 24 [========>      ] 59.5% Loss: 0.0673, Epoch 24, Batch 74, CE_loss: 0.06540605425834656, Dice_loss: 0.005905817728489637, Consistency_loss: 0.0006564586656168103\n",
      "[Training] Epoch: 24 [=========>     ] 60.3% Loss: 0.0672, Epoch 24, Batch 75, CE_loss: 0.0554044246673584, Dice_loss: 0.0051317051984369755, Consistency_loss: 0.0005926858866587281\n",
      "[Training] Epoch: 24 [=========>     ] 61.1% Loss: 0.0673, Epoch 24, Batch 76, CE_loss: 0.06540030986070633, Dice_loss: 0.006568895652890205, Consistency_loss: 0.00011324552906444296\n",
      "[Training] Epoch: 24 [=========>     ] 61.9% Loss: 0.0675, Epoch 24, Batch 77, CE_loss: 0.07795704901218414, Dice_loss: 0.008205472491681576, Consistency_loss: 0.0005028073792345822\n",
      "[Training] Epoch: 24 [=========>     ] 62.7% Loss: 0.0677, Epoch 24, Batch 78, CE_loss: 0.06925691664218903, Dice_loss: 0.006884148810058832, Consistency_loss: 0.00046868325443938375\n",
      "[Training] Epoch: 24 [=========>     ] 63.5% Loss: 0.0676, Epoch 24, Batch 79, CE_loss: 0.05936368927359581, Dice_loss: 0.005727620795369148, Consistency_loss: 0.0006647288682870567\n",
      "[Training] Epoch: 24 [=========>     ] 64.3% Loss: 0.0676, Epoch 24, Batch 80, CE_loss: 0.06080237030982971, Dice_loss: 0.005799284670501947, Consistency_loss: 0.000634242023807019\n",
      "[Training] Epoch: 24 [=========>     ] 65.1% Loss: 0.0681, Epoch 24, Batch 81, CE_loss: 0.09223657846450806, Dice_loss: 0.009431098587810993, Consistency_loss: 0.0009104011696763337\n",
      "[Training] Epoch: 24 [=========>     ] 65.9% Loss: 0.0680, Epoch 24, Batch 82, CE_loss: 0.06037160009145737, Dice_loss: 0.0059671238996088505, Consistency_loss: 0.0006637757178395987\n",
      "[Training] Epoch: 24 [==========>    ] 66.7% Loss: 0.0680, Epoch 24, Batch 83, CE_loss: 0.058345768600702286, Dice_loss: 0.005626416299492121, Consistency_loss: 0.000275009690085426\n",
      "[Training] Epoch: 24 [==========>    ] 67.5% Loss: 0.0681, Epoch 24, Batch 84, CE_loss: 0.06652529537677765, Dice_loss: 0.006811219733208418, Consistency_loss: 0.00037151426658965647\n",
      "[Training] Epoch: 24 [==========>    ] 68.3% Loss: 0.0681, Epoch 24, Batch 85, CE_loss: 0.06063677743077278, Dice_loss: 0.0060960534028708935, Consistency_loss: 0.0006537245353683829\n",
      "[Training] Epoch: 24 [==========>    ] 69.0% Loss: 0.0681, Epoch 24, Batch 86, CE_loss: 0.06457969546318054, Dice_loss: 0.00650847889482975, Consistency_loss: 0.0006747615989297628\n",
      "[Training] Epoch: 24 [==========>    ] 69.8% Loss: 0.0682, Epoch 24, Batch 87, CE_loss: 0.07139086723327637, Dice_loss: 0.007328067906200886, Consistency_loss: 0.0005162957822903991\n",
      "[Training] Epoch: 24 [==========>    ] 70.6% Loss: 0.0682, Epoch 24, Batch 88, CE_loss: 0.057500313967466354, Dice_loss: 0.005518739111721516, Consistency_loss: 0.0004223058058414608\n",
      "[Training] Epoch: 24 [==========>    ] 71.4% Loss: 0.0682, Epoch 24, Batch 89, CE_loss: 0.0673835501074791, Dice_loss: 0.0065993028692901134, Consistency_loss: 0.000544997223187238\n",
      "[Training] Epoch: 24 [==========>    ] 72.2% Loss: 0.0683, Epoch 24, Batch 90, CE_loss: 0.06753800809383392, Dice_loss: 0.006880228407680988, Consistency_loss: 0.00040376937249675393\n",
      "[Training] Epoch: 24 [==========>    ] 73.0% Loss: 0.0683, Epoch 24, Batch 91, CE_loss: 0.05620172619819641, Dice_loss: 0.0053970832377672195, Consistency_loss: 0.0007019316544756293\n",
      "[Training] Epoch: 24 [===========>   ] 73.8% Loss: 0.0683, Epoch 24, Batch 92, CE_loss: 0.06650926917791367, Dice_loss: 0.00673392741009593, Consistency_loss: 0.0005798157071694732\n",
      "[Training] Epoch: 24 [===========>   ] 74.6% Loss: 0.0683, Epoch 24, Batch 93, CE_loss: 0.05761287733912468, Dice_loss: 0.004815629217773676, Consistency_loss: 0.00010820593888638541\n",
      "[Training] Epoch: 24 [===========>   ] 75.4% Loss: 0.0685, Epoch 24, Batch 94, CE_loss: 0.08664461225271225, Dice_loss: 0.008218538947403431, Consistency_loss: 0.0001229811750818044\n",
      "[Training] Epoch: 24 [===========>   ] 76.2% Loss: 0.0684, Epoch 24, Batch 95, CE_loss: 0.051040954887866974, Dice_loss: 0.0047769565135240555, Consistency_loss: 0.0004363492189440876\n",
      "[Training] Epoch: 24 [===========>   ] 77.0% Loss: 0.0686, Epoch 24, Batch 96, CE_loss: 0.07775020599365234, Dice_loss: 0.007843289524316788, Consistency_loss: 0.00043451954843476415\n",
      "[Training] Epoch: 24 [===========>   ] 77.8% Loss: 0.0686, Epoch 24, Batch 97, CE_loss: 0.06446251273155212, Dice_loss: 0.006134024355560541, Consistency_loss: 0.00048145625623874366\n",
      "[Training] Epoch: 24 [===========>   ] 78.6% Loss: 0.0686, Epoch 24, Batch 98, CE_loss: 0.05789992958307266, Dice_loss: 0.005374642089009285, Consistency_loss: 0.0003696173953358084\n",
      "[Training] Epoch: 24 [===========>   ] 79.4% Loss: 0.0685, Epoch 24, Batch 99, CE_loss: 0.052593447268009186, Dice_loss: 0.004886014852672815, Consistency_loss: 0.0004312526434659958\n",
      "[Training] Epoch: 24 [============>  ] 80.2% Loss: 0.0684, Epoch 24, Batch 100, CE_loss: 0.05426076427102089, Dice_loss: 0.0050471932627260685, Consistency_loss: 0.0004945147666148841\n",
      "[Training] Epoch: 24 [============>  ] 81.0% Loss: 0.0685, Epoch 24, Batch 101, CE_loss: 0.06947100162506104, Dice_loss: 0.007055063731968403, Consistency_loss: 0.0006047658971510828\n",
      "[Training] Epoch: 24 [============>  ] 81.7% Loss: 0.0685, Epoch 24, Batch 102, CE_loss: 0.0642203614115715, Dice_loss: 0.00645293015986681, Consistency_loss: 0.00013949521235190332\n",
      "[Training] Epoch: 24 [============>  ] 82.5% Loss: 0.0685, Epoch 24, Batch 103, CE_loss: 0.06592562049627304, Dice_loss: 0.006876893807202578, Consistency_loss: 0.0003021156881004572\n",
      "[Training] Epoch: 24 [============>  ] 83.3% Loss: 0.0686, Epoch 24, Batch 104, CE_loss: 0.06800952553749084, Dice_loss: 0.007120044901967049, Consistency_loss: 0.0003082086914218962\n",
      "[Training] Epoch: 24 [============>  ] 84.1% Loss: 0.0685, Epoch 24, Batch 105, CE_loss: 0.056232426315546036, Dice_loss: 0.005216516554355621, Consistency_loss: 0.0004088872519787401\n",
      "[Training] Epoch: 24 [============>  ] 84.9% Loss: 0.0685, Epoch 24, Batch 106, CE_loss: 0.06365019083023071, Dice_loss: 0.0065206605941057205, Consistency_loss: 9.356462396681309e-05\n",
      "[Training] Epoch: 24 [============>  ] 85.7% Loss: 0.0685, Epoch 24, Batch 107, CE_loss: 0.05614783987402916, Dice_loss: 0.00549307931214571, Consistency_loss: 0.0006330091855488718\n",
      "[Training] Epoch: 24 [============>  ] 86.5% Loss: 0.0686, Epoch 24, Batch 108, CE_loss: 0.07071258127689362, Dice_loss: 0.007100044284015894, Consistency_loss: 0.0004912219010293484\n",
      "[Training] Epoch: 24 [=============> ] 87.3% Loss: 0.0686, Epoch 24, Batch 109, CE_loss: 0.06723237782716751, Dice_loss: 0.007003100588917732, Consistency_loss: 0.0002859383530449122\n",
      "[Training] Epoch: 24 [=============> ] 88.1% Loss: 0.0686, Epoch 24, Batch 110, CE_loss: 0.057775191962718964, Dice_loss: 0.005767161026597023, Consistency_loss: 0.00040800852002575994\n",
      "[Training] Epoch: 24 [=============> ] 88.9% Loss: 0.0684, Epoch 24, Batch 111, CE_loss: 0.04743361100554466, Dice_loss: 0.0040449234656989574, Consistency_loss: 0.00010936840408248827\n",
      "[Training] Epoch: 24 [=============> ] 89.7% Loss: 0.0684, Epoch 24, Batch 112, CE_loss: 0.059444230049848557, Dice_loss: 0.005965251009911299, Consistency_loss: 0.0007922250078991055\n",
      "[Training] Epoch: 24 [=============> ] 90.5% Loss: 0.0683, Epoch 24, Batch 113, CE_loss: 0.05380646139383316, Dice_loss: 0.004865817725658417, Consistency_loss: 0.0006877614068798721\n",
      "[Training] Epoch: 24 [=============> ] 91.3% Loss: 0.0685, Epoch 24, Batch 114, CE_loss: 0.07395609468221664, Dice_loss: 0.007513891439884901, Consistency_loss: 0.00042065521120093763\n",
      "[Training] Epoch: 24 [=============> ] 92.1% Loss: 0.0685, Epoch 24, Batch 115, CE_loss: 0.06643172353506088, Dice_loss: 0.006804554257541895, Consistency_loss: 0.0004633746575564146\n",
      "[Training] Epoch: 24 [=============> ] 92.9% Loss: 0.0684, Epoch 24, Batch 116, CE_loss: 0.05036529526114464, Dice_loss: 0.0045574624091386795, Consistency_loss: 0.0005581678706221282\n",
      "[Training] Epoch: 24 [==============>] 93.7% Loss: 0.0685, Epoch 24, Batch 117, CE_loss: 0.07118023931980133, Dice_loss: 0.007435222156345844, Consistency_loss: 0.0005867306026630104\n",
      "[Training] Epoch: 24 [==============>] 94.4% Loss: 0.0684, Epoch 24, Batch 118, CE_loss: 0.05480504035949707, Dice_loss: 0.005028306040912867, Consistency_loss: 0.00013108189159538597\n",
      "[Training] Epoch: 24 [==============>] 95.2% Loss: 0.0684, Epoch 24, Batch 119, CE_loss: 0.06164909526705742, Dice_loss: 0.006063710432499647, Consistency_loss: 0.0001268702617380768\n",
      "[Training] Epoch: 24 [==============>] 96.0% Loss: 0.0683, Epoch 24, Batch 120, CE_loss: 0.05126567557454109, Dice_loss: 0.004865648224949837, Consistency_loss: 0.0005721349152736366\n",
      "[Training] Epoch: 24 [==============>] 96.8% Loss: 0.0685, Epoch 24, Batch 121, CE_loss: 0.08391836285591125, Dice_loss: 0.007867648266255856, Consistency_loss: 0.00014863244723528624\n",
      "[Training] Epoch: 24 [==============>] 97.6% Loss: 0.0685, Epoch 24, Batch 122, CE_loss: 0.06608986854553223, Dice_loss: 0.006727677769958973, Consistency_loss: 0.00038764553028158844\n",
      "[Training] Epoch: 24 [==============>] 98.4% Loss: 0.0685, Epoch 24, Batch 123, CE_loss: 0.05321695655584335, Dice_loss: 0.0047956425696611404, Consistency_loss: 0.0006197324837557971\n",
      "[Training] Epoch: 24 [==============>] 99.2% Loss: 0.0683, Epoch 24, Batch 124, CE_loss: 0.049539852887392044, Dice_loss: 0.004614928737282753, Consistency_loss: 0.0005704410723410547\n",
      "[Training] Epoch: 24 [DONE]                                 \n",
      "Epoch 24, Batch 125, CE_loss: 0.06132471561431885, Dice_loss: 0.0059019955806434155, Consistency_loss: 0.0001573761401232332\n",
      "[Validation] Epoch: 24 [DONE]                                 \n",
      "[Epoch: 24, TrainLoss: 0.0683, TrainDice: 0.0060, ValLoss: 0.1430                                            \n",
      "Number of batches:  126\n",
      "[Training] Epoch: 25 [>              ] 0.8% Loss: 0.0626, Epoch 25, Batch 0, CE_loss: 0.05701757222414017, Dice_loss: 0.005455801263451576, Consistency_loss: 8.114486990962178e-05\n",
      "[Training] Epoch: 25 [>              ] 1.6% Loss: 0.0796, Epoch 25, Batch 1, CE_loss: 0.08734965324401855, Dice_loss: 0.008742570877075195, Consistency_loss: 0.00047947815619409084\n",
      "[Training] Epoch: 25 [>              ] 2.4% Loss: 0.0777, Epoch 25, Batch 2, CE_loss: 0.06687049567699432, Dice_loss: 0.0068943859077990055, Consistency_loss: 0.0002614466066006571\n",
      "[Training] Epoch: 25 [>              ] 3.2% Loss: 0.0817, Epoch 25, Batch 3, CE_loss: 0.08490873128175735, Dice_loss: 0.008185927756130695, Consistency_loss: 0.00037862014141865075\n",
      "[Training] Epoch: 25 [>              ] 4.0% Loss: 0.0812, Epoch 25, Batch 4, CE_loss: 0.07159864902496338, Dice_loss: 0.007057786453515291, Consistency_loss: 0.0004944477695971727\n",
      "[Training] Epoch: 25 [>              ] 4.8% Loss: 0.0807, Epoch 25, Batch 5, CE_loss: 0.07081161439418793, Dice_loss: 0.007296547759324312, Consistency_loss: 0.000128887128084898\n",
      "[Training] Epoch: 25 [>              ] 5.6% Loss: 0.0758, Epoch 25, Batch 6, CE_loss: 0.042986344546079636, Dice_loss: 0.003654353553429246, Consistency_loss: 0.00017280387692153454\n",
      "[Training] Epoch: 25 [>              ] 6.3% Loss: 0.0731, Epoch 25, Batch 7, CE_loss: 0.049538444727659225, Dice_loss: 0.00434948829934001, Consistency_loss: 0.00030598664307035506\n",
      "[Training] Epoch: 25 [=>             ] 7.1% Loss: 0.0739, Epoch 25, Batch 8, CE_loss: 0.07253363728523254, Dice_loss: 0.00728120980784297, Consistency_loss: 0.0001805896608857438\n",
      "[Training] Epoch: 25 [=>             ] 7.9% Loss: 0.0744, Epoch 25, Batch 9, CE_loss: 0.07104712724685669, Dice_loss: 0.00745165953412652, Consistency_loss: 0.00019076104217674583\n",
      "[Training] Epoch: 25 [=>             ] 8.7% Loss: 0.0744, Epoch 25, Batch 10, CE_loss: 0.06791096180677414, Dice_loss: 0.006637676153331995, Consistency_loss: 0.0005596534465439618\n",
      "[Training] Epoch: 25 [=>             ] 9.5% Loss: 0.0741, Epoch 25, Batch 11, CE_loss: 0.06326808780431747, Dice_loss: 0.006153703201562166, Consistency_loss: 0.0006300837267190218\n",
      "[Training] Epoch: 25 [=>             ] 10.3% Loss: 0.0732, Epoch 25, Batch 12, CE_loss: 0.05713438615202904, Dice_loss: 0.005633765831589699, Consistency_loss: 0.000522494432516396\n",
      "[Training] Epoch: 25 [=>             ] 11.1% Loss: 0.0727, Epoch 25, Batch 13, CE_loss: 0.059723611921072006, Dice_loss: 0.005877663381397724, Consistency_loss: 0.0005058125825598836\n",
      "[Training] Epoch: 25 [=>             ] 11.9% Loss: 0.0723, Epoch 25, Batch 14, CE_loss: 0.0602247379720211, Dice_loss: 0.005160136613994837, Consistency_loss: 0.00040178425842896104\n",
      "[Training] Epoch: 25 [=>             ] 12.7% Loss: 0.0720, Epoch 25, Batch 15, CE_loss: 0.062309470027685165, Dice_loss: 0.005853340029716492, Consistency_loss: 0.0004216079250909388\n",
      "[Training] Epoch: 25 [==>            ] 13.5% Loss: 0.0720, Epoch 25, Batch 16, CE_loss: 0.06427713483572006, Dice_loss: 0.006691696122288704, Consistency_loss: 0.0001547692809253931\n",
      "[Training] Epoch: 25 [==>            ] 14.3% Loss: 0.0721, Epoch 25, Batch 17, CE_loss: 0.06653765588998795, Dice_loss: 0.00688777444884181, Consistency_loss: 0.0004439565818756819\n",
      "[Training] Epoch: 25 [==>            ] 15.1% Loss: 0.0709, Epoch 25, Batch 18, CE_loss: 0.045678358525037766, Dice_loss: 0.004022303503006697, Consistency_loss: 0.00010876537271542475\n",
      "[Training] Epoch: 25 [==>            ] 15.9% Loss: 0.0708, Epoch 25, Batch 19, CE_loss: 0.06280520558357239, Dice_loss: 0.0058402554132044315, Consistency_loss: 0.00011077374074375257\n",
      "[Training] Epoch: 25 [==>            ] 16.7% Loss: 0.0697, Epoch 25, Batch 20, CE_loss: 0.04437607154250145, Dice_loss: 0.0037431346718221903, Consistency_loss: 0.00027690120623447\n",
      "[Training] Epoch: 25 [==>            ] 17.5% Loss: 0.0706, Epoch 25, Batch 21, CE_loss: 0.0807851031422615, Dice_loss: 0.007513417396694422, Consistency_loss: 0.0002532498328946531\n",
      "[Training] Epoch: 25 [==>            ] 18.3% Loss: 0.0701, Epoch 25, Batch 22, CE_loss: 0.05373913049697876, Dice_loss: 0.0047861384227871895, Consistency_loss: 4.30114014307037e-05\n",
      "[Training] Epoch: 25 [==>            ] 19.0% Loss: 0.0710, Epoch 25, Batch 23, CE_loss: 0.08281729370355606, Dice_loss: 0.00874417182058096, Consistency_loss: 0.00040387670742347836\n",
      "[Training] Epoch: 25 [==>            ] 19.8% Loss: 0.0710, Epoch 25, Batch 24, CE_loss: 0.06339994072914124, Dice_loss: 0.006377099547535181, Consistency_loss: 0.0003040501323994249\n",
      "[Training] Epoch: 25 [===>           ] 20.6% Loss: 0.0704, Epoch 25, Batch 25, CE_loss: 0.05078165978193283, Dice_loss: 0.004449168220162392, Consistency_loss: 0.00030439934926107526\n",
      "[Training] Epoch: 25 [===>           ] 21.4% Loss: 0.0709, Epoch 25, Batch 26, CE_loss: 0.0774102658033371, Dice_loss: 0.008084929548203945, Consistency_loss: 0.0002577505074441433\n",
      "[Training] Epoch: 25 [===>           ] 22.2% Loss: 0.0702, Epoch 25, Batch 27, CE_loss: 0.04658745601773262, Dice_loss: 0.003834910923615098, Consistency_loss: 0.000594459765125066\n",
      "[Training] Epoch: 25 [===>           ] 23.0% Loss: 0.0712, Epoch 25, Batch 28, CE_loss: 0.08788740634918213, Dice_loss: 0.00927570927888155, Consistency_loss: 0.00043462830944918096\n",
      "[Training] Epoch: 25 [===>           ] 23.8% Loss: 0.0706, Epoch 25, Batch 29, CE_loss: 0.04939420148730278, Dice_loss: 0.004627150483429432, Consistency_loss: 0.00045107732876203954\n",
      "[Training] Epoch: 25 [===>           ] 24.6% Loss: 0.0702, Epoch 25, Batch 30, CE_loss: 0.052988842129707336, Dice_loss: 0.005171934142708778, Consistency_loss: 0.0003786454035434872\n",
      "[Training] Epoch: 25 [===>           ] 25.4% Loss: 0.0703, Epoch 25, Batch 31, CE_loss: 0.0661955252289772, Dice_loss: 0.006816789973527193, Consistency_loss: 0.00013423076597973704\n",
      "[Training] Epoch: 25 [===>           ] 26.2% Loss: 0.0700, Epoch 25, Batch 32, CE_loss: 0.05509403347969055, Dice_loss: 0.0049743312411010265, Consistency_loss: 0.00033983270986936986\n",
      "[Training] Epoch: 25 [====>          ] 27.0% Loss: 0.0707, Epoch 25, Batch 33, CE_loss: 0.08583103120326996, Dice_loss: 0.007964404299855232, Consistency_loss: 0.0005683816852979362\n",
      "[Training] Epoch: 25 [====>          ] 27.8% Loss: 0.0708, Epoch 25, Batch 34, CE_loss: 0.06475906074047089, Dice_loss: 0.00656763045117259, Consistency_loss: 0.0006149167893454432\n",
      "[Training] Epoch: 25 [====>          ] 28.6% Loss: 0.0707, Epoch 25, Batch 35, CE_loss: 0.06222376599907875, Dice_loss: 0.006370108108967543, Consistency_loss: 0.00048461981350556016\n",
      "[Training] Epoch: 25 [====>          ] 29.4% Loss: 0.0701, Epoch 25, Batch 36, CE_loss: 0.045491721481084824, Dice_loss: 0.004087606444954872, Consistency_loss: 8.897004590835422e-05\n",
      "[Training] Epoch: 25 [====>          ] 30.2% Loss: 0.0696, Epoch 25, Batch 37, CE_loss: 0.04359348490834236, Dice_loss: 0.003826944623142481, Consistency_loss: 0.0006324072601273656\n",
      "[Training] Epoch: 25 [====>          ] 31.0% Loss: 0.0694, Epoch 25, Batch 38, CE_loss: 0.05749218165874481, Dice_loss: 0.00556005397811532, Consistency_loss: 0.0007623800775036216\n",
      "[Training] Epoch: 25 [====>          ] 31.7% Loss: 0.0691, Epoch 25, Batch 39, CE_loss: 0.051919594407081604, Dice_loss: 0.004930070135742426, Consistency_loss: 0.0009841452119871974\n",
      "[Training] Epoch: 25 [====>          ] 32.5% Loss: 0.0691, Epoch 25, Batch 40, CE_loss: 0.06150917708873749, Dice_loss: 0.0062061939388513565, Consistency_loss: 0.0001223289145855233\n",
      "[Training] Epoch: 25 [=====>         ] 33.3% Loss: 0.0691, Epoch 25, Batch 41, CE_loss: 0.06244226172566414, Dice_loss: 0.0060586812905967236, Consistency_loss: 0.0005893837078474462\n",
      "[Training] Epoch: 25 [=====>         ] 34.1% Loss: 0.0691, Epoch 25, Batch 42, CE_loss: 0.061784952878952026, Dice_loss: 0.005149010103195906, Consistency_loss: 0.0005826765554957092\n",
      "[Training] Epoch: 25 [=====>         ] 34.9% Loss: 0.0688, Epoch 25, Batch 43, CE_loss: 0.051718465983867645, Dice_loss: 0.005008788779377937, Consistency_loss: 0.0004138140066061169\n",
      "[Training] Epoch: 25 [=====>         ] 35.7% Loss: 0.0684, Epoch 25, Batch 44, CE_loss: 0.048026297241449356, Dice_loss: 0.004495248198509216, Consistency_loss: 0.0007992666214704514\n",
      "[Training] Epoch: 25 [=====>         ] 36.5% Loss: 0.0684, Epoch 25, Batch 45, CE_loss: 0.05905245617032051, Dice_loss: 0.00570399034768343, Consistency_loss: 0.0005294102593325078\n",
      "[Training] Epoch: 25 [=====>         ] 37.3% Loss: 0.0687, Epoch 25, Batch 46, CE_loss: 0.07586931437253952, Dice_loss: 0.007772277574986219, Consistency_loss: 0.0003949414531234652\n",
      "[Training] Epoch: 25 [=====>         ] 38.1% Loss: 0.0686, Epoch 25, Batch 47, CE_loss: 0.05553143471479416, Dice_loss: 0.005433972459286451, Consistency_loss: 0.00036427751183509827\n",
      "[Training] Epoch: 25 [=====>         ] 38.9% Loss: 0.0682, Epoch 25, Batch 48, CE_loss: 0.045208144932985306, Dice_loss: 0.0035484330728650093, Consistency_loss: 0.0007805218920111656\n",
      "[Training] Epoch: 25 [=====>         ] 39.7% Loss: 0.0679, Epoch 25, Batch 49, CE_loss: 0.04995260015130043, Dice_loss: 0.004672314506024122, Consistency_loss: 0.0003888305800501257\n",
      "[Training] Epoch: 25 [======>        ] 40.5% Loss: 0.0676, Epoch 25, Batch 50, CE_loss: 0.04686302691698074, Dice_loss: 0.004310882184654474, Consistency_loss: 0.00045290993875823915\n",
      "[Training] Epoch: 25 [======>        ] 41.3% Loss: 0.0677, Epoch 25, Batch 51, CE_loss: 0.0686422735452652, Dice_loss: 0.0070726992562413216, Consistency_loss: 0.00023541474365629256\n",
      "[Training] Epoch: 25 [======>        ] 42.1% Loss: 0.0677, Epoch 25, Batch 52, CE_loss: 0.05824653431773186, Dice_loss: 0.005554510746151209, Consistency_loss: 0.00015536847058683634\n",
      "[Training] Epoch: 25 [======>        ] 42.9% Loss: 0.0677, Epoch 25, Batch 53, CE_loss: 0.06280104070901871, Dice_loss: 0.0058214981108903885, Consistency_loss: 0.0002462102856952697\n",
      "[Training] Epoch: 25 [======>        ] 43.7% Loss: 0.0675, Epoch 25, Batch 54, CE_loss: 0.050366878509521484, Dice_loss: 0.004760930314660072, Consistency_loss: 0.00037192823947407305\n",
      "[Training] Epoch: 25 [======>        ] 44.4% Loss: 0.0677, Epoch 25, Batch 55, CE_loss: 0.07480620592832565, Dice_loss: 0.007307392545044422, Consistency_loss: 0.000372971233446151\n",
      "[Training] Epoch: 25 [======>        ] 45.2% Loss: 0.0677, Epoch 25, Batch 56, CE_loss: 0.061795659363269806, Dice_loss: 0.005772172007709742, Consistency_loss: 0.00041789226816035807\n",
      "[Training] Epoch: 25 [======>        ] 46.0% Loss: 0.0677, Epoch 25, Batch 57, CE_loss: 0.05655307695269585, Dice_loss: 0.00563820032402873, Consistency_loss: 0.00028459911118261516\n",
      "[Training] Epoch: 25 [=======>       ] 46.8% Loss: 0.0678, Epoch 25, Batch 58, CE_loss: 0.0674479678273201, Dice_loss: 0.00671766884624958, Consistency_loss: 0.00042538551497273147\n",
      "[Training] Epoch: 25 [=======>       ] 47.6% Loss: 0.0676, Epoch 25, Batch 59, CE_loss: 0.05084114894270897, Dice_loss: 0.004487501457333565, Consistency_loss: 0.0003569825494196266\n",
      "[Training] Epoch: 25 [=======>       ] 48.4% Loss: 0.0675, Epoch 25, Batch 60, CE_loss: 0.05997172370553017, Dice_loss: 0.0055413637310266495, Consistency_loss: 0.000144897450809367\n",
      "[Training] Epoch: 25 [=======>       ] 49.2% Loss: 0.0674, Epoch 25, Batch 61, CE_loss: 0.05081416293978691, Dice_loss: 0.004887436516582966, Consistency_loss: 0.000273174635367468\n",
      "[Training] Epoch: 25 [=======>       ] 50.0% Loss: 0.0670, Epoch 25, Batch 62, CE_loss: 0.04173845425248146, Dice_loss: 0.0035872759763151407, Consistency_loss: 0.0006838845438323915\n",
      "[Training] Epoch: 25 [=======>       ] 50.8% Loss: 0.0669, Epoch 25, Batch 63, CE_loss: 0.054963890463113785, Dice_loss: 0.005134016275405884, Consistency_loss: 0.0006626001559197903\n",
      "[Training] Epoch: 25 [=======>       ] 51.6% Loss: 0.0667, Epoch 25, Batch 64, CE_loss: 0.05020706728100777, Dice_loss: 0.004369086120277643, Consistency_loss: 0.0005873487098142505\n",
      "[Training] Epoch: 25 [=======>       ] 52.4% Loss: 0.0666, Epoch 25, Batch 65, CE_loss: 0.050919800996780396, Dice_loss: 0.00476248562335968, Consistency_loss: 0.0006003105663694441\n",
      "[Training] Epoch: 25 [=======>       ] 53.2% Loss: 0.0668, Epoch 25, Batch 66, CE_loss: 0.07259701937437057, Dice_loss: 0.007106312084943056, Consistency_loss: 0.00020759180188179016\n",
      "[Training] Epoch: 25 [========>      ] 54.0% Loss: 0.0668, Epoch 25, Batch 67, CE_loss: 0.062399063259363174, Dice_loss: 0.006185303907841444, Consistency_loss: 0.000271588156465441\n",
      "[Training] Epoch: 25 [========>      ] 54.8% Loss: 0.0668, Epoch 25, Batch 68, CE_loss: 0.05841916799545288, Dice_loss: 0.005707311909645796, Consistency_loss: 0.0002175839908886701\n",
      "[Training] Epoch: 25 [========>      ] 55.6% Loss: 0.0667, Epoch 25, Batch 69, CE_loss: 0.05940345302224159, Dice_loss: 0.005676998291164637, Consistency_loss: 0.0002192138199461624\n",
      "[Training] Epoch: 25 [========>      ] 56.3% Loss: 0.0666, Epoch 25, Batch 70, CE_loss: 0.049239784479141235, Dice_loss: 0.003927026875317097, Consistency_loss: 0.0005689230165444314\n",
      "[Training] Epoch: 25 [========>      ] 57.1% Loss: 0.0665, Epoch 25, Batch 71, CE_loss: 0.0543055422604084, Dice_loss: 0.00510680116713047, Consistency_loss: 0.0004371178802102804\n",
      "[Training] Epoch: 25 [========>      ] 57.9% Loss: 0.0664, Epoch 25, Batch 72, CE_loss: 0.05701924115419388, Dice_loss: 0.0053803506307303905, Consistency_loss: 0.0003956021391786635\n",
      "[Training] Epoch: 25 [========>      ] 58.7% Loss: 0.0666, Epoch 25, Batch 73, CE_loss: 0.06861744076013565, Dice_loss: 0.00707907835021615, Consistency_loss: 0.0005017327493987978\n",
      "[Training] Epoch: 25 [========>      ] 59.5% Loss: 0.0664, Epoch 25, Batch 74, CE_loss: 0.05235923081636429, Dice_loss: 0.0046082185581326485, Consistency_loss: 0.00024989069788716733\n",
      "[Training] Epoch: 25 [=========>     ] 60.3% Loss: 0.0663, Epoch 25, Batch 75, CE_loss: 0.0485808327794075, Dice_loss: 0.004563300404697657, Consistency_loss: 0.0007578416261821985\n",
      "[Training] Epoch: 25 [=========>     ] 61.1% Loss: 0.0663, Epoch 25, Batch 76, CE_loss: 0.06324918568134308, Dice_loss: 0.006221728399395943, Consistency_loss: 0.0004597742226906121\n",
      "[Training] Epoch: 25 [=========>     ] 61.9% Loss: 0.0665, Epoch 25, Batch 77, CE_loss: 0.07609012722969055, Dice_loss: 0.006925732363015413, Consistency_loss: 0.0004650808987207711\n",
      "[Training] Epoch: 25 [=========>     ] 62.7% Loss: 0.0665, Epoch 25, Batch 78, CE_loss: 0.0592334046959877, Dice_loss: 0.006041497457772493, Consistency_loss: 0.0005221439641900361\n",
      "[Training] Epoch: 25 [=========>     ] 63.5% Loss: 0.0665, Epoch 25, Batch 79, CE_loss: 0.05974046513438225, Dice_loss: 0.0055134776048362255, Consistency_loss: 0.00044933773460797966\n",
      "[Training] Epoch: 25 [=========>     ] 64.3% Loss: 0.0667, Epoch 25, Batch 80, CE_loss: 0.07101374119520187, Dice_loss: 0.007605493534356356, Consistency_loss: 0.00047991221072152257\n",
      "[Training] Epoch: 25 [=========>     ] 65.1% Loss: 0.0666, Epoch 25, Batch 81, CE_loss: 0.05186496675014496, Dice_loss: 0.004920534789562225, Consistency_loss: 0.0006272154278121889\n",
      "[Training] Epoch: 25 [=========>     ] 65.9% Loss: 0.0666, Epoch 25, Batch 82, CE_loss: 0.06030532717704773, Dice_loss: 0.006143327336758375, Consistency_loss: 0.0005838023498654366\n",
      "[Training] Epoch: 25 [==========>    ] 66.7% Loss: 0.0664, Epoch 25, Batch 83, CE_loss: 0.04886344447731972, Dice_loss: 0.004583783447742462, Consistency_loss: 0.00020670621597673744\n",
      "[Training] Epoch: 25 [==========>    ] 67.5% Loss: 0.0663, Epoch 25, Batch 84, CE_loss: 0.04877954348921776, Dice_loss: 0.004596448037773371, Consistency_loss: 0.0002523302973713726\n",
      "[Training] Epoch: 25 [==========>    ] 68.3% Loss: 0.0665, Epoch 25, Batch 85, CE_loss: 0.08230020105838776, Dice_loss: 0.008473474532365799, Consistency_loss: 0.0001906107208924368\n",
      "[Training] Epoch: 25 [==========>    ] 69.0% Loss: 0.0665, Epoch 25, Batch 86, CE_loss: 0.05454472079873085, Dice_loss: 0.00505613861605525, Consistency_loss: 0.0004062283260282129\n",
      "[Training] Epoch: 25 [==========>    ] 69.8% Loss: 0.0666, Epoch 25, Batch 87, CE_loss: 0.071929432451725, Dice_loss: 0.007454525213688612, Consistency_loss: 0.00037906033685430884\n",
      "[Training] Epoch: 25 [==========>    ] 70.6% Loss: 0.0668, Epoch 25, Batch 88, CE_loss: 0.07115329056978226, Dice_loss: 0.007508504670113325, Consistency_loss: 0.00029906004783697426\n",
      "[Training] Epoch: 25 [==========>    ] 71.4% Loss: 0.0668, Epoch 25, Batch 89, CE_loss: 0.06717251241207123, Dice_loss: 0.006248076446354389, Consistency_loss: 9.302535181632265e-05\n",
      "[Training] Epoch: 25 [==========>    ] 72.2% Loss: 0.0668, Epoch 25, Batch 90, CE_loss: 0.05399268865585327, Dice_loss: 0.005287371575832367, Consistency_loss: 0.0005356284091249108\n",
      "[Training] Epoch: 25 [==========>    ] 73.0% Loss: 0.0665, Epoch 25, Batch 91, CE_loss: 0.043246474117040634, Dice_loss: 0.003846430918201804, Consistency_loss: 0.0005662125768139958\n",
      "[Training] Epoch: 25 [===========>   ] 73.8% Loss: 0.0667, Epoch 25, Batch 92, CE_loss: 0.07491897791624069, Dice_loss: 0.007771423552185297, Consistency_loss: 6.969977403059602e-05\n",
      "[Training] Epoch: 25 [===========>   ] 74.6% Loss: 0.0668, Epoch 25, Batch 93, CE_loss: 0.06686603277921677, Dice_loss: 0.006833343300968409, Consistency_loss: 0.00038956740172579885\n",
      "[Training] Epoch: 25 [===========>   ] 75.4% Loss: 0.0669, Epoch 25, Batch 94, CE_loss: 0.07131730020046234, Dice_loss: 0.007108537945896387, Consistency_loss: 0.0003596511378418654\n",
      "[Training] Epoch: 25 [===========>   ] 76.2% Loss: 0.0672, Epoch 25, Batch 95, CE_loss: 0.08060836046934128, Dice_loss: 0.00868387520313263, Consistency_loss: 8.254271233454347e-05\n",
      "[Training] Epoch: 25 [===========>   ] 77.0% Loss: 0.0669, Epoch 25, Batch 96, CE_loss: 0.03903782367706299, Dice_loss: 0.003134925849735737, Consistency_loss: 0.0002686418010853231\n",
      "[Training] Epoch: 25 [===========>   ] 77.8% Loss: 0.0670, Epoch 25, Batch 97, CE_loss: 0.06970363110303879, Dice_loss: 0.0066805738024413586, Consistency_loss: 0.00029546889709308743\n",
      "[Training] Epoch: 25 [===========>   ] 78.6% Loss: 0.0671, Epoch 25, Batch 98, CE_loss: 0.06890720874071121, Dice_loss: 0.007234342861920595, Consistency_loss: 0.000399171985918656\n",
      "[Training] Epoch: 25 [===========>   ] 79.4% Loss: 0.0670, Epoch 25, Batch 99, CE_loss: 0.04813039302825928, Dice_loss: 0.0039971936494112015, Consistency_loss: 0.0003937178698834032\n",
      "[Training] Epoch: 25 [============>  ] 80.2% Loss: 0.0670, Epoch 25, Batch 100, CE_loss: 0.06455107033252716, Dice_loss: 0.006461692042648792, Consistency_loss: 0.0004166914732195437\n",
      "[Training] Epoch: 25 [============>  ] 81.0% Loss: 0.0670, Epoch 25, Batch 101, CE_loss: 0.05917227268218994, Dice_loss: 0.006004482973366976, Consistency_loss: 0.000500293099321425\n",
      "[Training] Epoch: 25 [============>  ] 81.7% Loss: 0.0670, Epoch 25, Batch 102, CE_loss: 0.0603453554213047, Dice_loss: 0.0061537702567875385, Consistency_loss: 0.0005788449198007584\n",
      "[Training] Epoch: 25 [============>  ] 82.5% Loss: 0.0671, Epoch 25, Batch 103, CE_loss: 0.07410755753517151, Dice_loss: 0.007480234373360872, Consistency_loss: 0.00025772140361368656\n",
      "[Training] Epoch: 25 [============>  ] 83.3% Loss: 0.0673, Epoch 25, Batch 104, CE_loss: 0.08019454032182693, Dice_loss: 0.008438820019364357, Consistency_loss: 0.0004311558441258967\n",
      "[Training] Epoch: 25 [============>  ] 84.1% Loss: 0.0674, Epoch 25, Batch 105, CE_loss: 0.06847356259822845, Dice_loss: 0.007080513518303633, Consistency_loss: 0.00030924356542527676\n",
      "[Training] Epoch: 25 [============>  ] 84.9% Loss: 0.0673, Epoch 25, Batch 106, CE_loss: 0.053558994084596634, Dice_loss: 0.005246852524578571, Consistency_loss: 0.0005571413785219193\n",
      "[Training] Epoch: 25 [============>  ] 85.7% Loss: 0.0674, Epoch 25, Batch 107, CE_loss: 0.06302402168512344, Dice_loss: 0.006473627872765064, Consistency_loss: 0.0007235488737933338\n",
      "[Training] Epoch: 25 [============>  ] 86.5% Loss: 0.0675, Epoch 25, Batch 108, CE_loss: 0.06881970912218094, Dice_loss: 0.007356088142842054, Consistency_loss: 0.00037491286639124155\n",
      "[Training] Epoch: 25 [=============> ] 87.3% Loss: 0.0677, Epoch 25, Batch 109, CE_loss: 0.08774569630622864, Dice_loss: 0.008881022222340107, Consistency_loss: 0.000408094929298386\n",
      "[Training] Epoch: 25 [=============> ] 88.1% Loss: 0.0679, Epoch 25, Batch 110, CE_loss: 0.07580485194921494, Dice_loss: 0.00793327298015356, Consistency_loss: 0.00040371506474912167\n",
      "[Training] Epoch: 25 [=============> ] 88.9% Loss: 0.0678, Epoch 25, Batch 111, CE_loss: 0.05714387819170952, Dice_loss: 0.005779592785984278, Consistency_loss: 0.00034567934926599264\n",
      "[Training] Epoch: 25 [=============> ] 89.7% Loss: 0.0678, Epoch 25, Batch 112, CE_loss: 0.05902974680066109, Dice_loss: 0.0054505798034369946, Consistency_loss: 0.0005335527821443975\n",
      "[Training] Epoch: 25 [=============> ] 90.5% Loss: 0.0676, Epoch 25, Batch 113, CE_loss: 0.0380585603415966, Dice_loss: 0.0032181725837290287, Consistency_loss: 0.000653980765491724\n",
      "[Training] Epoch: 25 [=============> ] 91.3% Loss: 0.0677, Epoch 25, Batch 114, CE_loss: 0.07240493595600128, Dice_loss: 0.007770440075546503, Consistency_loss: 0.0003426399198360741\n",
      "[Training] Epoch: 25 [=============> ] 92.1% Loss: 0.0676, Epoch 25, Batch 115, CE_loss: 0.056156329810619354, Dice_loss: 0.005632746499031782, Consistency_loss: 0.0003191096184309572\n",
      "[Training] Epoch: 25 [=============> ] 92.9% Loss: 0.0676, Epoch 25, Batch 116, CE_loss: 0.056048475205898285, Dice_loss: 0.005408003926277161, Consistency_loss: 0.00044601867557503283\n",
      "[Training] Epoch: 25 [==============>] 93.7% Loss: 0.0675, Epoch 25, Batch 117, CE_loss: 0.05356193706393242, Dice_loss: 0.0052098557353019714, Consistency_loss: 0.00040694596827961504\n",
      "[Training] Epoch: 25 [==============>] 94.4% Loss: 0.0673, Epoch 25, Batch 118, CE_loss: 0.04231433570384979, Dice_loss: 0.0034324408043175936, Consistency_loss: 9.53846174525097e-05\n",
      "[Training] Epoch: 25 [==============>] 95.2% Loss: 0.0673, Epoch 25, Batch 119, CE_loss: 0.06006008759140968, Dice_loss: 0.0058634658344089985, Consistency_loss: 0.00037428861833177507\n",
      "[Training] Epoch: 25 [==============>] 96.0% Loss: 0.0673, Epoch 25, Batch 120, CE_loss: 0.056205760687589645, Dice_loss: 0.005498327314853668, Consistency_loss: 0.0004984047845937312\n",
      "[Training] Epoch: 25 [==============>] 96.8% Loss: 0.0671, Epoch 25, Batch 121, CE_loss: 0.04283611848950386, Dice_loss: 0.0032674672547727823, Consistency_loss: 0.0003528479428496212\n",
      "[Training] Epoch: 25 [==============>] 97.6% Loss: 0.0671, Epoch 25, Batch 122, CE_loss: 0.0527522973716259, Dice_loss: 0.005186798050999641, Consistency_loss: 0.000646545086055994\n",
      "[Training] Epoch: 25 [==============>] 98.4% Loss: 0.0669, Epoch 25, Batch 123, CE_loss: 0.04397593066096306, Dice_loss: 0.0037163214292377234, Consistency_loss: 0.0005625037592835724\n",
      "[Training] Epoch: 25 [==============>] 99.2% Loss: 0.0669, Epoch 25, Batch 124, CE_loss: 0.06417828798294067, Dice_loss: 0.006098243873566389, Consistency_loss: 0.0005418517393991351\n",
      "[Training] Epoch: 25 [DONE]                                 \n",
      "Epoch 25, Batch 125, CE_loss: 0.0622432678937912, Dice_loss: 0.0063626826740801334, Consistency_loss: 9.99885014607571e-05\n",
      "[Validation] Epoch: 25 [DONE]                                 \n",
      "[Epoch: 25, TrainLoss: 0.0669, TrainDice: 0.0059, ValLoss: 0.1405                                            \n",
      "Number of batches:  126\n",
      "[Training] Epoch: 26 [>              ] 0.8% Loss: 0.0673, Epoch 26, Batch 0, CE_loss: 0.060851436108350754, Dice_loss: 0.006330755539238453, Consistency_loss: 7.372141408268362e-05\n",
      "[Training] Epoch: 26 [>              ] 1.6% Loss: 0.0612, Epoch 26, Batch 1, CE_loss: 0.05002737045288086, Dice_loss: 0.004713915288448334, Consistency_loss: 0.00033708763658069074\n",
      "[Training] Epoch: 26 [>              ] 2.4% Loss: 0.0627, Epoch 26, Batch 2, CE_loss: 0.05930919945240021, Dice_loss: 0.006018559914082289, Consistency_loss: 0.0003354494401719421\n",
      "[Training] Epoch: 26 [>              ] 3.2% Loss: 0.0649, Epoch 26, Batch 3, CE_loss: 0.06539971381425858, Dice_loss: 0.005757169798016548, Consistency_loss: 0.0003352276689838618\n",
      "[Training] Epoch: 26 [>              ] 4.0% Loss: 0.0666, Epoch 26, Batch 4, CE_loss: 0.06663281470537186, Dice_loss: 0.006351234391331673, Consistency_loss: 0.00036059212288819253\n",
      "[Training] Epoch: 26 [>              ] 4.8% Loss: 0.0676, Epoch 26, Batch 5, CE_loss: 0.06563784182071686, Dice_loss: 0.006868216674774885, Consistency_loss: 9.150531695922837e-05\n",
      "[Training] Epoch: 26 [>              ] 5.6% Loss: 0.0661, Epoch 26, Batch 6, CE_loss: 0.05188920348882675, Dice_loss: 0.004912215750664473, Consistency_loss: 0.00012839633563999087\n",
      "[Training] Epoch: 26 [>              ] 6.3% Loss: 0.0653, Epoch 26, Batch 7, CE_loss: 0.05432866886258125, Dice_loss: 0.005310840904712677, Consistency_loss: 0.00035486495471559465\n",
      "[Training] Epoch: 26 [=>             ] 7.1% Loss: 0.0631, Epoch 26, Batch 8, CE_loss: 0.0421236976981163, Dice_loss: 0.003663790412247181, Consistency_loss: 0.00013533959281630814\n",
      "[Training] Epoch: 26 [=>             ] 7.9% Loss: 0.0633, Epoch 26, Batch 9, CE_loss: 0.058359719812870026, Dice_loss: 0.005879286210983992, Consistency_loss: 0.0001499211648479104\n",
      "[Training] Epoch: 26 [=>             ] 8.7% Loss: 0.0663, Epoch 26, Batch 10, CE_loss: 0.08766376227140427, Dice_loss: 0.008340820670127869, Consistency_loss: 0.00040347236790694296\n",
      "[Training] Epoch: 26 [=>             ] 9.5% Loss: 0.0655, Epoch 26, Batch 11, CE_loss: 0.05207221210002899, Dice_loss: 0.005048820748925209, Consistency_loss: 0.0003897641145158559\n",
      "[Training] Epoch: 26 [=>             ] 10.3% Loss: 0.0636, Epoch 26, Batch 12, CE_loss: 0.03716813400387764, Dice_loss: 0.0030149193480610847, Consistency_loss: 0.00046619607019238174\n",
      "[Training] Epoch: 26 [=>             ] 11.1% Loss: 0.0633, Epoch 26, Batch 13, CE_loss: 0.054156191647052765, Dice_loss: 0.005008211825042963, Consistency_loss: 0.0004589503805618733\n",
      "[Training] Epoch: 26 [=>             ] 11.9% Loss: 0.0654, Epoch 26, Batch 14, CE_loss: 0.08513316512107849, Dice_loss: 0.008573019877076149, Consistency_loss: 0.0004338518774602562\n",
      "[Training] Epoch: 26 [=>             ] 12.7% Loss: 0.0648, Epoch 26, Batch 15, CE_loss: 0.05056559294462204, Dice_loss: 0.004784564953297377, Consistency_loss: 0.00042868286254815757\n",
      "[Training] Epoch: 26 [==>            ] 13.5% Loss: 0.0638, Epoch 26, Batch 16, CE_loss: 0.04304422065615654, Dice_loss: 0.003904214594513178, Consistency_loss: 0.0004205518926028162\n",
      "[Training] Epoch: 26 [==>            ] 14.3% Loss: 0.0642, Epoch 26, Batch 17, CE_loss: 0.06441204994916916, Dice_loss: 0.006665951106697321, Consistency_loss: 0.0005198855069465935\n",
      "[Training] Epoch: 26 [==>            ] 15.1% Loss: 0.0643, Epoch 26, Batch 18, CE_loss: 0.05914575979113579, Dice_loss: 0.005804644897580147, Consistency_loss: 0.0004941400839015841\n",
      "[Training] Epoch: 26 [==>            ] 15.9% Loss: 0.0643, Epoch 26, Batch 19, CE_loss: 0.0580902025103569, Dice_loss: 0.005907909944653511, Consistency_loss: 0.00034716466325335205\n",
      "[Training] Epoch: 26 [==>            ] 16.7% Loss: 0.0654, Epoch 26, Batch 20, CE_loss: 0.07919225096702576, Dice_loss: 0.008149955421686172, Consistency_loss: 0.0003949921519961208\n",
      "[Training] Epoch: 26 [==>            ] 17.5% Loss: 0.0649, Epoch 26, Batch 21, CE_loss: 0.04896243289113045, Dice_loss: 0.004586733877658844, Consistency_loss: 0.00026630135835148394\n",
      "[Training] Epoch: 26 [==>            ] 18.3% Loss: 0.0643, Epoch 26, Batch 22, CE_loss: 0.04802924394607544, Dice_loss: 0.00416561821475625, Consistency_loss: 0.0002802818489726633\n",
      "[Training] Epoch: 26 [==>            ] 19.0% Loss: 0.0642, Epoch 26, Batch 23, CE_loss: 0.05464963987469673, Dice_loss: 0.00539833027869463, Consistency_loss: 0.00041279607103206217\n",
      "[Training] Epoch: 26 [==>            ] 19.8% Loss: 0.0635, Epoch 26, Batch 24, CE_loss: 0.04414603114128113, Dice_loss: 0.00403277762234211, Consistency_loss: 6.167124229250476e-05\n",
      "[Training] Epoch: 26 [===>           ] 20.6% Loss: 0.0644, Epoch 26, Batch 25, CE_loss: 0.07847461849451065, Dice_loss: 0.0080273961648345, Consistency_loss: 0.00032025662949308753\n",
      "[Training] Epoch: 26 [===>           ] 21.4% Loss: 0.0644, Epoch 26, Batch 26, CE_loss: 0.05645288899540901, Dice_loss: 0.005738027393817902, Consistency_loss: 0.0006314352503977716\n",
      "[Training] Epoch: 26 [===>           ] 22.2% Loss: 0.0642, Epoch 26, Batch 27, CE_loss: 0.05401437729597092, Dice_loss: 0.005086394026875496, Consistency_loss: 0.00017774150182958692\n",
      "[Training] Epoch: 26 [===>           ] 23.0% Loss: 0.0642, Epoch 26, Batch 28, CE_loss: 0.05896228551864624, Dice_loss: 0.005735452752560377, Consistency_loss: 0.0005730403354391456\n",
      "[Training] Epoch: 26 [===>           ] 23.8% Loss: 0.0651, Epoch 26, Batch 29, CE_loss: 0.08001107722520828, Dice_loss: 0.008611835539340973, Consistency_loss: 0.00048066311865113676\n",
      "[Training] Epoch: 26 [===>           ] 24.6% Loss: 0.0649, Epoch 26, Batch 30, CE_loss: 0.0549180768430233, Dice_loss: 0.005563849583268166, Consistency_loss: 0.00046474795090034604\n",
      "[Training] Epoch: 26 [===>           ] 25.4% Loss: 0.0650, Epoch 26, Batch 31, CE_loss: 0.06049875169992447, Dice_loss: 0.006046240217983723, Consistency_loss: 0.00011929508036701009\n",
      "[Training] Epoch: 26 [===>           ] 26.2% Loss: 0.0651, Epoch 26, Batch 32, CE_loss: 0.06229087710380554, Dice_loss: 0.006437637377530336, Consistency_loss: 3.332982669235207e-05\n",
      "[Training] Epoch: 26 [====>          ] 27.0% Loss: 0.0650, Epoch 26, Batch 33, CE_loss: 0.05761828273534775, Dice_loss: 0.005854109302163124, Consistency_loss: 0.000287030910840258\n",
      "[Training] Epoch: 26 [====>          ] 27.8% Loss: 0.0650, Epoch 26, Batch 34, CE_loss: 0.05608786270022392, Dice_loss: 0.004999713972210884, Consistency_loss: 0.0006782670971006155\n",
      "[Training] Epoch: 26 [====>          ] 28.6% Loss: 0.0646, Epoch 26, Batch 35, CE_loss: 0.04750393331050873, Dice_loss: 0.004272209480404854, Consistency_loss: 0.00038736345595680177\n",
      "[Training] Epoch: 26 [====>          ] 29.4% Loss: 0.0655, Epoch 26, Batch 36, CE_loss: 0.08842206001281738, Dice_loss: 0.00985841453075409, Consistency_loss: 0.00037462692125700414\n",
      "[Training] Epoch: 26 [====>          ] 30.2% Loss: 0.0652, Epoch 26, Batch 37, CE_loss: 0.04916008189320564, Dice_loss: 0.00440276600420475, Consistency_loss: 0.00040964153595268726\n",
      "[Training] Epoch: 26 [====>          ] 31.0% Loss: 0.0651, Epoch 26, Batch 38, CE_loss: 0.05549206584692001, Dice_loss: 0.0053441631607711315, Consistency_loss: 6.552658305736259e-05\n",
      "[Training] Epoch: 26 [====>          ] 31.7% Loss: 0.0651, Epoch 26, Batch 39, CE_loss: 0.059286121279001236, Dice_loss: 0.005961697082966566, Consistency_loss: 9.742230031406507e-05\n",
      "[Training] Epoch: 26 [====>          ] 32.5% Loss: 0.0654, Epoch 26, Batch 40, CE_loss: 0.06800901144742966, Dice_loss: 0.006754388101398945, Consistency_loss: 0.000101236037153285\n",
      "[Training] Epoch: 26 [=====>         ] 33.3% Loss: 0.0654, Epoch 26, Batch 41, CE_loss: 0.060167424380779266, Dice_loss: 0.006119777448475361, Consistency_loss: 0.00037987178075127304\n",
      "[Training] Epoch: 26 [=====>         ] 34.1% Loss: 0.0649, Epoch 26, Batch 42, CE_loss: 0.04181944951415062, Dice_loss: 0.003415449056774378, Consistency_loss: 0.0006712136091664433\n",
      "[Training] Epoch: 26 [=====>         ] 34.9% Loss: 0.0649, Epoch 26, Batch 43, CE_loss: 0.05704377964138985, Dice_loss: 0.005386962089687586, Consistency_loss: 0.00034166962723247707\n",
      "[Training] Epoch: 26 [=====>         ] 35.7% Loss: 0.0647, Epoch 26, Batch 44, CE_loss: 0.05118285119533539, Dice_loss: 0.004881709814071655, Consistency_loss: 0.00047964678378775716\n",
      "[Training] Epoch: 26 [=====>         ] 36.5% Loss: 0.0652, Epoch 26, Batch 45, CE_loss: 0.07831928133964539, Dice_loss: 0.00846167653799057, Consistency_loss: 0.00012748860171996057\n",
      "[Training] Epoch: 26 [=====>         ] 37.3% Loss: 0.0650, Epoch 26, Batch 46, CE_loss: 0.05161939933896065, Dice_loss: 0.004839465022087097, Consistency_loss: 4.303923196857795e-05\n",
      "[Training] Epoch: 26 [=====>         ] 38.1% Loss: 0.0646, Epoch 26, Batch 47, CE_loss: 0.04372715577483177, Dice_loss: 0.003828460117802024, Consistency_loss: 0.00047018687473610044\n",
      "[Training] Epoch: 26 [=====>         ] 38.9% Loss: 0.0650, Epoch 26, Batch 48, CE_loss: 0.07374689728021622, Dice_loss: 0.007279278710484505, Consistency_loss: 0.0006010722718201578\n",
      "[Training] Epoch: 26 [=====>         ] 39.7% Loss: 0.0650, Epoch 26, Batch 49, CE_loss: 0.060487646609544754, Dice_loss: 0.005918384063988924, Consistency_loss: 0.0001068739002221264\n",
      "[Training] Epoch: 26 [======>        ] 40.5% Loss: 0.0651, Epoch 26, Batch 50, CE_loss: 0.06484124064445496, Dice_loss: 0.006346169393509626, Consistency_loss: 0.00031266346923075616\n",
      "[Training] Epoch: 26 [======>        ] 41.3% Loss: 0.0652, Epoch 26, Batch 51, CE_loss: 0.05998436361551285, Dice_loss: 0.005756288766860962, Consistency_loss: 0.0007111116428859532\n",
      "[Training] Epoch: 26 [======>        ] 42.1% Loss: 0.0654, Epoch 26, Batch 52, CE_loss: 0.06893232464790344, Dice_loss: 0.006966582033783197, Consistency_loss: 2.6364936275058426e-05\n",
      "[Training] Epoch: 26 [======>        ] 42.9% Loss: 0.0653, Epoch 26, Batch 53, CE_loss: 0.05772466957569122, Dice_loss: 0.005676019471138716, Consistency_loss: 0.00018068937060888857\n",
      "[Training] Epoch: 26 [======>        ] 43.7% Loss: 0.0655, Epoch 26, Batch 54, CE_loss: 0.06596416980028152, Dice_loss: 0.006701776757836342, Consistency_loss: 0.00038170424522832036\n",
      "[Training] Epoch: 26 [======>        ] 44.4% Loss: 0.0651, Epoch 26, Batch 55, CE_loss: 0.04213203862309456, Dice_loss: 0.0034247341100126505, Consistency_loss: 0.0003518536395858973\n",
      "[Training] Epoch: 26 [======>        ] 45.2% Loss: 0.0650, Epoch 26, Batch 56, CE_loss: 0.05274862051010132, Dice_loss: 0.005240097641944885, Consistency_loss: 0.00042600836604833603\n",
      "[Training] Epoch: 26 [======>        ] 46.0% Loss: 0.0653, Epoch 26, Batch 57, CE_loss: 0.07578177005052567, Dice_loss: 0.007661426439881325, Consistency_loss: 0.00031758807017467916\n",
      "[Training] Epoch: 26 [=======>       ] 46.8% Loss: 0.0651, Epoch 26, Batch 58, CE_loss: 0.04618073254823685, Dice_loss: 0.0043552774004638195, Consistency_loss: 0.00031626931740902364\n",
      "[Training] Epoch: 26 [=======>       ] 47.6% Loss: 0.0652, Epoch 26, Batch 59, CE_loss: 0.06335142999887466, Dice_loss: 0.006667413283139467, Consistency_loss: 0.0003648292913567275\n",
      "[Training] Epoch: 26 [=======>       ] 48.4% Loss: 0.0651, Epoch 26, Batch 60, CE_loss: 0.05446259677410126, Dice_loss: 0.005229252856224775, Consistency_loss: 6.136450974736363e-05\n",
      "[Training] Epoch: 26 [=======>       ] 49.2% Loss: 0.0651, Epoch 26, Batch 61, CE_loss: 0.06085791438817978, Dice_loss: 0.006224500015377998, Consistency_loss: 0.0003953012637794018\n",
      "[Training] Epoch: 26 [=======>       ] 50.0% Loss: 0.0654, Epoch 26, Batch 62, CE_loss: 0.07699552923440933, Dice_loss: 0.008210367523133755, Consistency_loss: 7.231026393128559e-05\n",
      "[Training] Epoch: 26 [=======>       ] 50.8% Loss: 0.0653, Epoch 26, Batch 63, CE_loss: 0.0485137477517128, Dice_loss: 0.004634401295334101, Consistency_loss: 0.0005939243128523231\n",
      "[Training] Epoch: 26 [=======>       ] 51.6% Loss: 0.0656, Epoch 26, Batch 64, CE_loss: 0.07903513312339783, Dice_loss: 0.008190733380615711, Consistency_loss: 0.0006069552036933601\n",
      "[Training] Epoch: 26 [=======>       ] 52.4% Loss: 0.0657, Epoch 26, Batch 65, CE_loss: 0.06428985297679901, Dice_loss: 0.006141847465187311, Consistency_loss: 0.0005712659331038594\n",
      "[Training] Epoch: 26 [=======>       ] 53.2% Loss: 0.0656, Epoch 26, Batch 66, CE_loss: 0.05644307658076286, Dice_loss: 0.0045415968634188175, Consistency_loss: 0.00020652356033679098\n",
      "[Training] Epoch: 26 [========>      ] 54.0% Loss: 0.0656, Epoch 26, Batch 67, CE_loss: 0.05482525750994682, Dice_loss: 0.0054870666936039925, Consistency_loss: 0.0003367335884831846\n",
      "[Training] Epoch: 26 [========>      ] 54.8% Loss: 0.0654, Epoch 26, Batch 68, CE_loss: 0.05201464518904686, Dice_loss: 0.005097154062241316, Consistency_loss: 6.136483716545627e-05\n",
      "[Training] Epoch: 26 [========>      ] 55.6% Loss: 0.0655, Epoch 26, Batch 69, CE_loss: 0.06142018362879753, Dice_loss: 0.0062213619239628315, Consistency_loss: 0.0002776838082354516\n",
      "[Training] Epoch: 26 [========>      ] 56.3% Loss: 0.0655, Epoch 26, Batch 70, CE_loss: 0.06121201068162918, Dice_loss: 0.006404109764844179, Consistency_loss: 0.0006855336832813919\n",
      "[Training] Epoch: 26 [========>      ] 57.1% Loss: 0.0656, Epoch 26, Batch 71, CE_loss: 0.06769707798957825, Dice_loss: 0.00601445185020566, Consistency_loss: 0.0004656029923353344\n",
      "[Training] Epoch: 26 [========>      ] 57.9% Loss: 0.0655, Epoch 26, Batch 72, CE_loss: 0.050574034452438354, Dice_loss: 0.004806353244930506, Consistency_loss: 8.705836080480367e-05\n",
      "[Training] Epoch: 26 [========>      ] 58.7% Loss: 0.0655, Epoch 26, Batch 73, CE_loss: 0.056685302406549454, Dice_loss: 0.005778184626251459, Consistency_loss: 0.00037921674083918333\n",
      "[Training] Epoch: 26 [========>      ] 59.5% Loss: 0.0653, Epoch 26, Batch 74, CE_loss: 0.04996850714087486, Dice_loss: 0.004922452848404646, Consistency_loss: 0.0005242784391157329\n",
      "[Training] Epoch: 26 [=========>     ] 60.3% Loss: 0.0653, Epoch 26, Batch 75, CE_loss: 0.05648810788989067, Dice_loss: 0.005596867296844721, Consistency_loss: 0.0006972537375986576\n",
      "[Training] Epoch: 26 [=========>     ] 61.1% Loss: 0.0651, Epoch 26, Batch 76, CE_loss: 0.04681185632944107, Dice_loss: 0.004021748900413513, Consistency_loss: 0.0004166717117186636\n",
      "[Training] Epoch: 26 [=========>     ] 61.9% Loss: 0.0651, Epoch 26, Batch 77, CE_loss: 0.0599653385579586, Dice_loss: 0.005808507092297077, Consistency_loss: 0.0004014250880572945\n",
      "[Training] Epoch: 26 [=========>     ] 62.7% Loss: 0.0652, Epoch 26, Batch 78, CE_loss: 0.06400742381811142, Dice_loss: 0.006772193592041731, Consistency_loss: 0.00022827529755886644\n",
      "[Training] Epoch: 26 [=========>     ] 63.5% Loss: 0.0654, Epoch 26, Batch 79, CE_loss: 0.07173120230436325, Dice_loss: 0.007720904424786568, Consistency_loss: 0.00022809112851973623\n",
      "[Training] Epoch: 26 [=========>     ] 64.3% Loss: 0.0654, Epoch 26, Batch 80, CE_loss: 0.061386000365018845, Dice_loss: 0.006220941431820393, Consistency_loss: 0.0004362165927886963\n",
      "[Training] Epoch: 26 [=========>     ] 65.1% Loss: 0.0653, Epoch 26, Batch 81, CE_loss: 0.04956861957907677, Dice_loss: 0.004587708506733179, Consistency_loss: 8.318813343066722e-05\n",
      "[Training] Epoch: 26 [=========>     ] 65.9% Loss: 0.0652, Epoch 26, Batch 82, CE_loss: 0.056661207228899, Dice_loss: 0.005309486761689186, Consistency_loss: 0.000567832263186574\n",
      "[Training] Epoch: 26 [==========>    ] 66.7% Loss: 0.0651, Epoch 26, Batch 83, CE_loss: 0.050602447241544724, Dice_loss: 0.004624302964657545, Consistency_loss: 4.746250851894729e-05\n",
      "[Training] Epoch: 26 [==========>    ] 67.5% Loss: 0.0651, Epoch 26, Batch 84, CE_loss: 0.05603405460715294, Dice_loss: 0.0056027816608548164, Consistency_loss: 5.7820609072223306e-05\n",
      "[Training] Epoch: 26 [==========>    ] 68.3% Loss: 0.0651, Epoch 26, Batch 85, CE_loss: 0.057298123836517334, Dice_loss: 0.0057558463886380196, Consistency_loss: 0.00038851084536872804\n",
      "[Training] Epoch: 26 [==========>    ] 69.0% Loss: 0.0652, Epoch 26, Batch 86, CE_loss: 0.07136808335781097, Dice_loss: 0.007504892535507679, Consistency_loss: 0.00046945709618739784\n",
      "[Training] Epoch: 26 [==========>    ] 69.8% Loss: 0.0655, Epoch 26, Batch 87, CE_loss: 0.07885587215423584, Dice_loss: 0.007415574975311756, Consistency_loss: 0.0003060195886064321\n",
      "[Training] Epoch: 26 [==========>    ] 70.6% Loss: 0.0654, Epoch 26, Batch 88, CE_loss: 0.05472531542181969, Dice_loss: 0.005540138576179743, Consistency_loss: 0.00031925278017297387\n",
      "[Training] Epoch: 26 [==========>    ] 71.4% Loss: 0.0652, Epoch 26, Batch 89, CE_loss: 0.044753871858119965, Dice_loss: 0.004127499647438526, Consistency_loss: 0.00037280292599461973\n",
      "[Training] Epoch: 26 [==========>    ] 72.2% Loss: 0.0651, Epoch 26, Batch 90, CE_loss: 0.04956376925110817, Dice_loss: 0.004788047168403864, Consistency_loss: 0.0004576632345560938\n",
      "[Training] Epoch: 26 [==========>    ] 73.0% Loss: 0.0650, Epoch 26, Batch 91, CE_loss: 0.05234958231449127, Dice_loss: 0.005059240851551294, Consistency_loss: 0.0005316594033502042\n",
      "[Training] Epoch: 26 [===========>   ] 73.8% Loss: 0.0654, Epoch 26, Batch 92, CE_loss: 0.08619450777769089, Dice_loss: 0.008496062830090523, Consistency_loss: 0.000553500431124121\n",
      "[Training] Epoch: 26 [===========>   ] 74.6% Loss: 0.0653, Epoch 26, Batch 93, CE_loss: 0.05099092423915863, Dice_loss: 0.0050329286605119705, Consistency_loss: 7.30948377167806e-05\n",
      "[Training] Epoch: 26 [===========>   ] 75.4% Loss: 0.0652, Epoch 26, Batch 94, CE_loss: 0.052680615335702896, Dice_loss: 0.005336214788258076, Consistency_loss: 0.00014530272164847702\n",
      "[Training] Epoch: 26 [===========>   ] 76.2% Loss: 0.0651, Epoch 26, Batch 95, CE_loss: 0.04723913595080376, Dice_loss: 0.004595974460244179, Consistency_loss: 0.0005004403064958751\n",
      "[Training] Epoch: 26 [===========>   ] 77.0% Loss: 0.0649, Epoch 26, Batch 96, CE_loss: 0.04472386837005615, Dice_loss: 0.004155810456722975, Consistency_loss: 0.0002530970668885857\n",
      "[Training] Epoch: 26 [===========>   ] 77.8% Loss: 0.0649, Epoch 26, Batch 97, CE_loss: 0.058812592178583145, Dice_loss: 0.005654610693454742, Consistency_loss: 0.00011072356574004516\n",
      "[Training] Epoch: 26 [===========>   ] 78.6% Loss: 0.0649, Epoch 26, Batch 98, CE_loss: 0.05681207776069641, Dice_loss: 0.005816285498440266, Consistency_loss: 8.0088124377653e-05\n",
      "[Training] Epoch: 26 [===========>   ] 79.4% Loss: 0.0647, Epoch 26, Batch 99, CE_loss: 0.04053203761577606, Dice_loss: 0.0036968442145735025, Consistency_loss: 0.00037052432890050113\n",
      "[Training] Epoch: 26 [============>  ] 80.2% Loss: 0.0646, Epoch 26, Batch 100, CE_loss: 0.05555872246623039, Dice_loss: 0.005307461600750685, Consistency_loss: 0.00042465474689379334\n",
      "[Training] Epoch: 26 [============>  ] 81.0% Loss: 0.0647, Epoch 26, Batch 101, CE_loss: 0.0645466297864914, Dice_loss: 0.006050388794392347, Consistency_loss: 0.00020615335961338133\n",
      "[Training] Epoch: 26 [============>  ] 81.7% Loss: 0.0647, Epoch 26, Batch 102, CE_loss: 0.05590047687292099, Dice_loss: 0.005444066599011421, Consistency_loss: 0.0005892812623642385\n",
      "[Training] Epoch: 26 [============>  ] 82.5% Loss: 0.0648, Epoch 26, Batch 103, CE_loss: 0.06797032058238983, Dice_loss: 0.00726954685524106, Consistency_loss: 0.000530577206518501\n",
      "[Training] Epoch: 26 [============>  ] 83.3% Loss: 0.0647, Epoch 26, Batch 104, CE_loss: 0.05132008716464043, Dice_loss: 0.005130685865879059, Consistency_loss: 5.560729914577678e-05\n",
      "[Training] Epoch: 26 [============>  ] 84.1% Loss: 0.0646, Epoch 26, Batch 105, CE_loss: 0.04546857997775078, Dice_loss: 0.004292897880077362, Consistency_loss: 6.39824356767349e-05\n",
      "[Training] Epoch: 26 [============>  ] 84.9% Loss: 0.0644, Epoch 26, Batch 106, CE_loss: 0.04118746891617775, Dice_loss: 0.003662453731521964, Consistency_loss: 0.00011485938739497215\n",
      "[Training] Epoch: 26 [============>  ] 85.7% Loss: 0.0643, Epoch 26, Batch 107, CE_loss: 0.055179353803396225, Dice_loss: 0.005332562606781721, Consistency_loss: 0.0006824448937550187\n",
      "[Training] Epoch: 26 [============>  ] 86.5% Loss: 0.0643, Epoch 26, Batch 108, CE_loss: 0.059190694242715836, Dice_loss: 0.005672282073646784, Consistency_loss: 0.00034003969631157815\n",
      "[Training] Epoch: 26 [=============> ] 87.3% Loss: 0.0642, Epoch 26, Batch 109, CE_loss: 0.044567354023456573, Dice_loss: 0.004185359459370375, Consistency_loss: 0.0002869402233045548\n",
      "[Training] Epoch: 26 [=============> ] 88.1% Loss: 0.0646, Epoch 26, Batch 110, CE_loss: 0.09487567842006683, Dice_loss: 0.009569433517754078, Consistency_loss: 0.000127775885630399\n",
      "[Training] Epoch: 26 [=============> ] 88.9% Loss: 0.0645, Epoch 26, Batch 111, CE_loss: 0.04744047299027443, Dice_loss: 0.0044386135414242744, Consistency_loss: 0.0004084377724211663\n",
      "[Training] Epoch: 26 [=============> ] 89.7% Loss: 0.0643, Epoch 26, Batch 112, CE_loss: 0.03747817501425743, Dice_loss: 0.0032550173345953226, Consistency_loss: 0.0001553086913190782\n",
      "[Training] Epoch: 26 [=============> ] 90.5% Loss: 0.0644, Epoch 26, Batch 113, CE_loss: 0.06792469322681427, Dice_loss: 0.007357724476605654, Consistency_loss: 0.0007851977134123445\n",
      "[Training] Epoch: 26 [=============> ] 91.3% Loss: 0.0645, Epoch 26, Batch 114, CE_loss: 0.07358234375715256, Dice_loss: 0.007217918522655964, Consistency_loss: 0.0003246842825319618\n",
      "[Training] Epoch: 26 [=============> ] 92.1% Loss: 0.0645, Epoch 26, Batch 115, CE_loss: 0.05614712834358215, Dice_loss: 0.00539631862193346, Consistency_loss: 0.00035353220300748944\n",
      "[Training] Epoch: 26 [=============> ] 92.9% Loss: 0.0644, Epoch 26, Batch 116, CE_loss: 0.05140320584177971, Dice_loss: 0.004554784391075373, Consistency_loss: 0.0004318372521083802\n",
      "[Training] Epoch: 26 [==============>] 93.7% Loss: 0.0643, Epoch 26, Batch 117, CE_loss: 0.04901145398616791, Dice_loss: 0.004722507670521736, Consistency_loss: 0.0005127924378030002\n",
      "[Training] Epoch: 26 [==============>] 94.4% Loss: 0.0644, Epoch 26, Batch 118, CE_loss: 0.0639813169836998, Dice_loss: 0.006576754618436098, Consistency_loss: 0.00038144440623000264\n",
      "[Training] Epoch: 26 [==============>] 95.2% Loss: 0.0644, Epoch 26, Batch 119, CE_loss: 0.05872640386223793, Dice_loss: 0.006077881436794996, Consistency_loss: 7.842666673241183e-05\n",
      "[Training] Epoch: 26 [==============>] 96.0% Loss: 0.0643, Epoch 26, Batch 120, CE_loss: 0.0533943846821785, Dice_loss: 0.005150588229298592, Consistency_loss: 0.0005584947648458183\n",
      "[Training] Epoch: 26 [==============>] 96.8% Loss: 0.0643, Epoch 26, Batch 121, CE_loss: 0.05406509339809418, Dice_loss: 0.0053019048646092415, Consistency_loss: 0.00028245613793842494\n",
      "[Training] Epoch: 26 [==============>] 97.6% Loss: 0.0642, Epoch 26, Batch 122, CE_loss: 0.05015699192881584, Dice_loss: 0.0049771834164857864, Consistency_loss: 0.000388232059776783\n",
      "[Training] Epoch: 26 [==============>] 98.4% Loss: 0.0643, Epoch 26, Batch 123, CE_loss: 0.06024442985653877, Dice_loss: 0.006296919658780098, Consistency_loss: 0.0005896200309507549\n",
      "[Training] Epoch: 26 [==============>] 99.2% Loss: 0.0641, Epoch 26, Batch 124, CE_loss: 0.04280519112944603, Dice_loss: 0.003734435187652707, Consistency_loss: 4.6061366447247565e-05\n",
      "[Training] Epoch: 26 [DONE]                                 \n",
      "Epoch 26, Batch 125, CE_loss: 0.05218905955553055, Dice_loss: 0.00527376402169466, Consistency_loss: 0.00017682604084257036\n",
      "[Validation] Epoch: 26 [DONE]                                 \n",
      "[Epoch: 26, TrainLoss: 0.0641, TrainDice: 0.0057, ValLoss: 0.1332                                            \n",
      "Number of batches:  126\n",
      "[Training] Epoch: 27 [>              ] 0.8% Loss: 0.0665, Epoch 27, Batch 0, CE_loss: 0.060115355998277664, Dice_loss: 0.006179948337376118, Consistency_loss: 0.000225297364522703\n",
      "[Training] Epoch: 27 [>              ] 1.6% Loss: 0.0712, Epoch 27, Batch 1, CE_loss: 0.06894070655107498, Dice_loss: 0.006432697642594576, Consistency_loss: 0.0004116507770959288\n",
      "[Training] Epoch: 27 [>              ] 2.4% Loss: 0.0712, Epoch 27, Batch 2, CE_loss: 0.06445702165365219, Dice_loss: 0.006864689756184816, Consistency_loss: 4.5549611968453974e-05\n",
      "[Training] Epoch: 27 [>              ] 3.2% Loss: 0.0739, Epoch 27, Batch 3, CE_loss: 0.07414312660694122, Dice_loss: 0.007671278901398182, Consistency_loss: 0.00026526875444687903\n",
      "[Training] Epoch: 27 [>              ] 4.0% Loss: 0.0739, Epoch 27, Batch 4, CE_loss: 0.06715986132621765, Dice_loss: 0.006199452560395002, Consistency_loss: 0.00039027523598633707\n",
      "[Training] Epoch: 27 [>              ] 4.8% Loss: 0.0709, Epoch 27, Batch 5, CE_loss: 0.05102438107132912, Dice_loss: 0.004703933373093605, Consistency_loss: 2.8783048037439585e-05\n",
      "[Training] Epoch: 27 [>              ] 5.6% Loss: 0.0702, Epoch 27, Batch 6, CE_loss: 0.0598592534661293, Dice_loss: 0.006020728033035994, Consistency_loss: 0.00012472629896365106\n",
      "[Training] Epoch: 27 [>              ] 6.3% Loss: 0.0687, Epoch 27, Batch 7, CE_loss: 0.053161561489105225, Dice_loss: 0.005155813880264759, Consistency_loss: 0.00015555279969703406\n",
      "[Training] Epoch: 27 [=>             ] 7.1% Loss: 0.0669, Epoch 27, Batch 8, CE_loss: 0.04795296490192413, Dice_loss: 0.004714626353234053, Consistency_loss: 9.97830429696478e-05\n",
      "[Training] Epoch: 27 [=>             ] 7.9% Loss: 0.0659, Epoch 27, Batch 9, CE_loss: 0.050987690687179565, Dice_loss: 0.005034890957176685, Consistency_loss: 0.00014276578440330923\n",
      "[Training] Epoch: 27 [=>             ] 8.7% Loss: 0.0634, Epoch 27, Batch 10, CE_loss: 0.03591429814696312, Dice_loss: 0.0029605284798890352, Consistency_loss: 0.0003920781600754708\n",
      "[Training] Epoch: 27 [=>             ] 9.5% Loss: 0.0621, Epoch 27, Batch 11, CE_loss: 0.043214693665504456, Dice_loss: 0.004033885896205902, Consistency_loss: 0.00010004850628320128\n",
      "[Training] Epoch: 27 [=>             ] 10.3% Loss: 0.0615, Epoch 27, Batch 12, CE_loss: 0.049151595681905746, Dice_loss: 0.0046710181050002575, Consistency_loss: 0.0004681479185819626\n",
      "[Training] Epoch: 27 [=>             ] 11.1% Loss: 0.0613, Epoch 27, Batch 13, CE_loss: 0.052727263420820236, Dice_loss: 0.005346943624317646, Consistency_loss: 0.00042912509525194764\n",
      "[Training] Epoch: 27 [=>             ] 11.9% Loss: 0.0603, Epoch 27, Batch 14, CE_loss: 0.04277388006448746, Dice_loss: 0.0038395465817302465, Consistency_loss: 0.0004039833729621023\n",
      "[Training] Epoch: 27 [=>             ] 12.7% Loss: 0.0607, Epoch 27, Batch 15, CE_loss: 0.06061547249555588, Dice_loss: 0.005852235946804285, Consistency_loss: 0.0003046072961296886\n",
      "[Training] Epoch: 27 [==>            ] 13.5% Loss: 0.0610, Epoch 27, Batch 16, CE_loss: 0.059178341180086136, Dice_loss: 0.006173059809952974, Consistency_loss: 0.0003133042773697525\n",
      "[Training] Epoch: 27 [==>            ] 14.3% Loss: 0.0606, Epoch 27, Batch 17, CE_loss: 0.04837077483534813, Dice_loss: 0.004384003579616547, Consistency_loss: 0.0004324913024902344\n",
      "[Training] Epoch: 27 [==>            ] 15.1% Loss: 0.0613, Epoch 27, Batch 18, CE_loss: 0.06775296479463577, Dice_loss: 0.006500722840428352, Consistency_loss: 0.0001903548400150612\n",
      "[Training] Epoch: 27 [==>            ] 15.9% Loss: 0.0616, Epoch 27, Batch 19, CE_loss: 0.06109318509697914, Dice_loss: 0.006408964283764362, Consistency_loss: 0.0003315226058475673\n",
      "[Training] Epoch: 27 [==>            ] 16.7% Loss: 0.0634, Epoch 27, Batch 20, CE_loss: 0.08940272778272629, Dice_loss: 0.009038092568516731, Consistency_loss: 7.417051529046148e-05\n",
      "[Training] Epoch: 27 [==>            ] 17.5% Loss: 0.0640, Epoch 27, Batch 21, CE_loss: 0.06843677908182144, Dice_loss: 0.0067326040007174015, Consistency_loss: 0.00021881387510802597\n",
      "[Training] Epoch: 27 [==>            ] 18.3% Loss: 0.0637, Epoch 27, Batch 22, CE_loss: 0.05220774933695793, Dice_loss: 0.00501972297206521, Consistency_loss: 0.00033929222263395786\n",
      "[Training] Epoch: 27 [==>            ] 19.0% Loss: 0.0642, Epoch 27, Batch 23, CE_loss: 0.0686803087592125, Dice_loss: 0.0071524279192090034, Consistency_loss: 0.00035911303712055087\n",
      "[Training] Epoch: 27 [==>            ] 19.8% Loss: 0.0644, Epoch 27, Batch 24, CE_loss: 0.06351878494024277, Dice_loss: 0.006520852912217379, Consistency_loss: 0.0002788996498566121\n",
      "[Training] Epoch: 27 [===>           ] 20.6% Loss: 0.0650, Epoch 27, Batch 25, CE_loss: 0.07086732238531113, Dice_loss: 0.007084657438099384, Consistency_loss: 0.00018692399316933006\n",
      "[Training] Epoch: 27 [===>           ] 21.4% Loss: 0.0655, Epoch 27, Batch 26, CE_loss: 0.07202384620904922, Dice_loss: 0.007755518425256014, Consistency_loss: 0.0005521692801266909\n",
      "[Training] Epoch: 27 [===>           ] 22.2% Loss: 0.0649, Epoch 27, Batch 27, CE_loss: 0.04249115660786629, Dice_loss: 0.003933142405003309, Consistency_loss: 0.0005557287950068712\n",
      "[Training] Epoch: 27 [===>           ] 23.0% Loss: 0.0645, Epoch 27, Batch 28, CE_loss: 0.048837415874004364, Dice_loss: 0.004461085889488459, Consistency_loss: 0.000495720945764333\n",
      "[Training] Epoch: 27 [===>           ] 23.8% Loss: 0.0646, Epoch 27, Batch 29, CE_loss: 0.06208714842796326, Dice_loss: 0.006094144657254219, Consistency_loss: 0.00026091639301739633\n",
      "[Training] Epoch: 27 [===>           ] 24.6% Loss: 0.0647, Epoch 27, Batch 30, CE_loss: 0.05930046737194061, Dice_loss: 0.006072137039154768, Consistency_loss: 0.00043418057612143457\n",
      "[Training] Epoch: 27 [===>           ] 25.4% Loss: 0.0644, Epoch 27, Batch 31, CE_loss: 0.05182425677776337, Dice_loss: 0.004930396564304829, Consistency_loss: 0.00014370593999046832\n",
      "[Training] Epoch: 27 [===>           ] 26.2% Loss: 0.0645, Epoch 27, Batch 32, CE_loss: 0.06173231825232506, Dice_loss: 0.006279387045651674, Consistency_loss: 7.722183363512158e-05\n",
      "[Training] Epoch: 27 [====>          ] 27.0% Loss: 0.0642, Epoch 27, Batch 33, CE_loss: 0.04981095716357231, Dice_loss: 0.004729530308395624, Consistency_loss: 5.853446782566607e-05\n",
      "[Training] Epoch: 27 [====>          ] 27.8% Loss: 0.0644, Epoch 27, Batch 34, CE_loss: 0.06274460256099701, Dice_loss: 0.006761218886822462, Consistency_loss: 9.11024326342158e-05\n",
      "[Training] Epoch: 27 [====>          ] 28.6% Loss: 0.0642, Epoch 27, Batch 35, CE_loss: 0.0506478026509285, Dice_loss: 0.005039544776082039, Consistency_loss: 0.0004196929221507162\n",
      "[Training] Epoch: 27 [====>          ] 29.4% Loss: 0.0644, Epoch 27, Batch 36, CE_loss: 0.06605097651481628, Dice_loss: 0.007151873782277107, Consistency_loss: 0.000338901998475194\n",
      "[Training] Epoch: 27 [====>          ] 30.2% Loss: 0.0649, Epoch 27, Batch 37, CE_loss: 0.07422930747270584, Dice_loss: 0.00809000339359045, Consistency_loss: 0.00043295236537232995\n",
      "[Training] Epoch: 27 [====>          ] 31.0% Loss: 0.0644, Epoch 27, Batch 38, CE_loss: 0.043188393115997314, Dice_loss: 0.004088044166564941, Consistency_loss: 5.560020872508176e-05\n",
      "[Training] Epoch: 27 [====>          ] 31.7% Loss: 0.0643, Epoch 27, Batch 39, CE_loss: 0.05260732024908066, Dice_loss: 0.0052901702001690865, Consistency_loss: 0.000747088750358671\n",
      "[Training] Epoch: 27 [====>          ] 32.5% Loss: 0.0641, Epoch 27, Batch 40, CE_loss: 0.04890074580907822, Dice_loss: 0.004829196725040674, Consistency_loss: 0.0004548058786895126\n",
      "[Training] Epoch: 27 [=====>         ] 33.3% Loss: 0.0638, Epoch 27, Batch 41, CE_loss: 0.04740582033991814, Dice_loss: 0.004688246641308069, Consistency_loss: 0.00040236275526694953\n",
      "[Training] Epoch: 27 [=====>         ] 34.1% Loss: 0.0638, Epoch 27, Batch 42, CE_loss: 0.05931926891207695, Dice_loss: 0.00614052452147007, Consistency_loss: 0.0007138852961361408\n",
      "[Training] Epoch: 27 [=====>         ] 34.9% Loss: 0.0645, Epoch 27, Batch 43, CE_loss: 0.08253931999206543, Dice_loss: 0.008647589944303036, Consistency_loss: 0.00035737440339289606\n",
      "[Training] Epoch: 27 [=====>         ] 35.7% Loss: 0.0642, Epoch 27, Batch 44, CE_loss: 0.04911511018872261, Dice_loss: 0.004410070367157459, Consistency_loss: 0.0005203770706430078\n",
      "[Training] Epoch: 27 [=====>         ] 36.5% Loss: 0.0640, Epoch 27, Batch 45, CE_loss: 0.048538025468587875, Dice_loss: 0.004761828575283289, Consistency_loss: 0.0002863421686924994\n",
      "[Training] Epoch: 27 [=====>         ] 37.3% Loss: 0.0635, Epoch 27, Batch 46, CE_loss: 0.03681805729866028, Dice_loss: 0.002948606153950095, Consistency_loss: 0.00027088430942967534\n",
      "[Training] Epoch: 27 [=====>         ] 38.1% Loss: 0.0634, Epoch 27, Batch 47, CE_loss: 0.05267215520143509, Dice_loss: 0.005063081160187721, Consistency_loss: 0.0006346552399918437\n",
      "[Training] Epoch: 27 [=====>         ] 38.9% Loss: 0.0635, Epoch 27, Batch 48, CE_loss: 0.060580819845199585, Dice_loss: 0.006088851485401392, Consistency_loss: 0.0006631123251281679\n",
      "[Training] Epoch: 27 [=====>         ] 39.7% Loss: 0.0633, Epoch 27, Batch 49, CE_loss: 0.0500449538230896, Dice_loss: 0.0050012157298624516, Consistency_loss: 0.0003893159155268222\n",
      "[Training] Epoch: 27 [======>        ] 40.5% Loss: 0.0630, Epoch 27, Batch 50, CE_loss: 0.04167996719479561, Dice_loss: 0.003924975171685219, Consistency_loss: 0.00013606416177935898\n",
      "[Training] Epoch: 27 [======>        ] 41.3% Loss: 0.0635, Epoch 27, Batch 51, CE_loss: 0.0792989730834961, Dice_loss: 0.008677814155817032, Consistency_loss: 0.0005731675191782415\n",
      "[Training] Epoch: 27 [======>        ] 42.1% Loss: 0.0638, Epoch 27, Batch 52, CE_loss: 0.0769365206360817, Dice_loss: 0.007303758058696985, Consistency_loss: 0.0001379017485305667\n",
      "[Training] Epoch: 27 [======>        ] 42.9% Loss: 0.0639, Epoch 27, Batch 53, CE_loss: 0.0628252923488617, Dice_loss: 0.006211240775883198, Consistency_loss: 0.0001408672396792099\n",
      "[Training] Epoch: 27 [======>        ] 43.7% Loss: 0.0639, Epoch 27, Batch 54, CE_loss: 0.056863464415073395, Dice_loss: 0.005609151907265186, Consistency_loss: 0.00011698645539581776\n",
      "[Training] Epoch: 27 [======>        ] 44.4% Loss: 0.0639, Epoch 27, Batch 55, CE_loss: 0.055390629917383194, Dice_loss: 0.004846313968300819, Consistency_loss: 8.349464769707993e-05\n",
      "[Training] Epoch: 27 [======>        ] 45.2% Loss: 0.0636, Epoch 27, Batch 56, CE_loss: 0.04607308283448219, Dice_loss: 0.004493710584938526, Consistency_loss: 0.0003595539601519704\n",
      "[Training] Epoch: 27 [======>        ] 46.0% Loss: 0.0634, Epoch 27, Batch 57, CE_loss: 0.04342738911509514, Dice_loss: 0.0036403434351086617, Consistency_loss: 0.0003415891551412642\n",
      "[Training] Epoch: 27 [=======>       ] 46.8% Loss: 0.0633, Epoch 27, Batch 58, CE_loss: 0.05685225874185562, Dice_loss: 0.005815525539219379, Consistency_loss: 0.00012451500515453517\n",
      "[Training] Epoch: 27 [=======>       ] 47.6% Loss: 0.0633, Epoch 27, Batch 59, CE_loss: 0.054374970495700836, Dice_loss: 0.005081396084278822, Consistency_loss: 0.0003216328623238951\n",
      "[Training] Epoch: 27 [=======>       ] 48.4% Loss: 0.0635, Epoch 27, Batch 60, CE_loss: 0.07130949199199677, Dice_loss: 0.006876612082123756, Consistency_loss: 0.0003327089943923056\n",
      "[Training] Epoch: 27 [=======>       ] 49.2% Loss: 0.0635, Epoch 27, Batch 61, CE_loss: 0.05848075449466705, Dice_loss: 0.0052196551114320755, Consistency_loss: 0.00038615913945250213\n",
      "[Training] Epoch: 27 [=======>       ] 50.0% Loss: 0.0638, Epoch 27, Batch 62, CE_loss: 0.07424969226121902, Dice_loss: 0.006917444057762623, Consistency_loss: 0.0006531294784508646\n",
      "[Training] Epoch: 27 [=======>       ] 50.8% Loss: 0.0637, Epoch 27, Batch 63, CE_loss: 0.04836578667163849, Dice_loss: 0.004600319545716047, Consistency_loss: 0.0005898889503441751\n",
      "[Training] Epoch: 27 [=======>       ] 51.6% Loss: 0.0638, Epoch 27, Batch 64, CE_loss: 0.06477676331996918, Dice_loss: 0.007022743113338947, Consistency_loss: 9.130563557846472e-05\n",
      "[Training] Epoch: 27 [=======>       ] 52.4% Loss: 0.0636, Epoch 27, Batch 65, CE_loss: 0.045051008462905884, Dice_loss: 0.004139788448810577, Consistency_loss: 7.11134125594981e-05\n",
      "[Training] Epoch: 27 [=======>       ] 53.2% Loss: 0.0636, Epoch 27, Batch 66, CE_loss: 0.06097501143813133, Dice_loss: 0.006277164909988642, Consistency_loss: 0.00022119567438494414\n",
      "[Training] Epoch: 27 [========>      ] 54.0% Loss: 0.0634, Epoch 27, Batch 67, CE_loss: 0.0441216342151165, Dice_loss: 0.0037522942293435335, Consistency_loss: 0.0003354678920004517\n",
      "[Training] Epoch: 27 [========>      ] 54.8% Loss: 0.0632, Epoch 27, Batch 68, CE_loss: 0.044506751000881195, Dice_loss: 0.004099152982234955, Consistency_loss: 0.00021791060862597078\n",
      "[Training] Epoch: 27 [========>      ] 55.6% Loss: 0.0633, Epoch 27, Batch 69, CE_loss: 0.0620880164206028, Dice_loss: 0.006457025185227394, Consistency_loss: 0.0001716724509606138\n",
      "[Training] Epoch: 27 [========>      ] 56.3% Loss: 0.0638, Epoch 27, Batch 70, CE_loss: 0.08719486743211746, Dice_loss: 0.009656225331127644, Consistency_loss: 0.0006397083634510636\n",
      "[Training] Epoch: 27 [========>      ] 57.1% Loss: 0.0635, Epoch 27, Batch 71, CE_loss: 0.041880931705236435, Dice_loss: 0.003733188146725297, Consistency_loss: 0.0005753171863034368\n",
      "[Training] Epoch: 27 [========>      ] 57.9% Loss: 0.0634, Epoch 27, Batch 72, CE_loss: 0.05183720588684082, Dice_loss: 0.005225488916039467, Consistency_loss: 0.00034105268423445523\n",
      "[Training] Epoch: 27 [========>      ] 58.7% Loss: 0.0633, Epoch 27, Batch 73, CE_loss: 0.05212490260601044, Dice_loss: 0.004720477852970362, Consistency_loss: 5.5048301874194294e-05\n",
      "[Training] Epoch: 27 [========>      ] 59.5% Loss: 0.0632, Epoch 27, Batch 74, CE_loss: 0.05029640719294548, Dice_loss: 0.004885572474449873, Consistency_loss: 0.000617399753537029\n",
      "[Training] Epoch: 27 [=========>     ] 60.3% Loss: 0.0630, Epoch 27, Batch 75, CE_loss: 0.0399400033056736, Dice_loss: 0.0036957578267902136, Consistency_loss: 0.000619791098870337\n",
      "[Training] Epoch: 27 [=========>     ] 61.1% Loss: 0.0630, Epoch 27, Batch 76, CE_loss: 0.058318912982940674, Dice_loss: 0.005578834097832441, Consistency_loss: 7.849654502933845e-05\n",
      "[Training] Epoch: 27 [=========>     ] 61.9% Loss: 0.0629, Epoch 27, Batch 77, CE_loss: 0.05017697438597679, Dice_loss: 0.004514779429882765, Consistency_loss: 0.0005591072258539498\n",
      "[Training] Epoch: 27 [=========>     ] 62.7% Loss: 0.0627, Epoch 27, Batch 78, CE_loss: 0.045981865376234055, Dice_loss: 0.0043337345123291016, Consistency_loss: 0.00023020361550152302\n",
      "[Training] Epoch: 27 [=========>     ] 63.5% Loss: 0.0628, Epoch 27, Batch 79, CE_loss: 0.059234727174043655, Dice_loss: 0.0060630799271166325, Consistency_loss: 0.0002620551676955074\n",
      "[Training] Epoch: 27 [=========>     ] 64.3% Loss: 0.0629, Epoch 27, Batch 80, CE_loss: 0.06176481023430824, Dice_loss: 0.006453690119087696, Consistency_loss: 0.00041807288653217256\n",
      "[Training] Epoch: 27 [=========>     ] 65.1% Loss: 0.0632, Epoch 27, Batch 81, CE_loss: 0.07971011847257614, Dice_loss: 0.008667411282658577, Consistency_loss: 0.0005524776061065495\n",
      "[Training] Epoch: 27 [=========>     ] 65.9% Loss: 0.0631, Epoch 27, Batch 82, CE_loss: 0.05183609202504158, Dice_loss: 0.005274733994156122, Consistency_loss: 0.0005276037263683975\n",
      "[Training] Epoch: 27 [==========>    ] 66.7% Loss: 0.0632, Epoch 27, Batch 83, CE_loss: 0.06355888396501541, Dice_loss: 0.006565118208527565, Consistency_loss: 0.0001789754314813763\n",
      "[Training] Epoch: 27 [==========>    ] 67.5% Loss: 0.0634, Epoch 27, Batch 84, CE_loss: 0.07261640578508377, Dice_loss: 0.007655730936676264, Consistency_loss: 0.00015711896412540227\n",
      "[Training] Epoch: 27 [==========>    ] 68.3% Loss: 0.0634, Epoch 27, Batch 85, CE_loss: 0.055275630205869675, Dice_loss: 0.005591024644672871, Consistency_loss: 0.0003462398599367589\n",
      "[Training] Epoch: 27 [==========>    ] 69.0% Loss: 0.0631, Epoch 27, Batch 86, CE_loss: 0.03641004115343094, Dice_loss: 0.0032314227428287268, Consistency_loss: 0.0003827015752904117\n",
      "[Training] Epoch: 27 [==========>    ] 69.8% Loss: 0.0632, Epoch 27, Batch 87, CE_loss: 0.06640374660491943, Dice_loss: 0.006876156199723482, Consistency_loss: 0.00040027996874414384\n",
      "[Training] Epoch: 27 [==========>    ] 70.6% Loss: 0.0632, Epoch 27, Batch 88, CE_loss: 0.054535914212465286, Dice_loss: 0.0054999906569719315, Consistency_loss: 0.0003276652132626623\n",
      "[Training] Epoch: 27 [==========>    ] 71.4% Loss: 0.0633, Epoch 27, Batch 89, CE_loss: 0.06367125362157822, Dice_loss: 0.00684150168672204, Consistency_loss: 0.0002596153353806585\n",
      "[Training] Epoch: 27 [==========>    ] 72.2% Loss: 0.0632, Epoch 27, Batch 90, CE_loss: 0.05192868039011955, Dice_loss: 0.005241765175014734, Consistency_loss: 0.00047531918971799314\n",
      "[Training] Epoch: 27 [==========>    ] 73.0% Loss: 0.0632, Epoch 27, Batch 91, CE_loss: 0.05223091319203377, Dice_loss: 0.005115544889122248, Consistency_loss: 0.00026033955509774387\n",
      "[Training] Epoch: 27 [===========>   ] 73.8% Loss: 0.0634, Epoch 27, Batch 92, CE_loss: 0.07629618793725967, Dice_loss: 0.007926598191261292, Consistency_loss: 0.000449053302872926\n",
      "[Training] Epoch: 27 [===========>   ] 74.6% Loss: 0.0633, Epoch 27, Batch 93, CE_loss: 0.0474451519548893, Dice_loss: 0.004741470795124769, Consistency_loss: 0.0005777193582616746\n",
      "[Training] Epoch: 27 [===========>   ] 75.4% Loss: 0.0631, Epoch 27, Batch 94, CE_loss: 0.0471690371632576, Dice_loss: 0.004351978190243244, Consistency_loss: 0.000359094119630754\n",
      "[Training] Epoch: 27 [===========>   ] 76.2% Loss: 0.0631, Epoch 27, Batch 95, CE_loss: 0.05676274746656418, Dice_loss: 0.005770871415734291, Consistency_loss: 0.0004407083324622363\n",
      "[Training] Epoch: 27 [===========>   ] 77.0% Loss: 0.0631, Epoch 27, Batch 96, CE_loss: 0.05651698634028435, Dice_loss: 0.005691549275070429, Consistency_loss: 0.0002427193394396454\n",
      "[Training] Epoch: 27 [===========>   ] 77.8% Loss: 0.0631, Epoch 27, Batch 97, CE_loss: 0.04961929842829704, Dice_loss: 0.004582451656460762, Consistency_loss: 0.000294287980068475\n",
      "[Training] Epoch: 27 [===========>   ] 78.6% Loss: 0.0631, Epoch 27, Batch 98, CE_loss: 0.06145348399877548, Dice_loss: 0.006514044478535652, Consistency_loss: 0.000301031133858487\n",
      "[Training] Epoch: 27 [===========>   ] 79.4% Loss: 0.0631, Epoch 27, Batch 99, CE_loss: 0.059853777289390564, Dice_loss: 0.006202098913490772, Consistency_loss: 0.00034708555904217064\n",
      "[Training] Epoch: 27 [============>  ] 80.2% Loss: 0.0630, Epoch 27, Batch 100, CE_loss: 0.04636956378817558, Dice_loss: 0.004335625562816858, Consistency_loss: 0.0003687460848595947\n",
      "[Training] Epoch: 27 [============>  ] 81.0% Loss: 0.0632, Epoch 27, Batch 101, CE_loss: 0.07072635740041733, Dice_loss: 0.007300834637135267, Consistency_loss: 0.0005036038346588612\n",
      "[Training] Epoch: 27 [============>  ] 81.7% Loss: 0.0632, Epoch 27, Batch 102, CE_loss: 0.056413955986499786, Dice_loss: 0.005889241583645344, Consistency_loss: 0.00010646215378073975\n",
      "[Training] Epoch: 27 [============>  ] 82.5% Loss: 0.0631, Epoch 27, Batch 103, CE_loss: 0.052617140114307404, Dice_loss: 0.005445908289402723, Consistency_loss: 0.00013914889132138342\n",
      "[Training] Epoch: 27 [============>  ] 83.3% Loss: 0.0634, Epoch 27, Batch 104, CE_loss: 0.08497235178947449, Dice_loss: 0.009313036687672138, Consistency_loss: 0.0002769256243482232\n",
      "[Training] Epoch: 27 [============>  ] 84.1% Loss: 0.0632, Epoch 27, Batch 105, CE_loss: 0.03896137326955795, Dice_loss: 0.0032406942918896675, Consistency_loss: 0.000230240126256831\n",
      "[Training] Epoch: 27 [============>  ] 84.9% Loss: 0.0632, Epoch 27, Batch 106, CE_loss: 0.05916836857795715, Dice_loss: 0.004978448152542114, Consistency_loss: 0.00020919377857353538\n",
      "[Training] Epoch: 27 [============>  ] 85.7% Loss: 0.0632, Epoch 27, Batch 107, CE_loss: 0.051036883145570755, Dice_loss: 0.005088660400360823, Consistency_loss: 6.644662062171847e-05\n",
      "[Training] Epoch: 27 [============>  ] 86.5% Loss: 0.0633, Epoch 27, Batch 108, CE_loss: 0.07147154957056046, Dice_loss: 0.007634219713509083, Consistency_loss: 0.0003722059482242912\n",
      "[Training] Epoch: 27 [=============> ] 87.3% Loss: 0.0633, Epoch 27, Batch 109, CE_loss: 0.05485096946358681, Dice_loss: 0.005601851735264063, Consistency_loss: 0.0003707697323989123\n",
      "[Training] Epoch: 27 [=============> ] 88.1% Loss: 0.0632, Epoch 27, Batch 110, CE_loss: 0.04771403223276138, Dice_loss: 0.004490769002586603, Consistency_loss: 0.00037462959880940616\n",
      "[Training] Epoch: 27 [=============> ] 88.9% Loss: 0.0632, Epoch 27, Batch 111, CE_loss: 0.057122852653265, Dice_loss: 0.0059724124148488045, Consistency_loss: 0.00035576216760091484\n",
      "[Training] Epoch: 27 [=============> ] 89.7% Loss: 0.0632, Epoch 27, Batch 112, CE_loss: 0.05467607080936432, Dice_loss: 0.005172412376850843, Consistency_loss: 0.0005407484131865203\n",
      "[Training] Epoch: 27 [=============> ] 90.5% Loss: 0.0632, Epoch 27, Batch 113, CE_loss: 0.056995462626218796, Dice_loss: 0.005829870700836182, Consistency_loss: 0.0006029045907780528\n",
      "[Training] Epoch: 27 [=============> ] 91.3% Loss: 0.0631, Epoch 27, Batch 114, CE_loss: 0.05420829728245735, Dice_loss: 0.005685089621692896, Consistency_loss: 0.0005665178177878261\n",
      "[Training] Epoch: 27 [=============> ] 92.1% Loss: 0.0632, Epoch 27, Batch 115, CE_loss: 0.06027267873287201, Dice_loss: 0.00615584896877408, Consistency_loss: 0.00029432238079607487\n",
      "[Training] Epoch: 27 [=============> ] 92.9% Loss: 0.0631, Epoch 27, Batch 116, CE_loss: 0.049209222197532654, Dice_loss: 0.00507001020014286, Consistency_loss: 0.0004130686284042895\n",
      "[Training] Epoch: 27 [==============>] 93.7% Loss: 0.0632, Epoch 27, Batch 117, CE_loss: 0.064134381711483, Dice_loss: 0.0069242254830896854, Consistency_loss: 8.176353730959818e-05\n",
      "[Training] Epoch: 27 [==============>] 94.4% Loss: 0.0632, Epoch 27, Batch 118, CE_loss: 0.05907332897186279, Dice_loss: 0.00547825125977397, Consistency_loss: 0.0002806771080940962\n",
      "[Training] Epoch: 27 [==============>] 95.2% Loss: 0.0631, Epoch 27, Batch 119, CE_loss: 0.048547178506851196, Dice_loss: 0.004796259105205536, Consistency_loss: 0.000303984503261745\n",
      "[Training] Epoch: 27 [==============>] 96.0% Loss: 0.0630, Epoch 27, Batch 120, CE_loss: 0.042410437017679214, Dice_loss: 0.00401570089161396, Consistency_loss: 0.00045641124597750604\n",
      "[Training] Epoch: 27 [==============>] 96.8% Loss: 0.0628, Epoch 27, Batch 121, CE_loss: 0.040549926459789276, Dice_loss: 0.003689101431518793, Consistency_loss: 0.0002973231894429773\n",
      "[Training] Epoch: 27 [==============>] 97.6% Loss: 0.0627, Epoch 27, Batch 122, CE_loss: 0.04320649430155754, Dice_loss: 0.0041167037561535835, Consistency_loss: 0.0003389498160686344\n",
      "[Training] Epoch: 27 [==============>] 98.4% Loss: 0.0627, Epoch 27, Batch 123, CE_loss: 0.061319805681705475, Dice_loss: 0.006142173893749714, Consistency_loss: 0.0005822527455165982\n",
      "[Training] Epoch: 27 [==============>] 99.2% Loss: 0.0628, Epoch 27, Batch 124, CE_loss: 0.05828382819890976, Dice_loss: 0.006226994562894106, Consistency_loss: 0.0005548528279177845\n",
      "[Training] Epoch: 27 [DONE]                                 \n",
      "Epoch 27, Batch 125, CE_loss: 0.043795716017484665, Dice_loss: 0.0037723348941653967, Consistency_loss: 8.847675053402781e-05\n",
      "[Validation] Epoch: 27 [DONE]                                 \n",
      "[Epoch: 27, TrainLoss: 0.0626, TrainDice: 0.0056, ValLoss: 0.1751                                            \n",
      "Number of batches:  126\n",
      "[Training] Epoch: 28 [>              ] 0.8% Loss: 0.0774, Epoch 28, Batch 0, CE_loss: 0.06966869533061981, Dice_loss: 0.007518862374126911, Consistency_loss: 0.00023695899290032685\n",
      "[Training] Epoch: 28 [>              ] 1.6% Loss: 0.0715, Epoch 28, Batch 1, CE_loss: 0.05933675169944763, Dice_loss: 0.006206533405929804, Consistency_loss: 8.102069841697812e-05\n",
      "[Training] Epoch: 28 [>              ] 2.4% Loss: 0.0683, Epoch 28, Batch 2, CE_loss: 0.056021593511104584, Dice_loss: 0.005461505148559809, Consistency_loss: 0.00021896565158385783\n",
      "[Training] Epoch: 28 [>              ] 3.2% Loss: 0.0665, Epoch 28, Batch 3, CE_loss: 0.055375270545482635, Dice_loss: 0.005655518267303705, Consistency_loss: 0.0002850579039659351\n",
      "[Training] Epoch: 28 [>              ] 4.0% Loss: 0.0680, Epoch 28, Batch 4, CE_loss: 0.06653157621622086, Dice_loss: 0.0069042700342834, Consistency_loss: 0.000415231246734038\n",
      "[Training] Epoch: 28 [>              ] 4.8% Loss: 0.0646, Epoch 28, Batch 5, CE_loss: 0.043298281729221344, Dice_loss: 0.00400738138705492, Consistency_loss: 8.950284973252565e-05\n",
      "[Training] Epoch: 28 [>              ] 5.6% Loss: 0.0623, Epoch 28, Batch 6, CE_loss: 0.044115208089351654, Dice_loss: 0.004190612118691206, Consistency_loss: 0.0002562004083301872\n",
      "[Training] Epoch: 28 [>              ] 6.3% Loss: 0.0609, Epoch 28, Batch 7, CE_loss: 0.046372879296541214, Dice_loss: 0.004337985999882221, Consistency_loss: 0.00025992485461756587\n",
      "[Training] Epoch: 28 [=>             ] 7.1% Loss: 0.0604, Epoch 28, Batch 8, CE_loss: 0.05135567858815193, Dice_loss: 0.005052884109318256, Consistency_loss: 9.052883979165927e-05\n",
      "[Training] Epoch: 28 [=>             ] 7.9% Loss: 0.0589, Epoch 28, Batch 9, CE_loss: 0.04189596325159073, Dice_loss: 0.0037418247666209936, Consistency_loss: 4.9009151553036645e-05\n",
      "[Training] Epoch: 28 [=>             ] 8.7% Loss: 0.0584, Epoch 28, Batch 10, CE_loss: 0.047874659299850464, Dice_loss: 0.004630936775356531, Consistency_loss: 0.0006059153820388019\n",
      "[Training] Epoch: 28 [=>             ] 9.5% Loss: 0.0589, Epoch 28, Batch 11, CE_loss: 0.05866149440407753, Dice_loss: 0.005565355997532606, Consistency_loss: 7.873536378610879e-05\n",
      "[Training] Epoch: 28 [=>             ] 10.3% Loss: 0.0598, Epoch 28, Batch 12, CE_loss: 0.06393711268901825, Dice_loss: 0.00677208648994565, Consistency_loss: 0.00042421670514158905\n",
      "[Training] Epoch: 28 [=>             ] 11.1% Loss: 0.0597, Epoch 28, Batch 13, CE_loss: 0.05179249495267868, Dice_loss: 0.00525317806750536, Consistency_loss: 0.0004828031233046204\n",
      "[Training] Epoch: 28 [=>             ] 11.9% Loss: 0.0610, Epoch 28, Batch 14, CE_loss: 0.07204373180866241, Dice_loss: 0.007659821305423975, Consistency_loss: 0.00028209274751134217\n",
      "[Training] Epoch: 28 [=>             ] 12.7% Loss: 0.0613, Epoch 28, Batch 15, CE_loss: 0.059223223477602005, Dice_loss: 0.00603768415749073, Consistency_loss: 0.00028086095699109137\n",
      "[Training] Epoch: 28 [==>            ] 13.5% Loss: 0.0636, Epoch 28, Batch 16, CE_loss: 0.09141366183757782, Dice_loss: 0.00920974463224411, Consistency_loss: 0.00013484460941981524\n",
      "[Training] Epoch: 28 [==>            ] 14.3% Loss: 0.0632, Epoch 28, Batch 17, CE_loss: 0.051485881209373474, Dice_loss: 0.0049758777022361755, Consistency_loss: 0.0004922983353026211\n",
      "[Training] Epoch: 28 [==>            ] 15.1% Loss: 0.0628, Epoch 28, Batch 18, CE_loss: 0.048868466168642044, Dice_loss: 0.004942100029438734, Consistency_loss: 0.000519182241987437\n",
      "[Training] Epoch: 28 [==>            ] 15.9% Loss: 0.0625, Epoch 28, Batch 19, CE_loss: 0.051486413925886154, Dice_loss: 0.005257017910480499, Consistency_loss: 0.00028152274899184704\n",
      "[Training] Epoch: 28 [==>            ] 16.7% Loss: 0.0636, Epoch 28, Batch 20, CE_loss: 0.07728445529937744, Dice_loss: 0.008282076567411423, Consistency_loss: 0.0003810226626228541\n",
      "[Training] Epoch: 28 [==>            ] 17.5% Loss: 0.0636, Epoch 28, Batch 21, CE_loss: 0.057981476187705994, Dice_loss: 0.006215746980160475, Consistency_loss: 0.0002187259087804705\n",
      "[Training] Epoch: 28 [==>            ] 18.3% Loss: 0.0632, Epoch 28, Batch 22, CE_loss: 0.04826333001255989, Dice_loss: 0.004613574128597975, Consistency_loss: 0.0004891933058388531\n",
      "[Training] Epoch: 28 [==>            ] 19.0% Loss: 0.0628, Epoch 28, Batch 23, CE_loss: 0.04840253293514252, Dice_loss: 0.00474038440734148, Consistency_loss: 0.0002305103262187913\n",
      "[Training] Epoch: 28 [==>            ] 19.8% Loss: 0.0627, Epoch 28, Batch 24, CE_loss: 0.05399981513619423, Dice_loss: 0.005465019028633833, Consistency_loss: 0.00017519846733193845\n",
      "[Training] Epoch: 28 [===>           ] 20.6% Loss: 0.0623, Epoch 28, Batch 25, CE_loss: 0.04871506243944168, Dice_loss: 0.005000187549740076, Consistency_loss: 0.0002323656080989167\n",
      "[Training] Epoch: 28 [===>           ] 21.4% Loss: 0.0621, Epoch 28, Batch 26, CE_loss: 0.05004363879561424, Dice_loss: 0.0048712315037846565, Consistency_loss: 0.0005293934955261648\n",
      "[Training] Epoch: 28 [===>           ] 22.2% Loss: 0.0614, Epoch 28, Batch 27, CE_loss: 0.03993455320596695, Dice_loss: 0.0035694034304469824, Consistency_loss: 0.00047843577340245247\n",
      "[Training] Epoch: 28 [===>           ] 23.0% Loss: 0.0612, Epoch 28, Batch 28, CE_loss: 0.050388533622026443, Dice_loss: 0.004933673422783613, Consistency_loss: 0.00010013279825216159\n",
      "[Training] Epoch: 28 [===>           ] 23.8% Loss: 0.0612, Epoch 28, Batch 29, CE_loss: 0.05444847047328949, Dice_loss: 0.0056062061339616776, Consistency_loss: 0.0003376855456735939\n",
      "[Training] Epoch: 28 [===>           ] 24.6% Loss: 0.0609, Epoch 28, Batch 30, CE_loss: 0.047317828983068466, Dice_loss: 0.004584458656609058, Consistency_loss: 0.0005662390612997115\n",
      "[Training] Epoch: 28 [===>           ] 25.4% Loss: 0.0603, Epoch 28, Batch 31, CE_loss: 0.03762267157435417, Dice_loss: 0.00340827414765954, Consistency_loss: 0.0002116880932589993\n",
      "[Training] Epoch: 28 [===>           ] 26.2% Loss: 0.0608, Epoch 28, Batch 32, CE_loss: 0.06966571509838104, Dice_loss: 0.00724412826821208, Consistency_loss: 0.0001805048668757081\n",
      "[Training] Epoch: 28 [====>          ] 27.0% Loss: 0.0605, Epoch 28, Batch 33, CE_loss: 0.04557732492685318, Dice_loss: 0.004223268013447523, Consistency_loss: 0.0005035118665546179\n",
      "[Training] Epoch: 28 [====>          ] 27.8% Loss: 0.0598, Epoch 28, Batch 34, CE_loss: 0.03209034353494644, Dice_loss: 0.0025771649088710546, Consistency_loss: 0.0002687146479729563\n",
      "[Training] Epoch: 28 [====>          ] 28.6% Loss: 0.0595, Epoch 28, Batch 35, CE_loss: 0.04730558767914772, Dice_loss: 0.004423168487846851, Consistency_loss: 0.00018413241195958108\n",
      "[Training] Epoch: 28 [====>          ] 29.4% Loss: 0.0596, Epoch 28, Batch 36, CE_loss: 0.055934078991413116, Dice_loss: 0.0058639394119381905, Consistency_loss: 0.00025610436568968\n",
      "[Training] Epoch: 28 [====>          ] 30.2% Loss: 0.0596, Epoch 28, Batch 37, CE_loss: 0.05392225831747055, Dice_loss: 0.00515638617798686, Consistency_loss: 8.606482151662931e-05\n",
      "[Training] Epoch: 28 [====>          ] 31.0% Loss: 0.0604, Epoch 28, Batch 38, CE_loss: 0.08055691421031952, Dice_loss: 0.008543591946363449, Consistency_loss: 0.0002796999760903418\n",
      "[Training] Epoch: 28 [====>          ] 31.7% Loss: 0.0605, Epoch 28, Batch 39, CE_loss: 0.05795793607831001, Dice_loss: 0.0061978744342923164, Consistency_loss: 0.0005745835951529443\n",
      "[Training] Epoch: 28 [====>          ] 32.5% Loss: 0.0609, Epoch 28, Batch 40, CE_loss: 0.07206426560878754, Dice_loss: 0.007682571187615395, Consistency_loss: 0.00010817246948136017\n",
      "[Training] Epoch: 28 [=====>         ] 33.3% Loss: 0.0608, Epoch 28, Batch 41, CE_loss: 0.050318095833063126, Dice_loss: 0.005106175318360329, Consistency_loss: 0.00032204462331719697\n",
      "[Training] Epoch: 28 [=====>         ] 34.1% Loss: 0.0610, Epoch 28, Batch 42, CE_loss: 0.05995585396885872, Dice_loss: 0.006058793049305677, Consistency_loss: 0.0006116818985901773\n",
      "[Training] Epoch: 28 [=====>         ] 34.9% Loss: 0.0606, Epoch 28, Batch 43, CE_loss: 0.04310319572687149, Dice_loss: 0.004076354205608368, Consistency_loss: 7.78000830905512e-05\n",
      "[Training] Epoch: 28 [=====>         ] 35.7% Loss: 0.0609, Epoch 28, Batch 44, CE_loss: 0.06569638103246689, Dice_loss: 0.006098154466599226, Consistency_loss: 0.000133444118546322\n",
      "[Training] Epoch: 28 [=====>         ] 36.5% Loss: 0.0619, Epoch 28, Batch 45, CE_loss: 0.0973079577088356, Dice_loss: 0.009938139468431473, Consistency_loss: 0.0001484095409978181\n",
      "[Training] Epoch: 28 [=====>         ] 37.3% Loss: 0.0619, Epoch 28, Batch 46, CE_loss: 0.05745158717036247, Dice_loss: 0.005765667650848627, Consistency_loss: 0.00030099618015810847\n",
      "[Training] Epoch: 28 [=====>         ] 38.1% Loss: 0.0616, Epoch 28, Batch 47, CE_loss: 0.043484870344400406, Dice_loss: 0.004295177757740021, Consistency_loss: 6.590739212697372e-05\n",
      "[Training] Epoch: 28 [=====>         ] 38.9% Loss: 0.0626, Epoch 28, Batch 48, CE_loss: 0.09723074734210968, Dice_loss: 0.010045736096799374, Consistency_loss: 0.0005525764427147806\n",
      "[Training] Epoch: 28 [=====>         ] 39.7% Loss: 0.0626, Epoch 28, Batch 49, CE_loss: 0.05534420907497406, Dice_loss: 0.005576513707637787, Consistency_loss: 0.0003710378077812493\n",
      "[Training] Epoch: 28 [======>        ] 40.5% Loss: 0.0625, Epoch 28, Batch 50, CE_loss: 0.05512098968029022, Dice_loss: 0.005634440574795008, Consistency_loss: 0.0005110620404593647\n",
      "[Training] Epoch: 28 [======>        ] 41.3% Loss: 0.0625, Epoch 28, Batch 51, CE_loss: 0.056215155869722366, Dice_loss: 0.005811640992760658, Consistency_loss: 0.0005595571710728109\n",
      "[Training] Epoch: 28 [======>        ] 42.1% Loss: 0.0626, Epoch 28, Batch 52, CE_loss: 0.05729881301522255, Dice_loss: 0.005890564993023872, Consistency_loss: 0.0001283337624045089\n",
      "[Training] Epoch: 28 [======>        ] 42.9% Loss: 0.0628, Epoch 28, Batch 53, CE_loss: 0.0694621279835701, Dice_loss: 0.0076324851252138615, Consistency_loss: 0.00012814722140319645\n",
      "[Training] Epoch: 28 [======>        ] 43.7% Loss: 0.0629, Epoch 28, Batch 54, CE_loss: 0.05796036869287491, Dice_loss: 0.006023517344146967, Consistency_loss: 0.00031243570265360177\n",
      "[Training] Epoch: 28 [======>        ] 44.4% Loss: 0.0627, Epoch 28, Batch 55, CE_loss: 0.047260649502277374, Dice_loss: 0.004708059132099152, Consistency_loss: 0.0004007306124549359\n",
      "[Training] Epoch: 28 [======>        ] 45.2% Loss: 0.0629, Epoch 28, Batch 56, CE_loss: 0.06767590343952179, Dice_loss: 0.0072850678116083145, Consistency_loss: 0.00046165866660885513\n",
      "[Training] Epoch: 28 [======>        ] 46.0% Loss: 0.0629, Epoch 28, Batch 57, CE_loss: 0.05727582052350044, Dice_loss: 0.005940552335232496, Consistency_loss: 0.00010446421947563067\n",
      "[Training] Epoch: 28 [=======>       ] 46.8% Loss: 0.0627, Epoch 28, Batch 58, CE_loss: 0.044935815036296844, Dice_loss: 0.004489468410611153, Consistency_loss: 0.00039493158692494035\n",
      "[Training] Epoch: 28 [=======>       ] 47.6% Loss: 0.0627, Epoch 28, Batch 59, CE_loss: 0.057153552770614624, Dice_loss: 0.0058404430747032166, Consistency_loss: 8.118278492474928e-05\n",
      "[Training] Epoch: 28 [=======>       ] 48.4% Loss: 0.0624, Epoch 28, Batch 60, CE_loss: 0.0393887534737587, Dice_loss: 0.0036742195952683687, Consistency_loss: 0.00044115629862062633\n",
      "[Training] Epoch: 28 [=======>       ] 49.2% Loss: 0.0625, Epoch 28, Batch 61, CE_loss: 0.062429919838905334, Dice_loss: 0.0067504094913601875, Consistency_loss: 0.0002813753962982446\n",
      "[Training] Epoch: 28 [=======>       ] 50.0% Loss: 0.0626, Epoch 28, Batch 62, CE_loss: 0.06394297629594803, Dice_loss: 0.007005769293755293, Consistency_loss: 0.0001070099460775964\n",
      "[Training] Epoch: 28 [=======>       ] 50.8% Loss: 0.0625, Epoch 28, Batch 63, CE_loss: 0.049933772534132004, Dice_loss: 0.0050477744080126286, Consistency_loss: 0.0006925818743184209\n",
      "[Training] Epoch: 28 [=======>       ] 51.6% Loss: 0.0630, Epoch 28, Batch 64, CE_loss: 0.0861593633890152, Dice_loss: 0.00887081678956747, Consistency_loss: 0.0006080554448999465\n",
      "[Training] Epoch: 28 [=======>       ] 52.4% Loss: 0.0628, Epoch 28, Batch 65, CE_loss: 0.04441310092806816, Dice_loss: 0.0041577816009521484, Consistency_loss: 8.999566489364952e-05\n",
      "[Training] Epoch: 28 [=======>       ] 53.2% Loss: 0.0627, Epoch 28, Batch 66, CE_loss: 0.049357812851667404, Dice_loss: 0.004900096450001001, Consistency_loss: 0.00021224297233857214\n",
      "[Training] Epoch: 28 [========>      ] 54.0% Loss: 0.0629, Epoch 28, Batch 67, CE_loss: 0.07008256018161774, Dice_loss: 0.00775168277323246, Consistency_loss: 0.0003104979114141315\n",
      "[Training] Epoch: 28 [========>      ] 54.8% Loss: 0.0628, Epoch 28, Batch 68, CE_loss: 0.050005096942186356, Dice_loss: 0.005140337627381086, Consistency_loss: 6.0071568441344425e-05\n",
      "[Training] Epoch: 28 [========>      ] 55.6% Loss: 0.0627, Epoch 28, Batch 69, CE_loss: 0.05030978471040726, Dice_loss: 0.0051885321736335754, Consistency_loss: 0.0002575155522208661\n",
      "[Training] Epoch: 28 [========>      ] 56.3% Loss: 0.0627, Epoch 28, Batch 70, CE_loss: 0.05872153118252754, Dice_loss: 0.006247656419873238, Consistency_loss: 0.0006694633048027754\n",
      "[Training] Epoch: 28 [========>      ] 57.1% Loss: 0.0627, Epoch 28, Batch 71, CE_loss: 0.05382251739501953, Dice_loss: 0.005501921754330397, Consistency_loss: 0.0003319506940897554\n",
      "[Training] Epoch: 28 [========>      ] 57.9% Loss: 0.0626, Epoch 28, Batch 72, CE_loss: 0.05041616037487984, Dice_loss: 0.004869863390922546, Consistency_loss: 6.603672227356583e-05\n",
      "[Training] Epoch: 28 [========>      ] 58.7% Loss: 0.0627, Epoch 28, Batch 73, CE_loss: 0.061597876250743866, Dice_loss: 0.0066150338388979435, Consistency_loss: 0.00039156083948910236\n",
      "[Training] Epoch: 28 [========>      ] 59.5% Loss: 0.0626, Epoch 28, Batch 74, CE_loss: 0.05150730162858963, Dice_loss: 0.005057618021965027, Consistency_loss: 0.0006140967016108334\n",
      "[Training] Epoch: 28 [=========>     ] 60.3% Loss: 0.0627, Epoch 28, Batch 75, CE_loss: 0.06253183633089066, Dice_loss: 0.006744879763573408, Consistency_loss: 0.000672459602355957\n",
      "[Training] Epoch: 28 [=========>     ] 61.1% Loss: 0.0628, Epoch 28, Batch 76, CE_loss: 0.06419385969638824, Dice_loss: 0.006724919658154249, Consistency_loss: 9.488456271355972e-05\n",
      "[Training] Epoch: 28 [=========>     ] 61.9% Loss: 0.0630, Epoch 28, Batch 77, CE_loss: 0.06828857213258743, Dice_loss: 0.006443837657570839, Consistency_loss: 0.0005866537685506046\n",
      "[Training] Epoch: 28 [=========>     ] 62.7% Loss: 0.0628, Epoch 28, Batch 78, CE_loss: 0.04768284410238266, Dice_loss: 0.004853859543800354, Consistency_loss: 0.000298898114124313\n",
      "[Training] Epoch: 28 [=========>     ] 63.5% Loss: 0.0628, Epoch 28, Batch 79, CE_loss: 0.05555290728807449, Dice_loss: 0.0054732803255319595, Consistency_loss: 0.00022721057757735252\n",
      "[Training] Epoch: 28 [=========>     ] 64.3% Loss: 0.0628, Epoch 28, Batch 80, CE_loss: 0.053641196340322495, Dice_loss: 0.005516191013157368, Consistency_loss: 6.103467239881866e-05\n",
      "[Training] Epoch: 28 [=========>     ] 65.1% Loss: 0.0629, Epoch 28, Batch 81, CE_loss: 0.0645853728055954, Dice_loss: 0.006802274379879236, Consistency_loss: 0.0005500916740857065\n",
      "[Training] Epoch: 28 [=========>     ] 65.9% Loss: 0.0628, Epoch 28, Batch 82, CE_loss: 0.051516663283109665, Dice_loss: 0.005346465390175581, Consistency_loss: 0.000584566208999604\n",
      "[Training] Epoch: 28 [==========>    ] 66.7% Loss: 0.0626, Epoch 28, Batch 83, CE_loss: 0.03765515983104706, Dice_loss: 0.0030844511929899454, Consistency_loss: 0.00016898509056773037\n",
      "[Training] Epoch: 28 [==========>    ] 67.5% Loss: 0.0626, Epoch 28, Batch 84, CE_loss: 0.06373028457164764, Dice_loss: 0.00663030007854104, Consistency_loss: 7.775471749482676e-05\n",
      "[Training] Epoch: 28 [==========>    ] 68.3% Loss: 0.0626, Epoch 28, Batch 85, CE_loss: 0.053514543920755386, Dice_loss: 0.005045011639595032, Consistency_loss: 0.00052450638031587\n",
      "[Training] Epoch: 28 [==========>    ] 69.0% Loss: 0.0627, Epoch 28, Batch 86, CE_loss: 0.06570856273174286, Dice_loss: 0.006925531197339296, Consistency_loss: 0.0005224416963756084\n",
      "[Training] Epoch: 28 [==========>    ] 69.8% Loss: 0.0625, Epoch 28, Batch 87, CE_loss: 0.04110855609178543, Dice_loss: 0.003883624216541648, Consistency_loss: 3.896763882949017e-05\n",
      "[Training] Epoch: 28 [==========>    ] 70.6% Loss: 0.0625, Epoch 28, Batch 88, CE_loss: 0.05613800883293152, Dice_loss: 0.005396698601543903, Consistency_loss: 0.00026362432981841266\n",
      "[Training] Epoch: 28 [==========>    ] 71.4% Loss: 0.0624, Epoch 28, Batch 89, CE_loss: 0.04278150573372841, Dice_loss: 0.0040878430008888245, Consistency_loss: 0.00046880138688720763\n",
      "[Training] Epoch: 28 [==========>    ] 72.2% Loss: 0.0623, Epoch 28, Batch 90, CE_loss: 0.05262552574276924, Dice_loss: 0.005482945125550032, Consistency_loss: 0.0004388371598906815\n",
      "[Training] Epoch: 28 [==========>    ] 73.0% Loss: 0.0622, Epoch 28, Batch 91, CE_loss: 0.04599076136946678, Dice_loss: 0.004505986347794533, Consistency_loss: 0.0005493611097335815\n",
      "[Training] Epoch: 28 [===========>   ] 73.8% Loss: 0.0622, Epoch 28, Batch 92, CE_loss: 0.06060231849551201, Dice_loss: 0.005476650781929493, Consistency_loss: 0.0005243381601758301\n",
      "[Training] Epoch: 28 [===========>   ] 74.6% Loss: 0.0621, Epoch 28, Batch 93, CE_loss: 0.04906194284558296, Dice_loss: 0.004558177664875984, Consistency_loss: 5.9187856095377356e-05\n",
      "[Training] Epoch: 28 [===========>   ] 75.4% Loss: 0.0622, Epoch 28, Batch 94, CE_loss: 0.057583343237638474, Dice_loss: 0.006090250797569752, Consistency_loss: 0.000280110165476799\n",
      "[Training] Epoch: 28 [===========>   ] 76.2% Loss: 0.0622, Epoch 28, Batch 95, CE_loss: 0.06274570524692535, Dice_loss: 0.0068257395178079605, Consistency_loss: 0.0004235709202475846\n",
      "[Training] Epoch: 28 [===========>   ] 77.0% Loss: 0.0622, Epoch 28, Batch 96, CE_loss: 0.04997734725475311, Dice_loss: 0.005125420168042183, Consistency_loss: 0.00026031563174910843\n",
      "[Training] Epoch: 28 [===========>   ] 77.8% Loss: 0.0621, Epoch 28, Batch 97, CE_loss: 0.05165822431445122, Dice_loss: 0.005348025355488062, Consistency_loss: 0.00031356196268461645\n",
      "[Training] Epoch: 28 [===========>   ] 78.6% Loss: 0.0621, Epoch 28, Batch 98, CE_loss: 0.04965990409255028, Dice_loss: 0.0050254943780601025, Consistency_loss: 0.00027266822871752083\n",
      "[Training] Epoch: 28 [===========>   ] 79.4% Loss: 0.0619, Epoch 28, Batch 99, CE_loss: 0.04613303765654564, Dice_loss: 0.004038646817207336, Consistency_loss: 0.0003310119791422039\n",
      "[Training] Epoch: 28 [============>  ] 80.2% Loss: 0.0617, Epoch 28, Batch 100, CE_loss: 0.03639337047934532, Dice_loss: 0.0030622065532952547, Consistency_loss: 0.0004259964625816792\n",
      "[Training] Epoch: 28 [============>  ] 81.0% Loss: 0.0616, Epoch 28, Batch 101, CE_loss: 0.04131685942411423, Dice_loss: 0.004026653245091438, Consistency_loss: 0.00013086418039165437\n",
      "[Training] Epoch: 28 [============>  ] 81.7% Loss: 0.0616, Epoch 28, Batch 102, CE_loss: 0.05976346135139465, Dice_loss: 0.006018814630806446, Consistency_loss: 7.989111327333376e-05\n",
      "[Training] Epoch: 28 [============>  ] 82.5% Loss: 0.0616, Epoch 28, Batch 103, CE_loss: 0.05171012878417969, Dice_loss: 0.0053745657205581665, Consistency_loss: 9.733248589327559e-05\n",
      "[Training] Epoch: 28 [============>  ] 83.3% Loss: 0.0617, Epoch 28, Batch 104, CE_loss: 0.06507977098226547, Dice_loss: 0.006140542216598988, Consistency_loss: 0.00024798623053357005\n",
      "[Training] Epoch: 28 [============>  ] 84.1% Loss: 0.0616, Epoch 28, Batch 105, CE_loss: 0.0501348078250885, Dice_loss: 0.005222533829510212, Consistency_loss: 0.00024938114802353084\n",
      "[Training] Epoch: 28 [============>  ] 84.9% Loss: 0.0616, Epoch 28, Batch 106, CE_loss: 0.05881962925195694, Dice_loss: 0.006040692795068026, Consistency_loss: 0.0006384745356626809\n",
      "[Training] Epoch: 28 [============>  ] 85.7% Loss: 0.0618, Epoch 28, Batch 107, CE_loss: 0.06736001372337341, Dice_loss: 0.0071102324873209, Consistency_loss: 2.90756142931059e-05\n",
      "[Training] Epoch: 28 [============>  ] 86.5% Loss: 0.0618, Epoch 28, Batch 108, CE_loss: 0.06253983825445175, Dice_loss: 0.006859874818474054, Consistency_loss: 0.0004212672356516123\n",
      "[Training] Epoch: 28 [=============> ] 87.3% Loss: 0.0620, Epoch 28, Batch 109, CE_loss: 0.06867175549268723, Dice_loss: 0.007292805705219507, Consistency_loss: 0.00022024963982403278\n",
      "[Training] Epoch: 28 [=============> ] 88.1% Loss: 0.0622, Epoch 28, Batch 110, CE_loss: 0.07685022056102753, Dice_loss: 0.008185087703168392, Consistency_loss: 3.8341542676789686e-05\n",
      "[Training] Epoch: 28 [=============> ] 88.9% Loss: 0.0622, Epoch 28, Batch 111, CE_loss: 0.0560416541993618, Dice_loss: 0.005879885051399469, Consistency_loss: 0.0004862607456743717\n",
      "[Training] Epoch: 28 [=============> ] 89.7% Loss: 0.0623, Epoch 28, Batch 112, CE_loss: 0.06641282141208649, Dice_loss: 0.007257150486111641, Consistency_loss: 0.0004401080368552357\n",
      "[Training] Epoch: 28 [=============> ] 90.5% Loss: 0.0622, Epoch 28, Batch 113, CE_loss: 0.0452549047768116, Dice_loss: 0.0044162217527627945, Consistency_loss: 0.0005280682235024869\n",
      "[Training] Epoch: 28 [=============> ] 91.3% Loss: 0.0622, Epoch 28, Batch 114, CE_loss: 0.059004656970500946, Dice_loss: 0.006327250972390175, Consistency_loss: 0.0006048490758985281\n",
      "[Training] Epoch: 28 [=============> ] 92.1% Loss: 0.0621, Epoch 28, Batch 115, CE_loss: 0.04633947089314461, Dice_loss: 0.004707822576165199, Consistency_loss: 6.478067371062934e-05\n",
      "[Training] Epoch: 28 [=============> ] 92.9% Loss: 0.0621, Epoch 28, Batch 116, CE_loss: 0.05507057160139084, Dice_loss: 0.005705322604626417, Consistency_loss: 0.0004258172702975571\n",
      "[Training] Epoch: 28 [==============>] 93.7% Loss: 0.0620, Epoch 28, Batch 117, CE_loss: 0.041088737547397614, Dice_loss: 0.003964421339333057, Consistency_loss: 0.00032581642153672874\n",
      "[Training] Epoch: 28 [==============>] 94.4% Loss: 0.0619, Epoch 28, Batch 118, CE_loss: 0.04918579384684563, Dice_loss: 0.004723611753433943, Consistency_loss: 0.00037296986556611955\n",
      "[Training] Epoch: 28 [==============>] 95.2% Loss: 0.0620, Epoch 28, Batch 119, CE_loss: 0.06342318654060364, Dice_loss: 0.006674087140709162, Consistency_loss: 0.00025870275567285717\n",
      "[Training] Epoch: 28 [==============>] 96.0% Loss: 0.0619, Epoch 28, Batch 120, CE_loss: 0.05341321974992752, Dice_loss: 0.005635102279484272, Consistency_loss: 0.00023970262554939836\n",
      "[Training] Epoch: 28 [==============>] 96.8% Loss: 0.0619, Epoch 28, Batch 121, CE_loss: 0.056705620139837265, Dice_loss: 0.005880260840058327, Consistency_loss: 0.0002920753904618323\n",
      "[Training] Epoch: 28 [==============>] 97.6% Loss: 0.0619, Epoch 28, Batch 122, CE_loss: 0.05024098977446556, Dice_loss: 0.004980768542736769, Consistency_loss: 0.0002801228256430477\n",
      "[Training] Epoch: 28 [==============>] 98.4% Loss: 0.0619, Epoch 28, Batch 123, CE_loss: 0.058938972651958466, Dice_loss: 0.005913944914937019, Consistency_loss: 0.0005685616051778197\n",
      "[Training] Epoch: 28 [==============>] 99.2% Loss: 0.0619, Epoch 28, Batch 124, CE_loss: 0.049808453768491745, Dice_loss: 0.005097668152302504, Consistency_loss: 0.000522366666700691\n",
      "[Training] Epoch: 28 [DONE]                                 \n",
      "Epoch 28, Batch 125, CE_loss: 0.05482838675379753, Dice_loss: 0.005640489049255848, Consistency_loss: 0.00017422357632312924\n",
      "[Validation] Epoch: 28 [DONE]                                 \n",
      "[Epoch: 28, TrainLoss: 0.0619, TrainDice: 0.0057, ValLoss: 0.1823                                            \n",
      "Number of batches:  126\n",
      "[Training] Epoch: 29 [>              ] 0.8% Loss: 0.0667, Epoch 29, Batch 0, CE_loss: 0.05983233451843262, Dice_loss: 0.006515291519463062, Consistency_loss: 0.00030432920902967453\n",
      "[Training] Epoch: 29 [>              ] 1.6% Loss: 0.0758, Epoch 29, Batch 1, CE_loss: 0.07624003291130066, Dice_loss: 0.008307029493153095, Consistency_loss: 0.00035931944148615\n",
      "[Training] Epoch: 29 [>              ] 2.4% Loss: 0.0728, Epoch 29, Batch 2, CE_loss: 0.060506999492645264, Dice_loss: 0.006247866433113813, Consistency_loss: 0.00021211081184446812\n",
      "[Training] Epoch: 29 [>              ] 3.2% Loss: 0.0665, Epoch 29, Batch 3, CE_loss: 0.04282074049115181, Dice_loss: 0.00420418381690979, Consistency_loss: 0.0004030679410789162\n",
      "[Training] Epoch: 29 [>              ] 4.0% Loss: 0.0635, Epoch 29, Batch 4, CE_loss: 0.04668901115655899, Dice_loss: 0.004756772890686989, Consistency_loss: 4.538338544080034e-05\n",
      "[Training] Epoch: 29 [>              ] 4.8% Loss: 0.0619, Epoch 29, Batch 5, CE_loss: 0.049131859093904495, Dice_loss: 0.004611361306160688, Consistency_loss: 0.00013018342724535614\n",
      "[Training] Epoch: 29 [>              ] 5.6% Loss: 0.0599, Epoch 29, Batch 6, CE_loss: 0.04364756494760513, Dice_loss: 0.003942324314266443, Consistency_loss: 0.00012150401016697288\n",
      "[Training] Epoch: 29 [>              ] 6.3% Loss: 0.0574, Epoch 29, Batch 7, CE_loss: 0.03685758262872696, Dice_loss: 0.0034210013691335917, Consistency_loss: 0.0002656023425515741\n",
      "[Training] Epoch: 29 [=>             ] 7.1% Loss: 0.0568, Epoch 29, Batch 8, CE_loss: 0.047725412994623184, Dice_loss: 0.004164670594036579, Consistency_loss: 0.00016029985272325575\n",
      "[Training] Epoch: 29 [=>             ] 7.9% Loss: 0.0568, Epoch 29, Batch 9, CE_loss: 0.05100834742188454, Dice_loss: 0.005052906461060047, Consistency_loss: 0.0001140254462370649\n",
      "[Training] Epoch: 29 [=>             ] 8.7% Loss: 0.0560, Epoch 29, Batch 10, CE_loss: 0.043265145272016525, Dice_loss: 0.004086716566234827, Consistency_loss: 0.0006145334336906672\n",
      "[Training] Epoch: 29 [=>             ] 9.5% Loss: 0.0569, Epoch 29, Batch 11, CE_loss: 0.06029927730560303, Dice_loss: 0.006093742325901985, Consistency_loss: 0.0006275794003158808\n",
      "[Training] Epoch: 29 [=>             ] 10.3% Loss: 0.0564, Epoch 29, Batch 12, CE_loss: 0.04533606767654419, Dice_loss: 0.004439624026417732, Consistency_loss: 0.00039716888568364084\n",
      "[Training] Epoch: 29 [=>             ] 11.1% Loss: 0.0556, Epoch 29, Batch 13, CE_loss: 0.04144131764769554, Dice_loss: 0.004047641530632973, Consistency_loss: 5.6517859775340185e-05\n",
      "[Training] Epoch: 29 [=>             ] 11.9% Loss: 0.0564, Epoch 29, Batch 14, CE_loss: 0.061516545712947845, Dice_loss: 0.00627305218949914, Consistency_loss: 0.0003908890357706696\n",
      "[Training] Epoch: 29 [=>             ] 12.7% Loss: 0.0560, Epoch 29, Batch 15, CE_loss: 0.04403823986649513, Dice_loss: 0.004378607962280512, Consistency_loss: 0.0004269736527930945\n",
      "[Training] Epoch: 29 [==>            ] 13.5% Loss: 0.0574, Epoch 29, Batch 16, CE_loss: 0.07236180454492569, Dice_loss: 0.007747547701001167, Consistency_loss: 0.0003520523605402559\n",
      "[Training] Epoch: 29 [==>            ] 14.3% Loss: 0.0577, Epoch 29, Batch 17, CE_loss: 0.05653419718146324, Dice_loss: 0.005812101066112518, Consistency_loss: 0.0003339432296343148\n",
      "[Training] Epoch: 29 [==>            ] 15.1% Loss: 0.0580, Epoch 29, Batch 18, CE_loss: 0.056486740708351135, Dice_loss: 0.005684101954102516, Consistency_loss: 0.00040258915396407247\n",
      "[Training] Epoch: 29 [==>            ] 15.9% Loss: 0.0583, Epoch 29, Batch 19, CE_loss: 0.058575935661792755, Dice_loss: 0.006204638164490461, Consistency_loss: 0.00023752065317239612\n",
      "[Training] Epoch: 29 [==>            ] 16.7% Loss: 0.0594, Epoch 29, Batch 20, CE_loss: 0.0728876143693924, Dice_loss: 0.007840808480978012, Consistency_loss: 6.028683856129646e-05\n",
      "[Training] Epoch: 29 [==>            ] 17.5% Loss: 0.0596, Epoch 29, Batch 21, CE_loss: 0.0575861893594265, Dice_loss: 0.006234535947442055, Consistency_loss: 0.00028955817106179893\n",
      "[Training] Epoch: 29 [==>            ] 18.3% Loss: 0.0598, Epoch 29, Batch 22, CE_loss: 0.05696602165699005, Dice_loss: 0.005861856509000063, Consistency_loss: 0.00041653827065601945\n",
      "[Training] Epoch: 29 [==>            ] 19.0% Loss: 0.0594, Epoch 29, Batch 23, CE_loss: 0.04657796025276184, Dice_loss: 0.004745194688439369, Consistency_loss: 0.00042741099605336785\n",
      "[Training] Epoch: 29 [==>            ] 19.8% Loss: 0.0591, Epoch 29, Batch 24, CE_loss: 0.04667624458670616, Dice_loss: 0.004448354244232178, Consistency_loss: 0.0002488223253749311\n",
      "[Training] Epoch: 29 [===>           ] 20.6% Loss: 0.0590, Epoch 29, Batch 25, CE_loss: 0.05072007700800896, Dice_loss: 0.005267058499157429, Consistency_loss: 0.0002589886134956032\n",
      "[Training] Epoch: 29 [===>           ] 21.4% Loss: 0.0589, Epoch 29, Batch 26, CE_loss: 0.05097796767950058, Dice_loss: 0.005286786239594221, Consistency_loss: 0.00012372767378110439\n",
      "[Training] Epoch: 29 [===>           ] 22.2% Loss: 0.0591, Epoch 29, Batch 27, CE_loss: 0.05874035134911537, Dice_loss: 0.006132871378213167, Consistency_loss: 0.00048288796097040176\n",
      "[Training] Epoch: 29 [===>           ] 23.0% Loss: 0.0583, Epoch 29, Batch 28, CE_loss: 0.03271448239684105, Dice_loss: 0.0028865174390375614, Consistency_loss: 0.0002475768269505352\n",
      "[Training] Epoch: 29 [===>           ] 23.8% Loss: 0.0585, Epoch 29, Batch 29, CE_loss: 0.058382123708724976, Dice_loss: 0.005656045861542225, Consistency_loss: 0.0004679914563894272\n",
      "[Training] Epoch: 29 [===>           ] 24.6% Loss: 0.0589, Epoch 29, Batch 30, CE_loss: 0.06477279961109161, Dice_loss: 0.005604122765362263, Consistency_loss: 0.0005465242429636419\n",
      "[Training] Epoch: 29 [===>           ] 25.4% Loss: 0.0591, Epoch 29, Batch 31, CE_loss: 0.05997270718216896, Dice_loss: 0.005836366210132837, Consistency_loss: 0.00010256440145894885\n",
      "[Training] Epoch: 29 [===>           ] 26.2% Loss: 0.0589, Epoch 29, Batch 32, CE_loss: 0.04490281641483307, Dice_loss: 0.004534216597676277, Consistency_loss: 0.0002559813729021698\n",
      "[Training] Epoch: 29 [====>          ] 27.0% Loss: 0.0589, Epoch 29, Batch 33, CE_loss: 0.0559089332818985, Dice_loss: 0.00530505646020174, Consistency_loss: 0.0004926465335302055\n",
      "[Training] Epoch: 29 [====>          ] 27.8% Loss: 0.0591, Epoch 29, Batch 34, CE_loss: 0.058644771575927734, Dice_loss: 0.005931321065872908, Consistency_loss: 7.674595690332353e-05\n",
      "[Training] Epoch: 29 [====>          ] 28.6% Loss: 0.0591, Epoch 29, Batch 35, CE_loss: 0.053770761936903, Dice_loss: 0.0056778788566589355, Consistency_loss: 0.0003548482491169125\n",
      "[Training] Epoch: 29 [====>          ] 29.4% Loss: 0.0591, Epoch 29, Batch 36, CE_loss: 0.05234922841191292, Dice_loss: 0.005525033455342054, Consistency_loss: 0.00027099373983219266\n",
      "[Training] Epoch: 29 [====>          ] 30.2% Loss: 0.0595, Epoch 29, Batch 37, CE_loss: 0.06625574827194214, Dice_loss: 0.0070804329589009285, Consistency_loss: 0.0004205036093480885\n",
      "[Training] Epoch: 29 [====>          ] 31.0% Loss: 0.0596, Epoch 29, Batch 38, CE_loss: 0.056011639535427094, Dice_loss: 0.006037295330315828, Consistency_loss: 0.0007373473490588367\n",
      "[Training] Epoch: 29 [====>          ] 31.7% Loss: 0.0596, Epoch 29, Batch 39, CE_loss: 0.05341319367289543, Dice_loss: 0.005691120401024818, Consistency_loss: 0.0006083298358134925\n",
      "[Training] Epoch: 29 [====>          ] 32.5% Loss: 0.0601, Epoch 29, Batch 40, CE_loss: 0.07262209802865982, Dice_loss: 0.007529211230576038, Consistency_loss: 0.000572747434489429\n",
      "[Training] Epoch: 29 [=====>         ] 33.3% Loss: 0.0600, Epoch 29, Batch 41, CE_loss: 0.052160926163196564, Dice_loss: 0.005162885878235102, Consistency_loss: 0.0004935348406434059\n",
      "[Training] Epoch: 29 [=====>         ] 34.1% Loss: 0.0600, Epoch 29, Batch 42, CE_loss: 0.0508931502699852, Dice_loss: 0.005166229791939259, Consistency_loss: 0.0005635849665850401\n",
      "[Training] Epoch: 29 [=====>         ] 34.9% Loss: 0.0607, Epoch 29, Batch 43, CE_loss: 0.08272099494934082, Dice_loss: 0.00875507015734911, Consistency_loss: 0.00017458236834499985\n",
      "[Training] Epoch: 29 [=====>         ] 35.7% Loss: 0.0605, Epoch 29, Batch 44, CE_loss: 0.04722382500767708, Dice_loss: 0.004694746807217598, Consistency_loss: 0.00011834822362288833\n",
      "[Training] Epoch: 29 [=====>         ] 36.5% Loss: 0.0604, Epoch 29, Batch 45, CE_loss: 0.05172834172844887, Dice_loss: 0.0052260830998420715, Consistency_loss: 0.000380725774448365\n",
      "[Training] Epoch: 29 [=====>         ] 37.3% Loss: 0.0605, Epoch 29, Batch 46, CE_loss: 0.059521809220314026, Dice_loss: 0.006475076545029879, Consistency_loss: 3.943451520171948e-05\n",
      "[Training] Epoch: 29 [=====>         ] 38.1% Loss: 0.0605, Epoch 29, Batch 47, CE_loss: 0.05125602334737778, Dice_loss: 0.005330273881554604, Consistency_loss: 8.05794625193812e-05\n",
      "[Training] Epoch: 29 [=====>         ] 38.9% Loss: 0.0608, Epoch 29, Batch 48, CE_loss: 0.06795667856931686, Dice_loss: 0.007271097972989082, Consistency_loss: 0.0006292141624726355\n",
      "[Training] Epoch: 29 [=====>         ] 39.7% Loss: 0.0605, Epoch 29, Batch 49, CE_loss: 0.04367825388908386, Dice_loss: 0.0043128314428031445, Consistency_loss: 0.00047153435298241675\n",
      "[Training] Epoch: 29 [======>        ] 40.5% Loss: 0.0606, Epoch 29, Batch 50, CE_loss: 0.057453230023384094, Dice_loss: 0.0062860832549631596, Consistency_loss: 0.0006063380860723555\n",
      "[Training] Epoch: 29 [======>        ] 41.3% Loss: 0.0604, Epoch 29, Batch 51, CE_loss: 0.043456073850393295, Dice_loss: 0.004370570182800293, Consistency_loss: 0.0006887717172503471\n",
      "[Training] Epoch: 29 [======>        ] 42.1% Loss: 0.0606, Epoch 29, Batch 52, CE_loss: 0.06798239797353745, Dice_loss: 0.007130013778805733, Consistency_loss: 0.0001572375767864287\n",
      "[Training] Epoch: 29 [======>        ] 42.9% Loss: 0.0607, Epoch 29, Batch 53, CE_loss: 0.0576467365026474, Dice_loss: 0.005871646571904421, Consistency_loss: 0.0001638384856050834\n",
      "[Training] Epoch: 29 [======>        ] 43.7% Loss: 0.0608, Epoch 29, Batch 54, CE_loss: 0.05933672562241554, Dice_loss: 0.006201696582138538, Consistency_loss: 0.0003040962910745293\n",
      "[Training] Epoch: 29 [======>        ] 44.4% Loss: 0.0608, Epoch 29, Batch 55, CE_loss: 0.05556637793779373, Dice_loss: 0.00569174624979496, Consistency_loss: 0.00012250919826328754\n",
      "[Training] Epoch: 29 [======>        ] 45.2% Loss: 0.0613, Epoch 29, Batch 56, CE_loss: 0.07884526997804642, Dice_loss: 0.008426200598478317, Consistency_loss: 0.00026240054285153747\n",
      "[Training] Epoch: 29 [======>        ] 46.0% Loss: 0.0615, Epoch 29, Batch 57, CE_loss: 0.0645364373922348, Dice_loss: 0.0066747223027050495, Consistency_loss: 0.00014351365098264068\n",
      "[Training] Epoch: 29 [=======>       ] 46.8% Loss: 0.0614, Epoch 29, Batch 58, CE_loss: 0.05144208297133446, Dice_loss: 0.005185215268284082, Consistency_loss: 0.0002934684744104743\n",
      "[Training] Epoch: 29 [=======>       ] 47.6% Loss: 0.0613, Epoch 29, Batch 59, CE_loss: 0.05008156597614288, Dice_loss: 0.00512972055003047, Consistency_loss: 0.0002150646469090134\n",
      "[Training] Epoch: 29 [=======>       ] 48.4% Loss: 0.0608, Epoch 29, Batch 60, CE_loss: 0.029524443671107292, Dice_loss: 0.002371287439018488, Consistency_loss: 5.2215509640518576e-05\n",
      "[Training] Epoch: 29 [=======>       ] 49.2% Loss: 0.0605, Epoch 29, Batch 61, CE_loss: 0.040128979831933975, Dice_loss: 0.0038277716375887394, Consistency_loss: 0.00043467702926136553\n",
      "[Training] Epoch: 29 [=======>       ] 50.0% Loss: 0.0603, Epoch 29, Batch 62, CE_loss: 0.0402703657746315, Dice_loss: 0.003965503070503473, Consistency_loss: 0.00010241177369607612\n",
      "[Training] Epoch: 29 [=======>       ] 50.8% Loss: 0.0602, Epoch 29, Batch 63, CE_loss: 0.048995763063430786, Dice_loss: 0.004849586170166731, Consistency_loss: 0.0006093487027101219\n",
      "[Training] Epoch: 29 [=======>       ] 51.6% Loss: 0.0601, Epoch 29, Batch 64, CE_loss: 0.047884877771139145, Dice_loss: 0.004505038261413574, Consistency_loss: 0.0005560428253374994\n",
      "[Training] Epoch: 29 [=======>       ] 52.4% Loss: 0.0605, Epoch 29, Batch 65, CE_loss: 0.08040496706962585, Dice_loss: 0.008790403604507446, Consistency_loss: 0.0004991227760910988\n",
      "[Training] Epoch: 29 [=======>       ] 53.2% Loss: 0.0603, Epoch 29, Batch 66, CE_loss: 0.0408221110701561, Dice_loss: 0.0037459195591509342, Consistency_loss: 0.00021424806618597358\n",
      "[Training] Epoch: 29 [========>      ] 54.0% Loss: 0.0601, Epoch 29, Batch 67, CE_loss: 0.044524334371089935, Dice_loss: 0.0045053064823150635, Consistency_loss: 0.00024149644013959914\n",
      "[Training] Epoch: 29 [========>      ] 54.8% Loss: 0.0601, Epoch 29, Batch 68, CE_loss: 0.05247030034661293, Dice_loss: 0.00544299790635705, Consistency_loss: 7.845699292374775e-05\n",
      "[Training] Epoch: 29 [========>      ] 55.6% Loss: 0.0602, Epoch 29, Batch 69, CE_loss: 0.061596211045980453, Dice_loss: 0.006020982749760151, Consistency_loss: 6.381358980434015e-05\n",
      "[Training] Epoch: 29 [========>      ] 56.3% Loss: 0.0605, Epoch 29, Batch 70, CE_loss: 0.07118663191795349, Dice_loss: 0.007772098761051893, Consistency_loss: 0.0007480871281586587\n",
      "[Training] Epoch: 29 [========>      ] 57.1% Loss: 0.0605, Epoch 29, Batch 71, CE_loss: 0.05738338828086853, Dice_loss: 0.006205527577549219, Consistency_loss: 0.00047233173972927034\n",
      "[Training] Epoch: 29 [========>      ] 57.9% Loss: 0.0607, Epoch 29, Batch 72, CE_loss: 0.06919237971305847, Dice_loss: 0.006948231253772974, Consistency_loss: 0.0003704678383655846\n",
      "[Training] Epoch: 29 [========>      ] 58.7% Loss: 0.0608, Epoch 29, Batch 73, CE_loss: 0.06016284599900246, Dice_loss: 0.006636044476181269, Consistency_loss: 0.0005227953661233187\n",
      "[Training] Epoch: 29 [========>      ] 59.5% Loss: 0.0609, Epoch 29, Batch 74, CE_loss: 0.060945287346839905, Dice_loss: 0.0067153978161513805, Consistency_loss: 0.00017020062659867108\n",
      "[Training] Epoch: 29 [=========>     ] 60.3% Loss: 0.0608, Epoch 29, Batch 75, CE_loss: 0.04872439056634903, Dice_loss: 0.005054354667663574, Consistency_loss: 0.0006349388277158141\n",
      "[Training] Epoch: 29 [=========>     ] 61.1% Loss: 0.0612, Epoch 29, Batch 76, CE_loss: 0.0813465565443039, Dice_loss: 0.008771230466663837, Consistency_loss: 0.0005823663668707013\n",
      "[Training] Epoch: 29 [=========>     ] 61.9% Loss: 0.0612, Epoch 29, Batch 77, CE_loss: 0.05388903617858887, Dice_loss: 0.005723065230995417, Consistency_loss: 0.0005546545726247132\n",
      "[Training] Epoch: 29 [=========>     ] 62.7% Loss: 0.0611, Epoch 29, Batch 78, CE_loss: 0.050221193581819534, Dice_loss: 0.004713857546448708, Consistency_loss: 0.0003544222272466868\n",
      "[Training] Epoch: 29 [=========>     ] 63.5% Loss: 0.0611, Epoch 29, Batch 79, CE_loss: 0.051927048712968826, Dice_loss: 0.005360318813472986, Consistency_loss: 0.0006923096952959895\n",
      "[Training] Epoch: 29 [=========>     ] 64.3% Loss: 0.0610, Epoch 29, Batch 80, CE_loss: 0.048054859042167664, Dice_loss: 0.004280488472431898, Consistency_loss: 0.0004803141637239605\n",
      "[Training] Epoch: 29 [=========>     ] 65.1% Loss: 0.0611, Epoch 29, Batch 81, CE_loss: 0.05860687792301178, Dice_loss: 0.006284612696617842, Consistency_loss: 0.0007055924506857991\n",
      "[Training] Epoch: 29 [=========>     ] 65.9% Loss: 0.0610, Epoch 29, Batch 82, CE_loss: 0.0495537668466568, Dice_loss: 0.005133792757987976, Consistency_loss: 0.0006014588288962841\n",
      "[Training] Epoch: 29 [==========>    ] 66.7% Loss: 0.0610, Epoch 29, Batch 83, CE_loss: 0.05855927988886833, Dice_loss: 0.006454307120293379, Consistency_loss: 0.00022329929925035685\n",
      "[Training] Epoch: 29 [==========>    ] 67.5% Loss: 0.0609, Epoch 29, Batch 84, CE_loss: 0.04762817919254303, Dice_loss: 0.00486285425722599, Consistency_loss: 0.00018798360542859882\n",
      "[Training] Epoch: 29 [==========>    ] 68.3% Loss: 0.0608, Epoch 29, Batch 85, CE_loss: 0.04219603165984154, Dice_loss: 0.004009048920124769, Consistency_loss: 0.0005697855958715081\n",
      "[Training] Epoch: 29 [==========>    ] 69.0% Loss: 0.0607, Epoch 29, Batch 86, CE_loss: 0.05099261924624443, Dice_loss: 0.005180937238037586, Consistency_loss: 0.0001703843881841749\n",
      "[Training] Epoch: 29 [==========>    ] 69.8% Loss: 0.0607, Epoch 29, Batch 87, CE_loss: 0.05198070779442787, Dice_loss: 0.0055559370666742325, Consistency_loss: 0.00024331077293027192\n",
      "[Training] Epoch: 29 [==========>    ] 70.6% Loss: 0.0607, Epoch 29, Batch 88, CE_loss: 0.055247195065021515, Dice_loss: 0.005772046744823456, Consistency_loss: 0.00010805959027493373\n",
      "[Training] Epoch: 29 [==========>    ] 71.4% Loss: 0.0609, Epoch 29, Batch 89, CE_loss: 0.07487504184246063, Dice_loss: 0.007334759924560785, Consistency_loss: 0.0004466249083634466\n",
      "[Training] Epoch: 29 [==========>    ] 72.2% Loss: 0.0608, Epoch 29, Batch 90, CE_loss: 0.04068960249423981, Dice_loss: 0.0038913534954190254, Consistency_loss: 0.000491938553750515\n",
      "[Training] Epoch: 29 [==========>    ] 73.0% Loss: 0.0606, Epoch 29, Batch 91, CE_loss: 0.0379018671810627, Dice_loss: 0.003655573818832636, Consistency_loss: 0.00039840000681579113\n",
      "[Training] Epoch: 29 [===========>   ] 73.8% Loss: 0.0606, Epoch 29, Batch 92, CE_loss: 0.05465073138475418, Dice_loss: 0.00577038386836648, Consistency_loss: 0.0003841581929009408\n",
      "[Training] Epoch: 29 [===========>   ] 74.6% Loss: 0.0605, Epoch 29, Batch 93, CE_loss: 0.04583842679858208, Dice_loss: 0.004382255952805281, Consistency_loss: 0.0003641834482550621\n",
      "[Training] Epoch: 29 [===========>   ] 75.4% Loss: 0.0604, Epoch 29, Batch 94, CE_loss: 0.04702122136950493, Dice_loss: 0.004869800992310047, Consistency_loss: 0.0002740348281804472\n",
      "[Training] Epoch: 29 [===========>   ] 76.2% Loss: 0.0602, Epoch 29, Batch 95, CE_loss: 0.04351019486784935, Dice_loss: 0.004434710834175348, Consistency_loss: 7.259276026161388e-05\n",
      "[Training] Epoch: 29 [===========>   ] 77.0% Loss: 0.0601, Epoch 29, Batch 96, CE_loss: 0.045141082257032394, Dice_loss: 0.0046465652994811535, Consistency_loss: 5.688904275302775e-05\n",
      "[Training] Epoch: 29 [===========>   ] 77.8% Loss: 0.0604, Epoch 29, Batch 97, CE_loss: 0.08114856481552124, Dice_loss: 0.008431895636022091, Consistency_loss: 0.00024386281438637525\n",
      "[Training] Epoch: 29 [===========>   ] 78.6% Loss: 0.0604, Epoch 29, Batch 98, CE_loss: 0.05428200587630272, Dice_loss: 0.005680194590240717, Consistency_loss: 0.00029345715302042663\n",
      "[Training] Epoch: 29 [===========>   ] 79.4% Loss: 0.0605, Epoch 29, Batch 99, CE_loss: 0.06262852996587753, Dice_loss: 0.006541358307003975, Consistency_loss: 0.0002319612103747204\n",
      "[Training] Epoch: 29 [============>  ] 80.2% Loss: 0.0604, Epoch 29, Batch 100, CE_loss: 0.04665256664156914, Dice_loss: 0.004753889515995979, Consistency_loss: 0.0001962732058018446\n",
      "[Training] Epoch: 29 [============>  ] 81.0% Loss: 0.0602, Epoch 29, Batch 101, CE_loss: 0.035870958119630814, Dice_loss: 0.0032565640285611153, Consistency_loss: 0.00047123702825047076\n",
      "[Training] Epoch: 29 [============>  ] 81.7% Loss: 0.0602, Epoch 29, Batch 102, CE_loss: 0.05083692818880081, Dice_loss: 0.005284707527607679, Consistency_loss: 9.937601862475276e-05\n",
      "[Training] Epoch: 29 [============>  ] 82.5% Loss: 0.0602, Epoch 29, Batch 103, CE_loss: 0.056236643344163895, Dice_loss: 0.006121842656284571, Consistency_loss: 0.00045208988012745976\n",
      "[Training] Epoch: 29 [============>  ] 83.3% Loss: 0.0603, Epoch 29, Batch 104, CE_loss: 0.06359096616506577, Dice_loss: 0.006752367597073317, Consistency_loss: 0.00046553160063922405\n",
      "[Training] Epoch: 29 [============>  ] 84.1% Loss: 0.0603, Epoch 29, Batch 105, CE_loss: 0.0482027605175972, Dice_loss: 0.004988385830074549, Consistency_loss: 0.00043185890535824\n",
      "[Training] Epoch: 29 [============>  ] 84.9% Loss: 0.0603, Epoch 29, Batch 106, CE_loss: 0.0577838271856308, Dice_loss: 0.006274429149925709, Consistency_loss: 0.0006444882601499557\n",
      "[Training] Epoch: 29 [============>  ] 85.7% Loss: 0.0602, Epoch 29, Batch 107, CE_loss: 0.04989330470561981, Dice_loss: 0.00477426964789629, Consistency_loss: 0.0005260470788925886\n",
      "[Training] Epoch: 29 [============>  ] 86.5% Loss: 0.0601, Epoch 29, Batch 108, CE_loss: 0.038025643676519394, Dice_loss: 0.0032703103497624397, Consistency_loss: 0.0002771163999568671\n",
      "[Training] Epoch: 29 [=============> ] 87.3% Loss: 0.0600, Epoch 29, Batch 109, CE_loss: 0.045068345963954926, Dice_loss: 0.0046211290173232555, Consistency_loss: 5.610675361822359e-05\n",
      "[Training] Epoch: 29 [=============> ] 88.1% Loss: 0.0599, Epoch 29, Batch 110, CE_loss: 0.04278608411550522, Dice_loss: 0.003637460060417652, Consistency_loss: 0.0003531408729031682\n",
      "[Training] Epoch: 29 [=============> ] 88.9% Loss: 0.0599, Epoch 29, Batch 111, CE_loss: 0.06005093455314636, Dice_loss: 0.00580135453492403, Consistency_loss: 0.00020567326282616705\n",
      "[Training] Epoch: 29 [=============> ] 89.7% Loss: 0.0598, Epoch 29, Batch 112, CE_loss: 0.04397829249501228, Dice_loss: 0.004392340779304504, Consistency_loss: 0.0004933992167934775\n",
      "[Training] Epoch: 29 [=============> ] 90.5% Loss: 0.0600, Epoch 29, Batch 113, CE_loss: 0.0701901912689209, Dice_loss: 0.0074495854787528515, Consistency_loss: 0.000786423624958843\n",
      "[Training] Epoch: 29 [=============> ] 91.3% Loss: 0.0600, Epoch 29, Batch 114, CE_loss: 0.0605546236038208, Dice_loss: 0.0065294536761939526, Consistency_loss: 0.0004296002152841538\n",
      "[Training] Epoch: 29 [=============> ] 92.1% Loss: 0.0599, Epoch 29, Batch 115, CE_loss: 0.03579936549067497, Dice_loss: 0.0033273028675466776, Consistency_loss: 0.00028398260474205017\n",
      "[Training] Epoch: 29 [=============> ] 92.9% Loss: 0.0599, Epoch 29, Batch 116, CE_loss: 0.06008880212903023, Dice_loss: 0.006227302830666304, Consistency_loss: 0.00011980319686699659\n",
      "[Training] Epoch: 29 [==============>] 93.7% Loss: 0.0599, Epoch 29, Batch 117, CE_loss: 0.05295994132757187, Dice_loss: 0.005635437555611134, Consistency_loss: 0.0002999726857524365\n",
      "[Training] Epoch: 29 [==============>] 94.4% Loss: 0.0599, Epoch 29, Batch 118, CE_loss: 0.048340559005737305, Dice_loss: 0.004633771255612373, Consistency_loss: 0.0003352569183334708\n",
      "[Training] Epoch: 29 [==============>] 95.2% Loss: 0.0598, Epoch 29, Batch 119, CE_loss: 0.04761335253715515, Dice_loss: 0.004972221329808235, Consistency_loss: 4.932922820444219e-05\n",
      "[Training] Epoch: 29 [==============>] 96.0% Loss: 0.0597, Epoch 29, Batch 120, CE_loss: 0.043587539345026016, Dice_loss: 0.004414518363773823, Consistency_loss: 0.00024857005337253213\n",
      "[Training] Epoch: 29 [==============>] 96.8% Loss: 0.0598, Epoch 29, Batch 121, CE_loss: 0.05995454266667366, Dice_loss: 0.0062737674452364445, Consistency_loss: 0.0003954892454203218\n",
      "[Training] Epoch: 29 [==============>] 97.6% Loss: 0.0598, Epoch 29, Batch 122, CE_loss: 0.060968220233917236, Dice_loss: 0.006752228830009699, Consistency_loss: 0.00033599583548493683\n",
      "[Training] Epoch: 29 [==============>] 98.4% Loss: 0.0597, Epoch 29, Batch 123, CE_loss: 0.03928442299365997, Dice_loss: 0.0038398371543735266, Consistency_loss: 0.00048611193778924644\n",
      "[Training] Epoch: 29 [==============>] 99.2% Loss: 0.0597, Epoch 29, Batch 124, CE_loss: 0.054651323705911636, Dice_loss: 0.005810152273625135, Consistency_loss: 0.0004945015534758568\n",
      "[Training] Epoch: 29 [DONE]                                 \n",
      "Epoch 29, Batch 125, CE_loss: 0.0883851870894432, Dice_loss: 0.008700755424797535, Consistency_loss: 0.00032040398218668997\n",
      "[Validation] Epoch: 29 [DONE]                                 \n",
      "[Epoch: 29, TrainLoss: 0.0600, TrainDice: 0.0055, ValLoss: 0.1627                                            \n",
      "Number of batches:  126\n",
      "[Training] Epoch: 30 [>              ] 0.8% Loss: 0.0393, Epoch 30, Batch 0, CE_loss: 0.035878028720617294, Dice_loss: 0.003313726279884577, Consistency_loss: 7.478805491700768e-05\n",
      "[Training] Epoch: 30 [>              ] 1.6% Loss: 0.0614, Epoch 30, Batch 1, CE_loss: 0.07624520361423492, Dice_loss: 0.007123808842152357, Consistency_loss: 0.0002357450284762308\n",
      "[Training] Epoch: 30 [>              ] 2.4% Loss: 0.0550, Epoch 30, Batch 2, CE_loss: 0.038189273327589035, Dice_loss: 0.00374118541367352, Consistency_loss: 4.8942940338747576e-05\n",
      "[Training] Epoch: 30 [>              ] 3.2% Loss: 0.0570, Epoch 30, Batch 3, CE_loss: 0.05712215602397919, Dice_loss: 0.005879138596355915, Consistency_loss: 0.0003062536125071347\n",
      "[Training] Epoch: 30 [>              ] 4.0% Loss: 0.0597, Epoch 30, Batch 4, CE_loss: 0.06359770894050598, Dice_loss: 0.006320313084870577, Consistency_loss: 0.00028295599622651935\n",
      "[Training] Epoch: 30 [>              ] 4.8% Loss: 0.0594, Epoch 30, Batch 5, CE_loss: 0.05310849845409393, Dice_loss: 0.004751913249492645, Consistency_loss: 0.00012586927914526314\n",
      "[Training] Epoch: 30 [>              ] 5.6% Loss: 0.0594, Epoch 30, Batch 6, CE_loss: 0.05398131161928177, Dice_loss: 0.005648401565849781, Consistency_loss: 0.00013770586519967765\n",
      "[Training] Epoch: 30 [>              ] 6.3% Loss: 0.0582, Epoch 30, Batch 7, CE_loss: 0.04530739784240723, Dice_loss: 0.004224197939038277, Consistency_loss: 0.00022512122814077884\n",
      "[Training] Epoch: 30 [=>             ] 7.1% Loss: 0.0575, Epoch 30, Batch 8, CE_loss: 0.04714294895529747, Dice_loss: 0.004655005410313606, Consistency_loss: 0.00012355860962998122\n",
      "[Training] Epoch: 30 [=>             ] 7.9% Loss: 0.0576, Epoch 30, Batch 9, CE_loss: 0.05291014537215233, Dice_loss: 0.00565295247361064, Consistency_loss: 4.145053026149981e-05\n",
      "[Training] Epoch: 30 [=>             ] 8.7% Loss: 0.0573, Epoch 30, Batch 10, CE_loss: 0.0484643392264843, Dice_loss: 0.005022414028644562, Consistency_loss: 0.0006549360114149749\n",
      "[Training] Epoch: 30 [=>             ] 9.5% Loss: 0.0585, Epoch 30, Batch 11, CE_loss: 0.06472480297088623, Dice_loss: 0.006545725744217634, Consistency_loss: 0.0004087424895260483\n",
      "[Training] Epoch: 30 [=>             ] 10.3% Loss: 0.0591, Epoch 30, Batch 12, CE_loss: 0.059489961713552475, Dice_loss: 0.006309879012405872, Consistency_loss: 0.0003057521826121956\n",
      "[Training] Epoch: 30 [=>             ] 11.1% Loss: 0.0600, Epoch 30, Batch 13, CE_loss: 0.0637662410736084, Dice_loss: 0.007043637800961733, Consistency_loss: 0.000465569639345631\n",
      "[Training] Epoch: 30 [=>             ] 11.9% Loss: 0.0585, Epoch 30, Batch 14, CE_loss: 0.034904345870018005, Dice_loss: 0.003149159485474229, Consistency_loss: 0.00041636807145550847\n",
      "[Training] Epoch: 30 [=>             ] 12.7% Loss: 0.0579, Epoch 30, Batch 15, CE_loss: 0.0427996851503849, Dice_loss: 0.004227903671562672, Consistency_loss: 0.000518244574777782\n",
      "[Training] Epoch: 30 [==>            ] 13.5% Loss: 0.0571, Epoch 30, Batch 16, CE_loss: 0.04127980023622513, Dice_loss: 0.003969012293964624, Consistency_loss: 0.000162047115736641\n",
      "[Training] Epoch: 30 [==>            ] 14.3% Loss: 0.0575, Epoch 30, Batch 17, CE_loss: 0.05793825536966324, Dice_loss: 0.006297992542386055, Consistency_loss: 0.00040326445014216006\n",
      "[Training] Epoch: 30 [==>            ] 15.1% Loss: 0.0581, Epoch 30, Batch 18, CE_loss: 0.06080198287963867, Dice_loss: 0.006168405991047621, Consistency_loss: 0.00034784036688506603\n",
      "[Training] Epoch: 30 [==>            ] 15.9% Loss: 0.0577, Epoch 30, Batch 19, CE_loss: 0.046592406928539276, Dice_loss: 0.0045957909896969795, Consistency_loss: 9.54303759499453e-05\n",
      "[Training] Epoch: 30 [==>            ] 16.7% Loss: 0.0583, Epoch 30, Batch 20, CE_loss: 0.06291134655475616, Dice_loss: 0.006737521383911371, Consistency_loss: 0.00030574866104871035\n",
      "[Training] Epoch: 30 [==>            ] 17.5% Loss: 0.0584, Epoch 30, Batch 21, CE_loss: 0.05438511446118355, Dice_loss: 0.005398531444370747, Consistency_loss: 5.614562542177737e-05\n",
      "[Training] Epoch: 30 [==>            ] 18.3% Loss: 0.0577, Epoch 30, Batch 22, CE_loss: 0.039110369980335236, Dice_loss: 0.003691761288791895, Consistency_loss: 0.0003773985954467207\n",
      "[Training] Epoch: 30 [==>            ] 19.0% Loss: 0.0581, Epoch 30, Batch 23, CE_loss: 0.06127316877245903, Dice_loss: 0.006540562491863966, Consistency_loss: 0.00023679887817706913\n",
      "[Training] Epoch: 30 [==>            ] 19.8% Loss: 0.0578, Epoch 30, Batch 24, CE_loss: 0.04442889243364334, Dice_loss: 0.004402609542012215, Consistency_loss: 0.00017474732885602862\n",
      "[Training] Epoch: 30 [===>           ] 20.6% Loss: 0.0578, Epoch 30, Batch 25, CE_loss: 0.05373639613389969, Dice_loss: 0.00572582334280014, Consistency_loss: 0.00024781469255685806\n",
      "[Training] Epoch: 30 [===>           ] 21.4% Loss: 0.0579, Epoch 30, Batch 26, CE_loss: 0.054338499903678894, Dice_loss: 0.005700467620044947, Consistency_loss: 0.0003620125644374639\n",
      "[Training] Epoch: 30 [===>           ] 22.2% Loss: 0.0582, Epoch 30, Batch 27, CE_loss: 0.05979831516742706, Dice_loss: 0.006104350555688143, Consistency_loss: 0.0005583998863585293\n",
      "[Training] Epoch: 30 [===>           ] 23.0% Loss: 0.0582, Epoch 30, Batch 28, CE_loss: 0.051062192767858505, Dice_loss: 0.005063898861408234, Consistency_loss: 0.00037514633731916547\n",
      "[Training] Epoch: 30 [===>           ] 23.8% Loss: 0.0590, Epoch 30, Batch 29, CE_loss: 0.07546406984329224, Dice_loss: 0.008047816343605518, Consistency_loss: 0.0004070335708092898\n",
      "[Training] Epoch: 30 [===>           ] 24.6% Loss: 0.0583, Epoch 30, Batch 30, CE_loss: 0.03373091295361519, Dice_loss: 0.00303793721832335, Consistency_loss: 0.0006017539999447763\n",
      "[Training] Epoch: 30 [===>           ] 25.4% Loss: 0.0584, Epoch 30, Batch 31, CE_loss: 0.05496416985988617, Dice_loss: 0.00594261335209012, Consistency_loss: 0.0002312121941940859\n",
      "[Training] Epoch: 30 [===>           ] 26.2% Loss: 0.0583, Epoch 30, Batch 32, CE_loss: 0.04874945804476738, Dice_loss: 0.005056983325630426, Consistency_loss: 4.018588151666336e-05\n",
      "[Training] Epoch: 30 [====>          ] 27.0% Loss: 0.0580, Epoch 30, Batch 33, CE_loss: 0.045173529535532, Dice_loss: 0.0045820134691894054, Consistency_loss: 4.7633999201934785e-05\n",
      "[Training] Epoch: 30 [====>          ] 27.8% Loss: 0.0581, Epoch 30, Batch 34, CE_loss: 0.05470392853021622, Dice_loss: 0.005871485453099012, Consistency_loss: 0.0005251608090475202\n",
      "[Training] Epoch: 30 [====>          ] 28.6% Loss: 0.0580, Epoch 30, Batch 35, CE_loss: 0.047653406858444214, Dice_loss: 0.0049378531984984875, Consistency_loss: 0.0003276925126556307\n",
      "[Training] Epoch: 30 [====>          ] 29.4% Loss: 0.0578, Epoch 30, Batch 36, CE_loss: 0.04749317467212677, Dice_loss: 0.004854306578636169, Consistency_loss: 0.00015312813047785312\n",
      "[Training] Epoch: 30 [====>          ] 30.2% Loss: 0.0579, Epoch 30, Batch 37, CE_loss: 0.05587022379040718, Dice_loss: 0.005446699447929859, Consistency_loss: 0.00032015788019634783\n",
      "[Training] Epoch: 30 [====>          ] 31.0% Loss: 0.0590, Epoch 30, Batch 38, CE_loss: 0.08974398672580719, Dice_loss: 0.009713776409626007, Consistency_loss: 0.0006248340359888971\n",
      "[Training] Epoch: 30 [====>          ] 31.7% Loss: 0.0584, Epoch 30, Batch 39, CE_loss: 0.031107977032661438, Dice_loss: 0.0027747631538659334, Consistency_loss: 0.0007176256622187793\n",
      "[Training] Epoch: 30 [====>          ] 32.5% Loss: 0.0583, Epoch 30, Batch 40, CE_loss: 0.04804041609168053, Dice_loss: 0.0050420076586306095, Consistency_loss: 0.0005364011158235371\n",
      "[Training] Epoch: 30 [=====>         ] 33.3% Loss: 0.0585, Epoch 30, Batch 41, CE_loss: 0.05840371176600456, Dice_loss: 0.006331725511699915, Consistency_loss: 0.0005424180999398232\n",
      "[Training] Epoch: 30 [=====>         ] 34.1% Loss: 0.0582, Epoch 30, Batch 42, CE_loss: 0.04420788213610649, Dice_loss: 0.00448806444182992, Consistency_loss: 0.00013617957301903516\n",
      "[Training] Epoch: 30 [=====>         ] 34.9% Loss: 0.0579, Epoch 30, Batch 43, CE_loss: 0.040576741099357605, Dice_loss: 0.0037397819105535746, Consistency_loss: 5.8239325881004333e-05\n",
      "[Training] Epoch: 30 [=====>         ] 35.7% Loss: 0.0584, Epoch 30, Batch 44, CE_loss: 0.06957567483186722, Dice_loss: 0.007594844792038202, Consistency_loss: 0.00041798848542384803\n",
      "[Training] Epoch: 30 [=====>         ] 36.5% Loss: 0.0589, Epoch 30, Batch 45, CE_loss: 0.07574401795864105, Dice_loss: 0.008427832275629044, Consistency_loss: 0.0002442372206132859\n",
      "[Training] Epoch: 30 [=====>         ] 37.3% Loss: 0.0588, Epoch 30, Batch 46, CE_loss: 0.047408100217580795, Dice_loss: 0.004952734801918268, Consistency_loss: 0.00023080450773704797\n",
      "[Training] Epoch: 30 [=====>         ] 38.1% Loss: 0.0594, Epoch 30, Batch 47, CE_loss: 0.07992084324359894, Dice_loss: 0.008796054869890213, Consistency_loss: 0.0005131826037541032\n",
      "[Training] Epoch: 30 [=====>         ] 38.9% Loss: 0.0595, Epoch 30, Batch 48, CE_loss: 0.05848143994808197, Dice_loss: 0.006315887439996004, Consistency_loss: 0.0001312841341132298\n",
      "[Training] Epoch: 30 [=====>         ] 39.7% Loss: 0.0599, Epoch 30, Batch 49, CE_loss: 0.07023109495639801, Dice_loss: 0.007650742307305336, Consistency_loss: 0.00038188553298823535\n",
      "[Training] Epoch: 30 [======>        ] 40.5% Loss: 0.0599, Epoch 30, Batch 50, CE_loss: 0.05274900048971176, Dice_loss: 0.005373198073357344, Consistency_loss: 0.0006531128892675042\n",
      "[Training] Epoch: 30 [======>        ] 41.3% Loss: 0.0598, Epoch 30, Batch 51, CE_loss: 0.04862989857792854, Dice_loss: 0.004831414204090834, Consistency_loss: 0.0007918672636151314\n",
      "[Training] Epoch: 30 [======>        ] 42.1% Loss: 0.0596, Epoch 30, Batch 52, CE_loss: 0.047467056661844254, Dice_loss: 0.004895407240837812, Consistency_loss: 0.00013443104398902506\n",
      "[Training] Epoch: 30 [======>        ] 42.9% Loss: 0.0593, Epoch 30, Batch 53, CE_loss: 0.0369449220597744, Dice_loss: 0.003443692810833454, Consistency_loss: 0.00018572801491245627\n",
      "[Training] Epoch: 30 [======>        ] 43.7% Loss: 0.0593, Epoch 30, Batch 54, CE_loss: 0.056342821568250656, Dice_loss: 0.006038707681000233, Consistency_loss: 0.00022369598445948213\n",
      "[Training] Epoch: 30 [======>        ] 44.4% Loss: 0.0589, Epoch 30, Batch 55, CE_loss: 0.03213759884238243, Dice_loss: 0.0029537202790379524, Consistency_loss: 0.00017507636221125722\n",
      "[Training] Epoch: 30 [======>        ] 45.2% Loss: 0.0589, Epoch 30, Batch 56, CE_loss: 0.051199134439229965, Dice_loss: 0.005270299501717091, Consistency_loss: 0.0001757242571329698\n",
      "[Training] Epoch: 30 [======>        ] 46.0% Loss: 0.0589, Epoch 30, Batch 57, CE_loss: 0.05531024560332298, Dice_loss: 0.006002721376717091, Consistency_loss: 0.00023600063286721706\n",
      "[Training] Epoch: 30 [=======>       ] 46.8% Loss: 0.0589, Epoch 30, Batch 58, CE_loss: 0.05287821590900421, Dice_loss: 0.005015015602111816, Consistency_loss: 0.0002459866809658706\n",
      "[Training] Epoch: 30 [=======>       ] 47.6% Loss: 0.0590, Epoch 30, Batch 59, CE_loss: 0.06046260893344879, Dice_loss: 0.006392146926373243, Consistency_loss: 5.190754382056184e-05\n",
      "[Training] Epoch: 30 [=======>       ] 48.4% Loss: 0.0589, Epoch 30, Batch 60, CE_loss: 0.044751737266778946, Dice_loss: 0.004292294383049011, Consistency_loss: 4.919857019558549e-05\n",
      "[Training] Epoch: 30 [=======>       ] 49.2% Loss: 0.0592, Epoch 30, Batch 61, CE_loss: 0.07097899168729782, Dice_loss: 0.007785746827721596, Consistency_loss: 4.9983878852799535e-05\n",
      "[Training] Epoch: 30 [=======>       ] 50.0% Loss: 0.0591, Epoch 30, Batch 62, CE_loss: 0.04741697385907173, Dice_loss: 0.004749732092022896, Consistency_loss: 6.185928941704333e-05\n",
      "[Training] Epoch: 30 [=======>       ] 50.8% Loss: 0.0587, Epoch 30, Batch 63, CE_loss: 0.03362114727497101, Dice_loss: 0.0030847371090203524, Consistency_loss: 0.00010048940748674795\n",
      "[Training] Epoch: 30 [=======>       ] 51.6% Loss: 0.0585, Epoch 30, Batch 64, CE_loss: 0.03809013590216637, Dice_loss: 0.0037462192121893167, Consistency_loss: 0.00046735210344195366\n",
      "[Training] Epoch: 30 [=======>       ] 52.4% Loss: 0.0585, Epoch 30, Batch 65, CE_loss: 0.056007251143455505, Dice_loss: 0.005794810131192207, Consistency_loss: 0.00043092892155982554\n",
      "[Training] Epoch: 30 [=======>       ] 53.2% Loss: 0.0587, Epoch 30, Batch 66, CE_loss: 0.06266357004642487, Dice_loss: 0.006361471489071846, Consistency_loss: 0.0001960516528924927\n",
      "[Training] Epoch: 30 [========>      ] 54.0% Loss: 0.0587, Epoch 30, Batch 67, CE_loss: 0.052306775003671646, Dice_loss: 0.005359545350074768, Consistency_loss: 0.0002604969486128539\n",
      "[Training] Epoch: 30 [========>      ] 54.8% Loss: 0.0585, Epoch 30, Batch 68, CE_loss: 0.038356322795152664, Dice_loss: 0.0035987289156764746, Consistency_loss: 0.0002470827894285321\n",
      "[Training] Epoch: 30 [========>      ] 55.6% Loss: 0.0584, Epoch 30, Batch 69, CE_loss: 0.04839874058961868, Dice_loss: 0.004888840019702911, Consistency_loss: 6.351748015731573e-05\n",
      "[Training] Epoch: 30 [========>      ] 56.3% Loss: 0.0586, Epoch 30, Batch 70, CE_loss: 0.06814346462488174, Dice_loss: 0.007573861163109541, Consistency_loss: 6.580290937563404e-05\n",
      "[Training] Epoch: 30 [========>      ] 57.1% Loss: 0.0587, Epoch 30, Batch 71, CE_loss: 0.05469934269785881, Dice_loss: 0.005393475294113159, Consistency_loss: 0.0005293049616739154\n",
      "[Training] Epoch: 30 [========>      ] 57.9% Loss: 0.0586, Epoch 30, Batch 72, CE_loss: 0.05008390173316002, Dice_loss: 0.005392232909798622, Consistency_loss: 3.863363599521108e-05\n",
      "[Training] Epoch: 30 [========>      ] 58.7% Loss: 0.0589, Epoch 30, Batch 73, CE_loss: 0.07038982212543488, Dice_loss: 0.0077304174192249775, Consistency_loss: 4.416930823936127e-05\n",
      "[Training] Epoch: 30 [========>      ] 59.5% Loss: 0.0589, Epoch 30, Batch 74, CE_loss: 0.052620843052864075, Dice_loss: 0.005587850697338581, Consistency_loss: 0.000565249181818217\n",
      "[Training] Epoch: 30 [=========>     ] 60.3% Loss: 0.0586, Epoch 30, Batch 75, CE_loss: 0.03449832275509834, Dice_loss: 0.003227891167625785, Consistency_loss: 0.0005288381362333894\n",
      "[Training] Epoch: 30 [=========>     ] 61.1% Loss: 0.0585, Epoch 30, Batch 76, CE_loss: 0.04692421108484268, Dice_loss: 0.00474593648687005, Consistency_loss: 0.0004735351540148258\n",
      "[Training] Epoch: 30 [=========>     ] 61.9% Loss: 0.0585, Epoch 30, Batch 77, CE_loss: 0.04832551255822182, Dice_loss: 0.004537148866802454, Consistency_loss: 0.0004959628568030894\n",
      "[Training] Epoch: 30 [=========>     ] 62.7% Loss: 0.0582, Epoch 30, Batch 78, CE_loss: 0.03688774257898331, Dice_loss: 0.00344102387316525, Consistency_loss: 0.0002839983208104968\n",
      "[Training] Epoch: 30 [=========>     ] 63.5% Loss: 0.0580, Epoch 30, Batch 79, CE_loss: 0.0391182005405426, Dice_loss: 0.0036646442022174597, Consistency_loss: 0.0002300743799423799\n",
      "[Training] Epoch: 30 [=========>     ] 64.3% Loss: 0.0581, Epoch 30, Batch 80, CE_loss: 0.060918137431144714, Dice_loss: 0.00604545371606946, Consistency_loss: 6.544349162140861e-05\n",
      "[Training] Epoch: 30 [=========>     ] 65.1% Loss: 0.0582, Epoch 30, Batch 81, CE_loss: 0.05719294399023056, Dice_loss: 0.0059741646982729435, Consistency_loss: 0.00047653020010329783\n",
      "[Training] Epoch: 30 [=========>     ] 65.9% Loss: 0.0583, Epoch 30, Batch 82, CE_loss: 0.05737057700753212, Dice_loss: 0.006045945454388857, Consistency_loss: 0.00044809209066443145\n",
      "[Training] Epoch: 30 [==========>    ] 66.7% Loss: 0.0583, Epoch 30, Batch 83, CE_loss: 0.056229542940855026, Dice_loss: 0.006000253837555647, Consistency_loss: 0.00015077994612511247\n",
      "[Training] Epoch: 30 [==========>    ] 67.5% Loss: 0.0586, Epoch 30, Batch 84, CE_loss: 0.07131580263376236, Dice_loss: 0.00768633047118783, Consistency_loss: 0.00011333158909110352\n",
      "[Training] Epoch: 30 [==========>    ] 68.3% Loss: 0.0585, Epoch 30, Batch 85, CE_loss: 0.04706742614507675, Dice_loss: 0.004854744765907526, Consistency_loss: 0.0005215437267906964\n",
      "[Training] Epoch: 30 [==========>    ] 69.0% Loss: 0.0584, Epoch 30, Batch 86, CE_loss: 0.04218217357993126, Dice_loss: 0.004153785295784473, Consistency_loss: 0.0004087127454113215\n",
      "[Training] Epoch: 30 [==========>    ] 69.8% Loss: 0.0584, Epoch 30, Batch 87, CE_loss: 0.05435389652848244, Dice_loss: 0.005981693044304848, Consistency_loss: 0.00017616819241084158\n",
      "[Training] Epoch: 30 [==========>    ] 70.6% Loss: 0.0587, Epoch 30, Batch 88, CE_loss: 0.07310938090085983, Dice_loss: 0.008041419088840485, Consistency_loss: 0.00021244736853986979\n",
      "[Training] Epoch: 30 [==========>    ] 71.4% Loss: 0.0587, Epoch 30, Batch 89, CE_loss: 0.05475207790732384, Dice_loss: 0.005701115820556879, Consistency_loss: 0.000379790406441316\n",
      "[Training] Epoch: 30 [==========>    ] 72.2% Loss: 0.0587, Epoch 30, Batch 90, CE_loss: 0.0531560517847538, Dice_loss: 0.005660824477672577, Consistency_loss: 0.0004659011901821941\n",
      "[Training] Epoch: 30 [==========>    ] 73.0% Loss: 0.0585, Epoch 30, Batch 91, CE_loss: 0.03620104119181633, Dice_loss: 0.003401367459446192, Consistency_loss: 0.0005420296802185476\n",
      "[Training] Epoch: 30 [===========>   ] 73.8% Loss: 0.0584, Epoch 30, Batch 92, CE_loss: 0.04444830119609833, Dice_loss: 0.004349845927208662, Consistency_loss: 0.00035277611459605396\n",
      "[Training] Epoch: 30 [===========>   ] 74.6% Loss: 0.0585, Epoch 30, Batch 93, CE_loss: 0.06199728697538376, Dice_loss: 0.006854582112282515, Consistency_loss: 0.00039010916952975094\n",
      "[Training] Epoch: 30 [===========>   ] 75.4% Loss: 0.0585, Epoch 30, Batch 94, CE_loss: 0.05605761706829071, Dice_loss: 0.0060355025343596935, Consistency_loss: 0.00031450411188416183\n",
      "[Training] Epoch: 30 [===========>   ] 76.2% Loss: 0.0587, Epoch 30, Batch 95, CE_loss: 0.06430792808532715, Dice_loss: 0.007006430998444557, Consistency_loss: 0.0005192998796701431\n",
      "[Training] Epoch: 30 [===========>   ] 77.0% Loss: 0.0586, Epoch 30, Batch 96, CE_loss: 0.049668088555336, Dice_loss: 0.00515342690050602, Consistency_loss: 0.0002418086223769933\n",
      "[Training] Epoch: 30 [===========>   ] 77.8% Loss: 0.0588, Epoch 30, Batch 97, CE_loss: 0.06727419048547745, Dice_loss: 0.007423827424645424, Consistency_loss: 8.272464037872851e-05\n",
      "[Training] Epoch: 30 [===========>   ] 78.6% Loss: 0.0588, Epoch 30, Batch 98, CE_loss: 0.054356399923563004, Dice_loss: 0.005921191070228815, Consistency_loss: 0.00021500907314475626\n",
      "[Training] Epoch: 30 [===========>   ] 79.4% Loss: 0.0588, Epoch 30, Batch 99, CE_loss: 0.04926982894539833, Dice_loss: 0.00439439294859767, Consistency_loss: 0.00023276417050510645\n",
      "[Training] Epoch: 30 [============>  ] 80.2% Loss: 0.0590, Epoch 30, Batch 100, CE_loss: 0.07155843824148178, Dice_loss: 0.007968355901539326, Consistency_loss: 0.0003887435595970601\n",
      "[Training] Epoch: 30 [============>  ] 81.0% Loss: 0.0591, Epoch 30, Batch 101, CE_loss: 0.06031900644302368, Dice_loss: 0.0067412094213068485, Consistency_loss: 8.696492295712233e-05\n",
      "[Training] Epoch: 30 [============>  ] 81.7% Loss: 0.0590, Epoch 30, Batch 102, CE_loss: 0.04400458559393883, Dice_loss: 0.0045255618169903755, Consistency_loss: 0.0001077618362614885\n",
      "[Training] Epoch: 30 [============>  ] 82.5% Loss: 0.0590, Epoch 30, Batch 103, CE_loss: 0.05472458153963089, Dice_loss: 0.005871328990906477, Consistency_loss: 0.00012058124411851168\n",
      "[Training] Epoch: 30 [============>  ] 83.3% Loss: 0.0589, Epoch 30, Batch 104, CE_loss: 0.04428701475262642, Dice_loss: 0.004216879606246948, Consistency_loss: 4.1857874748529866e-05\n",
      "[Training] Epoch: 30 [============>  ] 84.1% Loss: 0.0587, Epoch 30, Batch 105, CE_loss: 0.038533538579940796, Dice_loss: 0.0035575435031205416, Consistency_loss: 4.694626113632694e-05\n",
      "[Training] Epoch: 30 [============>  ] 84.9% Loss: 0.0588, Epoch 30, Batch 106, CE_loss: 0.06399916857481003, Dice_loss: 0.007046963553875685, Consistency_loss: 0.00028897234005853534\n",
      "[Training] Epoch: 30 [============>  ] 85.7% Loss: 0.0588, Epoch 30, Batch 107, CE_loss: 0.0531047061085701, Dice_loss: 0.0057220058515667915, Consistency_loss: 0.0006177056930027902\n",
      "[Training] Epoch: 30 [============>  ] 86.5% Loss: 0.0589, Epoch 30, Batch 108, CE_loss: 0.059921812266111374, Dice_loss: 0.00649742828682065, Consistency_loss: 0.0003032237000297755\n",
      "[Training] Epoch: 30 [=============> ] 87.3% Loss: 0.0588, Epoch 30, Batch 109, CE_loss: 0.045239802449941635, Dice_loss: 0.004585035145282745, Consistency_loss: 0.0002822481619659811\n",
      "[Training] Epoch: 30 [=============> ] 88.1% Loss: 0.0589, Epoch 30, Batch 110, CE_loss: 0.05557166785001755, Dice_loss: 0.006132209673523903, Consistency_loss: 3.940011083614081e-05\n",
      "[Training] Epoch: 30 [=============> ] 88.9% Loss: 0.0587, Epoch 30, Batch 111, CE_loss: 0.03876427561044693, Dice_loss: 0.0037820490542799234, Consistency_loss: 0.00021245729294605553\n",
      "[Training] Epoch: 30 [=============> ] 89.7% Loss: 0.0587, Epoch 30, Batch 112, CE_loss: 0.04619141295552254, Dice_loss: 0.004557386040687561, Consistency_loss: 0.0006087715155445039\n",
      "[Training] Epoch: 30 [=============> ] 90.5% Loss: 0.0587, Epoch 30, Batch 113, CE_loss: 0.055913522839546204, Dice_loss: 0.0061736986972391605, Consistency_loss: 0.0005479832179844379\n",
      "[Training] Epoch: 30 [=============> ] 91.3% Loss: 0.0585, Epoch 30, Batch 114, CE_loss: 0.03263155743479729, Dice_loss: 0.002911153482273221, Consistency_loss: 0.0003322864358779043\n",
      "[Training] Epoch: 30 [=============> ] 92.1% Loss: 0.0584, Epoch 30, Batch 115, CE_loss: 0.047267451882362366, Dice_loss: 0.0048425765708088875, Consistency_loss: 0.0002908855094574392\n",
      "[Training] Epoch: 30 [=============> ] 92.9% Loss: 0.0584, Epoch 30, Batch 116, CE_loss: 0.0473017543554306, Dice_loss: 0.004808897152543068, Consistency_loss: 0.00047287819324992597\n",
      "[Training] Epoch: 30 [==============>] 93.7% Loss: 0.0584, Epoch 30, Batch 117, CE_loss: 0.055563583970069885, Dice_loss: 0.006107139866799116, Consistency_loss: 0.00034073248389177024\n",
      "[Training] Epoch: 30 [==============>] 94.4% Loss: 0.0584, Epoch 30, Batch 118, CE_loss: 0.0517122708261013, Dice_loss: 0.005048016086220741, Consistency_loss: 0.0003476108831819147\n",
      "[Training] Epoch: 30 [==============>] 95.2% Loss: 0.0584, Epoch 30, Batch 119, CE_loss: 0.046391867101192474, Dice_loss: 0.004857941064983606, Consistency_loss: 0.00030017420067451894\n",
      "[Training] Epoch: 30 [==============>] 96.0% Loss: 0.0585, Epoch 30, Batch 120, CE_loss: 0.06616690754890442, Dice_loss: 0.0071183773688972, Consistency_loss: 9.507079812465236e-05\n",
      "[Training] Epoch: 30 [==============>] 96.8% Loss: 0.0584, Epoch 30, Batch 121, CE_loss: 0.042941633611917496, Dice_loss: 0.004437942989170551, Consistency_loss: 0.00025339910644106567\n",
      "[Training] Epoch: 30 [==============>] 97.6% Loss: 0.0585, Epoch 30, Batch 122, CE_loss: 0.06811316311359406, Dice_loss: 0.007510690484195948, Consistency_loss: 0.00035213303635828197\n",
      "[Training] Epoch: 30 [==============>] 98.4% Loss: 0.0584, Epoch 30, Batch 123, CE_loss: 0.041545093059539795, Dice_loss: 0.004295830614864826, Consistency_loss: 0.0001735316327540204\n",
      "[Training] Epoch: 30 [==============>] 99.2% Loss: 0.0585, Epoch 30, Batch 124, CE_loss: 0.0577925480902195, Dice_loss: 0.00615823594853282, Consistency_loss: 0.0005180374719202518\n",
      "[Training] Epoch: 30 [DONE]                                 \n",
      "Epoch 30, Batch 125, CE_loss: 0.05533094331622124, Dice_loss: 0.005398142617195845, Consistency_loss: 0.00047032107249833643\n",
      "[Validation] Epoch: 30 [DONE]                                 \n",
      "[Epoch: 30, TrainLoss: 0.0585, TrainDice: 0.0054, ValLoss: 0.1558                                            \n",
      "Number of batches:  126\n",
      "[Training] Epoch: 31 [>              ] 0.8% Loss: 0.0561, Epoch 31, Batch 0, CE_loss: 0.050602987408638, Dice_loss: 0.005405804608017206, Consistency_loss: 5.5182470532599837e-05\n",
      "[Training] Epoch: 31 [>              ] 1.6% Loss: 0.0510, Epoch 31, Batch 1, CE_loss: 0.04147522896528244, Dice_loss: 0.004274605307728052, Consistency_loss: 9.290192247135565e-05\n",
      "[Training] Epoch: 31 [>              ] 2.4% Loss: 0.0495, Epoch 31, Batch 2, CE_loss: 0.04260643199086189, Dice_loss: 0.0036862671840935946, Consistency_loss: 0.0001917404297273606\n",
      "[Training] Epoch: 31 [>              ] 3.2% Loss: 0.0541, Epoch 31, Batch 3, CE_loss: 0.06172884628176689, Dice_loss: 0.005711469333618879, Consistency_loss: 0.00039333521272055805\n",
      "[Training] Epoch: 31 [>              ] 4.0% Loss: 0.0600, Epoch 31, Batch 4, CE_loss: 0.07471314817667007, Dice_loss: 0.008529456332325935, Consistency_loss: 0.00028720134287141263\n",
      "[Training] Epoch: 31 [>              ] 4.8% Loss: 0.0607, Epoch 31, Batch 5, CE_loss: 0.058266956359148026, Dice_loss: 0.006061032880097628, Consistency_loss: 0.00021965759515296668\n",
      "[Training] Epoch: 31 [>              ] 5.6% Loss: 0.0576, Epoch 31, Batch 6, CE_loss: 0.03550892695784569, Dice_loss: 0.0033537002746015787, Consistency_loss: 0.00014568066399078816\n",
      "[Training] Epoch: 31 [>              ] 6.3% Loss: 0.0595, Epoch 31, Batch 7, CE_loss: 0.06603890657424927, Dice_loss: 0.006682312581688166, Consistency_loss: 0.00016961610526777804\n",
      "[Training] Epoch: 31 [=>             ] 7.1% Loss: 0.0600, Epoch 31, Batch 8, CE_loss: 0.057203032076358795, Dice_loss: 0.0063372463919222355, Consistency_loss: 0.00018261114018969238\n",
      "[Training] Epoch: 31 [=>             ] 7.9% Loss: 0.0571, Epoch 31, Batch 9, CE_loss: 0.028484834358096123, Dice_loss: 0.002145727165043354, Consistency_loss: 0.0001658970577409491\n",
      "[Training] Epoch: 31 [=>             ] 8.7% Loss: 0.0570, Epoch 31, Batch 10, CE_loss: 0.05021985247731209, Dice_loss: 0.005391387734562159, Consistency_loss: 0.0005784112145192921\n",
      "[Training] Epoch: 31 [=>             ] 9.5% Loss: 0.0558, Epoch 31, Batch 11, CE_loss: 0.038064271211624146, Dice_loss: 0.0038001539651304483, Consistency_loss: 0.0003888796200044453\n",
      "[Training] Epoch: 31 [=>             ] 10.3% Loss: 0.0560, Epoch 31, Batch 12, CE_loss: 0.05223201960325241, Dice_loss: 0.005654275417327881, Consistency_loss: 0.0005451402976177633\n",
      "[Training] Epoch: 31 [=>             ] 11.1% Loss: 0.0571, Epoch 31, Batch 13, CE_loss: 0.06408656388521194, Dice_loss: 0.007197520229965448, Consistency_loss: 0.00037830843939445913\n",
      "[Training] Epoch: 31 [=>             ] 11.9% Loss: 0.0576, Epoch 31, Batch 14, CE_loss: 0.05786142498254776, Dice_loss: 0.006376259494572878, Consistency_loss: 3.8087568100309e-05\n",
      "[Training] Epoch: 31 [=>             ] 12.7% Loss: 0.0580, Epoch 31, Batch 15, CE_loss: 0.057856470346450806, Dice_loss: 0.006034371443092823, Consistency_loss: 0.00021643044601660222\n",
      "[Training] Epoch: 31 [==>            ] 13.5% Loss: 0.0574, Epoch 31, Batch 16, CE_loss: 0.04326412081718445, Dice_loss: 0.0044916230253875256, Consistency_loss: 0.00026094759232364595\n",
      "[Training] Epoch: 31 [==>            ] 14.3% Loss: 0.0580, Epoch 31, Batch 17, CE_loss: 0.0610935315489769, Dice_loss: 0.006148557644337416, Consistency_loss: 0.0003593227593228221\n",
      "[Training] Epoch: 31 [==>            ] 15.1% Loss: 0.0581, Epoch 31, Batch 18, CE_loss: 0.05453977733850479, Dice_loss: 0.005898772273212671, Consistency_loss: 0.00024174533609766513\n",
      "[Training] Epoch: 31 [==>            ] 15.9% Loss: 0.0609, Epoch 31, Batch 19, CE_loss: 0.10215508192777634, Dice_loss: 0.01090580876916647, Consistency_loss: 0.00032712798565626144\n",
      "[Training] Epoch: 31 [==>            ] 16.7% Loss: 0.0610, Epoch 31, Batch 20, CE_loss: 0.05680286884307861, Dice_loss: 0.005878231022506952, Consistency_loss: 0.000270100892521441\n",
      "[Training] Epoch: 31 [==>            ] 17.5% Loss: 0.0600, Epoch 31, Batch 21, CE_loss: 0.03663904219865799, Dice_loss: 0.003564512822777033, Consistency_loss: 0.00025764643214643\n",
      "[Training] Epoch: 31 [==>            ] 18.3% Loss: 0.0609, Epoch 31, Batch 22, CE_loss: 0.07246840000152588, Dice_loss: 0.007764955051243305, Consistency_loss: 0.000409975036745891\n",
      "[Training] Epoch: 31 [==>            ] 19.0% Loss: 0.0605, Epoch 31, Batch 23, CE_loss: 0.04628359526395798, Dice_loss: 0.0045089456252753735, Consistency_loss: 0.00022779498249292374\n",
      "[Training] Epoch: 31 [==>            ] 19.8% Loss: 0.0603, Epoch 31, Batch 24, CE_loss: 0.04885713756084442, Dice_loss: 0.005159108433872461, Consistency_loss: 5.196130587137304e-05\n",
      "[Training] Epoch: 31 [===>           ] 20.6% Loss: 0.0602, Epoch 31, Batch 25, CE_loss: 0.05340247601270676, Dice_loss: 0.005779990926384926, Consistency_loss: 5.0567061407491565e-05\n",
      "[Training] Epoch: 31 [===>           ] 21.4% Loss: 0.0605, Epoch 31, Batch 26, CE_loss: 0.06054382771253586, Dice_loss: 0.006612351629883051, Consistency_loss: 0.00014093324716668576\n",
      "[Training] Epoch: 31 [===>           ] 22.2% Loss: 0.0608, Epoch 31, Batch 27, CE_loss: 0.062402285635471344, Dice_loss: 0.006880384869873524, Consistency_loss: 0.0005434140912257135\n",
      "[Training] Epoch: 31 [===>           ] 23.0% Loss: 0.0608, Epoch 31, Batch 28, CE_loss: 0.053853124380111694, Dice_loss: 0.00558346975594759, Consistency_loss: 0.00024400050460826606\n",
      "[Training] Epoch: 31 [===>           ] 23.8% Loss: 0.0601, Epoch 31, Batch 29, CE_loss: 0.037859465926885605, Dice_loss: 0.003622167045250535, Consistency_loss: 7.677784014958888e-05\n",
      "[Training] Epoch: 31 [===>           ] 24.6% Loss: 0.0598, Epoch 31, Batch 30, CE_loss: 0.04475085064768791, Dice_loss: 0.004552289843559265, Consistency_loss: 0.0007666178862564266\n",
      "[Training] Epoch: 31 [===>           ] 25.4% Loss: 0.0600, Epoch 31, Batch 31, CE_loss: 0.058001432567834854, Dice_loss: 0.006353491917252541, Consistency_loss: 2.5066487069125287e-05\n",
      "[Training] Epoch: 31 [===>           ] 26.2% Loss: 0.0605, Epoch 31, Batch 32, CE_loss: 0.06872855126857758, Dice_loss: 0.007775420323014259, Consistency_loss: 0.0002804824325721711\n",
      "[Training] Epoch: 31 [====>          ] 27.0% Loss: 0.0601, Epoch 31, Batch 33, CE_loss: 0.044914610683918, Dice_loss: 0.004554511979222298, Consistency_loss: 0.0002721802447922528\n",
      "[Training] Epoch: 31 [====>          ] 27.8% Loss: 0.0599, Epoch 31, Batch 34, CE_loss: 0.04542405530810356, Dice_loss: 0.00451313890516758, Consistency_loss: 0.00048213760601356626\n",
      "[Training] Epoch: 31 [====>          ] 28.6% Loss: 0.0598, Epoch 31, Batch 35, CE_loss: 0.05047743022441864, Dice_loss: 0.005050403065979481, Consistency_loss: 5.8019602874992415e-05\n",
      "[Training] Epoch: 31 [====>          ] 29.4% Loss: 0.0596, Epoch 31, Batch 36, CE_loss: 0.048712823539972305, Dice_loss: 0.005222386214882135, Consistency_loss: 4.5683769712923095e-05\n",
      "[Training] Epoch: 31 [====>          ] 30.2% Loss: 0.0595, Epoch 31, Batch 37, CE_loss: 0.050788864493370056, Dice_loss: 0.005278381984680891, Consistency_loss: 0.0003693765902426094\n",
      "[Training] Epoch: 31 [====>          ] 31.0% Loss: 0.0595, Epoch 31, Batch 38, CE_loss: 0.053077470511198044, Dice_loss: 0.005627153906971216, Consistency_loss: 0.0006285196868702769\n",
      "[Training] Epoch: 31 [====>          ] 31.7% Loss: 0.0591, Epoch 31, Batch 39, CE_loss: 0.04058567434549332, Dice_loss: 0.004069595132023096, Consistency_loss: 0.000529800949152559\n",
      "[Training] Epoch: 31 [====>          ] 32.5% Loss: 0.0592, Epoch 31, Batch 40, CE_loss: 0.0539238341152668, Dice_loss: 0.0055861384607851505, Consistency_loss: 0.00036168572842143476\n",
      "[Training] Epoch: 31 [=====>         ] 33.3% Loss: 0.0595, Epoch 31, Batch 41, CE_loss: 0.06615689396858215, Dice_loss: 0.007292649243026972, Consistency_loss: 0.0005698648747056723\n",
      "[Training] Epoch: 31 [=====>         ] 34.1% Loss: 0.0595, Epoch 31, Batch 42, CE_loss: 0.054317209869623184, Dice_loss: 0.005712895188480616, Consistency_loss: 0.00010485352686373517\n",
      "[Training] Epoch: 31 [=====>         ] 34.9% Loss: 0.0597, Epoch 31, Batch 43, CE_loss: 0.05872166156768799, Dice_loss: 0.0062418850138783455, Consistency_loss: 8.45343092805706e-05\n",
      "[Training] Epoch: 31 [=====>         ] 35.7% Loss: 0.0597, Epoch 31, Batch 44, CE_loss: 0.05443669483065605, Dice_loss: 0.005891780834645033, Consistency_loss: 0.0003926364879589528\n",
      "[Training] Epoch: 31 [=====>         ] 36.5% Loss: 0.0597, Epoch 31, Batch 45, CE_loss: 0.05527888983488083, Dice_loss: 0.005914096720516682, Consistency_loss: 0.00019906093075405806\n",
      "[Training] Epoch: 31 [=====>         ] 37.3% Loss: 0.0591, Epoch 31, Batch 46, CE_loss: 0.02963917702436447, Dice_loss: 0.002685691462829709, Consistency_loss: 0.00011885668209288269\n",
      "[Training] Epoch: 31 [=====>         ] 38.1% Loss: 0.0589, Epoch 31, Batch 47, CE_loss: 0.04080188646912575, Dice_loss: 0.004148541484028101, Consistency_loss: 0.00038496320485137403\n",
      "[Training] Epoch: 31 [=====>         ] 38.9% Loss: 0.0585, Epoch 31, Batch 48, CE_loss: 0.037035100162029266, Dice_loss: 0.0036715955939143896, Consistency_loss: 0.00017830473370850086\n",
      "[Training] Epoch: 31 [=====>         ] 39.7% Loss: 0.0586, Epoch 31, Batch 49, CE_loss: 0.05657871440052986, Dice_loss: 0.005850313697010279, Consistency_loss: 0.00037690604222007096\n",
      "[Training] Epoch: 31 [======>        ] 40.5% Loss: 0.0585, Epoch 31, Batch 50, CE_loss: 0.050874583423137665, Dice_loss: 0.00535961240530014, Consistency_loss: 0.00016174028860405087\n",
      "[Training] Epoch: 31 [======>        ] 41.3% Loss: 0.0585, Epoch 31, Batch 51, CE_loss: 0.05287854000926018, Dice_loss: 0.005398772656917572, Consistency_loss: 0.0006220699287950993\n",
      "[Training] Epoch: 31 [======>        ] 42.1% Loss: 0.0585, Epoch 31, Batch 52, CE_loss: 0.051229462027549744, Dice_loss: 0.00545867532491684, Consistency_loss: 2.5005805582622997e-05\n",
      "[Training] Epoch: 31 [======>        ] 42.9% Loss: 0.0589, Epoch 31, Batch 53, CE_loss: 0.07341402769088745, Dice_loss: 0.008475146256387234, Consistency_loss: 0.0001203740612254478\n",
      "[Training] Epoch: 31 [======>        ] 43.7% Loss: 0.0591, Epoch 31, Batch 54, CE_loss: 0.06092485040426254, Dice_loss: 0.006286217365413904, Consistency_loss: 8.233724656747654e-05\n",
      "[Training] Epoch: 31 [======>        ] 44.4% Loss: 0.0590, Epoch 31, Batch 55, CE_loss: 0.04602610319852829, Dice_loss: 0.004933400545269251, Consistency_loss: 0.00032508053118363023\n",
      "[Training] Epoch: 31 [======>        ] 45.2% Loss: 0.0591, Epoch 31, Batch 56, CE_loss: 0.05930476635694504, Dice_loss: 0.00655989209190011, Consistency_loss: 0.0003257524222135544\n",
      "[Training] Epoch: 31 [======>        ] 46.0% Loss: 0.0589, Epoch 31, Batch 57, CE_loss: 0.045505207031965256, Dice_loss: 0.00443385262042284, Consistency_loss: 0.0003084788331761956\n",
      "[Training] Epoch: 31 [=======>       ] 46.8% Loss: 0.0595, Epoch 31, Batch 58, CE_loss: 0.08508692681789398, Dice_loss: 0.009249535389244556, Consistency_loss: 9.458277054363862e-05\n",
      "[Training] Epoch: 31 [=======>       ] 47.6% Loss: 0.0593, Epoch 31, Batch 59, CE_loss: 0.044103026390075684, Dice_loss: 0.004482753574848175, Consistency_loss: 0.00022297566465567797\n",
      "[Training] Epoch: 31 [=======>       ] 48.4% Loss: 0.0592, Epoch 31, Batch 60, CE_loss: 0.04521737992763519, Dice_loss: 0.004680803511291742, Consistency_loss: 0.0004199664981570095\n",
      "[Training] Epoch: 31 [=======>       ] 49.2% Loss: 0.0595, Epoch 31, Batch 61, CE_loss: 0.06845332682132721, Dice_loss: 0.007505724206566811, Consistency_loss: 0.00045443582348525524\n",
      "[Training] Epoch: 31 [=======>       ] 50.0% Loss: 0.0595, Epoch 31, Batch 62, CE_loss: 0.056418661028146744, Dice_loss: 0.0059647951275110245, Consistency_loss: 6.891963857924566e-05\n",
      "[Training] Epoch: 31 [=======>       ] 50.8% Loss: 0.0592, Epoch 31, Batch 63, CE_loss: 0.03802917152643204, Dice_loss: 0.003639212343841791, Consistency_loss: 8.059915853664279e-05\n",
      "[Training] Epoch: 31 [=======>       ] 51.6% Loss: 0.0591, Epoch 31, Batch 64, CE_loss: 0.04281668737530708, Dice_loss: 0.004492391832172871, Consistency_loss: 0.0005597714334726334\n",
      "[Training] Epoch: 31 [=======>       ] 52.4% Loss: 0.0593, Epoch 31, Batch 65, CE_loss: 0.06682026386260986, Dice_loss: 0.0074227009899914265, Consistency_loss: 0.0005167783820070326\n",
      "[Training] Epoch: 31 [=======>       ] 53.2% Loss: 0.0595, Epoch 31, Batch 66, CE_loss: 0.06198563054203987, Dice_loss: 0.00676583219319582, Consistency_loss: 4.3760548578575253e-05\n",
      "[Training] Epoch: 31 [========>      ] 54.0% Loss: 0.0593, Epoch 31, Batch 67, CE_loss: 0.045552194118499756, Dice_loss: 0.004681626334786415, Consistency_loss: 0.0002822460373863578\n",
      "[Training] Epoch: 31 [========>      ] 54.8% Loss: 0.0593, Epoch 31, Batch 68, CE_loss: 0.0536838099360466, Dice_loss: 0.005775734782218933, Consistency_loss: 0.00021006939641665667\n",
      "[Training] Epoch: 31 [========>      ] 55.6% Loss: 0.0590, Epoch 31, Batch 69, CE_loss: 0.03032594732940197, Dice_loss: 0.00272073014639318, Consistency_loss: 0.0001174884382635355\n",
      "[Training] Epoch: 31 [========>      ] 56.3% Loss: 0.0588, Epoch 31, Batch 70, CE_loss: 0.046238359063863754, Dice_loss: 0.004715904593467712, Consistency_loss: 0.0006680047954432666\n",
      "[Training] Epoch: 31 [========>      ] 57.1% Loss: 0.0586, Epoch 31, Batch 71, CE_loss: 0.036145854741334915, Dice_loss: 0.0035979957319796085, Consistency_loss: 0.000336299097398296\n",
      "[Training] Epoch: 31 [========>      ] 57.9% Loss: 0.0587, Epoch 31, Batch 72, CE_loss: 0.05835879594087601, Dice_loss: 0.006134708411991596, Consistency_loss: 5.263305138214491e-05\n",
      "[Training] Epoch: 31 [========>      ] 58.7% Loss: 0.0586, Epoch 31, Batch 73, CE_loss: 0.04523062705993652, Dice_loss: 0.00471976725384593, Consistency_loss: 4.29042374889832e-05\n",
      "[Training] Epoch: 31 [========>      ] 59.5% Loss: 0.0586, Epoch 31, Batch 74, CE_loss: 0.05327233672142029, Dice_loss: 0.005762641318142414, Consistency_loss: 0.0005179744912311435\n",
      "[Training] Epoch: 31 [=========>     ] 60.3% Loss: 0.0585, Epoch 31, Batch 75, CE_loss: 0.046490997076034546, Dice_loss: 0.004907271359115839, Consistency_loss: 0.000480512622743845\n",
      "[Training] Epoch: 31 [=========>     ] 61.1% Loss: 0.0585, Epoch 31, Batch 76, CE_loss: 0.054105453193187714, Dice_loss: 0.005926568992435932, Consistency_loss: 0.0004469789273571223\n",
      "[Training] Epoch: 31 [=========>     ] 61.9% Loss: 0.0584, Epoch 31, Batch 77, CE_loss: 0.046710677444934845, Dice_loss: 0.0045913029462099075, Consistency_loss: 0.0004924535751342773\n",
      "[Training] Epoch: 31 [=========>     ] 62.7% Loss: 0.0583, Epoch 31, Batch 78, CE_loss: 0.04338978976011276, Dice_loss: 0.004493223503232002, Consistency_loss: 5.1411370804999024e-05\n",
      "[Training] Epoch: 31 [=========>     ] 63.5% Loss: 0.0583, Epoch 31, Batch 79, CE_loss: 0.050308194011449814, Dice_loss: 0.005430226214230061, Consistency_loss: 6.95984490448609e-05\n",
      "[Training] Epoch: 31 [=========>     ] 64.3% Loss: 0.0582, Epoch 31, Batch 80, CE_loss: 0.04643061012029648, Dice_loss: 0.004614552948623896, Consistency_loss: 7.951162115205079e-05\n",
      "[Training] Epoch: 31 [=========>     ] 65.1% Loss: 0.0580, Epoch 31, Batch 81, CE_loss: 0.040450457483530045, Dice_loss: 0.003930303733795881, Consistency_loss: 0.00041050161235034466\n",
      "[Training] Epoch: 31 [=========>     ] 65.9% Loss: 0.0580, Epoch 31, Batch 82, CE_loss: 0.049111805856227875, Dice_loss: 0.005312124267220497, Consistency_loss: 0.00045379562652669847\n",
      "[Training] Epoch: 31 [==========>    ] 66.7% Loss: 0.0579, Epoch 31, Batch 83, CE_loss: 0.04384148120880127, Dice_loss: 0.004501368384808302, Consistency_loss: 0.00018481191364116967\n",
      "[Training] Epoch: 31 [==========>    ] 67.5% Loss: 0.0577, Epoch 31, Batch 84, CE_loss: 0.04262322559952736, Dice_loss: 0.004227899014949799, Consistency_loss: 0.00012283431715331972\n",
      "[Training] Epoch: 31 [==========>    ] 68.3% Loss: 0.0577, Epoch 31, Batch 85, CE_loss: 0.05055641755461693, Dice_loss: 0.005241434555500746, Consistency_loss: 0.00011961146810790524\n",
      "[Training] Epoch: 31 [==========>    ] 69.0% Loss: 0.0577, Epoch 31, Batch 86, CE_loss: 0.05599605664610863, Dice_loss: 0.0053909095004200935, Consistency_loss: 7.935538451420143e-05\n",
      "[Training] Epoch: 31 [==========>    ] 69.8% Loss: 0.0578, Epoch 31, Batch 87, CE_loss: 0.05288214981555939, Dice_loss: 0.005733387544751167, Consistency_loss: 0.0001881378557300195\n",
      "[Training] Epoch: 31 [==========>    ] 70.6% Loss: 0.0577, Epoch 31, Batch 88, CE_loss: 0.043657541275024414, Dice_loss: 0.004227885976433754, Consistency_loss: 0.00022451784752774984\n",
      "[Training] Epoch: 31 [==========>    ] 71.4% Loss: 0.0577, Epoch 31, Batch 89, CE_loss: 0.056973885744810104, Dice_loss: 0.006295632105320692, Consistency_loss: 0.00034855285775847733\n",
      "[Training] Epoch: 31 [==========>    ] 72.2% Loss: 0.0576, Epoch 31, Batch 90, CE_loss: 0.042570196092128754, Dice_loss: 0.0041863382793962955, Consistency_loss: 3.5921311791753396e-05\n",
      "[Training] Epoch: 31 [==========>    ] 73.0% Loss: 0.0577, Epoch 31, Batch 91, CE_loss: 0.05656849965453148, Dice_loss: 0.006080125458538532, Consistency_loss: 0.0004940475919283926\n",
      "[Training] Epoch: 31 [===========>   ] 73.8% Loss: 0.0576, Epoch 31, Batch 92, CE_loss: 0.04414648562669754, Dice_loss: 0.004607458598911762, Consistency_loss: 0.0004028134571854025\n",
      "[Training] Epoch: 31 [===========>   ] 74.6% Loss: 0.0576, Epoch 31, Batch 93, CE_loss: 0.054568059742450714, Dice_loss: 0.005884798243641853, Consistency_loss: 5.591095759882592e-05\n",
      "[Training] Epoch: 31 [===========>   ] 75.4% Loss: 0.0576, Epoch 31, Batch 94, CE_loss: 0.05285422131419182, Dice_loss: 0.005712492857128382, Consistency_loss: 0.00012914935359731317\n",
      "[Training] Epoch: 31 [===========>   ] 76.2% Loss: 0.0576, Epoch 31, Batch 95, CE_loss: 0.051653411239385605, Dice_loss: 0.005287005100399256, Consistency_loss: 0.00037020150921307504\n",
      "[Training] Epoch: 31 [===========>   ] 77.0% Loss: 0.0577, Epoch 31, Batch 96, CE_loss: 0.05728450044989586, Dice_loss: 0.006305471528321505, Consistency_loss: 0.00022118716151453555\n",
      "[Training] Epoch: 31 [===========>   ] 77.8% Loss: 0.0577, Epoch 31, Batch 97, CE_loss: 0.05425029620528221, Dice_loss: 0.005981581285595894, Consistency_loss: 0.00023555905499961227\n",
      "[Training] Epoch: 31 [===========>   ] 78.6% Loss: 0.0577, Epoch 31, Batch 98, CE_loss: 0.05367270112037659, Dice_loss: 0.005549794528633356, Consistency_loss: 0.00023368462279904634\n",
      "[Training] Epoch: 31 [===========>   ] 79.4% Loss: 0.0576, Epoch 31, Batch 99, CE_loss: 0.04468915984034538, Dice_loss: 0.004765798337757587, Consistency_loss: 0.00023060839157551527\n",
      "[Training] Epoch: 31 [============>  ] 80.2% Loss: 0.0576, Epoch 31, Batch 100, CE_loss: 0.046145953238010406, Dice_loss: 0.004428792279213667, Consistency_loss: 0.0003332881024107337\n",
      "[Training] Epoch: 31 [============>  ] 81.0% Loss: 0.0576, Epoch 31, Batch 101, CE_loss: 0.05279843881726265, Dice_loss: 0.005723105743527412, Consistency_loss: 0.0003764019056688994\n",
      "[Training] Epoch: 31 [============>  ] 81.7% Loss: 0.0575, Epoch 31, Batch 102, CE_loss: 0.04763941466808319, Dice_loss: 0.004595933947712183, Consistency_loss: 8.471015462419018e-05\n",
      "[Training] Epoch: 31 [============>  ] 82.5% Loss: 0.0577, Epoch 31, Batch 103, CE_loss: 0.07219427078962326, Dice_loss: 0.007979643531143665, Consistency_loss: 0.000106871644675266\n",
      "[Training] Epoch: 31 [============>  ] 83.3% Loss: 0.0577, Epoch 31, Batch 104, CE_loss: 0.04499729350209236, Dice_loss: 0.004611003678292036, Consistency_loss: 0.0002478315436746925\n",
      "[Training] Epoch: 31 [============>  ] 84.1% Loss: 0.0577, Epoch 31, Batch 105, CE_loss: 0.05345412343740463, Dice_loss: 0.005749507341533899, Consistency_loss: 0.00016089789278339595\n",
      "[Training] Epoch: 31 [============>  ] 84.9% Loss: 0.0577, Epoch 31, Batch 106, CE_loss: 0.0562988817691803, Dice_loss: 0.0057173254899680614, Consistency_loss: 4.0100272599374875e-05\n",
      "[Training] Epoch: 31 [============>  ] 85.7% Loss: 0.0576, Epoch 31, Batch 107, CE_loss: 0.03977607190608978, Dice_loss: 0.004008177202194929, Consistency_loss: 0.0005319342017173767\n",
      "[Training] Epoch: 31 [============>  ] 86.5% Loss: 0.0577, Epoch 31, Batch 108, CE_loss: 0.05627511441707611, Dice_loss: 0.006002399604767561, Consistency_loss: 0.0002501367998775095\n",
      "[Training] Epoch: 31 [=============> ] 87.3% Loss: 0.0577, Epoch 31, Batch 109, CE_loss: 0.05615731701254845, Dice_loss: 0.006287590134888887, Consistency_loss: 6.307636067504063e-05\n",
      "[Training] Epoch: 31 [=============> ] 88.1% Loss: 0.0577, Epoch 31, Batch 110, CE_loss: 0.051779765635728836, Dice_loss: 0.0054983096197247505, Consistency_loss: 3.452019518590532e-05\n",
      "[Training] Epoch: 31 [=============> ] 88.9% Loss: 0.0576, Epoch 31, Batch 111, CE_loss: 0.042386043816804886, Dice_loss: 0.004170035012066364, Consistency_loss: 0.0001720636646496132\n",
      "[Training] Epoch: 31 [=============> ] 89.7% Loss: 0.0576, Epoch 31, Batch 112, CE_loss: 0.04785672947764397, Dice_loss: 0.00509277731180191, Consistency_loss: 0.00042425436549820006\n",
      "[Training] Epoch: 31 [=============> ] 90.5% Loss: 0.0574, Epoch 31, Batch 113, CE_loss: 0.03993716090917587, Dice_loss: 0.0039534601382911205, Consistency_loss: 0.0004010233678855002\n",
      "[Training] Epoch: 31 [=============> ] 91.3% Loss: 0.0577, Epoch 31, Batch 114, CE_loss: 0.08003483712673187, Dice_loss: 0.008524816483259201, Consistency_loss: 0.000364201667252928\n",
      "[Training] Epoch: 31 [=============> ] 92.1% Loss: 0.0576, Epoch 31, Batch 115, CE_loss: 0.043662697076797485, Dice_loss: 0.004302084445953369, Consistency_loss: 0.0002233066625194624\n",
      "[Training] Epoch: 31 [=============> ] 92.9% Loss: 0.0577, Epoch 31, Batch 116, CE_loss: 0.06365550309419632, Dice_loss: 0.0070655872114002705, Consistency_loss: 0.00032305039349012077\n",
      "[Training] Epoch: 31 [==============>] 93.7% Loss: 0.0577, Epoch 31, Batch 117, CE_loss: 0.04645855352282524, Dice_loss: 0.0048669311217963696, Consistency_loss: 0.0002558408014010638\n",
      "[Training] Epoch: 31 [==============>] 94.4% Loss: 0.0577, Epoch 31, Batch 118, CE_loss: 0.048266395926475525, Dice_loss: 0.004995869472622871, Consistency_loss: 0.00031492137350142\n",
      "[Training] Epoch: 31 [==============>] 95.2% Loss: 0.0577, Epoch 31, Batch 119, CE_loss: 0.054862555116415024, Dice_loss: 0.005990356672555208, Consistency_loss: 8.961077401181683e-05\n",
      "[Training] Epoch: 31 [==============>] 96.0% Loss: 0.0577, Epoch 31, Batch 120, CE_loss: 0.0577160008251667, Dice_loss: 0.0063213990069925785, Consistency_loss: 0.0002842927642632276\n",
      "[Training] Epoch: 31 [==============>] 96.8% Loss: 0.0576, Epoch 31, Batch 121, CE_loss: 0.03732840716838837, Dice_loss: 0.003262353129684925, Consistency_loss: 9.323335689259693e-05\n",
      "[Training] Epoch: 31 [==============>] 97.6% Loss: 0.0577, Epoch 31, Batch 122, CE_loss: 0.058380935341119766, Dice_loss: 0.00619499571621418, Consistency_loss: 0.00026710567180998623\n",
      "[Training] Epoch: 31 [==============>] 98.4% Loss: 0.0576, Epoch 31, Batch 123, CE_loss: 0.04913366585969925, Dice_loss: 0.0052482918836176395, Consistency_loss: 0.00020653703541029245\n",
      "[Training] Epoch: 31 [==============>] 99.2% Loss: 0.0574, Epoch 31, Batch 124, CE_loss: 0.029335588216781616, Dice_loss: 0.002627523383125663, Consistency_loss: 0.0005788065609522164\n",
      "[Training] Epoch: 31 [DONE]                                 \n",
      "Epoch 31, Batch 125, CE_loss: 0.04762992635369301, Dice_loss: 0.005011819303035736, Consistency_loss: 0.0005025492864660919\n",
      "[Validation] Epoch: 31 [DONE]                                 \n",
      "[Epoch: 31, TrainLoss: 0.0574, TrainDice: 0.0054, ValLoss: 0.1361                                            \n",
      "Number of batches:  126\n",
      "[Training] Epoch: 32 [>              ] 0.8% Loss: 0.0676, Epoch 32, Batch 0, CE_loss: 0.06063290685415268, Dice_loss: 0.00670350668951869, Consistency_loss: 0.0002767618861980736\n",
      "[Training] Epoch: 32 [>              ] 1.6% Loss: 0.0623, Epoch 32, Batch 1, CE_loss: 0.05152914673089981, Dice_loss: 0.0052423239685595036, Consistency_loss: 0.00013215330545790493\n",
      "[Training] Epoch: 32 [>              ] 2.4% Loss: 0.0567, Epoch 32, Batch 2, CE_loss: 0.04108094424009323, Dice_loss: 0.004213446751236916, Consistency_loss: 0.000218456843867898\n",
      "[Training] Epoch: 32 [>              ] 3.2% Loss: 0.0535, Epoch 32, Batch 3, CE_loss: 0.03978763520717621, Dice_loss: 0.004022169392555952, Consistency_loss: 0.0003517493896652013\n",
      "[Training] Epoch: 32 [>              ] 4.0% Loss: 0.0531, Epoch 32, Batch 4, CE_loss: 0.046388354152441025, Dice_loss: 0.004692582879215479, Consistency_loss: 0.0004588391166180372\n",
      "[Training] Epoch: 32 [>              ] 4.8% Loss: 0.0531, Epoch 32, Batch 5, CE_loss: 0.048103220760822296, Dice_loss: 0.004830153658986092, Consistency_loss: 0.0001264761231141165\n",
      "[Training] Epoch: 32 [>              ] 5.6% Loss: 0.0519, Epoch 32, Batch 6, CE_loss: 0.04055007919669151, Dice_loss: 0.004179418087005615, Consistency_loss: 4.5316217438085005e-05\n",
      "[Training] Epoch: 32 [>              ] 6.3% Loss: 0.0537, Epoch 32, Batch 7, CE_loss: 0.05949987471103668, Dice_loss: 0.006560254376381636, Consistency_loss: 6.941452738828957e-05\n",
      "[Training] Epoch: 32 [=>             ] 7.1% Loss: 0.0556, Epoch 32, Batch 8, CE_loss: 0.06336842477321625, Dice_loss: 0.006795461755245924, Consistency_loss: 0.00014247877697926015\n",
      "[Training] Epoch: 32 [=>             ] 7.9% Loss: 0.0563, Epoch 32, Batch 9, CE_loss: 0.05665364861488342, Dice_loss: 0.006063120439648628, Consistency_loss: 0.00013775994011666626\n",
      "[Training] Epoch: 32 [=>             ] 8.7% Loss: 0.0540, Epoch 32, Batch 10, CE_loss: 0.028081191703677177, Dice_loss: 0.0025107846595346928, Consistency_loss: 0.0005814452888444066\n",
      "[Training] Epoch: 32 [=>             ] 9.5% Loss: 0.0545, Epoch 32, Batch 11, CE_loss: 0.053320180624723434, Dice_loss: 0.0055648148991167545, Consistency_loss: 0.0004894416779279709\n",
      "[Training] Epoch: 32 [=>             ] 10.3% Loss: 0.0533, Epoch 32, Batch 12, CE_loss: 0.03588688746094704, Dice_loss: 0.003619033144786954, Consistency_loss: 0.0005050110048614442\n",
      "[Training] Epoch: 32 [=>             ] 11.1% Loss: 0.0534, Epoch 32, Batch 13, CE_loss: 0.04874568060040474, Dice_loss: 0.005242391023784876, Consistency_loss: 0.00043087947415187955\n",
      "[Training] Epoch: 32 [=>             ] 11.9% Loss: 0.0549, Epoch 32, Batch 14, CE_loss: 0.06821715831756592, Dice_loss: 0.007117058616131544, Consistency_loss: 0.00042551543447189033\n",
      "[Training] Epoch: 32 [=>             ] 12.7% Loss: 0.0551, Epoch 32, Batch 15, CE_loss: 0.05209038406610489, Dice_loss: 0.0051079499535262585, Consistency_loss: 0.0002392383321421221\n",
      "[Training] Epoch: 32 [==>            ] 13.5% Loss: 0.0554, Epoch 32, Batch 16, CE_loss: 0.05553394928574562, Dice_loss: 0.005767272785305977, Consistency_loss: 0.00012909866927657276\n",
      "[Training] Epoch: 32 [==>            ] 14.3% Loss: 0.0550, Epoch 32, Batch 17, CE_loss: 0.04233621433377266, Dice_loss: 0.004420544486492872, Consistency_loss: 0.00024352283799089491\n",
      "[Training] Epoch: 32 [==>            ] 15.1% Loss: 0.0552, Epoch 32, Batch 18, CE_loss: 0.053196195513010025, Dice_loss: 0.0055965231731534, Consistency_loss: 0.0005212410469539464\n",
      "[Training] Epoch: 32 [==>            ] 15.9% Loss: 0.0550, Epoch 32, Batch 19, CE_loss: 0.0455596037209034, Dice_loss: 0.004809116013348103, Consistency_loss: 0.0003931855026166886\n",
      "[Training] Epoch: 32 [==>            ] 16.7% Loss: 0.0547, Epoch 32, Batch 20, CE_loss: 0.04472919553518295, Dice_loss: 0.004798910114914179, Consistency_loss: 0.00027333523030392826\n",
      "[Training] Epoch: 32 [==>            ] 17.5% Loss: 0.0563, Epoch 32, Batch 21, CE_loss: 0.07992725819349289, Dice_loss: 0.008586985059082508, Consistency_loss: 0.00026782587519846857\n",
      "[Training] Epoch: 32 [==>            ] 18.3% Loss: 0.0569, Epoch 32, Batch 22, CE_loss: 0.06257496774196625, Dice_loss: 0.006845390889793634, Consistency_loss: 0.0003615517634898424\n",
      "[Training] Epoch: 32 [==>            ] 19.0% Loss: 0.0561, Epoch 32, Batch 23, CE_loss: 0.03514893352985382, Dice_loss: 0.00344905280508101, Consistency_loss: 4.577848449116573e-05\n",
      "[Training] Epoch: 32 [==>            ] 19.8% Loss: 0.0571, Epoch 32, Batch 24, CE_loss: 0.07216274738311768, Dice_loss: 0.008056341670453548, Consistency_loss: 0.00019867000810336322\n",
      "[Training] Epoch: 32 [===>           ] 20.6% Loss: 0.0573, Epoch 32, Batch 25, CE_loss: 0.05697854980826378, Dice_loss: 0.006249547470360994, Consistency_loss: 0.00020401342771947384\n",
      "[Training] Epoch: 32 [===>           ] 21.4% Loss: 0.0570, Epoch 32, Batch 26, CE_loss: 0.04420004040002823, Dice_loss: 0.004623784217983484, Consistency_loss: 0.0004107634595129639\n",
      "[Training] Epoch: 32 [===>           ] 22.2% Loss: 0.0570, Epoch 32, Batch 27, CE_loss: 0.05059342086315155, Dice_loss: 0.005348418839275837, Consistency_loss: 0.00014881067909300327\n",
      "[Training] Epoch: 32 [===>           ] 23.0% Loss: 0.0569, Epoch 32, Batch 28, CE_loss: 0.04957301542162895, Dice_loss: 0.004999177530407906, Consistency_loss: 9.426217729924247e-05\n",
      "[Training] Epoch: 32 [===>           ] 23.8% Loss: 0.0573, Epoch 32, Batch 29, CE_loss: 0.06251776218414307, Dice_loss: 0.006889048498123884, Consistency_loss: 6.10835340921767e-05\n",
      "[Training] Epoch: 32 [===>           ] 24.6% Loss: 0.0576, Epoch 32, Batch 30, CE_loss: 0.05874771997332573, Dice_loss: 0.006610711105167866, Consistency_loss: 0.00057941023260355\n",
      "[Training] Epoch: 32 [===>           ] 25.4% Loss: 0.0580, Epoch 32, Batch 31, CE_loss: 0.0624779537320137, Dice_loss: 0.0068200440146028996, Consistency_loss: 7.938674389151856e-05\n",
      "[Training] Epoch: 32 [===>           ] 26.2% Loss: 0.0577, Epoch 32, Batch 32, CE_loss: 0.04292535036802292, Dice_loss: 0.004273988306522369, Consistency_loss: 0.00022739358246326447\n",
      "[Training] Epoch: 32 [====>          ] 27.0% Loss: 0.0579, Epoch 32, Batch 33, CE_loss: 0.06035441905260086, Dice_loss: 0.00661753723397851, Consistency_loss: 3.975844447268173e-05\n",
      "[Training] Epoch: 32 [====>          ] 27.8% Loss: 0.0573, Epoch 32, Batch 34, CE_loss: 0.03119834139943123, Dice_loss: 0.0028622345998883247, Consistency_loss: 0.00025564184761606157\n",
      "[Training] Epoch: 32 [====>          ] 28.6% Loss: 0.0570, Epoch 32, Batch 35, CE_loss: 0.04215724393725395, Dice_loss: 0.004190138075500727, Consistency_loss: 0.00038568887975998223\n",
      "[Training] Epoch: 32 [====>          ] 29.4% Loss: 0.0570, Epoch 32, Batch 36, CE_loss: 0.05351223424077034, Dice_loss: 0.0053926752880215645, Consistency_loss: 0.0003365699667483568\n",
      "[Training] Epoch: 32 [====>          ] 30.2% Loss: 0.0571, Epoch 32, Batch 37, CE_loss: 0.054412778466939926, Dice_loss: 0.006029297597706318, Consistency_loss: 0.000398753909394145\n",
      "[Training] Epoch: 32 [====>          ] 31.0% Loss: 0.0574, Epoch 32, Batch 38, CE_loss: 0.06009228900074959, Dice_loss: 0.006638865452259779, Consistency_loss: 0.0006294885533861816\n",
      "[Training] Epoch: 32 [====>          ] 31.7% Loss: 0.0573, Epoch 32, Batch 39, CE_loss: 0.04903985187411308, Dice_loss: 0.005127141252160072, Consistency_loss: 0.000697303272318095\n",
      "[Training] Epoch: 32 [====>          ] 32.5% Loss: 0.0575, Epoch 32, Batch 40, CE_loss: 0.057811856269836426, Dice_loss: 0.006390685215592384, Consistency_loss: 4.985477062291466e-05\n",
      "[Training] Epoch: 32 [=====>         ] 33.3% Loss: 0.0571, Epoch 32, Batch 41, CE_loss: 0.03697512298822403, Dice_loss: 0.0034925222862511873, Consistency_loss: 0.0003926781937479973\n",
      "[Training] Epoch: 32 [=====>         ] 34.1% Loss: 0.0574, Epoch 32, Batch 42, CE_loss: 0.06314817070960999, Dice_loss: 0.007012331858277321, Consistency_loss: 0.0005172532983124256\n",
      "[Training] Epoch: 32 [=====>         ] 34.9% Loss: 0.0580, Epoch 32, Batch 43, CE_loss: 0.07611943781375885, Dice_loss: 0.008188489824533463, Consistency_loss: 0.00037052485276944935\n",
      "[Training] Epoch: 32 [=====>         ] 35.7% Loss: 0.0582, Epoch 32, Batch 44, CE_loss: 0.05744851380586624, Dice_loss: 0.006265940144658089, Consistency_loss: 0.00044374013668857515\n",
      "[Training] Epoch: 32 [=====>         ] 36.5% Loss: 0.0584, Epoch 32, Batch 45, CE_loss: 0.0617438443005085, Dice_loss: 0.00619222829118371, Consistency_loss: 0.00030413432978093624\n",
      "[Training] Epoch: 32 [=====>         ] 37.3% Loss: 0.0581, Epoch 32, Batch 46, CE_loss: 0.04260391741991043, Dice_loss: 0.004154384136199951, Consistency_loss: 0.00021095461852382869\n",
      "[Training] Epoch: 32 [=====>         ] 38.1% Loss: 0.0578, Epoch 32, Batch 47, CE_loss: 0.03842179849743843, Dice_loss: 0.003779581282287836, Consistency_loss: 8.206996426451951e-05\n",
      "[Training] Epoch: 32 [=====>         ] 38.9% Loss: 0.0576, Epoch 32, Batch 48, CE_loss: 0.041241951286792755, Dice_loss: 0.003972302656620741, Consistency_loss: 0.00047222385182976723\n",
      "[Training] Epoch: 32 [=====>         ] 39.7% Loss: 0.0576, Epoch 32, Batch 49, CE_loss: 0.05197833105921745, Dice_loss: 0.0056102159433066845, Consistency_loss: 0.00041057440103031695\n",
      "[Training] Epoch: 32 [======>        ] 40.5% Loss: 0.0575, Epoch 32, Batch 50, CE_loss: 0.04617106914520264, Dice_loss: 0.004860243294388056, Consistency_loss: 0.0005189293879084289\n",
      "[Training] Epoch: 32 [======>        ] 41.3% Loss: 0.0572, Epoch 32, Batch 51, CE_loss: 0.04153238609433174, Dice_loss: 0.004291092045605183, Consistency_loss: 0.0005223259213380516\n",
      "[Training] Epoch: 32 [======>        ] 42.1% Loss: 0.0571, Epoch 32, Batch 52, CE_loss: 0.044328730553388596, Dice_loss: 0.004722927697002888, Consistency_loss: 3.361169365234673e-05\n",
      "[Training] Epoch: 32 [======>        ] 42.9% Loss: 0.0568, Epoch 32, Batch 53, CE_loss: 0.03979571536183357, Dice_loss: 0.0039921775460243225, Consistency_loss: 0.00017735461005941033\n",
      "[Training] Epoch: 32 [======>        ] 43.7% Loss: 0.0569, Epoch 32, Batch 54, CE_loss: 0.05310333892703056, Dice_loss: 0.005512645933777094, Consistency_loss: 0.0002712252316996455\n",
      "[Training] Epoch: 32 [======>        ] 44.4% Loss: 0.0570, Epoch 32, Batch 55, CE_loss: 0.05862662196159363, Dice_loss: 0.006583281327039003, Consistency_loss: 0.00014664800255559385\n",
      "[Training] Epoch: 32 [======>        ] 45.2% Loss: 0.0572, Epoch 32, Batch 56, CE_loss: 0.06233455240726471, Dice_loss: 0.00621410645544529, Consistency_loss: 0.0003183559456374496\n",
      "[Training] Epoch: 32 [======>        ] 46.0% Loss: 0.0575, Epoch 32, Batch 57, CE_loss: 0.06783643364906311, Dice_loss: 0.00637804763391614, Consistency_loss: 0.00023477930517401546\n",
      "[Training] Epoch: 32 [=======>       ] 46.8% Loss: 0.0574, Epoch 32, Batch 58, CE_loss: 0.04491819813847542, Dice_loss: 0.004784453194588423, Consistency_loss: 0.00031478566234000027\n",
      "[Training] Epoch: 32 [=======>       ] 47.6% Loss: 0.0578, Epoch 32, Batch 59, CE_loss: 0.07314500212669373, Dice_loss: 0.008045903407037258, Consistency_loss: 0.00018650719721335918\n",
      "[Training] Epoch: 32 [=======>       ] 48.4% Loss: 0.0575, Epoch 32, Batch 60, CE_loss: 0.034729279577732086, Dice_loss: 0.0034207599237561226, Consistency_loss: 0.00035438252962194383\n",
      "[Training] Epoch: 32 [=======>       ] 49.2% Loss: 0.0576, Epoch 32, Batch 61, CE_loss: 0.05595022067427635, Dice_loss: 0.0062204585410654545, Consistency_loss: 0.00030583428451791406\n",
      "[Training] Epoch: 32 [=======>       ] 50.0% Loss: 0.0577, Epoch 32, Batch 62, CE_loss: 0.0580035001039505, Dice_loss: 0.0062415990978479385, Consistency_loss: 0.0005776432226411998\n",
      "[Training] Epoch: 32 [=======>       ] 50.8% Loss: 0.0574, Epoch 32, Batch 63, CE_loss: 0.033949144184589386, Dice_loss: 0.0032241852022707462, Consistency_loss: 0.00011647157225525007\n",
      "[Training] Epoch: 32 [=======>       ] 51.6% Loss: 0.0573, Epoch 32, Batch 64, CE_loss: 0.047860316932201385, Dice_loss: 0.0049124169163405895, Consistency_loss: 0.0005286631057970226\n",
      "[Training] Epoch: 32 [=======>       ] 52.4% Loss: 0.0575, Epoch 32, Batch 65, CE_loss: 0.06478746980428696, Dice_loss: 0.00699352053925395, Consistency_loss: 0.00048413011245429516\n",
      "[Training] Epoch: 32 [=======>       ] 53.2% Loss: 0.0579, Epoch 32, Batch 66, CE_loss: 0.07401815801858902, Dice_loss: 0.008370642550289631, Consistency_loss: 0.00016479440091643482\n",
      "[Training] Epoch: 32 [========>      ] 54.0% Loss: 0.0578, Epoch 32, Batch 67, CE_loss: 0.0431775264441967, Dice_loss: 0.004475882742553949, Consistency_loss: 0.0002618191356305033\n",
      "[Training] Epoch: 32 [========>      ] 54.8% Loss: 0.0577, Epoch 32, Batch 68, CE_loss: 0.04514682665467262, Dice_loss: 0.0047608003951609135, Consistency_loss: 0.0001519638899480924\n",
      "[Training] Epoch: 32 [========>      ] 55.6% Loss: 0.0577, Epoch 32, Batch 69, CE_loss: 0.053814686834812164, Dice_loss: 0.005842490587383509, Consistency_loss: 0.00019357116252649575\n",
      "[Training] Epoch: 32 [========>      ] 56.3% Loss: 0.0577, Epoch 32, Batch 70, CE_loss: 0.0535164475440979, Dice_loss: 0.005895835347473621, Consistency_loss: 0.0007122470997273922\n",
      "[Training] Epoch: 32 [========>      ] 57.1% Loss: 0.0577, Epoch 32, Batch 71, CE_loss: 0.04759156331419945, Dice_loss: 0.005117788910865784, Consistency_loss: 0.00028769063646905124\n",
      "[Training] Epoch: 32 [========>      ] 57.9% Loss: 0.0576, Epoch 32, Batch 72, CE_loss: 0.048732366412878036, Dice_loss: 0.0051139178685843945, Consistency_loss: 0.0004072161391377449\n",
      "[Training] Epoch: 32 [========>      ] 58.7% Loss: 0.0576, Epoch 32, Batch 73, CE_loss: 0.049352530390024185, Dice_loss: 0.005267201457172632, Consistency_loss: 0.000465800374513492\n",
      "[Training] Epoch: 32 [========>      ] 59.5% Loss: 0.0576, Epoch 32, Batch 74, CE_loss: 0.052942194044589996, Dice_loss: 0.005725693888962269, Consistency_loss: 0.0005681071197614074\n",
      "[Training] Epoch: 32 [=========>     ] 60.3% Loss: 0.0575, Epoch 32, Batch 75, CE_loss: 0.04535624384880066, Dice_loss: 0.004869349300861359, Consistency_loss: 0.0005378937348723412\n",
      "[Training] Epoch: 32 [=========>     ] 61.1% Loss: 0.0577, Epoch 32, Batch 76, CE_loss: 0.06488676369190216, Dice_loss: 0.0070884437300264835, Consistency_loss: 0.0005132963415235281\n",
      "[Training] Epoch: 32 [=========>     ] 61.9% Loss: 0.0576, Epoch 32, Batch 77, CE_loss: 0.04245852306485176, Dice_loss: 0.0044034854508936405, Consistency_loss: 5.014720591134392e-05\n",
      "[Training] Epoch: 32 [=========>     ] 62.7% Loss: 0.0573, Epoch 32, Batch 78, CE_loss: 0.036693163216114044, Dice_loss: 0.003447675844654441, Consistency_loss: 0.00019684343715198338\n",
      "[Training] Epoch: 32 [=========>     ] 63.5% Loss: 0.0572, Epoch 32, Batch 79, CE_loss: 0.038365770131349564, Dice_loss: 0.003821584628894925, Consistency_loss: 0.00019300621352158487\n",
      "[Training] Epoch: 32 [=========>     ] 64.3% Loss: 0.0571, Epoch 32, Batch 80, CE_loss: 0.04585988074541092, Dice_loss: 0.004862800240516663, Consistency_loss: 0.00023059395607560873\n",
      "[Training] Epoch: 32 [=========>     ] 65.1% Loss: 0.0568, Epoch 32, Batch 81, CE_loss: 0.03292861953377724, Dice_loss: 0.0031497806776314974, Consistency_loss: 0.0005423272959887981\n",
      "[Training] Epoch: 32 [=========>     ] 65.9% Loss: 0.0569, Epoch 32, Batch 82, CE_loss: 0.059570975601673126, Dice_loss: 0.00663909362629056, Consistency_loss: 0.00048272553249262273\n",
      "[Training] Epoch: 32 [==========>    ] 66.7% Loss: 0.0570, Epoch 32, Batch 83, CE_loss: 0.0571884848177433, Dice_loss: 0.006261263974010944, Consistency_loss: 3.0566432542400435e-05\n",
      "[Training] Epoch: 32 [==========>    ] 67.5% Loss: 0.0573, Epoch 32, Batch 84, CE_loss: 0.07399372011423111, Dice_loss: 0.008118501864373684, Consistency_loss: 3.31304436258506e-05\n",
      "[Training] Epoch: 32 [==========>    ] 68.3% Loss: 0.0573, Epoch 32, Batch 85, CE_loss: 0.048078130930662155, Dice_loss: 0.0049223992973566055, Consistency_loss: 0.0005895301583223045\n",
      "[Training] Epoch: 32 [==========>    ] 69.0% Loss: 0.0573, Epoch 32, Batch 86, CE_loss: 0.05682160332798958, Dice_loss: 0.006086759734898806, Consistency_loss: 0.00012287312711123377\n",
      "[Training] Epoch: 32 [==========>    ] 69.8% Loss: 0.0572, Epoch 32, Batch 87, CE_loss: 0.042463649064302444, Dice_loss: 0.00449464051052928, Consistency_loss: 0.00039366460987366736\n",
      "[Training] Epoch: 32 [==========>    ] 70.6% Loss: 0.0570, Epoch 32, Batch 88, CE_loss: 0.03483404591679573, Dice_loss: 0.0028829993680119514, Consistency_loss: 0.00022320942662190646\n",
      "[Training] Epoch: 32 [==========>    ] 71.4% Loss: 0.0569, Epoch 32, Batch 89, CE_loss: 0.04000350832939148, Dice_loss: 0.003908014390617609, Consistency_loss: 0.00040793485823087394\n",
      "[Training] Epoch: 32 [==========>    ] 72.2% Loss: 0.0568, Epoch 32, Batch 90, CE_loss: 0.04569844901561737, Dice_loss: 0.004727272782474756, Consistency_loss: 0.0004298546409700066\n",
      "[Training] Epoch: 32 [==========>    ] 73.0% Loss: 0.0569, Epoch 32, Batch 91, CE_loss: 0.05727396160364151, Dice_loss: 0.005696100182831287, Consistency_loss: 0.0004851435369346291\n",
      "[Training] Epoch: 32 [===========>   ] 73.8% Loss: 0.0568, Epoch 32, Batch 92, CE_loss: 0.042389288544654846, Dice_loss: 0.00416582403704524, Consistency_loss: 0.00048338519991375506\n",
      "[Training] Epoch: 32 [===========>   ] 74.6% Loss: 0.0568, Epoch 32, Batch 93, CE_loss: 0.050705865025520325, Dice_loss: 0.005507487338036299, Consistency_loss: 0.0004882945213466883\n",
      "[Training] Epoch: 32 [===========>   ] 75.4% Loss: 0.0569, Epoch 32, Batch 94, CE_loss: 0.06482847034931183, Dice_loss: 0.0070274281315505505, Consistency_loss: 0.0002363393286941573\n",
      "[Training] Epoch: 32 [===========>   ] 76.2% Loss: 0.0571, Epoch 32, Batch 95, CE_loss: 0.06804592907428741, Dice_loss: 0.007525263819843531, Consistency_loss: 0.00040874938713386655\n",
      "[Training] Epoch: 32 [===========>   ] 77.0% Loss: 0.0573, Epoch 32, Batch 96, CE_loss: 0.06466786563396454, Dice_loss: 0.0069785225205123425, Consistency_loss: 3.460640073171817e-05\n",
      "[Training] Epoch: 32 [===========>   ] 77.8% Loss: 0.0572, Epoch 32, Batch 97, CE_loss: 0.04203806445002556, Dice_loss: 0.004517367575317621, Consistency_loss: 7.417691085720435e-05\n",
      "[Training] Epoch: 32 [===========>   ] 78.6% Loss: 0.0572, Epoch 32, Batch 98, CE_loss: 0.053512219339609146, Dice_loss: 0.005949770100414753, Consistency_loss: 0.0002197532303398475\n",
      "[Training] Epoch: 32 [===========>   ] 79.4% Loss: 0.0569, Epoch 32, Batch 99, CE_loss: 0.02924290858209133, Dice_loss: 0.0024820805992931128, Consistency_loss: 0.0002036616497207433\n",
      "[Training] Epoch: 32 [============>  ] 80.2% Loss: 0.0571, Epoch 32, Batch 100, CE_loss: 0.0692022293806076, Dice_loss: 0.007728168740868568, Consistency_loss: 0.00027628702810034156\n",
      "[Training] Epoch: 32 [============>  ] 81.0% Loss: 0.0571, Epoch 32, Batch 101, CE_loss: 0.04607175663113594, Dice_loss: 0.0049313888885080814, Consistency_loss: 7.319913129322231e-05\n",
      "[Training] Epoch: 32 [============>  ] 81.7% Loss: 0.0570, Epoch 32, Batch 102, CE_loss: 0.044729650020599365, Dice_loss: 0.004832951817661524, Consistency_loss: 8.758401236264035e-05\n",
      "[Training] Epoch: 32 [============>  ] 82.5% Loss: 0.0570, Epoch 32, Batch 103, CE_loss: 0.04860464483499527, Dice_loss: 0.005316491704434156, Consistency_loss: 0.00011946334416279569\n",
      "[Training] Epoch: 32 [============>  ] 83.3% Loss: 0.0569, Epoch 32, Batch 104, CE_loss: 0.04321151599287987, Dice_loss: 0.0045294687151908875, Consistency_loss: 0.00036915676901116967\n",
      "[Training] Epoch: 32 [============>  ] 84.1% Loss: 0.0569, Epoch 32, Batch 105, CE_loss: 0.053924135863780975, Dice_loss: 0.005946931429207325, Consistency_loss: 5.5949174566194415e-05\n",
      "[Training] Epoch: 32 [============>  ] 84.9% Loss: 0.0567, Epoch 32, Batch 106, CE_loss: 0.03117695264518261, Dice_loss: 0.0028985515236854553, Consistency_loss: 0.0006303514237515628\n",
      "[Training] Epoch: 32 [============>  ] 85.7% Loss: 0.0567, Epoch 32, Batch 107, CE_loss: 0.047982506453990936, Dice_loss: 0.004994921386241913, Consistency_loss: 0.0005245005013421178\n",
      "[Training] Epoch: 32 [============>  ] 86.5% Loss: 0.0565, Epoch 32, Batch 108, CE_loss: 0.03691906854510307, Dice_loss: 0.0035127641167491674, Consistency_loss: 0.00026275721029378474\n",
      "[Training] Epoch: 32 [=============> ] 87.3% Loss: 0.0568, Epoch 32, Batch 109, CE_loss: 0.07292918860912323, Dice_loss: 0.008260533213615417, Consistency_loss: 0.0002828666183631867\n",
      "[Training] Epoch: 32 [=============> ] 88.1% Loss: 0.0569, Epoch 32, Batch 110, CE_loss: 0.05992099270224571, Dice_loss: 0.00609041191637516, Consistency_loss: 3.6886482121190056e-05\n",
      "[Training] Epoch: 32 [=============> ] 88.9% Loss: 0.0568, Epoch 32, Batch 111, CE_loss: 0.04994114488363266, Dice_loss: 0.0052862451411783695, Consistency_loss: 0.00030004893778823316\n",
      "[Training] Epoch: 32 [=============> ] 89.7% Loss: 0.0568, Epoch 32, Batch 112, CE_loss: 0.04598500579595566, Dice_loss: 0.004903122782707214, Consistency_loss: 0.00020093568309675902\n",
      "[Training] Epoch: 32 [=============> ] 90.5% Loss: 0.0569, Epoch 32, Batch 113, CE_loss: 0.06622619181871414, Dice_loss: 0.007035501766949892, Consistency_loss: 0.0005169789656065404\n",
      "[Training] Epoch: 32 [=============> ] 91.3% Loss: 0.0571, Epoch 32, Batch 114, CE_loss: 0.06580904871225357, Dice_loss: 0.006930251605808735, Consistency_loss: 0.0003562926431186497\n",
      "[Training] Epoch: 32 [=============> ] 92.1% Loss: 0.0571, Epoch 32, Batch 115, CE_loss: 0.04858100041747093, Dice_loss: 0.005272387061268091, Consistency_loss: 0.0002706764789763838\n",
      "[Training] Epoch: 32 [=============> ] 92.9% Loss: 0.0570, Epoch 32, Batch 116, CE_loss: 0.047214336693286896, Dice_loss: 0.005103881936520338, Consistency_loss: 0.00040322361746802926\n",
      "[Training] Epoch: 32 [==============>] 93.7% Loss: 0.0570, Epoch 32, Batch 117, CE_loss: 0.053580768406391144, Dice_loss: 0.005855123978108168, Consistency_loss: 0.00033021505805663764\n",
      "[Training] Epoch: 32 [==============>] 94.4% Loss: 0.0570, Epoch 32, Batch 118, CE_loss: 0.04398982599377632, Dice_loss: 0.004585165064781904, Consistency_loss: 0.0003830586501862854\n",
      "[Training] Epoch: 32 [==============>] 95.2% Loss: 0.0570, Epoch 32, Batch 119, CE_loss: 0.05080370977520943, Dice_loss: 0.005473888013511896, Consistency_loss: 0.0002946635358966887\n",
      "[Training] Epoch: 32 [==============>] 96.0% Loss: 0.0570, Epoch 32, Batch 120, CE_loss: 0.05624844506382942, Dice_loss: 0.006226265802979469, Consistency_loss: 0.0001112582758651115\n",
      "[Training] Epoch: 32 [==============>] 96.8% Loss: 0.0570, Epoch 32, Batch 121, CE_loss: 0.043924927711486816, Dice_loss: 0.004655416589230299, Consistency_loss: 0.0004625522706191987\n",
      "[Training] Epoch: 32 [==============>] 97.6% Loss: 0.0568, Epoch 32, Batch 122, CE_loss: 0.039649371057748795, Dice_loss: 0.003629435785114765, Consistency_loss: 0.00013673867215402424\n",
      "[Training] Epoch: 32 [==============>] 98.4% Loss: 0.0567, Epoch 32, Batch 123, CE_loss: 0.03834399953484535, Dice_loss: 0.0036248313263058662, Consistency_loss: 0.00018971376994159073\n",
      "[Training] Epoch: 32 [==============>] 99.2% Loss: 0.0566, Epoch 32, Batch 124, CE_loss: 0.03234182298183441, Dice_loss: 0.0030752511229366064, Consistency_loss: 0.00022963937954045832\n",
      "[Training] Epoch: 32 [DONE]                                 \n",
      "Epoch 32, Batch 125, CE_loss: 0.05019921064376831, Dice_loss: 0.005540987942367792, Consistency_loss: 0.000190342019777745\n",
      "[Validation] Epoch: 32 [DONE]                                 \n",
      "[Epoch: 32, TrainLoss: 0.0566, TrainDice: 0.0054, ValLoss: 0.1454                                            \n",
      "Number of batches:  126\n",
      "[Training] Epoch: 33 [>              ] 0.8% Loss: 0.0627, Epoch 33, Batch 0, CE_loss: 0.05650459975004196, Dice_loss: 0.005922098644077778, Consistency_loss: 0.0002800911315716803\n",
      "[Training] Epoch: 33 [>              ] 1.6% Loss: 0.0572, Epoch 33, Batch 1, CE_loss: 0.04644396901130676, Dice_loss: 0.004969092085957527, Consistency_loss: 0.0002734872978180647\n",
      "[Training] Epoch: 33 [>              ] 2.4% Loss: 0.0553, Epoch 33, Batch 2, CE_loss: 0.04675644636154175, Dice_loss: 0.004339246544986963, Consistency_loss: 0.0002789052086882293\n",
      "[Training] Epoch: 33 [>              ] 3.2% Loss: 0.0540, Epoch 33, Batch 3, CE_loss: 0.04501274228096008, Dice_loss: 0.004763925448060036, Consistency_loss: 0.000394578994018957\n",
      "[Training] Epoch: 33 [>              ] 4.0% Loss: 0.0531, Epoch 33, Batch 4, CE_loss: 0.04453488066792488, Dice_loss: 0.004374553449451923, Consistency_loss: 0.0004171071632299572\n",
      "[Training] Epoch: 33 [>              ] 4.8% Loss: 0.0551, Epoch 33, Batch 5, CE_loss: 0.05849846825003624, Dice_loss: 0.006442044861614704, Consistency_loss: 0.00011513649951666594\n",
      "[Training] Epoch: 33 [>              ] 5.6% Loss: 0.0564, Epoch 33, Batch 6, CE_loss: 0.05813560634851456, Dice_loss: 0.006376107223331928, Consistency_loss: 2.4267195840366185e-05\n",
      "[Training] Epoch: 33 [>              ] 6.3% Loss: 0.0585, Epoch 33, Batch 7, CE_loss: 0.06603585928678513, Dice_loss: 0.007054200861603022, Consistency_loss: 0.00019341181905474514\n",
      "[Training] Epoch: 33 [=>             ] 7.1% Loss: 0.0590, Epoch 33, Batch 8, CE_loss: 0.056544214487075806, Dice_loss: 0.006056915502995253, Consistency_loss: 0.0001492802839493379\n",
      "[Training] Epoch: 33 [=>             ] 7.9% Loss: 0.0579, Epoch 33, Batch 9, CE_loss: 0.04321939870715141, Dice_loss: 0.0045471759513020515, Consistency_loss: 0.00013497141480911523\n",
      "[Training] Epoch: 33 [=>             ] 8.7% Loss: 0.0592, Epoch 33, Batch 10, CE_loss: 0.06508499383926392, Dice_loss: 0.00700428057461977, Consistency_loss: 5.702141424990259e-05\n",
      "[Training] Epoch: 33 [=>             ] 9.5% Loss: 0.0574, Epoch 33, Batch 11, CE_loss: 0.03355666622519493, Dice_loss: 0.0033548669889569283, Consistency_loss: 0.0005005751736462116\n",
      "[Training] Epoch: 33 [=>             ] 10.3% Loss: 0.0576, Epoch 33, Batch 12, CE_loss: 0.05457942560315132, Dice_loss: 0.005928477738052607, Consistency_loss: 0.0005456016515381634\n",
      "[Training] Epoch: 33 [=>             ] 11.1% Loss: 0.0566, Epoch 33, Batch 13, CE_loss: 0.038449473679065704, Dice_loss: 0.0034779536072164774, Consistency_loss: 0.0004199682443868369\n",
      "[Training] Epoch: 33 [=>             ] 11.9% Loss: 0.0573, Epoch 33, Batch 14, CE_loss: 0.060555409640073776, Dice_loss: 0.006699684541672468, Consistency_loss: 0.0003937094588764012\n",
      "[Training] Epoch: 33 [=>             ] 12.7% Loss: 0.0566, Epoch 33, Batch 15, CE_loss: 0.04180306941270828, Dice_loss: 0.00400473503395915, Consistency_loss: 0.00030868229805491865\n",
      "[Training] Epoch: 33 [==>            ] 13.5% Loss: 0.0559, Epoch 33, Batch 16, CE_loss: 0.03991297632455826, Dice_loss: 0.004134750459343195, Consistency_loss: 0.0001596007205080241\n",
      "[Training] Epoch: 33 [==>            ] 14.3% Loss: 0.0549, Epoch 33, Batch 17, CE_loss: 0.034154053777456284, Dice_loss: 0.003221797989681363, Consistency_loss: 0.00042004865827038884\n",
      "[Training] Epoch: 33 [==>            ] 15.1% Loss: 0.0551, Epoch 33, Batch 18, CE_loss: 0.054027143865823746, Dice_loss: 0.005506731569766998, Consistency_loss: 0.00037678502849303186\n",
      "[Training] Epoch: 33 [==>            ] 15.9% Loss: 0.0547, Epoch 33, Batch 19, CE_loss: 0.04256073758006096, Dice_loss: 0.0044382065534591675, Consistency_loss: 0.00034735380904749036\n",
      "[Training] Epoch: 33 [==>            ] 16.7% Loss: 0.0554, Epoch 33, Batch 20, CE_loss: 0.060966942459344864, Dice_loss: 0.006779220886528492, Consistency_loss: 0.0002120475546689704\n",
      "[Training] Epoch: 33 [==>            ] 17.5% Loss: 0.0565, Epoch 33, Batch 21, CE_loss: 0.07132627815008163, Dice_loss: 0.008184265345335007, Consistency_loss: 3.092187034781091e-05\n",
      "[Training] Epoch: 33 [==>            ] 18.3% Loss: 0.0572, Epoch 33, Batch 22, CE_loss: 0.06558001041412354, Dice_loss: 0.007239349652081728, Consistency_loss: 2.896922524087131e-05\n",
      "[Training] Epoch: 33 [==>            ] 19.0% Loss: 0.0571, Epoch 33, Batch 23, CE_loss: 0.0496305488049984, Dice_loss: 0.005417007487267256, Consistency_loss: 0.00018897604604717344\n",
      "[Training] Epoch: 33 [==>            ] 19.8% Loss: 0.0569, Epoch 33, Batch 24, CE_loss: 0.046292394399642944, Dice_loss: 0.004899555817246437, Consistency_loss: 0.00022161479864735156\n",
      "[Training] Epoch: 33 [===>           ] 20.6% Loss: 0.0568, Epoch 33, Batch 25, CE_loss: 0.04975706338882446, Dice_loss: 0.005499932449311018, Consistency_loss: 0.00024539013975299895\n",
      "[Training] Epoch: 33 [===>           ] 21.4% Loss: 0.0563, Epoch 33, Batch 26, CE_loss: 0.038959041237831116, Dice_loss: 0.0040300325490534306, Consistency_loss: 0.00036302488297224045\n",
      "[Training] Epoch: 33 [===>           ] 22.2% Loss: 0.0560, Epoch 33, Batch 27, CE_loss: 0.04157983884215355, Dice_loss: 0.004381062462925911, Consistency_loss: 0.0003828717744909227\n",
      "[Training] Epoch: 33 [===>           ] 23.0% Loss: 0.0557, Epoch 33, Batch 28, CE_loss: 0.04425115883350372, Dice_loss: 0.004766603000462055, Consistency_loss: 0.0002444316342007369\n",
      "[Training] Epoch: 33 [===>           ] 23.8% Loss: 0.0564, Epoch 33, Batch 29, CE_loss: 0.06899546831846237, Dice_loss: 0.007408574689179659, Consistency_loss: 0.0003613860171753913\n",
      "[Training] Epoch: 33 [===>           ] 24.6% Loss: 0.0564, Epoch 33, Batch 30, CE_loss: 0.050674036145210266, Dice_loss: 0.005499641876667738, Consistency_loss: 0.00032959048985503614\n",
      "[Training] Epoch: 33 [===>           ] 25.4% Loss: 0.0559, Epoch 33, Batch 31, CE_loss: 0.03513878583908081, Dice_loss: 0.003557699965313077, Consistency_loss: 7.727696356596425e-05\n",
      "[Training] Epoch: 33 [===>           ] 26.2% Loss: 0.0564, Epoch 33, Batch 32, CE_loss: 0.06462685018777847, Dice_loss: 0.007050544489175081, Consistency_loss: 0.00023141007113736123\n",
      "[Training] Epoch: 33 [====>          ] 27.0% Loss: 0.0563, Epoch 33, Batch 33, CE_loss: 0.04836486652493477, Dice_loss: 0.005210875067859888, Consistency_loss: 0.00046217735507525504\n",
      "[Training] Epoch: 33 [====>          ] 27.8% Loss: 0.0561, Epoch 33, Batch 34, CE_loss: 0.04479502514004707, Dice_loss: 0.004806536715477705, Consistency_loss: 0.00045792790479026735\n",
      "[Training] Epoch: 33 [====>          ] 28.6% Loss: 0.0560, Epoch 33, Batch 35, CE_loss: 0.045704133808612823, Dice_loss: 0.004907079041004181, Consistency_loss: 0.0003729449526872486\n",
      "[Training] Epoch: 33 [====>          ] 29.4% Loss: 0.0560, Epoch 33, Batch 36, CE_loss: 0.05180548503994942, Dice_loss: 0.005649210885167122, Consistency_loss: 0.00026482713292352855\n",
      "[Training] Epoch: 33 [====>          ] 30.2% Loss: 0.0560, Epoch 33, Batch 37, CE_loss: 0.04975000023841858, Dice_loss: 0.004775673151016235, Consistency_loss: 4.6567241952288896e-05\n",
      "[Training] Epoch: 33 [====>          ] 31.0% Loss: 0.0555, Epoch 33, Batch 38, CE_loss: 0.031910061836242676, Dice_loss: 0.0028258280362933874, Consistency_loss: 0.000645774242002517\n",
      "[Training] Epoch: 33 [====>          ] 31.7% Loss: 0.0555, Epoch 33, Batch 39, CE_loss: 0.05203310400247574, Dice_loss: 0.005839321296662092, Consistency_loss: 0.0005327347898855805\n",
      "[Training] Epoch: 33 [====>          ] 32.5% Loss: 0.0556, Epoch 33, Batch 40, CE_loss: 0.05065099895000458, Dice_loss: 0.005340117495507002, Consistency_loss: 0.00044192979112267494\n",
      "[Training] Epoch: 33 [=====>         ] 33.3% Loss: 0.0556, Epoch 33, Batch 41, CE_loss: 0.053269222378730774, Dice_loss: 0.005833196919411421, Consistency_loss: 0.0003770531329791993\n",
      "[Training] Epoch: 33 [=====>         ] 34.1% Loss: 0.0561, Epoch 33, Batch 42, CE_loss: 0.06680150330066681, Dice_loss: 0.007061939220875502, Consistency_loss: 0.00010695093078538775\n",
      "[Training] Epoch: 33 [=====>         ] 34.9% Loss: 0.0563, Epoch 33, Batch 43, CE_loss: 0.05901218205690384, Dice_loss: 0.006251335609704256, Consistency_loss: 4.0345097659155726e-05\n",
      "[Training] Epoch: 33 [=====>         ] 35.7% Loss: 0.0562, Epoch 33, Batch 44, CE_loss: 0.047253020107746124, Dice_loss: 0.004858558066189289, Consistency_loss: 8.694715506862849e-05\n",
      "[Training] Epoch: 33 [=====>         ] 36.5% Loss: 0.0564, Epoch 33, Batch 45, CE_loss: 0.05873490124940872, Dice_loss: 0.006368811707943678, Consistency_loss: 0.00027705737738870084\n",
      "[Training] Epoch: 33 [=====>         ] 37.3% Loss: 0.0561, Epoch 33, Batch 46, CE_loss: 0.03864983469247818, Dice_loss: 0.004023823421448469, Consistency_loss: 0.00016894275904633105\n",
      "[Training] Epoch: 33 [=====>         ] 38.1% Loss: 0.0562, Epoch 33, Batch 47, CE_loss: 0.05261947214603424, Dice_loss: 0.0058462233282625675, Consistency_loss: 0.0004994626506231725\n",
      "[Training] Epoch: 33 [=====>         ] 38.9% Loss: 0.0559, Epoch 33, Batch 48, CE_loss: 0.03984078764915466, Dice_loss: 0.004136270377784967, Consistency_loss: 0.00014041426766198128\n",
      "[Training] Epoch: 33 [=====>         ] 39.7% Loss: 0.0562, Epoch 33, Batch 49, CE_loss: 0.06159641593694687, Dice_loss: 0.006747897248715162, Consistency_loss: 0.00046610328718088567\n",
      "[Training] Epoch: 33 [======>        ] 40.5% Loss: 0.0560, Epoch 33, Batch 50, CE_loss: 0.04008267819881439, Dice_loss: 0.004146985709667206, Consistency_loss: 0.00047529974835924804\n",
      "[Training] Epoch: 33 [======>        ] 41.3% Loss: 0.0558, Epoch 33, Batch 51, CE_loss: 0.04365566372871399, Dice_loss: 0.00443294970318675, Consistency_loss: 0.0006114669959060848\n",
      "[Training] Epoch: 33 [======>        ] 42.1% Loss: 0.0554, Epoch 33, Batch 52, CE_loss: 0.03191686421632767, Dice_loss: 0.0027593495324254036, Consistency_loss: 0.00016865026555024087\n",
      "[Training] Epoch: 33 [======>        ] 42.9% Loss: 0.0554, Epoch 33, Batch 53, CE_loss: 0.05081779137253761, Dice_loss: 0.004964648280292749, Consistency_loss: 0.0002033294440479949\n",
      "[Training] Epoch: 33 [======>        ] 43.7% Loss: 0.0554, Epoch 33, Batch 54, CE_loss: 0.049429357051849365, Dice_loss: 0.005229949951171875, Consistency_loss: 0.0002672973205335438\n",
      "[Training] Epoch: 33 [======>        ] 44.4% Loss: 0.0558, Epoch 33, Batch 55, CE_loss: 0.06929540634155273, Dice_loss: 0.007714207749813795, Consistency_loss: 0.0003806969616562128\n",
      "[Training] Epoch: 33 [======>        ] 45.2% Loss: 0.0557, Epoch 33, Batch 56, CE_loss: 0.044716887176036835, Dice_loss: 0.004704406950622797, Consistency_loss: 0.00024709783610887825\n",
      "[Training] Epoch: 33 [======>        ] 46.0% Loss: 0.0556, Epoch 33, Batch 57, CE_loss: 0.047491222620010376, Dice_loss: 0.004644128959625959, Consistency_loss: 0.0002706035738810897\n",
      "[Training] Epoch: 33 [=======>       ] 46.8% Loss: 0.0553, Epoch 33, Batch 58, CE_loss: 0.03382153436541557, Dice_loss: 0.003116508014500141, Consistency_loss: 0.00038148401654325426\n",
      "[Training] Epoch: 33 [=======>       ] 47.6% Loss: 0.0554, Epoch 33, Batch 59, CE_loss: 0.05508802831172943, Dice_loss: 0.006070867646485567, Consistency_loss: 0.00027175495051778853\n",
      "[Training] Epoch: 33 [=======>       ] 48.4% Loss: 0.0555, Epoch 33, Batch 60, CE_loss: 0.05561031401157379, Dice_loss: 0.0062125371769070625, Consistency_loss: 0.00030849460745230317\n",
      "[Training] Epoch: 33 [=======>       ] 49.2% Loss: 0.0555, Epoch 33, Batch 61, CE_loss: 0.047601666301488876, Dice_loss: 0.005012463312596083, Consistency_loss: 0.00015732384053990245\n",
      "[Training] Epoch: 33 [=======>       ] 50.0% Loss: 0.0557, Epoch 33, Batch 62, CE_loss: 0.06005574390292168, Dice_loss: 0.006677963305264711, Consistency_loss: 0.0005504802102223039\n",
      "[Training] Epoch: 33 [=======>       ] 50.8% Loss: 0.0560, Epoch 33, Batch 63, CE_loss: 0.06842043250799179, Dice_loss: 0.00635881582275033, Consistency_loss: 0.0005538453115150332\n",
      "[Training] Epoch: 33 [=======>       ] 51.6% Loss: 0.0561, Epoch 33, Batch 64, CE_loss: 0.055123183876276016, Dice_loss: 0.005872620735317469, Consistency_loss: 0.0005449190502986312\n",
      "[Training] Epoch: 33 [=======>       ] 52.4% Loss: 0.0559, Epoch 33, Batch 65, CE_loss: 0.04217318817973137, Dice_loss: 0.004174393601715565, Consistency_loss: 0.0004388058150652796\n",
      "[Training] Epoch: 33 [=======>       ] 53.2% Loss: 0.0559, Epoch 33, Batch 66, CE_loss: 0.04510573297739029, Dice_loss: 0.004883672576397657, Consistency_loss: 0.00019033536955248564\n",
      "[Training] Epoch: 33 [========>      ] 54.0% Loss: 0.0559, Epoch 33, Batch 67, CE_loss: 0.054655659943819046, Dice_loss: 0.006108932662755251, Consistency_loss: 0.0002592033997643739\n",
      "[Training] Epoch: 33 [========>      ] 54.8% Loss: 0.0560, Epoch 33, Batch 68, CE_loss: 0.054387181997299194, Dice_loss: 0.005935576744377613, Consistency_loss: 0.00027135355048812926\n",
      "[Training] Epoch: 33 [========>      ] 55.6% Loss: 0.0558, Epoch 33, Batch 69, CE_loss: 0.038015641272068024, Dice_loss: 0.003947161138057709, Consistency_loss: 6.144359213067219e-05\n",
      "[Training] Epoch: 33 [========>      ] 56.3% Loss: 0.0559, Epoch 33, Batch 70, CE_loss: 0.05588327348232269, Dice_loss: 0.005844207480549812, Consistency_loss: 0.0007202838896773756\n",
      "[Training] Epoch: 33 [========>      ] 57.1% Loss: 0.0561, Epoch 33, Batch 71, CE_loss: 0.06089366599917412, Dice_loss: 0.006839485839009285, Consistency_loss: 0.0004243047151248902\n",
      "[Training] Epoch: 33 [========>      ] 57.9% Loss: 0.0561, Epoch 33, Batch 72, CE_loss: 0.050229258835315704, Dice_loss: 0.005599764175713062, Consistency_loss: 0.0004461417847778648\n",
      "[Training] Epoch: 33 [========>      ] 58.7% Loss: 0.0562, Epoch 33, Batch 73, CE_loss: 0.06015016883611679, Dice_loss: 0.006732903886586428, Consistency_loss: 0.0004986150888726115\n",
      "[Training] Epoch: 33 [========>      ] 59.5% Loss: 0.0563, Epoch 33, Batch 74, CE_loss: 0.05496362969279289, Dice_loss: 0.005648316815495491, Consistency_loss: 0.00017972057685256004\n",
      "[Training] Epoch: 33 [=========>     ] 60.3% Loss: 0.0564, Epoch 33, Batch 75, CE_loss: 0.05623040348291397, Dice_loss: 0.006053969729691744, Consistency_loss: 7.078945054672658e-05\n",
      "[Training] Epoch: 33 [=========>     ] 61.1% Loss: 0.0562, Epoch 33, Batch 76, CE_loss: 0.042913347482681274, Dice_loss: 0.004574140999466181, Consistency_loss: 0.000425286270910874\n",
      "[Training] Epoch: 33 [=========>     ] 61.9% Loss: 0.0563, Epoch 33, Batch 77, CE_loss: 0.053084034472703934, Dice_loss: 0.005925777833908796, Consistency_loss: 9.112522820942104e-05\n",
      "[Training] Epoch: 33 [=========>     ] 62.7% Loss: 0.0562, Epoch 33, Batch 78, CE_loss: 0.04382321238517761, Dice_loss: 0.004650673363357782, Consistency_loss: 0.00032246820046566427\n",
      "[Training] Epoch: 33 [=========>     ] 63.5% Loss: 0.0561, Epoch 33, Batch 79, CE_loss: 0.041882727295160294, Dice_loss: 0.003988923504948616, Consistency_loss: 0.0001754044060362503\n",
      "[Training] Epoch: 33 [=========>     ] 64.3% Loss: 0.0562, Epoch 33, Batch 80, CE_loss: 0.05712015926837921, Dice_loss: 0.006002394948154688, Consistency_loss: 0.0004485387762542814\n",
      "[Training] Epoch: 33 [=========>     ] 65.1% Loss: 0.0560, Epoch 33, Batch 81, CE_loss: 0.036392942070961, Dice_loss: 0.003652525134384632, Consistency_loss: 0.0005675525753758848\n",
      "[Training] Epoch: 33 [=========>     ] 65.9% Loss: 0.0560, Epoch 33, Batch 82, CE_loss: 0.05304538086056709, Dice_loss: 0.005801318679004908, Consistency_loss: 0.0005517648532986641\n",
      "[Training] Epoch: 33 [==========>    ] 66.7% Loss: 0.0559, Epoch 33, Batch 83, CE_loss: 0.03993095085024834, Dice_loss: 0.0041466373950243, Consistency_loss: 0.00015720509691163898\n",
      "[Training] Epoch: 33 [==========>    ] 67.5% Loss: 0.0560, Epoch 33, Batch 84, CE_loss: 0.05917686969041824, Dice_loss: 0.006716948933899403, Consistency_loss: 0.0001373532140860334\n",
      "[Training] Epoch: 33 [==========>    ] 68.3% Loss: 0.0566, Epoch 33, Batch 85, CE_loss: 0.09580978751182556, Dice_loss: 0.010796173475682735, Consistency_loss: 5.239948586677201e-05\n",
      "[Training] Epoch: 33 [==========>    ] 69.0% Loss: 0.0566, Epoch 33, Batch 86, CE_loss: 0.0496876984834671, Dice_loss: 0.0054613263346254826, Consistency_loss: 0.0003841244906652719\n",
      "[Training] Epoch: 33 [==========>    ] 69.8% Loss: 0.0566, Epoch 33, Batch 87, CE_loss: 0.053571414202451706, Dice_loss: 0.005857430398464203, Consistency_loss: 0.00039927769103087485\n",
      "[Training] Epoch: 33 [==========>    ] 70.6% Loss: 0.0566, Epoch 33, Batch 88, CE_loss: 0.04935228452086449, Dice_loss: 0.005397011525928974, Consistency_loss: 3.229235517210327e-05\n",
      "[Training] Epoch: 33 [==========>    ] 71.4% Loss: 0.0563, Epoch 33, Batch 89, CE_loss: 0.029959101229906082, Dice_loss: 0.0027932077646255493, Consistency_loss: 0.00031567589030601084\n",
      "[Training] Epoch: 33 [==========>    ] 72.2% Loss: 0.0561, Epoch 33, Batch 90, CE_loss: 0.03581785783171654, Dice_loss: 0.0034447433426976204, Consistency_loss: 2.4378079615416937e-05\n",
      "[Training] Epoch: 33 [==========>    ] 73.0% Loss: 0.0561, Epoch 33, Batch 91, CE_loss: 0.04705677181482315, Dice_loss: 0.00513940304517746, Consistency_loss: 0.0005051963962614536\n",
      "[Training] Epoch: 33 [===========>   ] 73.8% Loss: 0.0561, Epoch 33, Batch 92, CE_loss: 0.04792185127735138, Dice_loss: 0.005212864372879267, Consistency_loss: 0.00041376720764674246\n",
      "[Training] Epoch: 33 [===========>   ] 74.6% Loss: 0.0563, Epoch 33, Batch 93, CE_loss: 0.07222704589366913, Dice_loss: 0.0081600621342659, Consistency_loss: 0.0003797222743742168\n",
      "[Training] Epoch: 33 [===========>   ] 75.4% Loss: 0.0562, Epoch 33, Batch 94, CE_loss: 0.03978487476706505, Dice_loss: 0.004252101760357618, Consistency_loss: 0.0003587913524825126\n",
      "[Training] Epoch: 33 [===========>   ] 76.2% Loss: 0.0564, Epoch 33, Batch 95, CE_loss: 0.07203788310289383, Dice_loss: 0.006972098723053932, Consistency_loss: 0.0004626257868949324\n",
      "[Training] Epoch: 33 [===========>   ] 77.0% Loss: 0.0565, Epoch 33, Batch 96, CE_loss: 0.05206451937556267, Dice_loss: 0.005668375175446272, Consistency_loss: 0.00021148417727090418\n",
      "[Training] Epoch: 33 [===========>   ] 77.8% Loss: 0.0563, Epoch 33, Batch 97, CE_loss: 0.03680155426263809, Dice_loss: 0.003722526365891099, Consistency_loss: 5.370082726585679e-05\n",
      "[Training] Epoch: 33 [===========>   ] 78.6% Loss: 0.0563, Epoch 33, Batch 98, CE_loss: 0.04842442646622658, Dice_loss: 0.005183413624763489, Consistency_loss: 4.778457514476031e-05\n",
      "[Training] Epoch: 33 [===========>   ] 79.4% Loss: 0.0561, Epoch 33, Batch 99, CE_loss: 0.03978081792593002, Dice_loss: 0.00391490338370204, Consistency_loss: 4.3217794882366434e-05\n",
      "[Training] Epoch: 33 [============>  ] 80.2% Loss: 0.0562, Epoch 33, Batch 100, CE_loss: 0.05625518411397934, Dice_loss: 0.006180744152516127, Consistency_loss: 4.5607401261804625e-05\n",
      "[Training] Epoch: 33 [============>  ] 81.0% Loss: 0.0561, Epoch 33, Batch 101, CE_loss: 0.04102260619401932, Dice_loss: 0.004171420820057392, Consistency_loss: 0.0004202368145342916\n",
      "[Training] Epoch: 33 [============>  ] 81.7% Loss: 0.0562, Epoch 33, Batch 102, CE_loss: 0.056479889899492264, Dice_loss: 0.006339374464005232, Consistency_loss: 0.00038868383853696287\n",
      "[Training] Epoch: 33 [============>  ] 82.5% Loss: 0.0561, Epoch 33, Batch 103, CE_loss: 0.04781746491789818, Dice_loss: 0.005060988944023848, Consistency_loss: 0.00040228440775536\n",
      "[Training] Epoch: 33 [============>  ] 83.3% Loss: 0.0562, Epoch 33, Batch 104, CE_loss: 0.05740797519683838, Dice_loss: 0.00645979680120945, Consistency_loss: 0.0003877253911923617\n",
      "[Training] Epoch: 33 [============>  ] 84.1% Loss: 0.0561, Epoch 33, Batch 105, CE_loss: 0.03717226907610893, Dice_loss: 0.0036456540692597628, Consistency_loss: 0.00020641859737224877\n",
      "[Training] Epoch: 33 [============>  ] 84.9% Loss: 0.0560, Epoch 33, Batch 106, CE_loss: 0.04428817704319954, Dice_loss: 0.004817207343876362, Consistency_loss: 0.000585968722589314\n",
      "[Training] Epoch: 33 [============>  ] 85.7% Loss: 0.0560, Epoch 33, Batch 107, CE_loss: 0.05141427740454674, Dice_loss: 0.005583832040429115, Consistency_loss: 0.0005600066506303847\n",
      "[Training] Epoch: 33 [============>  ] 86.5% Loss: 0.0564, Epoch 33, Batch 108, CE_loss: 0.0859382227063179, Dice_loss: 0.009842169471085072, Consistency_loss: 0.00025636699865572155\n",
      "[Training] Epoch: 33 [=============> ] 87.3% Loss: 0.0564, Epoch 33, Batch 109, CE_loss: 0.05108920857310295, Dice_loss: 0.005242055747658014, Consistency_loss: 0.00019684596918523312\n",
      "[Training] Epoch: 33 [=============> ] 88.1% Loss: 0.0564, Epoch 33, Batch 110, CE_loss: 0.046105656772851944, Dice_loss: 0.004990182816982269, Consistency_loss: 0.00031623823451809585\n",
      "[Training] Epoch: 33 [=============> ] 88.9% Loss: 0.0562, Epoch 33, Batch 111, CE_loss: 0.039567526429891586, Dice_loss: 0.004043202381581068, Consistency_loss: 0.00025614057085476816\n",
      "[Training] Epoch: 33 [=============> ] 89.7% Loss: 0.0562, Epoch 33, Batch 112, CE_loss: 0.042596153914928436, Dice_loss: 0.0044707017950713634, Consistency_loss: 0.0004451257118489593\n",
      "[Training] Epoch: 33 [=============> ] 90.5% Loss: 0.0561, Epoch 33, Batch 113, CE_loss: 0.0462944395840168, Dice_loss: 0.004937388002872467, Consistency_loss: 0.0002995271934196353\n",
      "[Training] Epoch: 33 [=============> ] 91.3% Loss: 0.0560, Epoch 33, Batch 114, CE_loss: 0.03979840502142906, Dice_loss: 0.004110101144760847, Consistency_loss: 0.0002524202864151448\n",
      "[Training] Epoch: 33 [=============> ] 92.1% Loss: 0.0560, Epoch 33, Batch 115, CE_loss: 0.048505812883377075, Dice_loss: 0.005351378116756678, Consistency_loss: 0.0002781643997877836\n",
      "[Training] Epoch: 33 [=============> ] 92.9% Loss: 0.0560, Epoch 33, Batch 116, CE_loss: 0.04534314572811127, Dice_loss: 0.004396927542984486, Consistency_loss: 0.0004299819120205939\n",
      "[Training] Epoch: 33 [==============>] 93.7% Loss: 0.0560, Epoch 33, Batch 117, CE_loss: 0.05849677324295044, Dice_loss: 0.005889469757676125, Consistency_loss: 5.90055606153328e-05\n",
      "[Training] Epoch: 33 [==============>] 94.4% Loss: 0.0559, Epoch 33, Batch 118, CE_loss: 0.03697673976421356, Dice_loss: 0.003687246236950159, Consistency_loss: 0.00032036579796113074\n",
      "[Training] Epoch: 33 [==============>] 95.2% Loss: 0.0560, Epoch 33, Batch 119, CE_loss: 0.056129079312086105, Dice_loss: 0.006140863988548517, Consistency_loss: 0.00020636431872844696\n",
      "[Training] Epoch: 33 [==============>] 96.0% Loss: 0.0560, Epoch 33, Batch 120, CE_loss: 0.05580544099211693, Dice_loss: 0.00620927382260561, Consistency_loss: 0.00033223250648006797\n",
      "[Training] Epoch: 33 [==============>] 96.8% Loss: 0.0559, Epoch 33, Batch 121, CE_loss: 0.035640884190797806, Dice_loss: 0.0036389888264238834, Consistency_loss: 8.502272248733789e-05\n",
      "[Training] Epoch: 33 [==============>] 97.6% Loss: 0.0558, Epoch 33, Batch 122, CE_loss: 0.042725592851638794, Dice_loss: 0.004355889745056629, Consistency_loss: 0.00021344581909943372\n",
      "[Training] Epoch: 33 [==============>] 98.4% Loss: 0.0558, Epoch 33, Batch 123, CE_loss: 0.047613419592380524, Dice_loss: 0.004567690193653107, Consistency_loss: 0.000138051706016995\n",
      "[Training] Epoch: 33 [==============>] 99.2% Loss: 0.0557, Epoch 33, Batch 124, CE_loss: 0.04231380298733711, Dice_loss: 0.004551252815872431, Consistency_loss: 2.744910125329625e-05\n",
      "[Training] Epoch: 33 [DONE]                                 \n",
      "Epoch 33, Batch 125, CE_loss: 0.037402208894491196, Dice_loss: 0.0038177224341779947, Consistency_loss: 0.0004758303693961352\n",
      "[Validation] Epoch: 33 [DONE]                                 \n",
      "[Epoch: 33, TrainLoss: 0.0556, TrainDice: 0.0053, ValLoss: 0.1646                                            \n",
      "Number of batches:  126\n",
      "[Training] Epoch: 34 [>              ] 0.8% Loss: 0.0578, Epoch 34, Batch 0, CE_loss: 0.05181717872619629, Dice_loss: 0.005772060249000788, Consistency_loss: 0.0002103269362123683\n",
      "[Training] Epoch: 34 [>              ] 1.6% Loss: 0.0675, Epoch 34, Batch 1, CE_loss: 0.06930025666952133, Dice_loss: 0.007609950378537178, Consistency_loss: 0.00019366727792657912\n",
      "[Training] Epoch: 34 [>              ] 2.4% Loss: 0.0745, Epoch 34, Batch 2, CE_loss: 0.08024200052022934, Dice_loss: 0.00828284490853548, Consistency_loss: 0.0002080991689581424\n",
      "[Training] Epoch: 34 [>              ] 3.2% Loss: 0.0656, Epoch 34, Batch 3, CE_loss: 0.03559606522321701, Dice_loss: 0.003288696752861142, Consistency_loss: 3.811084388871677e-05\n",
      "[Training] Epoch: 34 [>              ] 4.0% Loss: 0.0635, Epoch 34, Batch 4, CE_loss: 0.04936067759990692, Dice_loss: 0.005420391447842121, Consistency_loss: 0.00026005631661973894\n",
      "[Training] Epoch: 34 [>              ] 4.8% Loss: 0.0616, Epoch 34, Batch 5, CE_loss: 0.047243185341358185, Dice_loss: 0.005029705353081226, Consistency_loss: 1.8467528207111172e-05\n",
      "[Training] Epoch: 34 [>              ] 5.6% Loss: 0.0590, Epoch 34, Batch 6, CE_loss: 0.038865845650434494, Dice_loss: 0.0037909136153757572, Consistency_loss: 0.0002220393653260544\n",
      "[Training] Epoch: 34 [>              ] 6.3% Loss: 0.0575, Epoch 34, Batch 7, CE_loss: 0.04243173450231552, Dice_loss: 0.004339568316936493, Consistency_loss: 0.00027351692551746964\n",
      "[Training] Epoch: 34 [=>             ] 7.1% Loss: 0.0589, Epoch 34, Batch 8, CE_loss: 0.0641321912407875, Dice_loss: 0.006184512749314308, Consistency_loss: 0.000125432969070971\n",
      "[Training] Epoch: 34 [=>             ] 7.9% Loss: 0.0584, Epoch 34, Batch 9, CE_loss: 0.04894004389643669, Dice_loss: 0.004994899034500122, Consistency_loss: 2.356605909881182e-05\n",
      "[Training] Epoch: 34 [=>             ] 8.7% Loss: 0.0583, Epoch 34, Batch 10, CE_loss: 0.051409993320703506, Dice_loss: 0.005574886687099934, Consistency_loss: 0.0004796718421857804\n",
      "[Training] Epoch: 34 [=>             ] 9.5% Loss: 0.0597, Epoch 34, Batch 11, CE_loss: 0.06646902114152908, Dice_loss: 0.007544106338173151, Consistency_loss: 0.00042602719622664154\n",
      "[Training] Epoch: 34 [=>             ] 10.3% Loss: 0.0579, Epoch 34, Batch 12, CE_loss: 0.032980747520923615, Dice_loss: 0.003279805416241288, Consistency_loss: 0.00033166204229928553\n",
      "[Training] Epoch: 34 [=>             ] 11.1% Loss: 0.0565, Epoch 34, Batch 13, CE_loss: 0.03439415618777275, Dice_loss: 0.0031710462644696236, Consistency_loss: 0.0004706204927060753\n",
      "[Training] Epoch: 34 [=>             ] 11.9% Loss: 0.0563, Epoch 34, Batch 14, CE_loss: 0.048080287873744965, Dice_loss: 0.005328083410859108, Consistency_loss: 0.00036068970803171396\n",
      "[Training] Epoch: 34 [=>             ] 12.7% Loss: 0.0558, Epoch 34, Batch 15, CE_loss: 0.04421704262495041, Dice_loss: 0.004575643222779036, Consistency_loss: 0.00019469224207568914\n",
      "[Training] Epoch: 34 [==>            ] 13.5% Loss: 0.0556, Epoch 34, Batch 16, CE_loss: 0.045768097043037415, Dice_loss: 0.004944710526615381, Consistency_loss: 0.00021568580996245146\n",
      "[Training] Epoch: 34 [==>            ] 14.3% Loss: 0.0569, Epoch 34, Batch 17, CE_loss: 0.07189953327178955, Dice_loss: 0.007452205289155245, Consistency_loss: 4.88253244839143e-05\n",
      "[Training] Epoch: 34 [==>            ] 15.1% Loss: 0.0563, Epoch 34, Batch 18, CE_loss: 0.04095182567834854, Dice_loss: 0.004433146212249994, Consistency_loss: 8.45930990180932e-05\n",
      "[Training] Epoch: 34 [==>            ] 15.9% Loss: 0.0567, Epoch 34, Batch 19, CE_loss: 0.05778118595480919, Dice_loss: 0.0064896587282419205, Consistency_loss: 0.0002963869774248451\n",
      "[Training] Epoch: 34 [==>            ] 16.7% Loss: 0.0567, Epoch 34, Batch 20, CE_loss: 0.05150797218084335, Dice_loss: 0.005447253584861755, Consistency_loss: 0.00022999638167675585\n",
      "[Training] Epoch: 34 [==>            ] 17.5% Loss: 0.0569, Epoch 34, Batch 21, CE_loss: 0.05406149849295616, Dice_loss: 0.006013365462422371, Consistency_loss: 3.5749351809499785e-05\n",
      "[Training] Epoch: 34 [==>            ] 18.3% Loss: 0.0576, Epoch 34, Batch 22, CE_loss: 0.06675165891647339, Dice_loss: 0.007400282192975283, Consistency_loss: 4.350846211309545e-05\n",
      "[Training] Epoch: 34 [==>            ] 19.0% Loss: 0.0575, Epoch 34, Batch 23, CE_loss: 0.04903688281774521, Dice_loss: 0.0049376338720321655, Consistency_loss: 0.0003045749035663903\n",
      "[Training] Epoch: 34 [==>            ] 19.8% Loss: 0.0570, Epoch 34, Batch 24, CE_loss: 0.039829544723033905, Dice_loss: 0.004179275128990412, Consistency_loss: 0.0001691122743068263\n",
      "[Training] Epoch: 34 [===>           ] 20.6% Loss: 0.0574, Epoch 34, Batch 25, CE_loss: 0.06112590432167053, Dice_loss: 0.006689845118671656, Consistency_loss: 0.00024574421695433557\n",
      "[Training] Epoch: 34 [===>           ] 21.4% Loss: 0.0572, Epoch 34, Batch 26, CE_loss: 0.04728512093424797, Dice_loss: 0.005075092893093824, Consistency_loss: 6.873364327475429e-05\n",
      "[Training] Epoch: 34 [===>           ] 22.2% Loss: 0.0568, Epoch 34, Batch 27, CE_loss: 0.042005863040685654, Dice_loss: 0.004262834787368774, Consistency_loss: 0.00039175088750198483\n",
      "[Training] Epoch: 34 [===>           ] 23.0% Loss: 0.0570, Epoch 34, Batch 28, CE_loss: 0.05590661242604256, Dice_loss: 0.006220297887921333, Consistency_loss: 0.00022376752167474478\n",
      "[Training] Epoch: 34 [===>           ] 23.8% Loss: 0.0566, Epoch 34, Batch 29, CE_loss: 0.04025398567318916, Dice_loss: 0.004248547833412886, Consistency_loss: 0.00026394883752800524\n",
      "[Training] Epoch: 34 [===>           ] 24.6% Loss: 0.0562, Epoch 34, Batch 30, CE_loss: 0.0409475639462471, Dice_loss: 0.0037038447335362434, Consistency_loss: 0.00010168466542381793\n",
      "[Training] Epoch: 34 [===>           ] 25.4% Loss: 0.0556, Epoch 34, Batch 31, CE_loss: 0.03216300532221794, Dice_loss: 0.0027937397826462984, Consistency_loss: 0.00020578828116413206\n",
      "[Training] Epoch: 34 [===>           ] 26.2% Loss: 0.0554, Epoch 34, Batch 32, CE_loss: 0.04643712192773819, Dice_loss: 0.0049302177503705025, Consistency_loss: 0.00022265512961894274\n",
      "[Training] Epoch: 34 [====>          ] 27.0% Loss: 0.0558, Epoch 34, Batch 33, CE_loss: 0.05985856428742409, Dice_loss: 0.006530660670250654, Consistency_loss: 5.2780542318942025e-05\n",
      "[Training] Epoch: 34 [====>          ] 27.8% Loss: 0.0556, Epoch 34, Batch 34, CE_loss: 0.0452885739505291, Dice_loss: 0.00489330617710948, Consistency_loss: 4.07447041652631e-05\n",
      "[Training] Epoch: 34 [====>          ] 28.6% Loss: 0.0562, Epoch 34, Batch 35, CE_loss: 0.06760959327220917, Dice_loss: 0.007686750963330269, Consistency_loss: 0.00028719566762447357\n",
      "[Training] Epoch: 34 [====>          ] 29.4% Loss: 0.0561, Epoch 34, Batch 36, CE_loss: 0.04740400239825249, Dice_loss: 0.005153377540409565, Consistency_loss: 0.00027398447855375707\n",
      "[Training] Epoch: 34 [====>          ] 30.2% Loss: 0.0556, Epoch 34, Batch 37, CE_loss: 0.033429935574531555, Dice_loss: 0.0033660384360700846, Consistency_loss: 6.896655395394191e-05\n",
      "[Training] Epoch: 34 [====>          ] 31.0% Loss: 0.0555, Epoch 34, Batch 38, CE_loss: 0.04850291833281517, Dice_loss: 0.005280603654682636, Consistency_loss: 0.0005632154061459005\n",
      "[Training] Epoch: 34 [====>          ] 31.7% Loss: 0.0554, Epoch 34, Batch 39, CE_loss: 0.04369860514998436, Dice_loss: 0.004688698332756758, Consistency_loss: 0.0006329018506221473\n",
      "[Training] Epoch: 34 [====>          ] 32.5% Loss: 0.0552, Epoch 34, Batch 40, CE_loss: 0.042306844145059586, Dice_loss: 0.004477036185562611, Consistency_loss: 4.767498103319667e-05\n",
      "[Training] Epoch: 34 [=====>         ] 33.3% Loss: 0.0549, Epoch 34, Batch 41, CE_loss: 0.039635833352804184, Dice_loss: 0.0039298925548791885, Consistency_loss: 0.0002426979917800054\n",
      "[Training] Epoch: 34 [=====>         ] 34.1% Loss: 0.0555, Epoch 34, Batch 42, CE_loss: 0.07147113978862762, Dice_loss: 0.00735298590734601, Consistency_loss: 0.00013530996511690319\n",
      "[Training] Epoch: 34 [=====>         ] 34.9% Loss: 0.0556, Epoch 34, Batch 43, CE_loss: 0.0548844113945961, Dice_loss: 0.005891570821404457, Consistency_loss: 0.00011827830894617364\n",
      "[Training] Epoch: 34 [=====>         ] 35.7% Loss: 0.0561, Epoch 34, Batch 44, CE_loss: 0.06925536692142487, Dice_loss: 0.007759416475892067, Consistency_loss: 0.0005318030598573387\n",
      "[Training] Epoch: 34 [=====>         ] 36.5% Loss: 0.0566, Epoch 34, Batch 45, CE_loss: 0.07259266078472137, Dice_loss: 0.008356570266187191, Consistency_loss: 0.0002858567168004811\n",
      "[Training] Epoch: 34 [=====>         ] 37.3% Loss: 0.0565, Epoch 34, Batch 46, CE_loss: 0.046226222068071365, Dice_loss: 0.004887606482952833, Consistency_loss: 0.0001111551100621\n",
      "[Training] Epoch: 34 [=====>         ] 38.1% Loss: 0.0563, Epoch 34, Batch 47, CE_loss: 0.04124632850289345, Dice_loss: 0.004388563334941864, Consistency_loss: 5.066253288532607e-05\n",
      "[Training] Epoch: 34 [=====>         ] 38.9% Loss: 0.0562, Epoch 34, Batch 48, CE_loss: 0.04909118637442589, Dice_loss: 0.005372822284698486, Consistency_loss: 0.0005049533792771399\n",
      "[Training] Epoch: 34 [=====>         ] 39.7% Loss: 0.0559, Epoch 34, Batch 49, CE_loss: 0.03406408056616783, Dice_loss: 0.0034339295234531164, Consistency_loss: 0.00010452929564053193\n",
      "[Training] Epoch: 34 [======>        ] 40.5% Loss: 0.0558, Epoch 34, Batch 50, CE_loss: 0.04826536402106285, Dice_loss: 0.005241036415100098, Consistency_loss: 0.0005362831871025264\n",
      "[Training] Epoch: 34 [======>        ] 41.3% Loss: 0.0556, Epoch 34, Batch 51, CE_loss: 0.04145660251379013, Dice_loss: 0.004127606749534607, Consistency_loss: 0.0005075256340205669\n",
      "[Training] Epoch: 34 [======>        ] 42.1% Loss: 0.0558, Epoch 34, Batch 52, CE_loss: 0.05868620425462723, Dice_loss: 0.00635782815515995, Consistency_loss: 0.00010529327119002119\n",
      "[Training] Epoch: 34 [======>        ] 42.9% Loss: 0.0556, Epoch 34, Batch 53, CE_loss: 0.03809797391295433, Dice_loss: 0.0036468342877924442, Consistency_loss: 0.00014814022870268673\n",
      "[Training] Epoch: 34 [======>        ] 43.7% Loss: 0.0555, Epoch 34, Batch 54, CE_loss: 0.0449632965028286, Dice_loss: 0.00455254502594471, Consistency_loss: 0.00019540023640729487\n",
      "[Training] Epoch: 34 [======>        ] 44.4% Loss: 0.0556, Epoch 34, Batch 55, CE_loss: 0.05872679501771927, Dice_loss: 0.006439984310418367, Consistency_loss: 0.00038128363667055964\n",
      "[Training] Epoch: 34 [======>        ] 45.2% Loss: 0.0555, Epoch 34, Batch 56, CE_loss: 0.042932167649269104, Dice_loss: 0.004613051190972328, Consistency_loss: 5.4991436627460644e-05\n",
      "[Training] Epoch: 34 [======>        ] 46.0% Loss: 0.0555, Epoch 34, Batch 57, CE_loss: 0.04834478721022606, Dice_loss: 0.004893873818218708, Consistency_loss: 0.00027448232867754996\n",
      "[Training] Epoch: 34 [=======>       ] 46.8% Loss: 0.0557, Epoch 34, Batch 58, CE_loss: 0.06372389197349548, Dice_loss: 0.006854385603219271, Consistency_loss: 0.00030369337764568627\n",
      "[Training] Epoch: 34 [=======>       ] 47.6% Loss: 0.0559, Epoch 34, Batch 59, CE_loss: 0.05820035561919212, Dice_loss: 0.00645752577111125, Consistency_loss: 0.0003462148306425661\n",
      "[Training] Epoch: 34 [=======>       ] 48.4% Loss: 0.0557, Epoch 34, Batch 60, CE_loss: 0.040297526866197586, Dice_loss: 0.00424126535654068, Consistency_loss: 0.00038338350714184344\n",
      "[Training] Epoch: 34 [=======>       ] 49.2% Loss: 0.0557, Epoch 34, Batch 61, CE_loss: 0.04789172485470772, Dice_loss: 0.005337189417332411, Consistency_loss: 0.00028695070068351924\n",
      "[Training] Epoch: 34 [=======>       ] 50.0% Loss: 0.0556, Epoch 34, Batch 62, CE_loss: 0.04790087789297104, Dice_loss: 0.005292244255542755, Consistency_loss: 0.0006172109278850257\n",
      "[Training] Epoch: 34 [=======>       ] 50.8% Loss: 0.0556, Epoch 34, Batch 63, CE_loss: 0.04966801032423973, Dice_loss: 0.0054528373293578625, Consistency_loss: 0.00033964961767196655\n",
      "[Training] Epoch: 34 [=======>       ] 51.6% Loss: 0.0555, Epoch 34, Batch 64, CE_loss: 0.04458034411072731, Dice_loss: 0.00463743694126606, Consistency_loss: 0.0004923628875985742\n",
      "[Training] Epoch: 34 [=======>       ] 52.4% Loss: 0.0556, Epoch 34, Batch 65, CE_loss: 0.0531441867351532, Dice_loss: 0.005733052268624306, Consistency_loss: 0.0004981877864338458\n",
      "[Training] Epoch: 34 [=======>       ] 53.2% Loss: 0.0556, Epoch 34, Batch 66, CE_loss: 0.0474986769258976, Dice_loss: 0.00513795018196106, Consistency_loss: 0.00014735506556462497\n",
      "[Training] Epoch: 34 [========>      ] 54.0% Loss: 0.0557, Epoch 34, Batch 67, CE_loss: 0.05848764255642891, Dice_loss: 0.006547116208821535, Consistency_loss: 4.749820436700247e-05\n",
      "[Training] Epoch: 34 [========>      ] 54.8% Loss: 0.0557, Epoch 34, Batch 68, CE_loss: 0.0502803809940815, Dice_loss: 0.005582611542195082, Consistency_loss: 0.00019181601237505674\n",
      "[Training] Epoch: 34 [========>      ] 55.6% Loss: 0.0556, Epoch 34, Batch 69, CE_loss: 0.041055578738451004, Dice_loss: 0.004259643144905567, Consistency_loss: 0.00021490395010914654\n",
      "[Training] Epoch: 34 [========>      ] 56.3% Loss: 0.0559, Epoch 34, Batch 70, CE_loss: 0.07194286584854126, Dice_loss: 0.008062023669481277, Consistency_loss: 0.000665424217004329\n",
      "[Training] Epoch: 34 [========>      ] 57.1% Loss: 0.0559, Epoch 34, Batch 71, CE_loss: 0.051825329661369324, Dice_loss: 0.00572460750117898, Consistency_loss: 5.910507752560079e-05\n",
      "[Training] Epoch: 34 [========>      ] 57.9% Loss: 0.0557, Epoch 34, Batch 72, CE_loss: 0.0346212312579155, Dice_loss: 0.0035305784549564123, Consistency_loss: 0.0004325850459281355\n",
      "[Training] Epoch: 34 [========>      ] 58.7% Loss: 0.0558, Epoch 34, Batch 73, CE_loss: 0.05583048611879349, Dice_loss: 0.006353737786412239, Consistency_loss: 0.00041484792018309236\n",
      "[Training] Epoch: 34 [========>      ] 59.5% Loss: 0.0556, Epoch 34, Batch 74, CE_loss: 0.03564225882291794, Dice_loss: 0.0036684575024992228, Consistency_loss: 0.000471432285849005\n",
      "[Training] Epoch: 34 [=========>     ] 60.3% Loss: 0.0553, Epoch 34, Batch 75, CE_loss: 0.03279324993491173, Dice_loss: 0.0031046257354319096, Consistency_loss: 0.0005970338243059814\n",
      "[Training] Epoch: 34 [=========>     ] 61.1% Loss: 0.0553, Epoch 34, Batch 76, CE_loss: 0.04900089651346207, Dice_loss: 0.005440919194370508, Consistency_loss: 0.0004627619928214699\n",
      "[Training] Epoch: 34 [=========>     ] 61.9% Loss: 0.0555, Epoch 34, Batch 77, CE_loss: 0.06461721658706665, Dice_loss: 0.007149253971874714, Consistency_loss: 0.00045879182289354503\n",
      "[Training] Epoch: 34 [=========>     ] 62.7% Loss: 0.0555, Epoch 34, Batch 78, CE_loss: 0.04743991047143936, Dice_loss: 0.0052567943930625916, Consistency_loss: 0.0002542583679314703\n",
      "[Training] Epoch: 34 [=========>     ] 63.5% Loss: 0.0554, Epoch 34, Batch 79, CE_loss: 0.043055467307567596, Dice_loss: 0.004660248756408691, Consistency_loss: 5.235911157797091e-05\n",
      "[Training] Epoch: 34 [=========>     ] 64.3% Loss: 0.0552, Epoch 34, Batch 80, CE_loss: 0.03659839555621147, Dice_loss: 0.003652422223240137, Consistency_loss: 0.0003673205792438239\n",
      "[Training] Epoch: 34 [=========>     ] 65.1% Loss: 0.0552, Epoch 34, Batch 81, CE_loss: 0.0498657301068306, Dice_loss: 0.004799764137715101, Consistency_loss: 0.0002598641440272331\n",
      "[Training] Epoch: 34 [=========>     ] 65.9% Loss: 0.0553, Epoch 34, Batch 82, CE_loss: 0.05767848342657089, Dice_loss: 0.006351059768348932, Consistency_loss: 0.00016443569620605558\n",
      "[Training] Epoch: 34 [==========>    ] 66.7% Loss: 0.0553, Epoch 34, Batch 83, CE_loss: 0.04795875772833824, Dice_loss: 0.005321699660271406, Consistency_loss: 0.00017623584426473826\n",
      "[Training] Epoch: 34 [==========>    ] 67.5% Loss: 0.0553, Epoch 34, Batch 84, CE_loss: 0.04983768239617348, Dice_loss: 0.00527292350307107, Consistency_loss: 0.00017927911540027708\n",
      "[Training] Epoch: 34 [==========>    ] 68.3% Loss: 0.0553, Epoch 34, Batch 85, CE_loss: 0.05151009559631348, Dice_loss: 0.0054757120087742805, Consistency_loss: 0.000607765861786902\n",
      "[Training] Epoch: 34 [==========>    ] 69.0% Loss: 0.0552, Epoch 34, Batch 86, CE_loss: 0.04018315672874451, Dice_loss: 0.0042652846314013, Consistency_loss: 0.0003844772872980684\n",
      "[Training] Epoch: 34 [==========>    ] 69.8% Loss: 0.0552, Epoch 34, Batch 87, CE_loss: 0.04923084378242493, Dice_loss: 0.005506244488060474, Consistency_loss: 0.00039476805250160396\n",
      "[Training] Epoch: 34 [==========>    ] 70.6% Loss: 0.0552, Epoch 34, Batch 88, CE_loss: 0.04525129497051239, Dice_loss: 0.005009687040001154, Consistency_loss: 0.0002371573355048895\n",
      "[Training] Epoch: 34 [==========>    ] 71.4% Loss: 0.0553, Epoch 34, Batch 89, CE_loss: 0.06228364631533623, Dice_loss: 0.00663682259619236, Consistency_loss: 0.0004399367608129978\n",
      "[Training] Epoch: 34 [==========>    ] 72.2% Loss: 0.0552, Epoch 34, Batch 90, CE_loss: 0.04175104200839996, Dice_loss: 0.004516134038567543, Consistency_loss: 2.8749389457516372e-05\n",
      "[Training] Epoch: 34 [==========>    ] 73.0% Loss: 0.0555, Epoch 34, Batch 91, CE_loss: 0.07315593957901001, Dice_loss: 0.007242957130074501, Consistency_loss: 0.0005255157011561096\n",
      "[Training] Epoch: 34 [===========>   ] 73.8% Loss: 0.0556, Epoch 34, Batch 92, CE_loss: 0.055869534611701965, Dice_loss: 0.005904190707951784, Consistency_loss: 0.00042055227095261216\n",
      "[Training] Epoch: 34 [===========>   ] 74.6% Loss: 0.0554, Epoch 34, Batch 93, CE_loss: 0.034812282770872116, Dice_loss: 0.0035737173166126013, Consistency_loss: 0.0004857399908360094\n",
      "[Training] Epoch: 34 [===========>   ] 75.4% Loss: 0.0554, Epoch 34, Batch 94, CE_loss: 0.047021038830280304, Dice_loss: 0.00501623610034585, Consistency_loss: 6.278722867136821e-05\n",
      "[Training] Epoch: 34 [===========>   ] 76.2% Loss: 0.0553, Epoch 34, Batch 95, CE_loss: 0.04268060252070427, Dice_loss: 0.004366565030068159, Consistency_loss: 0.00021955929696559906\n",
      "[Training] Epoch: 34 [===========>   ] 77.0% Loss: 0.0553, Epoch 34, Batch 96, CE_loss: 0.04863014444708824, Dice_loss: 0.005042852833867073, Consistency_loss: 0.00022519745107274503\n",
      "[Training] Epoch: 34 [===========>   ] 77.8% Loss: 0.0552, Epoch 34, Batch 97, CE_loss: 0.04757028445601463, Dice_loss: 0.005244697909802198, Consistency_loss: 8.579219138482586e-05\n",
      "[Training] Epoch: 34 [===========>   ] 78.6% Loss: 0.0558, Epoch 34, Batch 98, CE_loss: 0.10207142680883408, Dice_loss: 0.010602754540741444, Consistency_loss: 0.0002502234128769487\n",
      "[Training] Epoch: 34 [===========>   ] 79.4% Loss: 0.0559, Epoch 34, Batch 99, CE_loss: 0.05512369051575661, Dice_loss: 0.00626453198492527, Consistency_loss: 0.00023618980776518583\n",
      "[Training] Epoch: 34 [============>  ] 80.2% Loss: 0.0557, Epoch 34, Batch 100, CE_loss: 0.036144401878118515, Dice_loss: 0.00372085883282125, Consistency_loss: 0.0004038251063320786\n",
      "[Training] Epoch: 34 [============>  ] 81.0% Loss: 0.0556, Epoch 34, Batch 101, CE_loss: 0.041225798428058624, Dice_loss: 0.0041436199098825455, Consistency_loss: 0.0003921711759176105\n",
      "[Training] Epoch: 34 [============>  ] 81.7% Loss: 0.0555, Epoch 34, Batch 102, CE_loss: 0.03595418855547905, Dice_loss: 0.0035277577117085457, Consistency_loss: 0.00048411646275781095\n",
      "[Training] Epoch: 34 [============>  ] 82.5% Loss: 0.0553, Epoch 34, Batch 103, CE_loss: 0.03517891466617584, Dice_loss: 0.00325791840441525, Consistency_loss: 0.000169313934748061\n",
      "[Training] Epoch: 34 [============>  ] 83.3% Loss: 0.0554, Epoch 34, Batch 104, CE_loss: 0.056301239877939224, Dice_loss: 0.005847081542015076, Consistency_loss: 4.6607270633103326e-05\n",
      "[Training] Epoch: 34 [============>  ] 84.1% Loss: 0.0556, Epoch 34, Batch 105, CE_loss: 0.07407013326883316, Dice_loss: 0.008616570383310318, Consistency_loss: 0.000233457496506162\n",
      "[Training] Epoch: 34 [============>  ] 84.9% Loss: 0.0558, Epoch 34, Batch 106, CE_loss: 0.06465264409780502, Dice_loss: 0.0072491527535021305, Consistency_loss: 0.00025416078278794885\n",
      "[Training] Epoch: 34 [============>  ] 85.7% Loss: 0.0557, Epoch 34, Batch 107, CE_loss: 0.03802178427577019, Dice_loss: 0.0038743929471820593, Consistency_loss: 0.000526642834302038\n",
      "[Training] Epoch: 34 [============>  ] 86.5% Loss: 0.0556, Epoch 34, Batch 108, CE_loss: 0.04385991767048836, Dice_loss: 0.004681590478867292, Consistency_loss: 0.0002887154114432633\n",
      "[Training] Epoch: 34 [=============> ] 87.3% Loss: 0.0557, Epoch 34, Batch 109, CE_loss: 0.05831045284867287, Dice_loss: 0.0066871945746243, Consistency_loss: 0.0002464074350427836\n",
      "[Training] Epoch: 34 [=============> ] 88.1% Loss: 0.0555, Epoch 34, Batch 110, CE_loss: 0.03002927638590336, Dice_loss: 0.0029326649382710457, Consistency_loss: 0.0003232336603105068\n",
      "[Training] Epoch: 34 [=============> ] 88.9% Loss: 0.0554, Epoch 34, Batch 111, CE_loss: 0.04111760854721069, Dice_loss: 0.004486656282097101, Consistency_loss: 5.9675145166693255e-05\n",
      "[Training] Epoch: 34 [=============> ] 89.7% Loss: 0.0554, Epoch 34, Batch 112, CE_loss: 0.04838091507554054, Dice_loss: 0.005207432899624109, Consistency_loss: 0.00043049469240941107\n",
      "[Training] Epoch: 34 [=============> ] 90.5% Loss: 0.0554, Epoch 34, Batch 113, CE_loss: 0.05470218509435654, Dice_loss: 0.0060201468877494335, Consistency_loss: 0.00016372934624087065\n",
      "[Training] Epoch: 34 [=============> ] 91.3% Loss: 0.0554, Epoch 34, Batch 114, CE_loss: 0.04987677186727524, Dice_loss: 0.00513373501598835, Consistency_loss: 4.438316318555735e-05\n",
      "[Training] Epoch: 34 [=============> ] 92.1% Loss: 0.0554, Epoch 34, Batch 115, CE_loss: 0.041753269731998444, Dice_loss: 0.0042953030206263065, Consistency_loss: 0.00029837479814887047\n",
      "[Training] Epoch: 34 [=============> ] 92.9% Loss: 0.0553, Epoch 34, Batch 116, CE_loss: 0.047745995223522186, Dice_loss: 0.005138374865055084, Consistency_loss: 0.00043173940503038466\n",
      "[Training] Epoch: 34 [==============>] 93.7% Loss: 0.0553, Epoch 34, Batch 117, CE_loss: 0.041412170976400375, Dice_loss: 0.0041073695756495, Consistency_loss: 0.0003026345802936703\n",
      "[Training] Epoch: 34 [==============>] 94.4% Loss: 0.0553, Epoch 34, Batch 118, CE_loss: 0.049369484186172485, Dice_loss: 0.00524354912340641, Consistency_loss: 0.00021907441259827465\n",
      "[Training] Epoch: 34 [==============>] 95.2% Loss: 0.0553, Epoch 34, Batch 119, CE_loss: 0.05301209166646004, Dice_loss: 0.0054671019315719604, Consistency_loss: 0.00021246695541776717\n",
      "[Training] Epoch: 34 [==============>] 96.0% Loss: 0.0553, Epoch 34, Batch 120, CE_loss: 0.054893769323825836, Dice_loss: 0.005912344437092543, Consistency_loss: 0.00032089356682263315\n",
      "[Training] Epoch: 34 [==============>] 96.8% Loss: 0.0552, Epoch 34, Batch 121, CE_loss: 0.036622725427150726, Dice_loss: 0.003748025046661496, Consistency_loss: 0.00023902776592876762\n",
      "[Training] Epoch: 34 [==============>] 97.6% Loss: 0.0552, Epoch 34, Batch 122, CE_loss: 0.049863964319229126, Dice_loss: 0.005467817187309265, Consistency_loss: 0.0002724396763369441\n",
      "[Training] Epoch: 34 [==============>] 98.4% Loss: 0.0552, Epoch 34, Batch 123, CE_loss: 0.05274538695812225, Dice_loss: 0.005925326142460108, Consistency_loss: 7.100390939740464e-05\n",
      "[Training] Epoch: 34 [==============>] 99.2% Loss: 0.0552, Epoch 34, Batch 124, CE_loss: 0.04056382179260254, Dice_loss: 0.004315482452511787, Consistency_loss: 0.0001777738652890548\n",
      "[Training] Epoch: 34 [DONE]                                 \n",
      "Epoch 34, Batch 125, CE_loss: 0.08007047325372696, Dice_loss: 0.007621903903782368, Consistency_loss: 0.00047572352923452854\n",
      "[Validation] Epoch: 34 [DONE]                                 \n",
      "[Epoch: 34, TrainLoss: 0.0554, TrainDice: 0.0053, ValLoss: 0.1382                                            \n",
      "Number of batches:  126\n",
      "[Training] Epoch: 35 [>              ] 0.8% Loss: 0.0609, Epoch 35, Batch 0, CE_loss: 0.054884787648916245, Dice_loss: 0.005811032839119434, Consistency_loss: 0.0002248632226837799\n",
      "[Training] Epoch: 35 [>              ] 1.6% Loss: 0.0525, Epoch 35, Batch 1, CE_loss: 0.03972003236413002, Dice_loss: 0.0041823238134384155, Consistency_loss: 0.00019564712420105934\n",
      "[Training] Epoch: 35 [>              ] 2.4% Loss: 0.0567, Epoch 35, Batch 2, CE_loss: 0.05856119096279144, Dice_loss: 0.006314465776085854, Consistency_loss: 0.0003356362576596439\n",
      "[Training] Epoch: 35 [>              ] 3.2% Loss: 0.0547, Epoch 35, Batch 3, CE_loss: 0.043346576392650604, Dice_loss: 0.004735082387924194, Consistency_loss: 0.0003803876752499491\n",
      "[Training] Epoch: 35 [>              ] 4.0% Loss: 0.0508, Epoch 35, Batch 4, CE_loss: 0.03182262182235718, Dice_loss: 0.0032593444921076298, Consistency_loss: 0.0003236747288610786\n",
      "[Training] Epoch: 35 [>              ] 4.8% Loss: 0.0505, Epoch 35, Batch 5, CE_loss: 0.044060785323381424, Dice_loss: 0.004771015141159296, Consistency_loss: 0.00017712223052512854\n",
      "[Training] Epoch: 35 [>              ] 5.6% Loss: 0.0541, Epoch 35, Batch 6, CE_loss: 0.06888549029827118, Dice_loss: 0.006865878589451313, Consistency_loss: 0.00015050933870952576\n",
      "[Training] Epoch: 35 [>              ] 6.3% Loss: 0.0539, Epoch 35, Batch 7, CE_loss: 0.046841878443956375, Dice_loss: 0.004942761734127998, Consistency_loss: 0.00022678561799693853\n",
      "[Training] Epoch: 35 [=>             ] 7.1% Loss: 0.0543, Epoch 35, Batch 8, CE_loss: 0.051965516060590744, Dice_loss: 0.005929068196564913, Consistency_loss: 0.00015581662592012435\n",
      "[Training] Epoch: 35 [=>             ] 7.9% Loss: 0.0548, Epoch 35, Batch 9, CE_loss: 0.05278044566512108, Dice_loss: 0.005661481991410255, Consistency_loss: 0.00015156429435592145\n",
      "[Training] Epoch: 35 [=>             ] 8.7% Loss: 0.0543, Epoch 35, Batch 10, CE_loss: 0.044454675167798996, Dice_loss: 0.004851637873798609, Consistency_loss: 0.00042989649227820337\n",
      "[Training] Epoch: 35 [=>             ] 9.5% Loss: 0.0560, Epoch 35, Batch 11, CE_loss: 0.06721480935811996, Dice_loss: 0.007251924369484186, Consistency_loss: 0.0005276852170936763\n",
      "[Training] Epoch: 35 [=>             ] 10.3% Loss: 0.0560, Epoch 35, Batch 12, CE_loss: 0.04944446310400963, Dice_loss: 0.00542668579146266, Consistency_loss: 0.0003294547786936164\n",
      "[Training] Epoch: 35 [=>             ] 11.1% Loss: 0.0558, Epoch 35, Batch 13, CE_loss: 0.04756676033139229, Dice_loss: 0.005251671653240919, Consistency_loss: 0.0003070900565944612\n",
      "[Training] Epoch: 35 [=>             ] 11.9% Loss: 0.0551, Epoch 35, Batch 14, CE_loss: 0.04188825935125351, Dice_loss: 0.004373346455395222, Consistency_loss: 0.00025835243286564946\n",
      "[Training] Epoch: 35 [=>             ] 12.7% Loss: 0.0542, Epoch 35, Batch 15, CE_loss: 0.03659197315573692, Dice_loss: 0.003275911556556821, Consistency_loss: 0.00027240568306297064\n",
      "[Training] Epoch: 35 [==>            ] 13.5% Loss: 0.0544, Epoch 35, Batch 16, CE_loss: 0.05161804333329201, Dice_loss: 0.005857211537659168, Consistency_loss: 0.0002896522346418351\n",
      "[Training] Epoch: 35 [==>            ] 14.3% Loss: 0.0542, Epoch 35, Batch 17, CE_loss: 0.045569390058517456, Dice_loss: 0.004919770639389753, Consistency_loss: 0.000531390483956784\n",
      "[Training] Epoch: 35 [==>            ] 15.1% Loss: 0.0537, Epoch 35, Batch 18, CE_loss: 0.04055701196193695, Dice_loss: 0.004200446885079145, Consistency_loss: 0.00023707517539151013\n",
      "[Training] Epoch: 35 [==>            ] 15.9% Loss: 0.0542, Epoch 35, Batch 19, CE_loss: 0.05576160550117493, Dice_loss: 0.006030361633747816, Consistency_loss: 6.904249312356114e-05\n",
      "[Training] Epoch: 35 [==>            ] 16.7% Loss: 0.0543, Epoch 35, Batch 20, CE_loss: 0.050860460847616196, Dice_loss: 0.005532681941986084, Consistency_loss: 5.549621346290223e-05\n",
      "[Training] Epoch: 35 [==>            ] 17.5% Loss: 0.0553, Epoch 35, Batch 21, CE_loss: 0.06916292011737823, Dice_loss: 0.007475392892956734, Consistency_loss: 0.00023243237228598446\n",
      "[Training] Epoch: 35 [==>            ] 18.3% Loss: 0.0544, Epoch 35, Batch 22, CE_loss: 0.03182526305317879, Dice_loss: 0.003193205688148737, Consistency_loss: 0.00025743708829395473\n",
      "[Training] Epoch: 35 [==>            ] 19.0% Loss: 0.0542, Epoch 35, Batch 23, CE_loss: 0.04333200678229332, Dice_loss: 0.004723611753433943, Consistency_loss: 0.00019524063100107014\n",
      "[Training] Epoch: 35 [==>            ] 19.8% Loss: 0.0541, Epoch 35, Batch 24, CE_loss: 0.046418797224760056, Dice_loss: 0.005080122034996748, Consistency_loss: 0.0002485359145794064\n",
      "[Training] Epoch: 35 [===>           ] 20.6% Loss: 0.0535, Epoch 35, Batch 25, CE_loss: 0.03646062687039375, Dice_loss: 0.0034290836192667484, Consistency_loss: 0.00022520129277836531\n",
      "[Training] Epoch: 35 [===>           ] 21.4% Loss: 0.0535, Epoch 35, Batch 26, CE_loss: 0.046224940568208694, Dice_loss: 0.004959507379680872, Consistency_loss: 0.00037008029175922275\n",
      "[Training] Epoch: 35 [===>           ] 22.2% Loss: 0.0528, Epoch 35, Batch 27, CE_loss: 0.03234487399458885, Dice_loss: 0.0032877714838832617, Consistency_loss: 0.000506343727465719\n",
      "[Training] Epoch: 35 [===>           ] 23.0% Loss: 0.0529, Epoch 35, Batch 28, CE_loss: 0.05032438412308693, Dice_loss: 0.005294788163155317, Consistency_loss: 6.089593443903141e-05\n",
      "[Training] Epoch: 35 [===>           ] 23.8% Loss: 0.0524, Epoch 35, Batch 29, CE_loss: 0.03406989201903343, Dice_loss: 0.003503322834149003, Consistency_loss: 0.0003315932990517467\n",
      "[Training] Epoch: 35 [===>           ] 24.6% Loss: 0.0529, Epoch 35, Batch 30, CE_loss: 0.06067480519413948, Dice_loss: 0.006904792971909046, Consistency_loss: 0.00018518319120630622\n",
      "[Training] Epoch: 35 [===>           ] 25.4% Loss: 0.0534, Epoch 35, Batch 31, CE_loss: 0.06113283336162567, Dice_loss: 0.006467369385063648, Consistency_loss: 0.000210208585485816\n",
      "[Training] Epoch: 35 [===>           ] 26.2% Loss: 0.0531, Epoch 35, Batch 32, CE_loss: 0.038387641310691833, Dice_loss: 0.0035679370630532503, Consistency_loss: 0.00020539364777505398\n",
      "[Training] Epoch: 35 [====>          ] 27.0% Loss: 0.0536, Epoch 35, Batch 33, CE_loss: 0.06360027194023132, Dice_loss: 0.007169602904468775, Consistency_loss: 0.0002500767877791077\n",
      "[Training] Epoch: 35 [====>          ] 27.8% Loss: 0.0537, Epoch 35, Batch 34, CE_loss: 0.053144671022892, Dice_loss: 0.005835463292896748, Consistency_loss: 0.00023078305821400136\n",
      "[Training] Epoch: 35 [====>          ] 28.6% Loss: 0.0534, Epoch 35, Batch 35, CE_loss: 0.0388566292822361, Dice_loss: 0.004195274785161018, Consistency_loss: 5.793326999992132e-05\n",
      "[Training] Epoch: 35 [====>          ] 29.4% Loss: 0.0533, Epoch 35, Batch 36, CE_loss: 0.04216601699590683, Dice_loss: 0.004428407642990351, Consistency_loss: 0.00012877043627668172\n",
      "[Training] Epoch: 35 [====>          ] 30.2% Loss: 0.0529, Epoch 35, Batch 37, CE_loss: 0.03580544516444206, Dice_loss: 0.003683880204334855, Consistency_loss: 0.0001939090871019289\n",
      "[Training] Epoch: 35 [====>          ] 31.0% Loss: 0.0529, Epoch 35, Batch 38, CE_loss: 0.04804840311408043, Dice_loss: 0.00525674968957901, Consistency_loss: 4.01416327804327e-05\n",
      "[Training] Epoch: 35 [====>          ] 31.7% Loss: 0.0529, Epoch 35, Batch 39, CE_loss: 0.0451996885240078, Dice_loss: 0.004463173449039459, Consistency_loss: 0.0006834255182184279\n",
      "[Training] Epoch: 35 [====>          ] 32.5% Loss: 0.0535, Epoch 35, Batch 40, CE_loss: 0.07080105692148209, Dice_loss: 0.008159159682691097, Consistency_loss: 0.000521911948453635\n",
      "[Training] Epoch: 35 [=====>         ] 33.3% Loss: 0.0532, Epoch 35, Batch 41, CE_loss: 0.03842415288090706, Dice_loss: 0.004087507724761963, Consistency_loss: 4.872306817560457e-05\n",
      "[Training] Epoch: 35 [=====>         ] 34.1% Loss: 0.0531, Epoch 35, Batch 42, CE_loss: 0.04242146387696266, Dice_loss: 0.004605643451213837, Consistency_loss: 0.0007498614140786231\n",
      "[Training] Epoch: 35 [=====>         ] 34.9% Loss: 0.0541, Epoch 35, Batch 43, CE_loss: 0.0844738781452179, Dice_loss: 0.009684089571237564, Consistency_loss: 0.0001729887881083414\n",
      "[Training] Epoch: 35 [=====>         ] 35.7% Loss: 0.0543, Epoch 35, Batch 44, CE_loss: 0.05707940086722374, Dice_loss: 0.006433949340134859, Consistency_loss: 0.0005387413548305631\n",
      "[Training] Epoch: 35 [=====>         ] 36.5% Loss: 0.0544, Epoch 35, Batch 45, CE_loss: 0.054351747035980225, Dice_loss: 0.006107372231781483, Consistency_loss: 0.0003028973878826946\n",
      "[Training] Epoch: 35 [=====>         ] 37.3% Loss: 0.0542, Epoch 35, Batch 46, CE_loss: 0.03833293542265892, Dice_loss: 0.003974533174186945, Consistency_loss: 0.0002588606148492545\n",
      "[Training] Epoch: 35 [=====>         ] 38.1% Loss: 0.0539, Epoch 35, Batch 47, CE_loss: 0.0390174426138401, Dice_loss: 0.004152734763920307, Consistency_loss: 0.00043355292291380465\n",
      "[Training] Epoch: 35 [=====>         ] 38.9% Loss: 0.0542, Epoch 35, Batch 48, CE_loss: 0.058969248086214066, Dice_loss: 0.006233221385627985, Consistency_loss: 0.0006374124786816537\n",
      "[Training] Epoch: 35 [=====>         ] 39.7% Loss: 0.0544, Epoch 35, Batch 49, CE_loss: 0.058490343391895294, Dice_loss: 0.0066710966639220715, Consistency_loss: 0.0004113033355679363\n",
      "[Training] Epoch: 35 [======>        ] 40.5% Loss: 0.0543, Epoch 35, Batch 50, CE_loss: 0.04131058230996132, Dice_loss: 0.004470290616154671, Consistency_loss: 0.0004352492396719754\n",
      "[Training] Epoch: 35 [======>        ] 41.3% Loss: 0.0545, Epoch 35, Batch 51, CE_loss: 0.05880703032016754, Dice_loss: 0.006243239622563124, Consistency_loss: 0.00033162126783281565\n",
      "[Training] Epoch: 35 [======>        ] 42.1% Loss: 0.0547, Epoch 35, Batch 52, CE_loss: 0.061008863151073456, Dice_loss: 0.007038420531898737, Consistency_loss: 0.00012920935114379972\n",
      "[Training] Epoch: 35 [======>        ] 42.9% Loss: 0.0546, Epoch 35, Batch 53, CE_loss: 0.044269293546676636, Dice_loss: 0.004825294017791748, Consistency_loss: 0.00015913195966277272\n",
      "[Training] Epoch: 35 [======>        ] 43.7% Loss: 0.0544, Epoch 35, Batch 54, CE_loss: 0.03798779845237732, Dice_loss: 0.0038851082790642977, Consistency_loss: 0.00022404426999855787\n",
      "[Training] Epoch: 35 [======>        ] 44.4% Loss: 0.0549, Epoch 35, Batch 55, CE_loss: 0.075212761759758, Dice_loss: 0.00864508654922247, Consistency_loss: 0.0004225126176606864\n",
      "[Training] Epoch: 35 [======>        ] 45.2% Loss: 0.0552, Epoch 35, Batch 56, CE_loss: 0.06079860404133797, Dice_loss: 0.006789726205170155, Consistency_loss: 0.00038028566632419825\n",
      "[Training] Epoch: 35 [======>        ] 46.0% Loss: 0.0551, Epoch 35, Batch 57, CE_loss: 0.04560106620192528, Dice_loss: 0.004738573916256428, Consistency_loss: 0.0002951751521322876\n",
      "[Training] Epoch: 35 [=======>       ] 46.8% Loss: 0.0548, Epoch 35, Batch 58, CE_loss: 0.03367995098233223, Dice_loss: 0.003476026700809598, Consistency_loss: 0.00036035990342497826\n",
      "[Training] Epoch: 35 [=======>       ] 47.6% Loss: 0.0546, Epoch 35, Batch 59, CE_loss: 0.03753887489438057, Dice_loss: 0.0038810984697192907, Consistency_loss: 0.0002150109939975664\n",
      "[Training] Epoch: 35 [=======>       ] 48.4% Loss: 0.0546, Epoch 35, Batch 60, CE_loss: 0.05162077397108078, Dice_loss: 0.005595414433628321, Consistency_loss: 0.00038408077671192586\n",
      "[Training] Epoch: 35 [=======>       ] 49.2% Loss: 0.0546, Epoch 35, Batch 61, CE_loss: 0.0502605177462101, Dice_loss: 0.0054711210541427135, Consistency_loss: 0.0002765589451882988\n",
      "[Training] Epoch: 35 [=======>       ] 50.0% Loss: 0.0548, Epoch 35, Batch 62, CE_loss: 0.05996481329202652, Dice_loss: 0.006746327970176935, Consistency_loss: 6.84742844896391e-05\n",
      "[Training] Epoch: 35 [=======>       ] 50.8% Loss: 0.0550, Epoch 35, Batch 63, CE_loss: 0.058938588947057724, Dice_loss: 0.006654972210526466, Consistency_loss: 0.0006574496510438621\n",
      "[Training] Epoch: 35 [=======>       ] 51.6% Loss: 0.0553, Epoch 35, Batch 64, CE_loss: 0.0644102469086647, Dice_loss: 0.00735595403239131, Consistency_loss: 0.0005303400685079396\n",
      "[Training] Epoch: 35 [=======>       ] 52.4% Loss: 0.0550, Epoch 35, Batch 65, CE_loss: 0.03232509270310402, Dice_loss: 0.0032709003426134586, Consistency_loss: 0.0005501338164322078\n",
      "[Training] Epoch: 35 [=======>       ] 53.2% Loss: 0.0550, Epoch 35, Batch 66, CE_loss: 0.05064208060503006, Dice_loss: 0.005497509613633156, Consistency_loss: 0.00017248444783035666\n",
      "[Training] Epoch: 35 [========>      ] 54.0% Loss: 0.0551, Epoch 35, Batch 67, CE_loss: 0.05562414601445198, Dice_loss: 0.0061495364643633366, Consistency_loss: 4.925185930915177e-05\n",
      "[Training] Epoch: 35 [========>      ] 54.8% Loss: 0.0551, Epoch 35, Batch 68, CE_loss: 0.04817013069987297, Dice_loss: 0.005327131133526564, Consistency_loss: 0.00021455319074448198\n",
      "[Training] Epoch: 35 [========>      ] 55.6% Loss: 0.0549, Epoch 35, Batch 69, CE_loss: 0.0389251783490181, Dice_loss: 0.003911541774868965, Consistency_loss: 0.00018367148004472256\n",
      "[Training] Epoch: 35 [========>      ] 56.3% Loss: 0.0548, Epoch 35, Batch 70, CE_loss: 0.0407533273100853, Dice_loss: 0.004283103626221418, Consistency_loss: 0.000631373783107847\n",
      "[Training] Epoch: 35 [========>      ] 57.1% Loss: 0.0547, Epoch 35, Batch 71, CE_loss: 0.043719809502363205, Dice_loss: 0.004688470158725977, Consistency_loss: 0.0005841222009621561\n",
      "[Training] Epoch: 35 [========>      ] 57.9% Loss: 0.0547, Epoch 35, Batch 72, CE_loss: 0.05077872797846794, Dice_loss: 0.00566397188231349, Consistency_loss: 0.00043835933320224285\n",
      "[Training] Epoch: 35 [========>      ] 58.7% Loss: 0.0546, Epoch 35, Batch 73, CE_loss: 0.038782574236392975, Dice_loss: 0.004159113857895136, Consistency_loss: 0.00042311716242693365\n",
      "[Training] Epoch: 35 [========>      ] 59.5% Loss: 0.0546, Epoch 35, Batch 74, CE_loss: 0.0475127212703228, Dice_loss: 0.005104172509163618, Consistency_loss: 0.00046680355444550514\n",
      "[Training] Epoch: 35 [=========>     ] 60.3% Loss: 0.0547, Epoch 35, Batch 75, CE_loss: 0.05716129019856453, Dice_loss: 0.006464964244514704, Consistency_loss: 0.0006057959399186075\n",
      "[Training] Epoch: 35 [=========>     ] 61.1% Loss: 0.0548, Epoch 35, Batch 76, CE_loss: 0.05621158704161644, Dice_loss: 0.006431324873119593, Consistency_loss: 0.0003594188892748207\n",
      "[Training] Epoch: 35 [=========>     ] 61.9% Loss: 0.0546, Epoch 35, Batch 77, CE_loss: 0.03713010251522064, Dice_loss: 0.00360525562427938, Consistency_loss: 0.0005418291548267007\n",
      "[Training] Epoch: 35 [=========>     ] 62.7% Loss: 0.0545, Epoch 35, Batch 78, CE_loss: 0.04329771548509598, Dice_loss: 0.004639171063899994, Consistency_loss: 5.658858208335005e-05\n",
      "[Training] Epoch: 35 [=========>     ] 63.5% Loss: 0.0545, Epoch 35, Batch 79, CE_loss: 0.04362759739160538, Dice_loss: 0.004658071789890528, Consistency_loss: 0.00015508662909269333\n",
      "[Training] Epoch: 35 [=========>     ] 64.3% Loss: 0.0544, Epoch 35, Batch 80, CE_loss: 0.04412972927093506, Dice_loss: 0.0046885148622095585, Consistency_loss: 0.00033332835300825536\n",
      "[Training] Epoch: 35 [=========>     ] 65.1% Loss: 0.0543, Epoch 35, Batch 81, CE_loss: 0.03854723647236824, Dice_loss: 0.00402096239849925, Consistency_loss: 9.459062130190432e-05\n",
      "[Training] Epoch: 35 [=========>     ] 65.9% Loss: 0.0543, Epoch 35, Batch 82, CE_loss: 0.05414215102791786, Dice_loss: 0.005622598808258772, Consistency_loss: 0.0005375298205763102\n",
      "[Training] Epoch: 35 [==========>    ] 66.7% Loss: 0.0543, Epoch 35, Batch 83, CE_loss: 0.0460236556828022, Dice_loss: 0.00462995795533061, Consistency_loss: 0.00014883614494465292\n",
      "[Training] Epoch: 35 [==========>    ] 67.5% Loss: 0.0543, Epoch 35, Batch 84, CE_loss: 0.053580861538648605, Dice_loss: 0.005827631335705519, Consistency_loss: 0.00020008992578368634\n",
      "[Training] Epoch: 35 [==========>    ] 68.3% Loss: 0.0544, Epoch 35, Batch 85, CE_loss: 0.05407772585749626, Dice_loss: 0.006040849257260561, Consistency_loss: 0.00046573797590099275\n",
      "[Training] Epoch: 35 [==========>    ] 69.0% Loss: 0.0543, Epoch 35, Batch 86, CE_loss: 0.03939368575811386, Dice_loss: 0.003832107875496149, Consistency_loss: 9.72236375673674e-05\n",
      "[Training] Epoch: 35 [==========>    ] 69.8% Loss: 0.0543, Epoch 35, Batch 87, CE_loss: 0.049727194011211395, Dice_loss: 0.005430646240711212, Consistency_loss: 4.992921094526537e-05\n",
      "[Training] Epoch: 35 [==========>    ] 70.6% Loss: 0.0542, Epoch 35, Batch 88, CE_loss: 0.03865781053900719, Dice_loss: 0.004062214866280556, Consistency_loss: 0.0002181789604946971\n",
      "[Training] Epoch: 35 [==========>    ] 71.4% Loss: 0.0543, Epoch 35, Batch 89, CE_loss: 0.0554242841899395, Dice_loss: 0.006018327549099922, Consistency_loss: 5.5239212088054046e-05\n",
      "[Training] Epoch: 35 [==========>    ] 72.2% Loss: 0.0543, Epoch 35, Batch 90, CE_loss: 0.053187161684036255, Dice_loss: 0.005867605097591877, Consistency_loss: 0.0004914034507237375\n",
      "[Training] Epoch: 35 [==========>    ] 73.0% Loss: 0.0542, Epoch 35, Batch 91, CE_loss: 0.03932145610451698, Dice_loss: 0.00425077835097909, Consistency_loss: 0.00048331203288398683\n",
      "[Training] Epoch: 35 [===========>   ] 73.8% Loss: 0.0540, Epoch 35, Batch 92, CE_loss: 0.03517456725239754, Dice_loss: 0.003653655992820859, Consistency_loss: 0.0005074733053334057\n",
      "[Training] Epoch: 35 [===========>   ] 74.6% Loss: 0.0540, Epoch 35, Batch 93, CE_loss: 0.044732466340065, Dice_loss: 0.004884866066277027, Consistency_loss: 0.00037916048313491046\n",
      "[Training] Epoch: 35 [===========>   ] 75.4% Loss: 0.0539, Epoch 35, Batch 94, CE_loss: 0.036963917315006256, Dice_loss: 0.003821647260338068, Consistency_loss: 5.5291249736910686e-05\n",
      "[Training] Epoch: 35 [===========>   ] 76.2% Loss: 0.0538, Epoch 35, Batch 95, CE_loss: 0.04221083223819733, Dice_loss: 0.004581848159432411, Consistency_loss: 0.00016708005568943918\n",
      "[Training] Epoch: 35 [===========>   ] 77.0% Loss: 0.0538, Epoch 35, Batch 96, CE_loss: 0.04755965620279312, Dice_loss: 0.004771395120769739, Consistency_loss: 0.0002212605468230322\n",
      "[Training] Epoch: 35 [===========>   ] 77.8% Loss: 0.0539, Epoch 35, Batch 97, CE_loss: 0.06258030980825424, Dice_loss: 0.007175150793045759, Consistency_loss: 0.0003155274025630206\n",
      "[Training] Epoch: 35 [===========>   ] 78.6% Loss: 0.0539, Epoch 35, Batch 98, CE_loss: 0.04161997511982918, Dice_loss: 0.004279120359569788, Consistency_loss: 0.00032398701296187937\n",
      "[Training] Epoch: 35 [===========>   ] 79.4% Loss: 0.0538, Epoch 35, Batch 99, CE_loss: 0.04367586597800255, Dice_loss: 0.00464601069688797, Consistency_loss: 4.501130388234742e-05\n",
      "[Training] Epoch: 35 [============>  ] 80.2% Loss: 0.0538, Epoch 35, Batch 100, CE_loss: 0.04887155815958977, Dice_loss: 0.0049155279994010925, Consistency_loss: 0.0002107088075717911\n",
      "[Training] Epoch: 35 [============>  ] 81.0% Loss: 0.0538, Epoch 35, Batch 101, CE_loss: 0.04534411057829857, Dice_loss: 0.0049668122082948685, Consistency_loss: 0.0004721634031739086\n",
      "[Training] Epoch: 35 [============>  ] 81.7% Loss: 0.0538, Epoch 35, Batch 102, CE_loss: 0.04689902439713478, Dice_loss: 0.00510738231241703, Consistency_loss: 0.0004311199299991131\n",
      "[Training] Epoch: 35 [============>  ] 82.5% Loss: 0.0539, Epoch 35, Batch 103, CE_loss: 0.060337550938129425, Dice_loss: 0.006775774527341127, Consistency_loss: 0.00043242060928605497\n",
      "[Training] Epoch: 35 [============>  ] 83.3% Loss: 0.0539, Epoch 35, Batch 104, CE_loss: 0.04696284607052803, Dice_loss: 0.004949328489601612, Consistency_loss: 0.0003084045019932091\n",
      "[Training] Epoch: 35 [============>  ] 84.1% Loss: 0.0541, Epoch 35, Batch 105, CE_loss: 0.073308564722538, Dice_loss: 0.0077056740410625935, Consistency_loss: 0.0003557624004315585\n",
      "[Training] Epoch: 35 [============>  ] 84.9% Loss: 0.0542, Epoch 35, Batch 106, CE_loss: 0.05297335609793663, Dice_loss: 0.005942125804722309, Consistency_loss: 0.0006808179314248264\n",
      "[Training] Epoch: 35 [============>  ] 85.7% Loss: 0.0541, Epoch 35, Batch 107, CE_loss: 0.04145989194512367, Dice_loss: 0.004379716701805592, Consistency_loss: 0.0006619817577302456\n",
      "[Training] Epoch: 35 [============>  ] 86.5% Loss: 0.0540, Epoch 35, Batch 108, CE_loss: 0.03853003308176994, Dice_loss: 0.003810243448242545, Consistency_loss: 0.00029268593061715364\n",
      "[Training] Epoch: 35 [=============> ] 87.3% Loss: 0.0539, Epoch 35, Batch 109, CE_loss: 0.03761005774140358, Dice_loss: 0.003915618639439344, Consistency_loss: 0.00024288501299452037\n",
      "[Training] Epoch: 35 [=============> ] 88.1% Loss: 0.0541, Epoch 35, Batch 110, CE_loss: 0.06527154892683029, Dice_loss: 0.007420098874717951, Consistency_loss: 0.00038560942630283535\n",
      "[Training] Epoch: 35 [=============> ] 88.9% Loss: 0.0541, Epoch 35, Batch 111, CE_loss: 0.05424880608916283, Dice_loss: 0.005620948970317841, Consistency_loss: 0.00021212792489677668\n",
      "[Training] Epoch: 35 [=============> ] 89.7% Loss: 0.0541, Epoch 35, Batch 112, CE_loss: 0.04581219330430031, Dice_loss: 0.004585763905197382, Consistency_loss: 0.0002458779199514538\n",
      "[Training] Epoch: 35 [=============> ] 90.5% Loss: 0.0541, Epoch 35, Batch 113, CE_loss: 0.04855920374393463, Dice_loss: 0.004880113992840052, Consistency_loss: 0.0005963057046756148\n",
      "[Training] Epoch: 35 [=============> ] 91.3% Loss: 0.0541, Epoch 35, Batch 114, CE_loss: 0.0445079579949379, Dice_loss: 0.004717295058071613, Consistency_loss: 0.0004426347732078284\n",
      "[Training] Epoch: 35 [=============> ] 92.1% Loss: 0.0542, Epoch 35, Batch 115, CE_loss: 0.06377027928829193, Dice_loss: 0.007250359747558832, Consistency_loss: 4.485041063162498e-05\n",
      "[Training] Epoch: 35 [=============> ] 92.9% Loss: 0.0541, Epoch 35, Batch 116, CE_loss: 0.03583173081278801, Dice_loss: 0.003451685653999448, Consistency_loss: 0.0004385968204587698\n",
      "[Training] Epoch: 35 [==============>] 93.7% Loss: 0.0542, Epoch 35, Batch 117, CE_loss: 0.056690286844968796, Dice_loss: 0.0061682541854679585, Consistency_loss: 0.0003974757273681462\n",
      "[Training] Epoch: 35 [==============>] 94.4% Loss: 0.0541, Epoch 35, Batch 118, CE_loss: 0.03885990381240845, Dice_loss: 0.003934349399060011, Consistency_loss: 0.00035002801450900733\n",
      "[Training] Epoch: 35 [==============>] 95.2% Loss: 0.0541, Epoch 35, Batch 119, CE_loss: 0.05068449676036835, Dice_loss: 0.00561804324388504, Consistency_loss: 0.00027673583826981485\n",
      "[Training] Epoch: 35 [==============>] 96.0% Loss: 0.0542, Epoch 35, Batch 120, CE_loss: 0.06098146736621857, Dice_loss: 0.006689738016575575, Consistency_loss: 0.00013585218403022736\n",
      "[Training] Epoch: 35 [==============>] 96.8% Loss: 0.0541, Epoch 35, Batch 121, CE_loss: 0.03641480579972267, Dice_loss: 0.0037229331210255623, Consistency_loss: 0.00029051382443867624\n",
      "[Training] Epoch: 35 [==============>] 97.6% Loss: 0.0541, Epoch 35, Batch 122, CE_loss: 0.04959053546190262, Dice_loss: 0.005571735091507435, Consistency_loss: 0.00018889631610363722\n",
      "[Training] Epoch: 35 [==============>] 98.4% Loss: 0.0541, Epoch 35, Batch 123, CE_loss: 0.04488926753401756, Dice_loss: 0.004738233983516693, Consistency_loss: 0.00040863576577976346\n",
      "[Training] Epoch: 35 [==============>] 99.2% Loss: 0.0541, Epoch 35, Batch 124, CE_loss: 0.055762555450201035, Dice_loss: 0.006373773794621229, Consistency_loss: 0.0005930533516220748\n",
      "[Training] Epoch: 35 [DONE]                                 \n",
      "Epoch 35, Batch 125, CE_loss: 0.07610271126031876, Dice_loss: 0.00829367246478796, Consistency_loss: 4.653516225516796e-05\n",
      "[Validation] Epoch: 35 [DONE]                                 \n",
      "[Epoch: 35, TrainLoss: 0.0544, TrainDice: 0.0053, ValLoss: 0.1457                                            \n",
      "Number of batches:  126\n",
      "[Training] Epoch: 36 [>              ] 0.8% Loss: 0.0635, Epoch 36, Batch 0, CE_loss: 0.05719301104545593, Dice_loss: 0.005941079929471016, Consistency_loss: 0.00034643488470464945\n",
      "[Training] Epoch: 36 [>              ] 1.6% Loss: 0.0521, Epoch 36, Batch 1, CE_loss: 0.036545101553201675, Dice_loss: 0.003845192724838853, Consistency_loss: 0.000263003894360736\n",
      "[Training] Epoch: 36 [>              ] 2.4% Loss: 0.0603, Epoch 36, Batch 2, CE_loss: 0.06872358173131943, Dice_loss: 0.007793618831783533, Consistency_loss: 0.0002781741786748171\n",
      "[Training] Epoch: 36 [>              ] 3.2% Loss: 0.0636, Epoch 36, Batch 3, CE_loss: 0.06551168859004974, Dice_loss: 0.007417944259941578, Consistency_loss: 0.00035292544635012746\n",
      "[Training] Epoch: 36 [>              ] 4.0% Loss: 0.0669, Epoch 36, Batch 4, CE_loss: 0.07204477488994598, Dice_loss: 0.008164881728589535, Consistency_loss: 0.0002998606360051781\n",
      "[Training] Epoch: 36 [>              ] 4.8% Loss: 0.0676, Epoch 36, Batch 5, CE_loss: 0.06319702416658401, Dice_loss: 0.007330817170441151, Consistency_loss: 8.724706276552752e-05\n",
      "[Training] Epoch: 36 [>              ] 5.6% Loss: 0.0667, Epoch 36, Batch 6, CE_loss: 0.055931415408849716, Dice_loss: 0.005784648936241865, Consistency_loss: 3.667025885079056e-05\n",
      "[Training] Epoch: 36 [>              ] 6.3% Loss: 0.0641, Epoch 36, Batch 7, CE_loss: 0.040837015956640244, Dice_loss: 0.00445967772975564, Consistency_loss: 0.00022230211470741779\n",
      "[Training] Epoch: 36 [=>             ] 7.1% Loss: 0.0599, Epoch 36, Batch 8, CE_loss: 0.024095946922898293, Dice_loss: 0.0022330330684781075, Consistency_loss: 0.00014748038665857166\n",
      "[Training] Epoch: 36 [=>             ] 7.9% Loss: 0.0596, Epoch 36, Batch 9, CE_loss: 0.05089827626943588, Dice_loss: 0.005701683461666107, Consistency_loss: 0.00011582577280933037\n",
      "[Training] Epoch: 36 [=>             ] 8.7% Loss: 0.0585, Epoch 36, Batch 10, CE_loss: 0.04333696514368057, Dice_loss: 0.004254184663295746, Consistency_loss: 0.0005114480154588819\n",
      "[Training] Epoch: 36 [=>             ] 9.5% Loss: 0.0598, Epoch 36, Batch 11, CE_loss: 0.06608236581087112, Dice_loss: 0.007687206845730543, Consistency_loss: 0.0002318257902516052\n",
      "[Training] Epoch: 36 [=>             ] 10.3% Loss: 0.0578, Epoch 36, Batch 12, CE_loss: 0.030122656375169754, Dice_loss: 0.0030145796481519938, Consistency_loss: 4.605310459737666e-05\n",
      "[Training] Epoch: 36 [=>             ] 11.1% Loss: 0.0577, Epoch 36, Batch 13, CE_loss: 0.04993811994791031, Dice_loss: 0.005545395892113447, Consistency_loss: 0.0005479957908391953\n",
      "[Training] Epoch: 36 [=>             ] 11.9% Loss: 0.0575, Epoch 36, Batch 14, CE_loss: 0.04912729561328888, Dice_loss: 0.005437727551907301, Consistency_loss: 0.0004358277656137943\n",
      "[Training] Epoch: 36 [=>             ] 12.7% Loss: 0.0577, Epoch 36, Batch 15, CE_loss: 0.05402413010597229, Dice_loss: 0.006059803534299135, Consistency_loss: 0.00024063291493803263\n",
      "[Training] Epoch: 36 [==>            ] 13.5% Loss: 0.0573, Epoch 36, Batch 16, CE_loss: 0.04714755341410637, Dice_loss: 0.004828436765819788, Consistency_loss: 0.0003438187704887241\n",
      "[Training] Epoch: 36 [==>            ] 14.3% Loss: 0.0563, Epoch 36, Batch 17, CE_loss: 0.03475942090153694, Dice_loss: 0.0036740631330758333, Consistency_loss: 0.00011909592285519466\n",
      "[Training] Epoch: 36 [==>            ] 15.1% Loss: 0.0568, Epoch 36, Batch 18, CE_loss: 0.059273671358823776, Dice_loss: 0.006447261665016413, Consistency_loss: 7.06757273292169e-05\n",
      "[Training] Epoch: 36 [==>            ] 15.9% Loss: 0.0564, Epoch 36, Batch 19, CE_loss: 0.0439397394657135, Dice_loss: 0.004756728187203407, Consistency_loss: 0.0003066754143219441\n",
      "[Training] Epoch: 36 [==>            ] 16.7% Loss: 0.0560, Epoch 36, Batch 20, CE_loss: 0.04373091831803322, Dice_loss: 0.004791619256138802, Consistency_loss: 7.785600610077381e-05\n",
      "[Training] Epoch: 36 [==>            ] 17.5% Loss: 0.0567, Epoch 36, Batch 21, CE_loss: 0.06380138546228409, Dice_loss: 0.007398690562695265, Consistency_loss: 0.000197609027964063\n",
      "[Training] Epoch: 36 [==>            ] 18.3% Loss: 0.0555, Epoch 36, Batch 22, CE_loss: 0.024709613993763924, Dice_loss: 0.0022671506740152836, Consistency_loss: 0.00035461370134726167\n",
      "[Training] Epoch: 36 [==>            ] 19.0% Loss: 0.0547, Epoch 36, Batch 23, CE_loss: 0.033699534833431244, Dice_loss: 0.0034290344920009375, Consistency_loss: 0.00034568729461170733\n",
      "[Training] Epoch: 36 [==>            ] 19.8% Loss: 0.0544, Epoch 36, Batch 24, CE_loss: 0.042695630341768265, Dice_loss: 0.004648943431675434, Consistency_loss: 0.00010782844765344635\n",
      "[Training] Epoch: 36 [===>           ] 20.6% Loss: 0.0540, Epoch 36, Batch 25, CE_loss: 0.03961363062262535, Dice_loss: 0.0041512236930429935, Consistency_loss: 0.0001792165421647951\n",
      "[Training] Epoch: 36 [===>           ] 21.4% Loss: 0.0539, Epoch 36, Batch 26, CE_loss: 0.04587427154183388, Dice_loss: 0.004790827631950378, Consistency_loss: 0.000335854449076578\n",
      "[Training] Epoch: 36 [===>           ] 22.2% Loss: 0.0541, Epoch 36, Batch 27, CE_loss: 0.05263940989971161, Dice_loss: 0.005509480834007263, Consistency_loss: 0.00041224187589250505\n",
      "[Training] Epoch: 36 [===>           ] 23.0% Loss: 0.0544, Epoch 36, Batch 28, CE_loss: 0.05708721652626991, Dice_loss: 0.006611001677811146, Consistency_loss: 7.20852185622789e-05\n",
      "[Training] Epoch: 36 [===>           ] 23.8% Loss: 0.0546, Epoch 36, Batch 29, CE_loss: 0.055191345512866974, Dice_loss: 0.006139049306511879, Consistency_loss: 0.0003197041223756969\n",
      "[Training] Epoch: 36 [===>           ] 24.6% Loss: 0.0541, Epoch 36, Batch 30, CE_loss: 0.03437142074108124, Dice_loss: 0.003474524710327387, Consistency_loss: 0.0006058017024770379\n",
      "[Training] Epoch: 36 [===>           ] 25.4% Loss: 0.0535, Epoch 36, Batch 31, CE_loss: 0.030869778245687485, Dice_loss: 0.002775290748104453, Consistency_loss: 1.7178195776068605e-05\n",
      "[Training] Epoch: 36 [===>           ] 26.2% Loss: 0.0540, Epoch 36, Batch 32, CE_loss: 0.06356598436832428, Dice_loss: 0.007074330933392048, Consistency_loss: 0.00019980080833192915\n",
      "[Training] Epoch: 36 [====>          ] 27.0% Loss: 0.0540, Epoch 36, Batch 33, CE_loss: 0.047810763120651245, Dice_loss: 0.005150373559445143, Consistency_loss: 0.00042502075666561723\n",
      "[Training] Epoch: 36 [====>          ] 27.8% Loss: 0.0541, Epoch 36, Batch 34, CE_loss: 0.050323422998189926, Dice_loss: 0.0056352633982896805, Consistency_loss: 0.000504952622577548\n",
      "[Training] Epoch: 36 [====>          ] 28.6% Loss: 0.0538, Epoch 36, Batch 35, CE_loss: 0.0385173000395298, Dice_loss: 0.004171058535575867, Consistency_loss: 0.0003397286927793175\n",
      "[Training] Epoch: 36 [====>          ] 29.4% Loss: 0.0534, Epoch 36, Batch 36, CE_loss: 0.03511505946516991, Dice_loss: 0.003696213709190488, Consistency_loss: 0.0003436194674577564\n",
      "[Training] Epoch: 36 [====>          ] 30.2% Loss: 0.0529, Epoch 36, Batch 37, CE_loss: 0.03333442658185959, Dice_loss: 0.003370660590007901, Consistency_loss: 3.725061105797067e-05\n",
      "[Training] Epoch: 36 [====>          ] 31.0% Loss: 0.0527, Epoch 36, Batch 38, CE_loss: 0.039720043540000916, Dice_loss: 0.0041205259039998055, Consistency_loss: 0.00026049636653624475\n",
      "[Training] Epoch: 36 [====>          ] 31.7% Loss: 0.0531, Epoch 36, Batch 39, CE_loss: 0.06088132783770561, Dice_loss: 0.0066247256472706795, Consistency_loss: 6.7632929130923e-05\n",
      "[Training] Epoch: 36 [====>          ] 32.5% Loss: 0.0535, Epoch 36, Batch 40, CE_loss: 0.06408758461475372, Dice_loss: 0.007265523541718721, Consistency_loss: 0.00040471527609042823\n",
      "[Training] Epoch: 36 [=====>         ] 33.3% Loss: 0.0534, Epoch 36, Batch 41, CE_loss: 0.04396706447005272, Dice_loss: 0.004817605018615723, Consistency_loss: 6.25022075837478e-05\n",
      "[Training] Epoch: 36 [=====>         ] 34.1% Loss: 0.0531, Epoch 36, Batch 42, CE_loss: 0.03594451770186424, Dice_loss: 0.003853422589600086, Consistency_loss: 0.000610560062341392\n",
      "[Training] Epoch: 36 [=====>         ] 34.9% Loss: 0.0530, Epoch 36, Batch 43, CE_loss: 0.04407820478081703, Dice_loss: 0.004778498783707619, Consistency_loss: 2.4706727344891988e-05\n",
      "[Training] Epoch: 36 [=====>         ] 35.7% Loss: 0.0531, Epoch 36, Batch 44, CE_loss: 0.0527694933116436, Dice_loss: 0.006009216886013746, Consistency_loss: 8.522872667526826e-05\n",
      "[Training] Epoch: 36 [=====>         ] 36.5% Loss: 0.0530, Epoch 36, Batch 45, CE_loss: 0.041702914983034134, Dice_loss: 0.0038367838133126497, Consistency_loss: 0.00013281415158417076\n",
      "[Training] Epoch: 36 [=====>         ] 37.3% Loss: 0.0527, Epoch 36, Batch 46, CE_loss: 0.0370677225291729, Dice_loss: 0.003844638355076313, Consistency_loss: 0.0003161369822919369\n",
      "[Training] Epoch: 36 [=====>         ] 38.1% Loss: 0.0528, Epoch 36, Batch 47, CE_loss: 0.05087072774767876, Dice_loss: 0.005481903441250324, Consistency_loss: 0.0004089004942215979\n",
      "[Training] Epoch: 36 [=====>         ] 38.9% Loss: 0.0530, Epoch 36, Batch 48, CE_loss: 0.0532856248319149, Dice_loss: 0.005933252163231373, Consistency_loss: 0.00036282208748161793\n",
      "[Training] Epoch: 36 [=====>         ] 39.7% Loss: 0.0530, Epoch 36, Batch 49, CE_loss: 0.04906214773654938, Dice_loss: 0.005412688944488764, Consistency_loss: 0.00015803883434273303\n",
      "[Training] Epoch: 36 [======>        ] 40.5% Loss: 0.0529, Epoch 36, Batch 50, CE_loss: 0.04387928545475006, Dice_loss: 0.004190526902675629, Consistency_loss: 0.00028060917975381017\n",
      "[Training] Epoch: 36 [======>        ] 41.3% Loss: 0.0530, Epoch 36, Batch 51, CE_loss: 0.05014904588460922, Dice_loss: 0.005570447538048029, Consistency_loss: 0.00012320505629759282\n",
      "[Training] Epoch: 36 [======>        ] 42.1% Loss: 0.0531, Epoch 36, Batch 52, CE_loss: 0.055424995720386505, Dice_loss: 0.005884435959160328, Consistency_loss: 0.00014263647608458996\n",
      "[Training] Epoch: 36 [======>        ] 42.9% Loss: 0.0533, Epoch 36, Batch 53, CE_loss: 0.05424358323216438, Dice_loss: 0.00617861608043313, Consistency_loss: 0.00019079430785495788\n",
      "[Training] Epoch: 36 [======>        ] 43.7% Loss: 0.0530, Epoch 36, Batch 54, CE_loss: 0.03450389206409454, Dice_loss: 0.003514762269333005, Consistency_loss: 0.00028935496811755\n",
      "[Training] Epoch: 36 [======>        ] 44.4% Loss: 0.0527, Epoch 36, Batch 55, CE_loss: 0.035237301141023636, Dice_loss: 0.0036523507442325354, Consistency_loss: 0.00021850863413419574\n",
      "[Training] Epoch: 36 [======>        ] 45.2% Loss: 0.0525, Epoch 36, Batch 56, CE_loss: 0.034184977412223816, Dice_loss: 0.0031727494206279516, Consistency_loss: 0.0003207071276847273\n",
      "[Training] Epoch: 36 [======>        ] 46.0% Loss: 0.0524, Epoch 36, Batch 57, CE_loss: 0.04201384633779526, Dice_loss: 0.004534533713012934, Consistency_loss: 0.00023751069966237992\n",
      "[Training] Epoch: 36 [=======>       ] 46.8% Loss: 0.0521, Epoch 36, Batch 58, CE_loss: 0.03096230886876583, Dice_loss: 0.0031074376311153173, Consistency_loss: 0.00022509170230478048\n",
      "[Training] Epoch: 36 [=======>       ] 47.6% Loss: 0.0519, Epoch 36, Batch 59, CE_loss: 0.036582428961992264, Dice_loss: 0.003865988692268729, Consistency_loss: 0.00030742090893909335\n",
      "[Training] Epoch: 36 [=======>       ] 48.4% Loss: 0.0519, Epoch 36, Batch 60, CE_loss: 0.04753643646836281, Dice_loss: 0.0052250102162361145, Consistency_loss: 0.00013206619769334793\n",
      "[Training] Epoch: 36 [=======>       ] 49.2% Loss: 0.0518, Epoch 36, Batch 61, CE_loss: 0.04039010778069496, Dice_loss: 0.00428357720375061, Consistency_loss: 0.0003971323894802481\n",
      "[Training] Epoch: 36 [=======>       ] 50.0% Loss: 0.0520, Epoch 36, Batch 62, CE_loss: 0.05834661424160004, Dice_loss: 0.006637783721089363, Consistency_loss: 0.0006638621562160552\n",
      "[Training] Epoch: 36 [=======>       ] 50.8% Loss: 0.0517, Epoch 36, Batch 63, CE_loss: 0.03140970692038536, Dice_loss: 0.0030861676204949617, Consistency_loss: 0.0006889263750053942\n",
      "[Training] Epoch: 36 [=======>       ] 51.6% Loss: 0.0517, Epoch 36, Batch 64, CE_loss: 0.04196520894765854, Dice_loss: 0.0044624581933021545, Consistency_loss: 0.0005622131866402924\n",
      "[Training] Epoch: 36 [=======>       ] 52.4% Loss: 0.0515, Epoch 36, Batch 65, CE_loss: 0.039024386554956436, Dice_loss: 0.004084356129169464, Consistency_loss: 3.835373354377225e-05\n",
      "[Training] Epoch: 36 [=======>       ] 53.2% Loss: 0.0518, Epoch 36, Batch 66, CE_loss: 0.06365147978067398, Dice_loss: 0.007205008063465357, Consistency_loss: 0.0002252761332783848\n",
      "[Training] Epoch: 36 [========>      ] 54.0% Loss: 0.0517, Epoch 36, Batch 67, CE_loss: 0.03848778083920479, Dice_loss: 0.004036385100334883, Consistency_loss: 0.00024062306329142302\n",
      "[Training] Epoch: 36 [========>      ] 54.8% Loss: 0.0518, Epoch 36, Batch 68, CE_loss: 0.05288279056549072, Dice_loss: 0.005698304157704115, Consistency_loss: 3.5493456380208954e-05\n",
      "[Training] Epoch: 36 [========>      ] 55.6% Loss: 0.0515, Epoch 36, Batch 69, CE_loss: 0.027872011065483093, Dice_loss: 0.0026971669867634773, Consistency_loss: 0.0002060670667560771\n",
      "[Training] Epoch: 36 [========>      ] 56.3% Loss: 0.0514, Epoch 36, Batch 70, CE_loss: 0.041931163519620895, Dice_loss: 0.004265320487320423, Consistency_loss: 0.0007326530758291483\n",
      "[Training] Epoch: 36 [========>      ] 57.1% Loss: 0.0515, Epoch 36, Batch 71, CE_loss: 0.05231115594506264, Dice_loss: 0.005697391927242279, Consistency_loss: 0.0005737150786444545\n",
      "[Training] Epoch: 36 [========>      ] 57.9% Loss: 0.0515, Epoch 36, Batch 72, CE_loss: 0.04723627492785454, Dice_loss: 0.005218613427132368, Consistency_loss: 0.0003482414176687598\n",
      "[Training] Epoch: 36 [========>      ] 58.7% Loss: 0.0517, Epoch 36, Batch 73, CE_loss: 0.05512046068906784, Dice_loss: 0.005949296522885561, Consistency_loss: 0.0005311961867846549\n",
      "[Training] Epoch: 36 [========>      ] 59.5% Loss: 0.0517, Epoch 36, Batch 74, CE_loss: 0.04733071103692055, Dice_loss: 0.005153574049472809, Consistency_loss: 0.0006876988336443901\n",
      "[Training] Epoch: 36 [=========>     ] 60.3% Loss: 0.0514, Epoch 36, Batch 75, CE_loss: 0.028547264635562897, Dice_loss: 0.0026288912631571293, Consistency_loss: 0.000701020413544029\n",
      "[Training] Epoch: 36 [=========>     ] 61.1% Loss: 0.0516, Epoch 36, Batch 76, CE_loss: 0.05943392589688301, Dice_loss: 0.006817084737122059, Consistency_loss: 4.610449104802683e-05\n",
      "[Training] Epoch: 36 [=========>     ] 61.9% Loss: 0.0515, Epoch 36, Batch 77, CE_loss: 0.036690421402454376, Dice_loss: 0.0036665217485278845, Consistency_loss: 0.0006989724352024496\n",
      "[Training] Epoch: 36 [=========>     ] 62.7% Loss: 0.0516, Epoch 36, Batch 78, CE_loss: 0.05092268064618111, Dice_loss: 0.005449484568089247, Consistency_loss: 0.0003612322616390884\n",
      "[Training] Epoch: 36 [=========>     ] 63.5% Loss: 0.0517, Epoch 36, Batch 79, CE_loss: 0.054317206144332886, Dice_loss: 0.005560452118515968, Consistency_loss: 0.00027575105195865035\n",
      "[Training] Epoch: 36 [=========>     ] 64.3% Loss: 0.0517, Epoch 36, Batch 80, CE_loss: 0.04499128833413124, Dice_loss: 0.004995900671929121, Consistency_loss: 7.314212416531518e-05\n",
      "[Training] Epoch: 36 [=========>     ] 65.1% Loss: 0.0516, Epoch 36, Batch 81, CE_loss: 0.042132578790187836, Dice_loss: 0.004419055767357349, Consistency_loss: 0.0006937926518730819\n",
      "[Training] Epoch: 36 [=========>     ] 65.9% Loss: 0.0518, Epoch 36, Batch 82, CE_loss: 0.06385533511638641, Dice_loss: 0.00690249539911747, Consistency_loss: 0.0006212329608388245\n",
      "[Training] Epoch: 36 [==========>    ] 66.7% Loss: 0.0518, Epoch 36, Batch 83, CE_loss: 0.044338349252939224, Dice_loss: 0.004765297751873732, Consistency_loss: 0.0001541062956675887\n",
      "[Training] Epoch: 36 [==========>    ] 67.5% Loss: 0.0520, Epoch 36, Batch 84, CE_loss: 0.05958319082856178, Dice_loss: 0.0066211046651005745, Consistency_loss: 0.00023496003996115178\n",
      "[Training] Epoch: 36 [==========>    ] 68.3% Loss: 0.0520, Epoch 36, Batch 85, CE_loss: 0.047754835337400436, Dice_loss: 0.005147127900272608, Consistency_loss: 5.159522333997302e-05\n",
      "[Training] Epoch: 36 [==========>    ] 69.0% Loss: 0.0521, Epoch 36, Batch 86, CE_loss: 0.05810253322124481, Dice_loss: 0.006366478279232979, Consistency_loss: 0.00012158408208051696\n",
      "[Training] Epoch: 36 [==========>    ] 69.8% Loss: 0.0521, Epoch 36, Batch 87, CE_loss: 0.04787521809339523, Dice_loss: 0.005000876262784004, Consistency_loss: 0.0002104537416016683\n",
      "[Training] Epoch: 36 [==========>    ] 70.6% Loss: 0.0525, Epoch 36, Batch 88, CE_loss: 0.07321266084909439, Dice_loss: 0.007647103164345026, Consistency_loss: 5.053112909081392e-05\n",
      "[Training] Epoch: 36 [==========>    ] 71.4% Loss: 0.0525, Epoch 36, Batch 89, CE_loss: 0.049598127603530884, Dice_loss: 0.005409519653767347, Consistency_loss: 0.00022286373132374138\n",
      "[Training] Epoch: 36 [==========>    ] 72.2% Loss: 0.0525, Epoch 36, Batch 90, CE_loss: 0.045780863612890244, Dice_loss: 0.005043174605816603, Consistency_loss: 0.00029166985768824816\n",
      "[Training] Epoch: 36 [==========>    ] 73.0% Loss: 0.0524, Epoch 36, Batch 91, CE_loss: 0.036667026579380035, Dice_loss: 0.003534624120220542, Consistency_loss: 0.00046316857333295047\n",
      "[Training] Epoch: 36 [===========>   ] 73.8% Loss: 0.0524, Epoch 36, Batch 92, CE_loss: 0.047638654708862305, Dice_loss: 0.005211465060710907, Consistency_loss: 0.0005797448684461415\n",
      "[Training] Epoch: 36 [===========>   ] 74.6% Loss: 0.0523, Epoch 36, Batch 93, CE_loss: 0.043362293392419815, Dice_loss: 0.004700432997196913, Consistency_loss: 6.251293234527111e-05\n",
      "[Training] Epoch: 36 [===========>   ] 75.4% Loss: 0.0522, Epoch 36, Batch 94, CE_loss: 0.04058624058961868, Dice_loss: 0.00429835170507431, Consistency_loss: 0.0003654221072793007\n",
      "[Training] Epoch: 36 [===========>   ] 76.2% Loss: 0.0524, Epoch 36, Batch 95, CE_loss: 0.06370614469051361, Dice_loss: 0.006888319738209248, Consistency_loss: 0.00046455542906187475\n",
      "[Training] Epoch: 36 [===========>   ] 77.0% Loss: 0.0523, Epoch 36, Batch 96, CE_loss: 0.03206771984696388, Dice_loss: 0.003218986326828599, Consistency_loss: 0.00017724251665640622\n",
      "[Training] Epoch: 36 [===========>   ] 77.8% Loss: 0.0523, Epoch 36, Batch 97, CE_loss: 0.0508008673787117, Dice_loss: 0.005689721088856459, Consistency_loss: 0.0002333527518203482\n",
      "[Training] Epoch: 36 [===========>   ] 78.6% Loss: 0.0522, Epoch 36, Batch 98, CE_loss: 0.03794238343834877, Dice_loss: 0.003998445346951485, Consistency_loss: 0.00032398811890743673\n",
      "[Training] Epoch: 36 [===========>   ] 79.4% Loss: 0.0524, Epoch 36, Batch 99, CE_loss: 0.06506840139627457, Dice_loss: 0.007246712222695351, Consistency_loss: 0.0002770213468465954\n",
      "[Training] Epoch: 36 [============>  ] 80.2% Loss: 0.0525, Epoch 36, Batch 100, CE_loss: 0.05886964127421379, Dice_loss: 0.0063245599158108234, Consistency_loss: 3.8917620258871466e-05\n",
      "[Training] Epoch: 36 [============>  ] 81.0% Loss: 0.0526, Epoch 36, Batch 101, CE_loss: 0.05103001371026039, Dice_loss: 0.00574365584179759, Consistency_loss: 4.9964513891609386e-05\n",
      "[Training] Epoch: 36 [============>  ] 81.7% Loss: 0.0526, Epoch 36, Batch 102, CE_loss: 0.05218737944960594, Dice_loss: 0.005858574993908405, Consistency_loss: 0.00048359675565734506\n",
      "[Training] Epoch: 36 [============>  ] 82.5% Loss: 0.0527, Epoch 36, Batch 103, CE_loss: 0.05206316336989403, Dice_loss: 0.0055677699856460094, Consistency_loss: 0.00015730342420283705\n",
      "[Training] Epoch: 36 [============>  ] 83.3% Loss: 0.0526, Epoch 36, Batch 104, CE_loss: 0.038952864706516266, Dice_loss: 0.004108344204723835, Consistency_loss: 0.0003163532819598913\n",
      "[Training] Epoch: 36 [============>  ] 84.1% Loss: 0.0524, Epoch 36, Batch 105, CE_loss: 0.0301978699862957, Dice_loss: 0.0030483396258205175, Consistency_loss: 0.0003515669668558985\n",
      "[Training] Epoch: 36 [============>  ] 84.9% Loss: 0.0523, Epoch 36, Batch 106, CE_loss: 0.038709912449121475, Dice_loss: 0.004139426629990339, Consistency_loss: 0.0007594890776090324\n",
      "[Training] Epoch: 36 [============>  ] 85.7% Loss: 0.0524, Epoch 36, Batch 107, CE_loss: 0.05173100531101227, Dice_loss: 0.005673077888786793, Consistency_loss: 0.0006952843978069723\n",
      "[Training] Epoch: 36 [============>  ] 86.5% Loss: 0.0526, Epoch 36, Batch 108, CE_loss: 0.06497713923454285, Dice_loss: 0.007409160025417805, Consistency_loss: 0.00022141430235933512\n",
      "[Training] Epoch: 36 [=============> ] 87.3% Loss: 0.0526, Epoch 36, Batch 109, CE_loss: 0.04691378027200699, Dice_loss: 0.005085982382297516, Consistency_loss: 0.0002876211074180901\n",
      "[Training] Epoch: 36 [=============> ] 88.1% Loss: 0.0527, Epoch 36, Batch 110, CE_loss: 0.058203596621751785, Dice_loss: 0.006638525519520044, Consistency_loss: 0.0004181919794064015\n",
      "[Training] Epoch: 36 [=============> ] 88.9% Loss: 0.0528, Epoch 36, Batch 111, CE_loss: 0.055519841611385345, Dice_loss: 0.0058877174742519855, Consistency_loss: 6.698110519209877e-05\n",
      "[Training] Epoch: 36 [=============> ] 89.7% Loss: 0.0528, Epoch 36, Batch 112, CE_loss: 0.046431005001068115, Dice_loss: 0.0050762551836669445, Consistency_loss: 0.0005969120538793504\n",
      "[Training] Epoch: 36 [=============> ] 90.5% Loss: 0.0528, Epoch 36, Batch 113, CE_loss: 0.04923349246382713, Dice_loss: 0.004885116592049599, Consistency_loss: 0.0005469310563057661\n",
      "[Training] Epoch: 36 [=============> ] 91.3% Loss: 0.0529, Epoch 36, Batch 114, CE_loss: 0.05565006658434868, Dice_loss: 0.006107823923230171, Consistency_loss: 0.0006495401030406356\n",
      "[Training] Epoch: 36 [=============> ] 92.1% Loss: 0.0528, Epoch 36, Batch 115, CE_loss: 0.03644606098532677, Dice_loss: 0.0036006735172122717, Consistency_loss: 0.00037250324385240674\n",
      "[Training] Epoch: 36 [=============> ] 92.9% Loss: 0.0527, Epoch 36, Batch 116, CE_loss: 0.03876183554530144, Dice_loss: 0.004009800031781197, Consistency_loss: 0.0005039325333200395\n",
      "[Training] Epoch: 36 [==============>] 93.7% Loss: 0.0528, Epoch 36, Batch 117, CE_loss: 0.05898784101009369, Dice_loss: 0.006542113609611988, Consistency_loss: 3.547123196767643e-05\n",
      "[Training] Epoch: 36 [==============>] 94.4% Loss: 0.0526, Epoch 36, Batch 118, CE_loss: 0.02967008948326111, Dice_loss: 0.002898775041103363, Consistency_loss: 0.0003936849534511566\n",
      "[Training] Epoch: 36 [==============>] 95.2% Loss: 0.0526, Epoch 36, Batch 119, CE_loss: 0.042336802929639816, Dice_loss: 0.004590274766087532, Consistency_loss: 0.00037014487315900624\n",
      "[Training] Epoch: 36 [==============>] 96.0% Loss: 0.0526, Epoch 36, Batch 120, CE_loss: 0.051734425127506256, Dice_loss: 0.005778301041573286, Consistency_loss: 0.0002994914539158344\n",
      "[Training] Epoch: 36 [==============>] 96.8% Loss: 0.0526, Epoch 36, Batch 121, CE_loss: 0.03981498256325722, Dice_loss: 0.004283519461750984, Consistency_loss: 0.0003512595721986145\n",
      "[Training] Epoch: 36 [==============>] 97.6% Loss: 0.0524, Epoch 36, Batch 122, CE_loss: 0.03022272139787674, Dice_loss: 0.002682964550331235, Consistency_loss: 0.00047449578414671123\n",
      "[Training] Epoch: 36 [==============>] 98.4% Loss: 0.0523, Epoch 36, Batch 123, CE_loss: 0.03171274811029434, Dice_loss: 0.0031149880960583687, Consistency_loss: 0.00041329345549456775\n",
      "[Training] Epoch: 36 [==============>] 99.2% Loss: 0.0524, Epoch 36, Batch 124, CE_loss: 0.06685463339090347, Dice_loss: 0.0074996487237513065, Consistency_loss: 0.0007068135892041028\n",
      "[Training] Epoch: 36 [DONE]                                 \n",
      "Epoch 36, Batch 125, CE_loss: 0.04786047339439392, Dice_loss: 0.005167508497834206, Consistency_loss: 0.0006420759600587189\n",
      "[Validation] Epoch: 36 [DONE]                                 \n",
      "[Epoch: 36, TrainLoss: 0.0525, TrainDice: 0.0051, ValLoss: 0.1463                                            \n",
      "Number of batches:  126\n",
      "[Training] Epoch: 37 [>              ] 0.8% Loss: 0.0529, Epoch 37, Batch 0, CE_loss: 0.04783530905842781, Dice_loss: 0.004818293731659651, Consistency_loss: 0.00024262302031274885\n",
      "[Training] Epoch: 37 [>              ] 1.6% Loss: 0.0684, Epoch 37, Batch 1, CE_loss: 0.07569319754838943, Dice_loss: 0.008032947778701782, Consistency_loss: 0.0002717148163355887\n",
      "[Training] Epoch: 37 [>              ] 2.4% Loss: 0.0586, Epoch 37, Batch 2, CE_loss: 0.034988608211278915, Dice_loss: 0.0035818354226648808, Consistency_loss: 0.00047772630932740867\n",
      "[Training] Epoch: 37 [>              ] 3.2% Loss: 0.0541, Epoch 37, Batch 3, CE_loss: 0.036596935242414474, Dice_loss: 0.003817548044025898, Consistency_loss: 5.4645835916744545e-05\n",
      "[Training] Epoch: 37 [>              ] 4.0% Loss: 0.0528, Epoch 37, Batch 4, CE_loss: 0.042799804359674454, Dice_loss: 0.004454366862773895, Consistency_loss: 0.00010370626114308834\n",
      "[Training] Epoch: 37 [>              ] 4.8% Loss: 0.0517, Epoch 37, Batch 5, CE_loss: 0.04192433878779411, Dice_loss: 0.004540215712040663, Consistency_loss: 0.00019177714420948178\n",
      "[Training] Epoch: 37 [>              ] 5.6% Loss: 0.0502, Epoch 37, Batch 6, CE_loss: 0.03686360642313957, Dice_loss: 0.0037668051663786173, Consistency_loss: 0.00018382479902356863\n",
      "[Training] Epoch: 37 [>              ] 6.3% Loss: 0.0487, Epoch 37, Batch 7, CE_loss: 0.03480513021349907, Dice_loss: 0.0036336020566523075, Consistency_loss: 0.00025093607837334275\n",
      "[Training] Epoch: 37 [=>             ] 7.1% Loss: 0.0487, Epoch 37, Batch 8, CE_loss: 0.043628547340631485, Dice_loss: 0.004469347186386585, Consistency_loss: 0.00018551581888459623\n",
      "[Training] Epoch: 37 [=>             ] 7.9% Loss: 0.0500, Epoch 37, Batch 9, CE_loss: 0.055308617651462555, Dice_loss: 0.005870940163731575, Consistency_loss: 0.00014567455218639225\n",
      "[Training] Epoch: 37 [=>             ] 8.7% Loss: 0.0506, Epoch 37, Batch 10, CE_loss: 0.051100198179483414, Dice_loss: 0.005251738708466291, Consistency_loss: 0.00069727300433442\n",
      "[Training] Epoch: 37 [=>             ] 9.5% Loss: 0.0499, Epoch 37, Batch 11, CE_loss: 0.03785891458392143, Dice_loss: 0.003864889033138752, Consistency_loss: 4.113971954211593e-05\n",
      "[Training] Epoch: 37 [=>             ] 10.3% Loss: 0.0499, Epoch 37, Batch 12, CE_loss: 0.04517342895269394, Dice_loss: 0.0048881517723202705, Consistency_loss: 0.0007254771771840751\n",
      "[Training] Epoch: 37 [=>             ] 11.1% Loss: 0.0498, Epoch 37, Batch 13, CE_loss: 0.043165966868400574, Dice_loss: 0.004510514438152313, Consistency_loss: 0.0005841091624461114\n",
      "[Training] Epoch: 37 [=>             ] 11.9% Loss: 0.0501, Epoch 37, Batch 14, CE_loss: 0.0485619455575943, Dice_loss: 0.005146886687725782, Consistency_loss: 0.0004339079896453768\n",
      "[Training] Epoch: 37 [=>             ] 12.7% Loss: 0.0503, Epoch 37, Batch 15, CE_loss: 0.048441845923662186, Dice_loss: 0.005304662976413965, Consistency_loss: 0.00022910475672688335\n",
      "[Training] Epoch: 37 [==>            ] 13.5% Loss: 0.0514, Epoch 37, Batch 16, CE_loss: 0.06078384071588516, Dice_loss: 0.006787688005715609, Consistency_loss: 0.0002529003832023591\n",
      "[Training] Epoch: 37 [==>            ] 14.3% Loss: 0.0521, Epoch 37, Batch 17, CE_loss: 0.057599715888500214, Dice_loss: 0.0064973654225468636, Consistency_loss: 0.0006428243359550834\n",
      "[Training] Epoch: 37 [==>            ] 15.1% Loss: 0.0523, Epoch 37, Batch 18, CE_loss: 0.05014348775148392, Dice_loss: 0.005324654281139374, Consistency_loss: 0.00036790352896787226\n",
      "[Training] Epoch: 37 [==>            ] 15.9% Loss: 0.0527, Epoch 37, Batch 19, CE_loss: 0.05366602912545204, Dice_loss: 0.005962859373539686, Consistency_loss: 0.00019487994723021984\n",
      "[Training] Epoch: 37 [==>            ] 16.7% Loss: 0.0523, Epoch 37, Batch 20, CE_loss: 0.04094880819320679, Dice_loss: 0.004329894669353962, Consistency_loss: 0.0002831815218087286\n",
      "[Training] Epoch: 37 [==>            ] 17.5% Loss: 0.0522, Epoch 37, Batch 21, CE_loss: 0.04393032565712929, Dice_loss: 0.004720630124211311, Consistency_loss: 0.00024066185869742185\n",
      "[Training] Epoch: 37 [==>            ] 18.3% Loss: 0.0519, Epoch 37, Batch 22, CE_loss: 0.04173045977950096, Dice_loss: 0.0040174308232963085, Consistency_loss: 4.326736234361306e-05\n",
      "[Training] Epoch: 37 [==>            ] 19.0% Loss: 0.0518, Epoch 37, Batch 23, CE_loss: 0.044838402420282364, Dice_loss: 0.004943941719830036, Consistency_loss: 0.00016665247676428407\n",
      "[Training] Epoch: 37 [==>            ] 19.8% Loss: 0.0511, Epoch 37, Batch 24, CE_loss: 0.02932778187096119, Dice_loss: 0.0028637589421123266, Consistency_loss: 0.00027106492780148983\n",
      "[Training] Epoch: 37 [===>           ] 20.6% Loss: 0.0516, Epoch 37, Batch 25, CE_loss: 0.058584097772836685, Dice_loss: 0.0063920398242771626, Consistency_loss: 3.7330330087570474e-05\n",
      "[Training] Epoch: 37 [===>           ] 21.4% Loss: 0.0516, Epoch 37, Batch 26, CE_loss: 0.04674895852804184, Dice_loss: 0.0050975251942873, Consistency_loss: 0.00024755881167948246\n",
      "[Training] Epoch: 37 [===>           ] 22.2% Loss: 0.0521, Epoch 37, Batch 27, CE_loss: 0.058086469769477844, Dice_loss: 0.006265426054596901, Consistency_loss: 0.0003969143144786358\n",
      "[Training] Epoch: 37 [===>           ] 23.0% Loss: 0.0527, Epoch 37, Batch 28, CE_loss: 0.06247737631201744, Dice_loss: 0.007155342493206263, Consistency_loss: 3.628181366366334e-05\n",
      "[Training] Epoch: 37 [===>           ] 23.8% Loss: 0.0525, Epoch 37, Batch 29, CE_loss: 0.041792914271354675, Dice_loss: 0.0043207574635744095, Consistency_loss: 0.0005575803807005286\n",
      "[Training] Epoch: 37 [===>           ] 24.6% Loss: 0.0523, Epoch 37, Batch 30, CE_loss: 0.040593221783638, Dice_loss: 0.004353940486907959, Consistency_loss: 0.0006665156688541174\n",
      "[Training] Epoch: 37 [===>           ] 25.4% Loss: 0.0522, Epoch 37, Batch 31, CE_loss: 0.0438830740749836, Dice_loss: 0.004741099663078785, Consistency_loss: 2.393177965132054e-05\n",
      "[Training] Epoch: 37 [===>           ] 26.2% Loss: 0.0525, Epoch 37, Batch 32, CE_loss: 0.05592377856373787, Dice_loss: 0.006157601252198219, Consistency_loss: 3.245337211410515e-05\n",
      "[Training] Epoch: 37 [====>          ] 27.0% Loss: 0.0532, Epoch 37, Batch 33, CE_loss: 0.07077983021736145, Dice_loss: 0.00768008129671216, Consistency_loss: 0.0005980185233056545\n",
      "[Training] Epoch: 37 [====>          ] 27.8% Loss: 0.0534, Epoch 37, Batch 34, CE_loss: 0.05271358788013458, Dice_loss: 0.005791559815406799, Consistency_loss: 3.5014596505789086e-05\n",
      "[Training] Epoch: 37 [====>          ] 28.6% Loss: 0.0534, Epoch 37, Batch 35, CE_loss: 0.04767337813973427, Dice_loss: 0.00509993452578783, Consistency_loss: 0.0004230753693263978\n",
      "[Training] Epoch: 37 [====>          ] 29.4% Loss: 0.0537, Epoch 37, Batch 36, CE_loss: 0.05818873643875122, Dice_loss: 0.00641716318204999, Consistency_loss: 6.528827361762524e-05\n",
      "[Training] Epoch: 37 [====>          ] 30.2% Loss: 0.0535, Epoch 37, Batch 37, CE_loss: 0.04275418445467949, Dice_loss: 0.0044502317905426025, Consistency_loss: 0.00026921535027213395\n",
      "[Training] Epoch: 37 [====>          ] 31.0% Loss: 0.0534, Epoch 37, Batch 38, CE_loss: 0.042420390993356705, Dice_loss: 0.0044890702702105045, Consistency_loss: 0.0008513120119459927\n",
      "[Training] Epoch: 37 [====>          ] 31.7% Loss: 0.0539, Epoch 37, Batch 39, CE_loss: 0.06729360669851303, Dice_loss: 0.007501137442886829, Consistency_loss: 0.0009636049508117139\n",
      "[Training] Epoch: 37 [====>          ] 32.5% Loss: 0.0536, Epoch 37, Batch 40, CE_loss: 0.03594188019633293, Dice_loss: 0.0036794589832425117, Consistency_loss: 0.0005081439740024507\n",
      "[Training] Epoch: 37 [=====>         ] 33.3% Loss: 0.0534, Epoch 37, Batch 41, CE_loss: 0.03911401331424713, Dice_loss: 0.004104307387024164, Consistency_loss: 0.0004683877050410956\n",
      "[Training] Epoch: 37 [=====>         ] 34.1% Loss: 0.0536, Epoch 37, Batch 42, CE_loss: 0.05816277489066124, Dice_loss: 0.0062719122506678104, Consistency_loss: 0.0001546651474200189\n",
      "[Training] Epoch: 37 [=====>         ] 34.9% Loss: 0.0535, Epoch 37, Batch 43, CE_loss: 0.04119516536593437, Dice_loss: 0.0043917507864534855, Consistency_loss: 0.0004869805707130581\n",
      "[Training] Epoch: 37 [=====>         ] 35.7% Loss: 0.0532, Epoch 37, Batch 44, CE_loss: 0.037166208028793335, Dice_loss: 0.0038747237995266914, Consistency_loss: 0.0006614922313019633\n",
      "[Training] Epoch: 37 [=====>         ] 36.5% Loss: 0.0531, Epoch 37, Batch 45, CE_loss: 0.043966181576251984, Dice_loss: 0.004718765616416931, Consistency_loss: 0.0002608025388326496\n",
      "[Training] Epoch: 37 [=====>         ] 37.3% Loss: 0.0529, Epoch 37, Batch 46, CE_loss: 0.03750847652554512, Dice_loss: 0.003926105797290802, Consistency_loss: 0.000468926242319867\n",
      "[Training] Epoch: 37 [=====>         ] 38.1% Loss: 0.0527, Epoch 37, Batch 47, CE_loss: 0.03882847726345062, Dice_loss: 0.0040478515438735485, Consistency_loss: 0.0003194865712430328\n",
      "[Training] Epoch: 37 [=====>         ] 38.9% Loss: 0.0522, Epoch 37, Batch 48, CE_loss: 0.026435349136590958, Dice_loss: 0.002469451865181327, Consistency_loss: 0.00019412235997151583\n",
      "[Training] Epoch: 37 [=====>         ] 39.7% Loss: 0.0520, Epoch 37, Batch 49, CE_loss: 0.0398569256067276, Dice_loss: 0.004197818227112293, Consistency_loss: 0.00012106071517337114\n",
      "[Training] Epoch: 37 [======>        ] 40.5% Loss: 0.0519, Epoch 37, Batch 50, CE_loss: 0.04313071072101593, Dice_loss: 0.004591861739754677, Consistency_loss: 0.0006704772240482271\n",
      "[Training] Epoch: 37 [======>        ] 41.3% Loss: 0.0519, Epoch 37, Batch 51, CE_loss: 0.04545711725950241, Dice_loss: 0.004928335547447205, Consistency_loss: 0.000681952980812639\n",
      "[Training] Epoch: 37 [======>        ] 42.1% Loss: 0.0517, Epoch 37, Batch 52, CE_loss: 0.03435005992650986, Dice_loss: 0.003377616638317704, Consistency_loss: 0.000272545003099367\n",
      "[Training] Epoch: 37 [======>        ] 42.9% Loss: 0.0517, Epoch 37, Batch 53, CE_loss: 0.04733782261610031, Dice_loss: 0.005038941279053688, Consistency_loss: 0.00026962911942973733\n",
      "[Training] Epoch: 37 [======>        ] 43.7% Loss: 0.0516, Epoch 37, Batch 54, CE_loss: 0.04447302594780922, Dice_loss: 0.004867981653660536, Consistency_loss: 4.940864891977981e-05\n",
      "[Training] Epoch: 37 [======>        ] 44.4% Loss: 0.0518, Epoch 37, Batch 55, CE_loss: 0.055833518505096436, Dice_loss: 0.006247848737984896, Consistency_loss: 0.00031596608459949493\n",
      "[Training] Epoch: 37 [======>        ] 45.2% Loss: 0.0521, Epoch 37, Batch 56, CE_loss: 0.059604108333587646, Dice_loss: 0.006489242892712355, Consistency_loss: 0.000534836552105844\n",
      "[Training] Epoch: 37 [======>        ] 46.0% Loss: 0.0519, Epoch 37, Batch 57, CE_loss: 0.0382586233317852, Dice_loss: 0.004047793336212635, Consistency_loss: 0.00040494962013326585\n",
      "[Training] Epoch: 37 [=======>       ] 46.8% Loss: 0.0521, Epoch 37, Batch 58, CE_loss: 0.05612260848283768, Dice_loss: 0.006397618446499109, Consistency_loss: 0.00026299318415112793\n",
      "[Training] Epoch: 37 [=======>       ] 47.6% Loss: 0.0521, Epoch 37, Batch 59, CE_loss: 0.04695916548371315, Dice_loss: 0.005209842696785927, Consistency_loss: 0.0001678010303294286\n",
      "[Training] Epoch: 37 [=======>       ] 48.4% Loss: 0.0524, Epoch 37, Batch 60, CE_loss: 0.0634397491812706, Dice_loss: 0.006804782431572676, Consistency_loss: 0.0006566685042344034\n",
      "[Training] Epoch: 37 [=======>       ] 49.2% Loss: 0.0523, Epoch 37, Batch 61, CE_loss: 0.03750480338931084, Dice_loss: 0.003898246679455042, Consistency_loss: 0.0006823670119047165\n",
      "[Training] Epoch: 37 [=======>       ] 50.0% Loss: 0.0522, Epoch 37, Batch 62, CE_loss: 0.0431339256465435, Dice_loss: 0.004730415530502796, Consistency_loss: 0.0009435801766812801\n",
      "[Training] Epoch: 37 [=======>       ] 50.8% Loss: 0.0521, Epoch 37, Batch 63, CE_loss: 0.04076778143644333, Dice_loss: 0.004310935735702515, Consistency_loss: 0.0010593662736937404\n",
      "[Training] Epoch: 37 [=======>       ] 51.6% Loss: 0.0521, Epoch 37, Batch 64, CE_loss: 0.048615291714668274, Dice_loss: 0.005357994232326746, Consistency_loss: 5.0318492867518216e-05\n",
      "[Training] Epoch: 37 [=======>       ] 52.4% Loss: 0.0520, Epoch 37, Batch 65, CE_loss: 0.03661400079727173, Dice_loss: 0.003890745574608445, Consistency_loss: 0.00023122814309317619\n",
      "[Training] Epoch: 37 [=======>       ] 53.2% Loss: 0.0520, Epoch 37, Batch 66, CE_loss: 0.0462590791285038, Dice_loss: 0.004940137267112732, Consistency_loss: 0.00022879742027726024\n",
      "[Training] Epoch: 37 [========>      ] 54.0% Loss: 0.0522, Epoch 37, Batch 67, CE_loss: 0.06165001913905144, Dice_loss: 0.006832838524132967, Consistency_loss: 0.00045384999248199165\n",
      "[Training] Epoch: 37 [========>      ] 54.8% Loss: 0.0522, Epoch 37, Batch 68, CE_loss: 0.04439300671219826, Dice_loss: 0.004667079541832209, Consistency_loss: 0.0002309784758836031\n",
      "[Training] Epoch: 37 [========>      ] 55.6% Loss: 0.0522, Epoch 37, Batch 69, CE_loss: 0.04896362125873566, Dice_loss: 0.005267943721264601, Consistency_loss: 0.0003334523644298315\n",
      "[Training] Epoch: 37 [========>      ] 56.3% Loss: 0.0521, Epoch 37, Batch 70, CE_loss: 0.03806709870696068, Dice_loss: 0.0035912590101361275, Consistency_loss: 0.0010436258744448423\n",
      "[Training] Epoch: 37 [========>      ] 57.1% Loss: 0.0519, Epoch 37, Batch 71, CE_loss: 0.03464016690850258, Dice_loss: 0.0033100293949246407, Consistency_loss: 0.0008955515222623944\n",
      "[Training] Epoch: 37 [========>      ] 57.9% Loss: 0.0519, Epoch 37, Batch 72, CE_loss: 0.0469672791659832, Dice_loss: 0.004593770485371351, Consistency_loss: 0.0006669782451353967\n",
      "[Training] Epoch: 37 [========>      ] 58.7% Loss: 0.0519, Epoch 37, Batch 73, CE_loss: 0.045346956700086594, Dice_loss: 0.004840493202209473, Consistency_loss: 0.00016837716975715011\n",
      "[Training] Epoch: 37 [========>      ] 59.5% Loss: 0.0519, Epoch 37, Batch 74, CE_loss: 0.0502532422542572, Dice_loss: 0.005569580476731062, Consistency_loss: 0.0007889405824244022\n",
      "[Training] Epoch: 37 [=========>     ] 60.3% Loss: 0.0521, Epoch 37, Batch 75, CE_loss: 0.05596832558512688, Dice_loss: 0.0062345401383936405, Consistency_loss: 5.765727473772131e-05\n",
      "[Training] Epoch: 37 [=========>     ] 61.1% Loss: 0.0520, Epoch 37, Batch 76, CE_loss: 0.04328000545501709, Dice_loss: 0.004656511824578047, Consistency_loss: 0.000425473292125389\n",
      "[Training] Epoch: 37 [=========>     ] 61.9% Loss: 0.0520, Epoch 37, Batch 77, CE_loss: 0.04680350422859192, Dice_loss: 0.005086272954940796, Consistency_loss: 0.0003866199986077845\n",
      "[Training] Epoch: 37 [=========>     ] 62.7% Loss: 0.0521, Epoch 37, Batch 78, CE_loss: 0.049256447702646255, Dice_loss: 0.005255493801087141, Consistency_loss: 4.8899673856794834e-05\n",
      "[Training] Epoch: 37 [=========>     ] 63.5% Loss: 0.0521, Epoch 37, Batch 79, CE_loss: 0.04978514090180397, Dice_loss: 0.005617019720375538, Consistency_loss: 0.0002498494286555797\n",
      "[Training] Epoch: 37 [=========>     ] 64.3% Loss: 0.0520, Epoch 37, Batch 80, CE_loss: 0.03991764038801193, Dice_loss: 0.0036686451639980078, Consistency_loss: 0.0003654664906207472\n",
      "[Training] Epoch: 37 [=========>     ] 65.1% Loss: 0.0524, Epoch 37, Batch 81, CE_loss: 0.07522745430469513, Dice_loss: 0.008578053675591946, Consistency_loss: 0.0008487909217365086\n",
      "[Training] Epoch: 37 [=========>     ] 65.9% Loss: 0.0522, Epoch 37, Batch 82, CE_loss: 0.0309629887342453, Dice_loss: 0.002730167005211115, Consistency_loss: 0.0008020249078981578\n",
      "[Training] Epoch: 37 [==========>    ] 66.7% Loss: 0.0520, Epoch 37, Batch 83, CE_loss: 0.03429156541824341, Dice_loss: 0.003568272339180112, Consistency_loss: 0.00018743934924714267\n",
      "[Training] Epoch: 37 [==========>    ] 67.5% Loss: 0.0520, Epoch 37, Batch 84, CE_loss: 0.04468163847923279, Dice_loss: 0.004889269359409809, Consistency_loss: 0.00028860176098532975\n",
      "[Training] Epoch: 37 [==========>    ] 68.3% Loss: 0.0518, Epoch 37, Batch 85, CE_loss: 0.03159617260098457, Dice_loss: 0.0032416554167866707, Consistency_loss: 0.0007744503091089427\n",
      "[Training] Epoch: 37 [==========>    ] 69.0% Loss: 0.0519, Epoch 37, Batch 86, CE_loss: 0.056636419147253036, Dice_loss: 0.006212836597114801, Consistency_loss: 4.422751590027474e-05\n",
      "[Training] Epoch: 37 [==========>    ] 69.8% Loss: 0.0519, Epoch 37, Batch 87, CE_loss: 0.0424504391849041, Dice_loss: 0.004650365095585585, Consistency_loss: 0.0002448730228934437\n",
      "[Training] Epoch: 37 [==========>    ] 70.6% Loss: 0.0519, Epoch 37, Batch 88, CE_loss: 0.0447392538189888, Dice_loss: 0.004848450422286987, Consistency_loss: 0.000357088225428015\n",
      "[Training] Epoch: 37 [==========>    ] 71.4% Loss: 0.0521, Epoch 37, Batch 89, CE_loss: 0.06436607241630554, Dice_loss: 0.007045354228466749, Consistency_loss: 0.0005635576671920717\n",
      "[Training] Epoch: 37 [==========>    ] 72.2% Loss: 0.0521, Epoch 37, Batch 90, CE_loss: 0.04893144220113754, Dice_loss: 0.0050786156207323074, Consistency_loss: 0.0007694255909882486\n",
      "[Training] Epoch: 37 [==========>    ] 73.0% Loss: 0.0520, Epoch 37, Batch 91, CE_loss: 0.03980923071503639, Dice_loss: 0.0042577385902404785, Consistency_loss: 0.0008454362978227437\n",
      "[Training] Epoch: 37 [===========>   ] 73.8% Loss: 0.0519, Epoch 37, Batch 92, CE_loss: 0.03464869409799576, Dice_loss: 0.0036266909446567297, Consistency_loss: 0.0007303256425075233\n",
      "[Training] Epoch: 37 [===========>   ] 74.6% Loss: 0.0518, Epoch 37, Batch 93, CE_loss: 0.041432224214076996, Dice_loss: 0.0043951706029474735, Consistency_loss: 0.0007896494935266674\n",
      "[Training] Epoch: 37 [===========>   ] 75.4% Loss: 0.0518, Epoch 37, Batch 94, CE_loss: 0.04506058990955353, Dice_loss: 0.004916145000606775, Consistency_loss: 5.8235309552401304e-05\n",
      "[Training] Epoch: 37 [===========>   ] 76.2% Loss: 0.0519, Epoch 37, Batch 95, CE_loss: 0.054980844259262085, Dice_loss: 0.005873058922588825, Consistency_loss: 0.0004516100452747196\n",
      "[Training] Epoch: 37 [===========>   ] 77.0% Loss: 0.0520, Epoch 37, Batch 96, CE_loss: 0.05154898390173912, Dice_loss: 0.005633966997265816, Consistency_loss: 0.00022976112086325884\n",
      "[Training] Epoch: 37 [===========>   ] 77.8% Loss: 0.0518, Epoch 37, Batch 97, CE_loss: 0.030034322291612625, Dice_loss: 0.0028328329790383577, Consistency_loss: 0.0004192497581243515\n",
      "[Training] Epoch: 37 [===========>   ] 78.6% Loss: 0.0518, Epoch 37, Batch 98, CE_loss: 0.048662859946489334, Dice_loss: 0.00515522388741374, Consistency_loss: 0.0003534531861077994\n",
      "[Training] Epoch: 37 [===========>   ] 79.4% Loss: 0.0518, Epoch 37, Batch 99, CE_loss: 0.04762120172381401, Dice_loss: 0.00511535257101059, Consistency_loss: 0.00045691567356698215\n",
      "[Training] Epoch: 37 [============>  ] 80.2% Loss: 0.0518, Epoch 37, Batch 100, CE_loss: 0.044523146003484726, Dice_loss: 0.004632693715393543, Consistency_loss: 0.00048569656792096794\n",
      "[Training] Epoch: 37 [============>  ] 81.0% Loss: 0.0517, Epoch 37, Batch 101, CE_loss: 0.03822987154126167, Dice_loss: 0.0036488326732069254, Consistency_loss: 0.00022637935762759298\n",
      "[Training] Epoch: 37 [============>  ] 81.7% Loss: 0.0517, Epoch 37, Batch 102, CE_loss: 0.04766282066702843, Dice_loss: 0.005255860276520252, Consistency_loss: 0.00020175644021946937\n",
      "[Training] Epoch: 37 [============>  ] 82.5% Loss: 0.0517, Epoch 37, Batch 103, CE_loss: 0.04560266435146332, Dice_loss: 0.004894387908279896, Consistency_loss: 0.0007859754259698093\n",
      "[Training] Epoch: 37 [============>  ] 83.3% Loss: 0.0517, Epoch 37, Batch 104, CE_loss: 0.047063011676073074, Dice_loss: 0.005192685406655073, Consistency_loss: 0.0003885929472744465\n",
      "[Training] Epoch: 37 [============>  ] 84.1% Loss: 0.0517, Epoch 37, Batch 105, CE_loss: 0.04726963862776756, Dice_loss: 0.005105884745717049, Consistency_loss: 0.0004654768854379654\n",
      "[Training] Epoch: 37 [============>  ] 84.9% Loss: 0.0516, Epoch 37, Batch 106, CE_loss: 0.033133406192064285, Dice_loss: 0.0028890252579003572, Consistency_loss: 0.000926852342672646\n",
      "[Training] Epoch: 37 [============>  ] 85.7% Loss: 0.0514, Epoch 37, Batch 107, CE_loss: 0.030261114239692688, Dice_loss: 0.0030819925013929605, Consistency_loss: 6.980134639889002e-05\n",
      "[Training] Epoch: 37 [============>  ] 86.5% Loss: 0.0513, Epoch 37, Batch 108, CE_loss: 0.036154214292764664, Dice_loss: 0.0036535935942083597, Consistency_loss: 0.00046013432438485324\n",
      "[Training] Epoch: 37 [=============> ] 87.3% Loss: 0.0513, Epoch 37, Batch 109, CE_loss: 0.04832569882273674, Dice_loss: 0.005366148427128792, Consistency_loss: 0.0002993938105646521\n",
      "[Training] Epoch: 37 [=============> ] 88.1% Loss: 0.0513, Epoch 37, Batch 110, CE_loss: 0.04522611200809479, Dice_loss: 0.00456417677924037, Consistency_loss: 0.0006031033117324114\n",
      "[Training] Epoch: 37 [=============> ] 88.9% Loss: 0.0512, Epoch 37, Batch 111, CE_loss: 0.028290212154388428, Dice_loss: 0.0028388770297169685, Consistency_loss: 0.000719130621291697\n",
      "[Training] Epoch: 37 [=============> ] 89.7% Loss: 0.0511, Epoch 37, Batch 112, CE_loss: 0.0398394912481308, Dice_loss: 0.004180442076176405, Consistency_loss: 0.000669158820528537\n",
      "[Training] Epoch: 37 [=============> ] 90.5% Loss: 0.0511, Epoch 37, Batch 113, CE_loss: 0.04057516157627106, Dice_loss: 0.004209097009152174, Consistency_loss: 0.000655020703561604\n",
      "[Training] Epoch: 37 [=============> ] 91.3% Loss: 0.0512, Epoch 37, Batch 114, CE_loss: 0.057219136506319046, Dice_loss: 0.0065086353570222855, Consistency_loss: 0.0006241505616344512\n",
      "[Training] Epoch: 37 [=============> ] 92.1% Loss: 0.0511, Epoch 37, Batch 115, CE_loss: 0.04226061701774597, Dice_loss: 0.004670955240726471, Consistency_loss: 0.0003543061902746558\n",
      "[Training] Epoch: 37 [=============> ] 92.9% Loss: 0.0510, Epoch 37, Batch 116, CE_loss: 0.036127492785453796, Dice_loss: 0.003833283670246601, Consistency_loss: 5.366132972994819e-05\n",
      "[Training] Epoch: 37 [==============>] 93.7% Loss: 0.0512, Epoch 37, Batch 117, CE_loss: 0.05808361619710922, Dice_loss: 0.006266490090638399, Consistency_loss: 0.0004738699644804001\n",
      "[Training] Epoch: 37 [==============>] 94.4% Loss: 0.0511, Epoch 37, Batch 118, CE_loss: 0.038113340735435486, Dice_loss: 0.004101155791431665, Consistency_loss: 0.00046818709233775735\n",
      "[Training] Epoch: 37 [==============>] 95.2% Loss: 0.0510, Epoch 37, Batch 119, CE_loss: 0.035543110221624374, Dice_loss: 0.0037294107023626566, Consistency_loss: 5.6252705689985305e-05\n",
      "[Training] Epoch: 37 [==============>] 96.0% Loss: 0.0510, Epoch 37, Batch 120, CE_loss: 0.04343023896217346, Dice_loss: 0.00475193141028285, Consistency_loss: 0.0004649277834687382\n",
      "[Training] Epoch: 37 [==============>] 96.8% Loss: 0.0509, Epoch 37, Batch 121, CE_loss: 0.04083498194813728, Dice_loss: 0.004266656935214996, Consistency_loss: 0.00038380210753530264\n",
      "[Training] Epoch: 37 [==============>] 97.6% Loss: 0.0508, Epoch 37, Batch 122, CE_loss: 0.03139472380280495, Dice_loss: 0.0031481848563998938, Consistency_loss: 0.0005713230930268764\n",
      "[Training] Epoch: 37 [==============>] 98.4% Loss: 0.0508, Epoch 37, Batch 123, CE_loss: 0.04376165568828583, Dice_loss: 0.00479474849998951, Consistency_loss: 0.0006848560879006982\n",
      "[Training] Epoch: 37 [==============>] 99.2% Loss: 0.0507, Epoch 37, Batch 124, CE_loss: 0.03312880918383598, Dice_loss: 0.0029179886914789677, Consistency_loss: 0.0006133951828815043\n",
      "[Training] Epoch: 37 [DONE]                                 \n",
      "Epoch 37, Batch 125, CE_loss: 0.04017049819231033, Dice_loss: 0.0042795585468411446, Consistency_loss: 0.0007556478376500309\n",
      "[Validation] Epoch: 37 [DONE]                                 \n",
      "[Epoch: 37, TrainLoss: 0.0506, TrainDice: 0.0048, ValLoss: 0.1395                                            \n",
      "Number of batches:  126\n",
      "[Training] Epoch: 38 [>              ] 0.8% Loss: 0.0449, Epoch 38, Batch 0, CE_loss: 0.040482304990291595, Dice_loss: 0.004363927524536848, Consistency_loss: 5.685994983650744e-05\n",
      "[Training] Epoch: 38 [>              ] 1.6% Loss: 0.0485, Epoch 38, Batch 1, CE_loss: 0.046932533383369446, Dice_loss: 0.004763840232044458, Consistency_loss: 0.00038346010842360556\n",
      "[Training] Epoch: 38 [>              ] 2.4% Loss: 0.0434, Epoch 38, Batch 2, CE_loss: 0.029920605942606926, Dice_loss: 0.0028899596072733402, Consistency_loss: 0.0003035980917047709\n",
      "[Training] Epoch: 38 [>              ] 3.2% Loss: 0.0515, Epoch 38, Batch 3, CE_loss: 0.06803496181964874, Dice_loss: 0.007459509652107954, Consistency_loss: 0.0004481965734157711\n",
      "[Training] Epoch: 38 [>              ] 4.0% Loss: 0.0479, Epoch 38, Batch 4, CE_loss: 0.03004540130496025, Dice_loss: 0.0029567198362201452, Consistency_loss: 0.0005191786913201213\n",
      "[Training] Epoch: 38 [>              ] 4.8% Loss: 0.0481, Epoch 38, Batch 5, CE_loss: 0.04446018487215042, Dice_loss: 0.004473155830055475, Consistency_loss: 0.00013787946954835206\n",
      "[Training] Epoch: 38 [>              ] 5.6% Loss: 0.0496, Epoch 38, Batch 6, CE_loss: 0.05284646153450012, Dice_loss: 0.005699805915355682, Consistency_loss: 0.0002568924392107874\n",
      "[Training] Epoch: 38 [>              ] 6.3% Loss: 0.0499, Epoch 38, Batch 7, CE_loss: 0.04631391912698746, Dice_loss: 0.005107274744659662, Consistency_loss: 0.0002370820875512436\n",
      "[Training] Epoch: 38 [=>             ] 7.1% Loss: 0.0482, Epoch 38, Batch 8, CE_loss: 0.031071949750185013, Dice_loss: 0.0030552151147276163, Consistency_loss: 0.0002769382845144719\n",
      "[Training] Epoch: 38 [=>             ] 7.9% Loss: 0.0490, Epoch 38, Batch 9, CE_loss: 0.051529090851545334, Dice_loss: 0.005038927774876356, Consistency_loss: 0.0002440590033074841\n",
      "[Training] Epoch: 38 [=>             ] 8.7% Loss: 0.0497, Epoch 38, Batch 10, CE_loss: 0.05000259354710579, Dice_loss: 0.0053478870540857315, Consistency_loss: 0.0009520441526547074\n",
      "[Training] Epoch: 38 [=>             ] 9.5% Loss: 0.0487, Epoch 38, Batch 11, CE_loss: 0.0338905043900013, Dice_loss: 0.0035047533456236124, Consistency_loss: 0.0009128862875513732\n",
      "[Training] Epoch: 38 [=>             ] 10.3% Loss: 0.0488, Epoch 38, Batch 12, CE_loss: 0.044349201023578644, Dice_loss: 0.004815647378563881, Consistency_loss: 0.0005041753756813705\n",
      "[Training] Epoch: 38 [=>             ] 11.1% Loss: 0.0502, Epoch 38, Batch 13, CE_loss: 0.060978882014751434, Dice_loss: 0.0066399653442204, Consistency_loss: 0.00041608206811361015\n",
      "[Training] Epoch: 38 [=>             ] 11.9% Loss: 0.0498, Epoch 38, Batch 14, CE_loss: 0.03982323780655861, Dice_loss: 0.0039906129240989685, Consistency_loss: 0.0006190337589941919\n",
      "[Training] Epoch: 38 [=>             ] 12.7% Loss: 0.0500, Epoch 38, Batch 15, CE_loss: 0.047097451984882355, Dice_loss: 0.005028238985687494, Consistency_loss: 0.0002914253273047507\n",
      "[Training] Epoch: 38 [==>            ] 13.5% Loss: 0.0495, Epoch 38, Batch 16, CE_loss: 0.03839898109436035, Dice_loss: 0.003696897765621543, Consistency_loss: 0.00023213772510644048\n",
      "[Training] Epoch: 38 [==>            ] 14.3% Loss: 0.0490, Epoch 38, Batch 17, CE_loss: 0.036396533250808716, Dice_loss: 0.003779961261898279, Consistency_loss: 0.0005230341921560466\n",
      "[Training] Epoch: 38 [==>            ] 15.1% Loss: 0.0490, Epoch 38, Batch 18, CE_loss: 0.04366467520594597, Dice_loss: 0.004840292036533356, Consistency_loss: 0.00042240796028636396\n",
      "[Training] Epoch: 38 [==>            ] 15.9% Loss: 0.0494, Epoch 38, Batch 19, CE_loss: 0.050788115710020065, Dice_loss: 0.0055694375187158585, Consistency_loss: 0.00010301382280886173\n",
      "[Training] Epoch: 38 [==>            ] 16.7% Loss: 0.0487, Epoch 38, Batch 20, CE_loss: 0.03181964159011841, Dice_loss: 0.0032970339525491, Consistency_loss: 0.0003549422253854573\n",
      "[Training] Epoch: 38 [==>            ] 17.5% Loss: 0.0493, Epoch 38, Batch 21, CE_loss: 0.05484598129987717, Dice_loss: 0.006040598731487989, Consistency_loss: 0.000413114350521937\n",
      "[Training] Epoch: 38 [==>            ] 18.3% Loss: 0.0493, Epoch 38, Batch 22, CE_loss: 0.04490543156862259, Dice_loss: 0.004812214057892561, Consistency_loss: 3.787235982599668e-05\n",
      "[Training] Epoch: 38 [==>            ] 19.0% Loss: 0.0494, Epoch 38, Batch 23, CE_loss: 0.04489710181951523, Dice_loss: 0.00477316090837121, Consistency_loss: 0.0005809965659864247\n",
      "[Training] Epoch: 38 [==>            ] 19.8% Loss: 0.0491, Epoch 38, Batch 24, CE_loss: 0.03765521198511124, Dice_loss: 0.0038079367950558662, Consistency_loss: 0.0003194129385519773\n",
      "[Training] Epoch: 38 [===>           ] 20.6% Loss: 0.0489, Epoch 38, Batch 25, CE_loss: 0.04120342805981636, Dice_loss: 0.004197254776954651, Consistency_loss: 0.00021690409630537033\n",
      "[Training] Epoch: 38 [===>           ] 21.4% Loss: 0.0488, Epoch 38, Batch 26, CE_loss: 0.04226447269320488, Dice_loss: 0.004152640700340271, Consistency_loss: 0.00038658632547594607\n",
      "[Training] Epoch: 38 [===>           ] 22.2% Loss: 0.0502, Epoch 38, Batch 27, CE_loss: 0.07689952105283737, Dice_loss: 0.008577656000852585, Consistency_loss: 0.0006051555392332375\n",
      "[Training] Epoch: 38 [===>           ] 23.0% Loss: 0.0496, Epoch 38, Batch 28, CE_loss: 0.030775388702750206, Dice_loss: 0.003138564759865403, Consistency_loss: 0.0003903373726643622\n",
      "[Training] Epoch: 38 [===>           ] 23.8% Loss: 0.0496, Epoch 38, Batch 29, CE_loss: 0.04272123798727989, Dice_loss: 0.004658518824726343, Consistency_loss: 0.0006502268370240927\n",
      "[Training] Epoch: 38 [===>           ] 24.6% Loss: 0.0497, Epoch 38, Batch 30, CE_loss: 0.047091029584407806, Dice_loss: 0.005064261145889759, Consistency_loss: 0.00025293746148236096\n",
      "[Training] Epoch: 38 [===>           ] 25.4% Loss: 0.0496, Epoch 38, Batch 31, CE_loss: 0.04301208630204201, Dice_loss: 0.004710804205387831, Consistency_loss: 0.00021755698253400624\n",
      "[Training] Epoch: 38 [===>           ] 26.2% Loss: 0.0500, Epoch 38, Batch 32, CE_loss: 0.056762006133794785, Dice_loss: 0.0063027446158230305, Consistency_loss: 0.00024029251653701067\n",
      "[Training] Epoch: 38 [====>          ] 27.0% Loss: 0.0496, Epoch 38, Batch 33, CE_loss: 0.032749928534030914, Dice_loss: 0.003013171488419175, Consistency_loss: 5.67425049666781e-05\n",
      "[Training] Epoch: 38 [====>          ] 27.8% Loss: 0.0495, Epoch 38, Batch 34, CE_loss: 0.04104716703295708, Dice_loss: 0.0043172212317585945, Consistency_loss: 0.0009717732900753617\n",
      "[Training] Epoch: 38 [====>          ] 28.6% Loss: 0.0494, Epoch 38, Batch 35, CE_loss: 0.039926812052726746, Dice_loss: 0.004288342781364918, Consistency_loss: 0.0006244422984309494\n",
      "[Training] Epoch: 38 [====>          ] 29.4% Loss: 0.0490, Epoch 38, Batch 36, CE_loss: 0.03258616849780083, Dice_loss: 0.0034154043532907963, Consistency_loss: 0.0005035052890889347\n",
      "[Training] Epoch: 38 [====>          ] 30.2% Loss: 0.0498, Epoch 38, Batch 37, CE_loss: 0.07115568965673447, Dice_loss: 0.007644184399396181, Consistency_loss: 0.0008945660083554685\n",
      "[Training] Epoch: 38 [====>          ] 31.0% Loss: 0.0505, Epoch 38, Batch 38, CE_loss: 0.06650074571371078, Dice_loss: 0.007473819423466921, Consistency_loss: 6.913102697581053e-05\n",
      "[Training] Epoch: 38 [====>          ] 31.7% Loss: 0.0501, Epoch 38, Batch 39, CE_loss: 0.03249993920326233, Dice_loss: 0.0032084539998322725, Consistency_loss: 0.0011735736625269055\n",
      "[Training] Epoch: 38 [====>          ] 32.5% Loss: 0.0505, Epoch 38, Batch 40, CE_loss: 0.05705305561423302, Dice_loss: 0.006332110147923231, Consistency_loss: 6.693416798952967e-05\n",
      "[Training] Epoch: 38 [=====>         ] 33.3% Loss: 0.0500, Epoch 38, Batch 41, CE_loss: 0.027214551344513893, Dice_loss: 0.0026034326292574406, Consistency_loss: 0.0009030470973812044\n",
      "[Training] Epoch: 38 [=====>         ] 34.1% Loss: 0.0501, Epoch 38, Batch 42, CE_loss: 0.048578470945358276, Dice_loss: 0.005417253356426954, Consistency_loss: 0.000887426664121449\n",
      "[Training] Epoch: 38 [=====>         ] 34.9% Loss: 0.0501, Epoch 38, Batch 43, CE_loss: 0.04323356971144676, Dice_loss: 0.004705770406872034, Consistency_loss: 0.00015021406579762697\n",
      "[Training] Epoch: 38 [=====>         ] 35.7% Loss: 0.0506, Epoch 38, Batch 44, CE_loss: 0.06807870417833328, Dice_loss: 0.007280905731022358, Consistency_loss: 0.00010523174569243565\n",
      "[Training] Epoch: 38 [=====>         ] 36.5% Loss: 0.0507, Epoch 38, Batch 45, CE_loss: 0.048898737877607346, Dice_loss: 0.0051606688648462296, Consistency_loss: 3.5048771678702906e-05\n",
      "[Training] Epoch: 38 [=====>         ] 37.3% Loss: 0.0506, Epoch 38, Batch 46, CE_loss: 0.04298947751522064, Dice_loss: 0.004660512786358595, Consistency_loss: 0.0005203986656852067\n",
      "[Training] Epoch: 38 [=====>         ] 38.1% Loss: 0.0505, Epoch 38, Batch 47, CE_loss: 0.04148881882429123, Dice_loss: 0.0045930552296340466, Consistency_loss: 5.656642679241486e-05\n",
      "[Training] Epoch: 38 [=====>         ] 38.9% Loss: 0.0511, Epoch 38, Batch 48, CE_loss: 0.0674927681684494, Dice_loss: 0.007513059768825769, Consistency_loss: 0.0006795861409045756\n",
      "[Training] Epoch: 38 [=====>         ] 39.7% Loss: 0.0508, Epoch 38, Batch 49, CE_loss: 0.033335816115140915, Dice_loss: 0.003550864988937974, Consistency_loss: 0.0002892038901336491\n",
      "[Training] Epoch: 38 [======>        ] 40.5% Loss: 0.0507, Epoch 38, Batch 50, CE_loss: 0.039788998663425446, Dice_loss: 0.004337150137871504, Consistency_loss: 0.0007731496589258313\n",
      "[Training] Epoch: 38 [======>        ] 41.3% Loss: 0.0506, Epoch 38, Batch 51, CE_loss: 0.04009990766644478, Dice_loss: 0.0042027938179671764, Consistency_loss: 0.0007060265052132308\n",
      "[Training] Epoch: 38 [======>        ] 42.1% Loss: 0.0509, Epoch 38, Batch 52, CE_loss: 0.06237724423408508, Dice_loss: 0.006853674538433552, Consistency_loss: 0.00029064202681183815\n",
      "[Training] Epoch: 38 [======>        ] 42.9% Loss: 0.0510, Epoch 38, Batch 53, CE_loss: 0.05014369636774063, Dice_loss: 0.004986070096492767, Consistency_loss: 0.0003255250630900264\n",
      "[Training] Epoch: 38 [======>        ] 43.7% Loss: 0.0509, Epoch 38, Batch 54, CE_loss: 0.04235971346497536, Dice_loss: 0.004579827189445496, Consistency_loss: 4.370801616460085e-05\n",
      "[Training] Epoch: 38 [======>        ] 44.4% Loss: 0.0507, Epoch 38, Batch 55, CE_loss: 0.03561710938811302, Dice_loss: 0.0037509710527956486, Consistency_loss: 7.883663784014061e-05\n",
      "[Training] Epoch: 38 [======>        ] 45.2% Loss: 0.0504, Epoch 38, Batch 56, CE_loss: 0.02994253672659397, Dice_loss: 0.00273378798738122, Consistency_loss: 0.0004653609066735953\n",
      "[Training] Epoch: 38 [======>        ] 46.0% Loss: 0.0504, Epoch 38, Batch 57, CE_loss: 0.04410555958747864, Dice_loss: 0.004780309274792671, Consistency_loss: 0.0004121755191590637\n",
      "[Training] Epoch: 38 [=======>       ] 46.8% Loss: 0.0506, Epoch 38, Batch 58, CE_loss: 0.056435827165842056, Dice_loss: 0.006348949857056141, Consistency_loss: 0.0002850315941032022\n",
      "[Training] Epoch: 38 [=======>       ] 47.6% Loss: 0.0505, Epoch 38, Batch 59, CE_loss: 0.03937019407749176, Dice_loss: 0.0036079781129956245, Consistency_loss: 0.00032368014217354357\n",
      "[Training] Epoch: 38 [=======>       ] 48.4% Loss: 0.0505, Epoch 38, Batch 60, CE_loss: 0.04757637530565262, Dice_loss: 0.005398607347160578, Consistency_loss: 0.000473821914056316\n",
      "[Training] Epoch: 38 [=======>       ] 49.2% Loss: 0.0504, Epoch 38, Batch 61, CE_loss: 0.04032425209879875, Dice_loss: 0.004205802455544472, Consistency_loss: 0.0007586641586385667\n",
      "[Training] Epoch: 38 [=======>       ] 50.0% Loss: 0.0505, Epoch 38, Batch 62, CE_loss: 0.04760335385799408, Dice_loss: 0.00465221144258976, Consistency_loss: 0.0009247250854969025\n",
      "[Training] Epoch: 38 [=======>       ] 50.8% Loss: 0.0504, Epoch 38, Batch 63, CE_loss: 0.041233040392398834, Dice_loss: 0.004570238292217255, Consistency_loss: 0.0009270960581488907\n",
      "[Training] Epoch: 38 [=======>       ] 51.6% Loss: 0.0504, Epoch 38, Batch 64, CE_loss: 0.04397610202431679, Dice_loss: 0.004870686214417219, Consistency_loss: 0.0010473168222233653\n",
      "[Training] Epoch: 38 [=======>       ] 52.4% Loss: 0.0505, Epoch 38, Batch 65, CE_loss: 0.05098624527454376, Dice_loss: 0.005190195515751839, Consistency_loss: 0.0008080275729298592\n",
      "[Training] Epoch: 38 [=======>       ] 53.2% Loss: 0.0502, Epoch 38, Batch 66, CE_loss: 0.02765968069434166, Dice_loss: 0.002811156213283539, Consistency_loss: 0.00046095167635940015\n",
      "[Training] Epoch: 38 [========>      ] 54.0% Loss: 0.0500, Epoch 38, Batch 67, CE_loss: 0.030071595683693886, Dice_loss: 0.003049117513000965, Consistency_loss: 0.0005022073164582253\n",
      "[Training] Epoch: 38 [========>      ] 54.8% Loss: 0.0502, Epoch 38, Batch 68, CE_loss: 0.05740921571850777, Dice_loss: 0.0063900817185640335, Consistency_loss: 2.871510514523834e-05\n",
      "[Training] Epoch: 38 [========>      ] 55.6% Loss: 0.0505, Epoch 38, Batch 69, CE_loss: 0.06191280484199524, Dice_loss: 0.006977690849453211, Consistency_loss: 0.0003613043518271297\n",
      "[Training] Epoch: 38 [========>      ] 56.3% Loss: 0.0504, Epoch 38, Batch 70, CE_loss: 0.04029126092791557, Dice_loss: 0.004415327683091164, Consistency_loss: 0.0012870149221271276\n",
      "[Training] Epoch: 38 [========>      ] 57.1% Loss: 0.0502, Epoch 38, Batch 71, CE_loss: 0.03540612757205963, Dice_loss: 0.0038187282625585794, Consistency_loss: 8.122840517899022e-05\n",
      "[Training] Epoch: 38 [========>      ] 57.9% Loss: 0.0502, Epoch 38, Batch 72, CE_loss: 0.04349358752369881, Dice_loss: 0.004809017758816481, Consistency_loss: 0.0005545406602323055\n",
      "[Training] Epoch: 38 [========>      ] 58.7% Loss: 0.0503, Epoch 38, Batch 73, CE_loss: 0.047403834760189056, Dice_loss: 0.0053054229356348515, Consistency_loss: 0.0008873793412931263\n",
      "[Training] Epoch: 38 [========>      ] 59.5% Loss: 0.0502, Epoch 38, Batch 74, CE_loss: 0.038415223360061646, Dice_loss: 0.0036534012760967016, Consistency_loss: 0.0011990630300715566\n",
      "[Training] Epoch: 38 [=========>     ] 60.3% Loss: 0.0501, Epoch 38, Batch 75, CE_loss: 0.041283588856458664, Dice_loss: 0.004537095315754414, Consistency_loss: 0.0011296075535938144\n",
      "[Training] Epoch: 38 [=========>     ] 61.1% Loss: 0.0501, Epoch 38, Batch 76, CE_loss: 0.044506244361400604, Dice_loss: 0.004898120649158955, Consistency_loss: 0.0004861963971052319\n",
      "[Training] Epoch: 38 [=========>     ] 61.9% Loss: 0.0500, Epoch 38, Batch 77, CE_loss: 0.03853735700249672, Dice_loss: 0.004068410489708185, Consistency_loss: 0.0010087470291182399\n",
      "[Training] Epoch: 38 [=========>     ] 62.7% Loss: 0.0504, Epoch 38, Batch 78, CE_loss: 0.06755254417657852, Dice_loss: 0.007688342127948999, Consistency_loss: 0.0005871811881661415\n",
      "[Training] Epoch: 38 [=========>     ] 63.5% Loss: 0.0503, Epoch 38, Batch 79, CE_loss: 0.041317082941532135, Dice_loss: 0.004530926235020161, Consistency_loss: 0.00016284761659335345\n",
      "[Training] Epoch: 38 [=========>     ] 64.3% Loss: 0.0503, Epoch 38, Batch 80, CE_loss: 0.04028068855404854, Dice_loss: 0.004272383637726307, Consistency_loss: 0.0002495846420060843\n",
      "[Training] Epoch: 38 [=========>     ] 65.1% Loss: 0.0501, Epoch 38, Batch 81, CE_loss: 0.03489403426647186, Dice_loss: 0.0038061486557126045, Consistency_loss: 0.0010776784038171172\n",
      "[Training] Epoch: 38 [=========>     ] 65.9% Loss: 0.0499, Epoch 38, Batch 82, CE_loss: 0.026373637840151787, Dice_loss: 0.002519609173759818, Consistency_loss: 0.001047062803991139\n",
      "[Training] Epoch: 38 [==========>    ] 66.7% Loss: 0.0497, Epoch 38, Batch 83, CE_loss: 0.031549565494060516, Dice_loss: 0.003277480835095048, Consistency_loss: 5.5007298215059564e-05\n",
      "[Training] Epoch: 38 [==========>    ] 67.5% Loss: 0.0497, Epoch 38, Batch 84, CE_loss: 0.04510630667209625, Dice_loss: 0.004680025856941938, Consistency_loss: 0.00022431362594943494\n",
      "[Training] Epoch: 38 [==========>    ] 68.3% Loss: 0.0494, Epoch 38, Batch 85, CE_loss: 0.02428358979523182, Dice_loss: 0.0023029313888400793, Consistency_loss: 0.000967781525105238\n",
      "[Training] Epoch: 38 [==========>    ] 69.0% Loss: 0.0495, Epoch 38, Batch 86, CE_loss: 0.04927380755543709, Dice_loss: 0.005158603191375732, Consistency_loss: 8.160204743035138e-05\n",
      "[Training] Epoch: 38 [==========>    ] 69.8% Loss: 0.0499, Epoch 38, Batch 87, CE_loss: 0.07392234355211258, Dice_loss: 0.007995840162038803, Consistency_loss: 7.078747876221314e-05\n",
      "[Training] Epoch: 38 [==========>    ] 70.6% Loss: 0.0498, Epoch 38, Batch 88, CE_loss: 0.038291990756988525, Dice_loss: 0.003992937505245209, Consistency_loss: 0.0003506191715132445\n",
      "[Training] Epoch: 38 [==========>    ] 71.4% Loss: 0.0497, Epoch 38, Batch 89, CE_loss: 0.03851271793246269, Dice_loss: 0.004182914271950722, Consistency_loss: 0.00038418290205299854\n",
      "[Training] Epoch: 38 [==========>    ] 72.2% Loss: 0.0498, Epoch 38, Batch 90, CE_loss: 0.0525292232632637, Dice_loss: 0.005845691543072462, Consistency_loss: 0.0009173848084174097\n",
      "[Training] Epoch: 38 [==========>    ] 73.0% Loss: 0.0497, Epoch 38, Batch 91, CE_loss: 0.037352509796619415, Dice_loss: 0.004017739091068506, Consistency_loss: 0.0009881261503323913\n",
      "[Training] Epoch: 38 [===========>   ] 73.8% Loss: 0.0497, Epoch 38, Batch 92, CE_loss: 0.04198965057730675, Dice_loss: 0.004198444075882435, Consistency_loss: 8.734220318729058e-05\n",
      "[Training] Epoch: 38 [===========>   ] 74.6% Loss: 0.0499, Epoch 38, Batch 93, CE_loss: 0.06255996972322464, Dice_loss: 0.006789856124669313, Consistency_loss: 0.0008725767838768661\n",
      "[Training] Epoch: 38 [===========>   ] 75.4% Loss: 0.0499, Epoch 38, Batch 94, CE_loss: 0.04305562376976013, Dice_loss: 0.004646127112209797, Consistency_loss: 5.629409133689478e-05\n",
      "[Training] Epoch: 38 [===========>   ] 76.2% Loss: 0.0501, Epoch 38, Batch 95, CE_loss: 0.058513350784778595, Dice_loss: 0.006574635393917561, Consistency_loss: 0.0007168774609453976\n",
      "[Training] Epoch: 38 [===========>   ] 77.0% Loss: 0.0501, Epoch 38, Batch 96, CE_loss: 0.04703494906425476, Dice_loss: 0.005234407261013985, Consistency_loss: 0.00034322016290389\n",
      "[Training] Epoch: 38 [===========>   ] 77.8% Loss: 0.0500, Epoch 38, Batch 97, CE_loss: 0.03983185067772865, Dice_loss: 0.004263648763298988, Consistency_loss: 0.00030190087272785604\n",
      "[Training] Epoch: 38 [===========>   ] 78.6% Loss: 0.0501, Epoch 38, Batch 98, CE_loss: 0.053985871374607086, Dice_loss: 0.006122875493019819, Consistency_loss: 0.00039559975266456604\n",
      "[Training] Epoch: 38 [===========>   ] 79.4% Loss: 0.0502, Epoch 38, Batch 99, CE_loss: 0.05335526168346405, Dice_loss: 0.0053102197125554085, Consistency_loss: 0.0005010372260585427\n",
      "[Training] Epoch: 38 [============>  ] 80.2% Loss: 0.0501, Epoch 38, Batch 100, CE_loss: 0.029668008908629417, Dice_loss: 0.0030602619517594576, Consistency_loss: 0.0003495813289191574\n",
      "[Training] Epoch: 38 [============>  ] 81.0% Loss: 0.0501, Epoch 38, Batch 101, CE_loss: 0.050029776990413666, Dice_loss: 0.005683158524334431, Consistency_loss: 0.0007396206492558122\n",
      "[Training] Epoch: 38 [============>  ] 81.7% Loss: 0.0502, Epoch 38, Batch 102, CE_loss: 0.05007351189851761, Dice_loss: 0.005558726377785206, Consistency_loss: 0.0008940268307924271\n",
      "[Training] Epoch: 38 [============>  ] 82.5% Loss: 0.0501, Epoch 38, Batch 103, CE_loss: 0.03956738859415054, Dice_loss: 0.004307301715016365, Consistency_loss: 0.0008707164088264108\n",
      "[Training] Epoch: 38 [============>  ] 83.3% Loss: 0.0500, Epoch 38, Batch 104, CE_loss: 0.029533278197050095, Dice_loss: 0.0029493840411305428, Consistency_loss: 0.0005230485112406313\n",
      "[Training] Epoch: 38 [============>  ] 84.1% Loss: 0.0499, Epoch 38, Batch 105, CE_loss: 0.03973823040723801, Dice_loss: 0.004372291266918182, Consistency_loss: 0.00029331198311410844\n",
      "[Training] Epoch: 38 [============>  ] 84.9% Loss: 0.0499, Epoch 38, Batch 106, CE_loss: 0.045252203941345215, Dice_loss: 0.005086952820420265, Consistency_loss: 0.0012122491607442498\n",
      "[Training] Epoch: 38 [============>  ] 85.7% Loss: 0.0498, Epoch 38, Batch 107, CE_loss: 0.03504542261362076, Dice_loss: 0.003730260068550706, Consistency_loss: 0.00108465610537678\n",
      "[Training] Epoch: 38 [============>  ] 86.5% Loss: 0.0498, Epoch 38, Batch 108, CE_loss: 0.03688640147447586, Dice_loss: 0.0039510056376457214, Consistency_loss: 6.912909157108516e-05\n",
      "[Training] Epoch: 38 [=============> ] 87.3% Loss: 0.0498, Epoch 38, Batch 109, CE_loss: 0.045548006892204285, Dice_loss: 0.005153752863407135, Consistency_loss: 0.00034903539926745\n",
      "[Training] Epoch: 38 [=============> ] 88.1% Loss: 0.0496, Epoch 38, Batch 110, CE_loss: 0.0311767365783453, Dice_loss: 0.003309314139187336, Consistency_loss: 7.335209375014529e-05\n",
      "[Training] Epoch: 38 [=============> ] 88.9% Loss: 0.0497, Epoch 38, Batch 111, CE_loss: 0.04888307675719261, Dice_loss: 0.00539361871778965, Consistency_loss: 0.0005763379158452153\n",
      "[Training] Epoch: 38 [=============> ] 89.7% Loss: 0.0497, Epoch 38, Batch 112, CE_loss: 0.0476006418466568, Dice_loss: 0.005248837172985077, Consistency_loss: 0.0007531687733717263\n",
      "[Training] Epoch: 38 [=============> ] 90.5% Loss: 0.0497, Epoch 38, Batch 113, CE_loss: 0.042542897164821625, Dice_loss: 0.004708890803158283, Consistency_loss: 0.0007272543734870851\n",
      "[Training] Epoch: 38 [=============> ] 91.3% Loss: 0.0498, Epoch 38, Batch 114, CE_loss: 0.05077793076634407, Dice_loss: 0.005899509880691767, Consistency_loss: 7.091229053912684e-05\n",
      "[Training] Epoch: 38 [=============> ] 92.1% Loss: 0.0497, Epoch 38, Batch 115, CE_loss: 0.034501273185014725, Dice_loss: 0.003755758749321103, Consistency_loss: 0.0004875198064837605\n",
      "[Training] Epoch: 38 [=============> ] 92.9% Loss: 0.0496, Epoch 38, Batch 116, CE_loss: 0.03678848221898079, Dice_loss: 0.003813645336776972, Consistency_loss: 0.0005668690428137779\n",
      "[Training] Epoch: 38 [==============>] 93.7% Loss: 0.0496, Epoch 38, Batch 117, CE_loss: 0.04899314045906067, Dice_loss: 0.005620908923447132, Consistency_loss: 0.0004879082553088665\n",
      "[Training] Epoch: 38 [==============>] 94.4% Loss: 0.0497, Epoch 38, Batch 118, CE_loss: 0.047101836651563644, Dice_loss: 0.005269946530461311, Consistency_loss: 7.11987740942277e-05\n",
      "[Training] Epoch: 38 [==============>] 95.2% Loss: 0.0497, Epoch 38, Batch 119, CE_loss: 0.05326148122549057, Dice_loss: 0.0059705572202801704, Consistency_loss: 0.0005908971652388573\n",
      "[Training] Epoch: 38 [==============>] 96.0% Loss: 0.0497, Epoch 38, Batch 120, CE_loss: 0.03424743562936783, Dice_loss: 0.003663937794044614, Consistency_loss: 0.00018081713642459363\n",
      "[Training] Epoch: 38 [==============>] 96.8% Loss: 0.0495, Epoch 38, Batch 121, CE_loss: 0.029053200036287308, Dice_loss: 0.002956438111141324, Consistency_loss: 0.0005979185807518661\n",
      "[Training] Epoch: 38 [==============>] 97.6% Loss: 0.0494, Epoch 38, Batch 122, CE_loss: 0.03638521209359169, Dice_loss: 0.004039107356220484, Consistency_loss: 0.0005966969765722752\n",
      "[Training] Epoch: 38 [==============>] 98.4% Loss: 0.0494, Epoch 38, Batch 123, CE_loss: 0.04337567836046219, Dice_loss: 0.004804292693734169, Consistency_loss: 0.0009638257324695587\n",
      "[Training] Epoch: 38 [==============>] 99.2% Loss: 0.0494, Epoch 38, Batch 124, CE_loss: 0.041974473744630814, Dice_loss: 0.004173803608864546, Consistency_loss: 0.0009270597365684807\n",
      "[Training] Epoch: 38 [DONE]                                 \n",
      "Epoch 38, Batch 125, CE_loss: 0.035736940801143646, Dice_loss: 0.00390795199200511, Consistency_loss: 0.00016705594316590577\n",
      "[Validation] Epoch: 38 [DONE]                                 \n",
      "[Epoch: 38, TrainLoss: 0.0493, TrainDice: 0.0047, ValLoss: 0.1256                                            \n",
      "Number of batches:  126\n",
      "[Training] Epoch: 39 [>              ] 0.8% Loss: 0.0443, Epoch 39, Batch 0, CE_loss: 0.039376407861709595, Dice_loss: 0.00440366892144084, Consistency_loss: 0.0004987448919564486\n",
      "[Training] Epoch: 39 [>              ] 1.6% Loss: 0.0411, Epoch 39, Batch 1, CE_loss: 0.03419492021203041, Dice_loss: 0.003273734590038657, Consistency_loss: 0.00052234111353755\n",
      "[Training] Epoch: 39 [>              ] 2.4% Loss: 0.0448, Epoch 39, Batch 2, CE_loss: 0.046509865671396255, Dice_loss: 0.00521676242351532, Consistency_loss: 0.0005302149802446365\n",
      "[Training] Epoch: 39 [>              ] 3.2% Loss: 0.0475, Epoch 39, Batch 3, CE_loss: 0.04989418759942055, Dice_loss: 0.005103600211441517, Consistency_loss: 0.0006047603092156351\n",
      "[Training] Epoch: 39 [>              ] 4.0% Loss: 0.0494, Epoch 39, Batch 4, CE_loss: 0.05031951889395714, Dice_loss: 0.00573740154504776, Consistency_loss: 0.0006734855705872178\n",
      "[Training] Epoch: 39 [>              ] 4.8% Loss: 0.0472, Epoch 39, Batch 5, CE_loss: 0.03274653106927872, Dice_loss: 0.0034741894342005253, Consistency_loss: 2.6609011911205016e-05\n",
      "[Training] Epoch: 39 [>              ] 5.6% Loss: 0.0453, Epoch 39, Batch 6, CE_loss: 0.03059650957584381, Dice_loss: 0.003211069153621793, Consistency_loss: 0.00036369278677739203\n",
      "[Training] Epoch: 39 [>              ] 6.3% Loss: 0.0483, Epoch 39, Batch 7, CE_loss: 0.06159612908959389, Dice_loss: 0.0071129146963357925, Consistency_loss: 0.0002458865928929299\n",
      "[Training] Epoch: 39 [=>             ] 7.1% Loss: 0.0482, Epoch 39, Batch 8, CE_loss: 0.04280184581875801, Dice_loss: 0.004723455291241407, Consistency_loss: 0.00036278399056755006\n",
      "[Training] Epoch: 39 [=>             ] 7.9% Loss: 0.0482, Epoch 39, Batch 9, CE_loss: 0.04280884936451912, Dice_loss: 0.004757814109325409, Consistency_loss: 0.0002796293410938233\n",
      "[Training] Epoch: 39 [=>             ] 8.7% Loss: 0.0470, Epoch 39, Batch 10, CE_loss: 0.030915861949324608, Dice_loss: 0.003162404987961054, Consistency_loss: 0.0011553181102499366\n",
      "[Training] Epoch: 39 [=>             ] 9.5% Loss: 0.0467, Epoch 39, Batch 11, CE_loss: 0.03892893344163895, Dice_loss: 0.004000591114163399, Consistency_loss: 0.0007571022142656147\n",
      "[Training] Epoch: 39 [=>             ] 10.3% Loss: 0.0463, Epoch 39, Batch 12, CE_loss: 0.035871315747499466, Dice_loss: 0.0038645670283585787, Consistency_loss: 0.001163397915661335\n",
      "[Training] Epoch: 39 [=>             ] 11.1% Loss: 0.0463, Epoch 39, Batch 13, CE_loss: 0.040794990956783295, Dice_loss: 0.004452122841030359, Consistency_loss: 0.0009378352551721036\n",
      "[Training] Epoch: 39 [=>             ] 11.9% Loss: 0.0463, Epoch 39, Batch 14, CE_loss: 0.0413774810731411, Dice_loss: 0.004598853178322315, Consistency_loss: 0.0008277594461105764\n",
      "[Training] Epoch: 39 [=>             ] 12.7% Loss: 0.0467, Epoch 39, Batch 15, CE_loss: 0.046663798391819, Dice_loss: 0.0048771146684885025, Consistency_loss: 0.0004120005469303578\n",
      "[Training] Epoch: 39 [==>            ] 13.5% Loss: 0.0466, Epoch 39, Batch 16, CE_loss: 0.04094130918383598, Dice_loss: 0.004533693194389343, Consistency_loss: 0.0003273833717685193\n",
      "[Training] Epoch: 39 [==>            ] 14.3% Loss: 0.0468, Epoch 39, Batch 17, CE_loss: 0.04339905083179474, Dice_loss: 0.004847628064453602, Consistency_loss: 0.0008252562838606536\n",
      "[Training] Epoch: 39 [==>            ] 15.1% Loss: 0.0466, Epoch 39, Batch 18, CE_loss: 0.038543764501810074, Dice_loss: 0.004169892054051161, Consistency_loss: 0.0007649637991562486\n",
      "[Training] Epoch: 39 [==>            ] 15.9% Loss: 0.0469, Epoch 39, Batch 19, CE_loss: 0.04669273644685745, Dice_loss: 0.005053237080574036, Consistency_loss: 0.0004886715323664248\n",
      "[Training] Epoch: 39 [==>            ] 16.7% Loss: 0.0468, Epoch 39, Batch 20, CE_loss: 0.04087291285395622, Dice_loss: 0.004553456790745258, Consistency_loss: 0.0005883564590476453\n",
      "[Training] Epoch: 39 [==>            ] 17.5% Loss: 0.0462, Epoch 39, Batch 21, CE_loss: 0.029836520552635193, Dice_loss: 0.002651350339874625, Consistency_loss: 0.0004069340939167887\n",
      "[Training] Epoch: 39 [==>            ] 18.3% Loss: 0.0466, Epoch 39, Batch 22, CE_loss: 0.050420165061950684, Dice_loss: 0.005313384812325239, Consistency_loss: 0.0006830365746282041\n",
      "[Training] Epoch: 39 [==>            ] 19.0% Loss: 0.0466, Epoch 39, Batch 23, CE_loss: 0.041854240000247955, Dice_loss: 0.004736754577606916, Consistency_loss: 0.0002445825084578246\n",
      "[Training] Epoch: 39 [==>            ] 19.8% Loss: 0.0465, Epoch 39, Batch 24, CE_loss: 0.03917965292930603, Dice_loss: 0.00420401431620121, Consistency_loss: 0.00015876989345997572\n",
      "[Training] Epoch: 39 [===>           ] 20.6% Loss: 0.0463, Epoch 39, Batch 25, CE_loss: 0.03614603355526924, Dice_loss: 0.004101285710930824, Consistency_loss: 0.00027762542595155537\n",
      "[Training] Epoch: 39 [===>           ] 21.4% Loss: 0.0463, Epoch 39, Batch 26, CE_loss: 0.040665701031684875, Dice_loss: 0.004440495744347572, Consistency_loss: 0.00011009309673681855\n",
      "[Training] Epoch: 39 [===>           ] 22.2% Loss: 0.0459, Epoch 39, Batch 27, CE_loss: 0.03240916132926941, Dice_loss: 0.003167796181514859, Consistency_loss: 0.0005367744015529752\n",
      "[Training] Epoch: 39 [===>           ] 23.0% Loss: 0.0459, Epoch 39, Batch 28, CE_loss: 0.04056412726640701, Dice_loss: 0.004488681443035603, Consistency_loss: 0.0002106915198964998\n",
      "[Training] Epoch: 39 [===>           ] 23.8% Loss: 0.0458, Epoch 39, Batch 29, CE_loss: 0.039906010031700134, Dice_loss: 0.004315683618187904, Consistency_loss: 0.0003228686691727489\n",
      "[Training] Epoch: 39 [===>           ] 24.6% Loss: 0.0458, Epoch 39, Batch 30, CE_loss: 0.0390031524002552, Dice_loss: 0.004041579551994801, Consistency_loss: 0.0005818141507916152\n",
      "[Training] Epoch: 39 [===>           ] 25.4% Loss: 0.0455, Epoch 39, Batch 31, CE_loss: 0.03504408895969391, Dice_loss: 0.0038263278547674417, Consistency_loss: 0.00017063895938917994\n",
      "[Training] Epoch: 39 [===>           ] 26.2% Loss: 0.0461, Epoch 39, Batch 32, CE_loss: 0.058066848665475845, Dice_loss: 0.006213735323399305, Consistency_loss: 0.0002841739042196423\n",
      "[Training] Epoch: 39 [====>          ] 27.0% Loss: 0.0465, Epoch 39, Batch 33, CE_loss: 0.0518660843372345, Dice_loss: 0.00594421336427331, Consistency_loss: 0.0009990707039833069\n",
      "[Training] Epoch: 39 [====>          ] 27.8% Loss: 0.0468, Epoch 39, Batch 34, CE_loss: 0.053075410425662994, Dice_loss: 0.005546942353248596, Consistency_loss: 4.23132223659195e-05\n",
      "[Training] Epoch: 39 [====>          ] 28.6% Loss: 0.0463, Epoch 39, Batch 35, CE_loss: 0.025249717757105827, Dice_loss: 0.002083316445350647, Consistency_loss: 0.0006759045645594597\n",
      "[Training] Epoch: 39 [====>          ] 29.4% Loss: 0.0460, Epoch 39, Batch 36, CE_loss: 0.032049596309661865, Dice_loss: 0.0034386233892291784, Consistency_loss: 0.0003251946181990206\n",
      "[Training] Epoch: 39 [====>          ] 30.2% Loss: 0.0465, Epoch 39, Batch 37, CE_loss: 0.057798270136117935, Dice_loss: 0.006441584322601557, Consistency_loss: 0.0006227869889698923\n",
      "[Training] Epoch: 39 [====>          ] 31.0% Loss: 0.0463, Epoch 39, Batch 38, CE_loss: 0.033619556576013565, Dice_loss: 0.0036492394283413887, Consistency_loss: 0.00010959590872516856\n",
      "[Training] Epoch: 39 [====>          ] 31.7% Loss: 0.0461, Epoch 39, Batch 39, CE_loss: 0.034908317029476166, Dice_loss: 0.003857253585010767, Consistency_loss: 0.0012714891927316785\n",
      "[Training] Epoch: 39 [====>          ] 32.5% Loss: 0.0462, Epoch 39, Batch 40, CE_loss: 0.04397475719451904, Dice_loss: 0.004893167410045862, Consistency_loss: 0.0006697391509078443\n",
      "[Training] Epoch: 39 [=====>         ] 33.3% Loss: 0.0461, Epoch 39, Batch 41, CE_loss: 0.035588182508945465, Dice_loss: 0.003987474832683802, Consistency_loss: 0.0008229539962485433\n",
      "[Training] Epoch: 39 [=====>         ] 34.1% Loss: 0.0463, Epoch 39, Batch 42, CE_loss: 0.048752352595329285, Dice_loss: 0.005132018122822046, Consistency_loss: 0.0010420557809993625\n",
      "[Training] Epoch: 39 [=====>         ] 34.9% Loss: 0.0463, Epoch 39, Batch 43, CE_loss: 0.04134310036897659, Dice_loss: 0.004512968938797712, Consistency_loss: 0.0001892659638542682\n",
      "[Training] Epoch: 39 [=====>         ] 35.7% Loss: 0.0465, Epoch 39, Batch 44, CE_loss: 0.049034472554922104, Dice_loss: 0.0051878392696380615, Consistency_loss: 0.000793325889389962\n",
      "[Training] Epoch: 39 [=====>         ] 36.5% Loss: 0.0468, Epoch 39, Batch 45, CE_loss: 0.054447293281555176, Dice_loss: 0.0059461938217282295, Consistency_loss: 0.0005486852605827153\n",
      "[Training] Epoch: 39 [=====>         ] 37.3% Loss: 0.0468, Epoch 39, Batch 46, CE_loss: 0.04025302082300186, Dice_loss: 0.004460321739315987, Consistency_loss: 0.00018406761228106916\n",
      "[Training] Epoch: 39 [=====>         ] 38.1% Loss: 0.0473, Epoch 39, Batch 47, CE_loss: 0.06624764204025269, Dice_loss: 0.007370540872216225, Consistency_loss: 0.0008496000664308667\n",
      "[Training] Epoch: 39 [=====>         ] 38.9% Loss: 0.0473, Epoch 39, Batch 48, CE_loss: 0.04267638921737671, Dice_loss: 0.004806326702237129, Consistency_loss: 0.0006841432768851519\n",
      "[Training] Epoch: 39 [=====>         ] 39.7% Loss: 0.0473, Epoch 39, Batch 49, CE_loss: 0.04212729632854462, Dice_loss: 0.00468218931928277, Consistency_loss: 9.241272346116602e-05\n",
      "[Training] Epoch: 39 [======>        ] 40.5% Loss: 0.0475, Epoch 39, Batch 50, CE_loss: 0.0478317067027092, Dice_loss: 0.005096908193081617, Consistency_loss: 0.0010964706307277083\n",
      "[Training] Epoch: 39 [======>        ] 41.3% Loss: 0.0474, Epoch 39, Batch 51, CE_loss: 0.0371529757976532, Dice_loss: 0.00395832397043705, Consistency_loss: 0.0005974340601824224\n",
      "[Training] Epoch: 39 [======>        ] 42.1% Loss: 0.0471, Epoch 39, Batch 52, CE_loss: 0.0314987376332283, Dice_loss: 0.0030217634048312902, Consistency_loss: 0.00023865171533543617\n",
      "[Training] Epoch: 39 [======>        ] 42.9% Loss: 0.0469, Epoch 39, Batch 53, CE_loss: 0.030581418424844742, Dice_loss: 0.0031545953825116158, Consistency_loss: 4.364401684142649e-05\n",
      "[Training] Epoch: 39 [======>        ] 43.7% Loss: 0.0468, Epoch 39, Batch 54, CE_loss: 0.03735003247857094, Dice_loss: 0.003823869163170457, Consistency_loss: 4.672373688663356e-05\n",
      "[Training] Epoch: 39 [======>        ] 44.4% Loss: 0.0468, Epoch 39, Batch 55, CE_loss: 0.04333724454045296, Dice_loss: 0.00497220316901803, Consistency_loss: 7.842851482564583e-05\n",
      "[Training] Epoch: 39 [======>        ] 45.2% Loss: 0.0467, Epoch 39, Batch 56, CE_loss: 0.03631652519106865, Dice_loss: 0.0037706540897488594, Consistency_loss: 0.000600573664996773\n",
      "[Training] Epoch: 39 [======>        ] 46.0% Loss: 0.0472, Epoch 39, Batch 57, CE_loss: 0.0667579174041748, Dice_loss: 0.007274169009178877, Consistency_loss: 0.00036584000918082893\n",
      "[Training] Epoch: 39 [=======>       ] 46.8% Loss: 0.0472, Epoch 39, Batch 58, CE_loss: 0.04229842126369476, Dice_loss: 0.004795691464096308, Consistency_loss: 0.00030386444996111095\n",
      "[Training] Epoch: 39 [=======>       ] 47.6% Loss: 0.0470, Epoch 39, Batch 59, CE_loss: 0.03232165798544884, Dice_loss: 0.003518374403938651, Consistency_loss: 0.00043962799827568233\n",
      "[Training] Epoch: 39 [=======>       ] 48.4% Loss: 0.0471, Epoch 39, Batch 60, CE_loss: 0.047014255076646805, Dice_loss: 0.005442376714199781, Consistency_loss: 0.000761499919462949\n",
      "[Training] Epoch: 39 [=======>       ] 49.2% Loss: 0.0470, Epoch 39, Batch 61, CE_loss: 0.03524643927812576, Dice_loss: 0.003677138825878501, Consistency_loss: 0.0007572178146801889\n",
      "[Training] Epoch: 39 [=======>       ] 50.0% Loss: 0.0468, Epoch 39, Batch 62, CE_loss: 0.029952561482787132, Dice_loss: 0.0031299502588808537, Consistency_loss: 0.0010375106940045953\n",
      "[Training] Epoch: 39 [=======>       ] 50.8% Loss: 0.0469, Epoch 39, Batch 63, CE_loss: 0.04849538207054138, Dice_loss: 0.0055069150403141975, Consistency_loss: 0.0010144234402105212\n",
      "[Training] Epoch: 39 [=======>       ] 51.6% Loss: 0.0470, Epoch 39, Batch 64, CE_loss: 0.04891249164938927, Dice_loss: 0.004586210940033197, Consistency_loss: 8.388508285861462e-05\n",
      "[Training] Epoch: 39 [=======>       ] 52.4% Loss: 0.0470, Epoch 39, Batch 65, CE_loss: 0.040289055556058884, Dice_loss: 0.004429976921528578, Consistency_loss: 0.0009338571107946336\n",
      "[Training] Epoch: 39 [=======>       ] 53.2% Loss: 0.0468, Epoch 39, Batch 66, CE_loss: 0.029217008501291275, Dice_loss: 0.003134156810119748, Consistency_loss: 5.106681419420056e-05\n",
      "[Training] Epoch: 39 [========>      ] 54.0% Loss: 0.0467, Epoch 39, Batch 67, CE_loss: 0.040081366896629333, Dice_loss: 0.004572947509586811, Consistency_loss: 0.0004801602044608444\n",
      "[Training] Epoch: 39 [========>      ] 54.8% Loss: 0.0468, Epoch 39, Batch 68, CE_loss: 0.04574974253773689, Dice_loss: 0.005191026721149683, Consistency_loss: 0.000539298343937844\n",
      "[Training] Epoch: 39 [========>      ] 55.6% Loss: 0.0468, Epoch 39, Batch 69, CE_loss: 0.040123362094163895, Dice_loss: 0.004405005369335413, Consistency_loss: 7.112868479453027e-05\n",
      "[Training] Epoch: 39 [========>      ] 56.3% Loss: 0.0469, Epoch 39, Batch 70, CE_loss: 0.045618023723363876, Dice_loss: 0.005138603039085865, Consistency_loss: 0.0013024909421801567\n",
      "[Training] Epoch: 39 [========>      ] 57.1% Loss: 0.0470, Epoch 39, Batch 71, CE_loss: 0.048441920429468155, Dice_loss: 0.005609089508652687, Consistency_loss: 0.0011640622979030013\n",
      "[Training] Epoch: 39 [========>      ] 57.9% Loss: 0.0469, Epoch 39, Batch 72, CE_loss: 0.04066763073205948, Dice_loss: 0.0044730305671691895, Consistency_loss: 5.422916729003191e-05\n",
      "[Training] Epoch: 39 [========>      ] 58.7% Loss: 0.0469, Epoch 39, Batch 73, CE_loss: 0.04217226803302765, Dice_loss: 0.004232932813465595, Consistency_loss: 0.0001815286959754303\n",
      "[Training] Epoch: 39 [========>      ] 59.5% Loss: 0.0470, Epoch 39, Batch 74, CE_loss: 0.04578416422009468, Dice_loss: 0.0051039354875683784, Consistency_loss: 0.00123660359531641\n",
      "[Training] Epoch: 39 [=========>     ] 60.3% Loss: 0.0470, Epoch 39, Batch 75, CE_loss: 0.0391046404838562, Dice_loss: 0.004349644761532545, Consistency_loss: 0.0013599906815215945\n",
      "[Training] Epoch: 39 [=========>     ] 61.1% Loss: 0.0469, Epoch 39, Batch 76, CE_loss: 0.0363483801484108, Dice_loss: 0.0040235863998532295, Consistency_loss: 0.0006318417144939303\n",
      "[Training] Epoch: 39 [=========>     ] 61.9% Loss: 0.0469, Epoch 39, Batch 77, CE_loss: 0.042182497680187225, Dice_loss: 0.004673284478485584, Consistency_loss: 0.0010915504535660148\n",
      "[Training] Epoch: 39 [=========>     ] 62.7% Loss: 0.0470, Epoch 39, Batch 78, CE_loss: 0.04756178706884384, Dice_loss: 0.005322034936398268, Consistency_loss: 6.277604552451521e-05\n",
      "[Training] Epoch: 39 [=========>     ] 63.5% Loss: 0.0471, Epoch 39, Batch 79, CE_loss: 0.0490042045712471, Dice_loss: 0.0055125923827290535, Consistency_loss: 8.087290188996121e-05\n",
      "[Training] Epoch: 39 [=========>     ] 64.3% Loss: 0.0472, Epoch 39, Batch 80, CE_loss: 0.05161295086145401, Dice_loss: 0.005170767195522785, Consistency_loss: 0.000410192966228351\n",
      "[Training] Epoch: 39 [=========>     ] 65.1% Loss: 0.0473, Epoch 39, Batch 81, CE_loss: 0.05211470276117325, Dice_loss: 0.005761836655437946, Consistency_loss: 0.00044747116044163704\n",
      "[Training] Epoch: 39 [=========>     ] 65.9% Loss: 0.0474, Epoch 39, Batch 82, CE_loss: 0.04427866265177727, Dice_loss: 0.004705801606178284, Consistency_loss: 0.0012405065353959799\n",
      "[Training] Epoch: 39 [==========>    ] 66.7% Loss: 0.0471, Epoch 39, Batch 83, CE_loss: 0.024317771196365356, Dice_loss: 0.0023995088413357735, Consistency_loss: 0.0002719238109420985\n",
      "[Training] Epoch: 39 [==========>    ] 67.5% Loss: 0.0473, Epoch 39, Batch 84, CE_loss: 0.05287836864590645, Dice_loss: 0.006029624026268721, Consistency_loss: 0.00038829268305562437\n",
      "[Training] Epoch: 39 [==========>    ] 68.3% Loss: 0.0474, Epoch 39, Batch 85, CE_loss: 0.05132175236940384, Dice_loss: 0.005128106568008661, Consistency_loss: 0.0008558526751585305\n",
      "[Training] Epoch: 39 [==========>    ] 69.0% Loss: 0.0474, Epoch 39, Batch 86, CE_loss: 0.039479464292526245, Dice_loss: 0.0041285231709480286, Consistency_loss: 0.0008304491057060659\n",
      "[Training] Epoch: 39 [==========>    ] 69.8% Loss: 0.0474, Epoch 39, Batch 87, CE_loss: 0.041095830500125885, Dice_loss: 0.004530099220573902, Consistency_loss: 0.0007674568914808333\n",
      "[Training] Epoch: 39 [==========>    ] 70.6% Loss: 0.0476, Epoch 39, Batch 88, CE_loss: 0.059046339243650436, Dice_loss: 0.006654310505837202, Consistency_loss: 0.0003632213920354843\n",
      "[Training] Epoch: 39 [==========>    ] 71.4% Loss: 0.0476, Epoch 39, Batch 89, CE_loss: 0.04442894086241722, Dice_loss: 0.004886247217655182, Consistency_loss: 0.0008357935003004968\n",
      "[Training] Epoch: 39 [==========>    ] 72.2% Loss: 0.0476, Epoch 39, Batch 90, CE_loss: 0.04618029668927193, Dice_loss: 0.004895653109997511, Consistency_loss: 3.821542122750543e-05\n",
      "[Training] Epoch: 39 [==========>    ] 73.0% Loss: 0.0476, Epoch 39, Batch 91, CE_loss: 0.03945491462945938, Dice_loss: 0.004511140286922455, Consistency_loss: 0.0011420705122873187\n",
      "[Training] Epoch: 39 [===========>   ] 73.8% Loss: 0.0475, Epoch 39, Batch 92, CE_loss: 0.03168632462620735, Dice_loss: 0.003320530289784074, Consistency_loss: 0.000913115800358355\n",
      "[Training] Epoch: 39 [===========>   ] 74.6% Loss: 0.0474, Epoch 39, Batch 93, CE_loss: 0.03725238889455795, Dice_loss: 0.003969857469201088, Consistency_loss: 0.0009800841799005866\n",
      "[Training] Epoch: 39 [===========>   ] 75.4% Loss: 0.0474, Epoch 39, Batch 94, CE_loss: 0.04071078822016716, Dice_loss: 0.004482293501496315, Consistency_loss: 0.0007504908717237413\n",
      "[Training] Epoch: 39 [===========>   ] 76.2% Loss: 0.0474, Epoch 39, Batch 95, CE_loss: 0.03966469690203667, Dice_loss: 0.00429341197013855, Consistency_loss: 0.0008764517842791975\n",
      "[Training] Epoch: 39 [===========>   ] 77.0% Loss: 0.0473, Epoch 39, Batch 96, CE_loss: 0.037918418645858765, Dice_loss: 0.00409023929387331, Consistency_loss: 0.00026205426547676325\n",
      "[Training] Epoch: 39 [===========>   ] 77.8% Loss: 0.0473, Epoch 39, Batch 97, CE_loss: 0.03806804120540619, Dice_loss: 0.004125269129872322, Consistency_loss: 0.0002810277510434389\n",
      "[Training] Epoch: 39 [===========>   ] 78.6% Loss: 0.0473, Epoch 39, Batch 98, CE_loss: 0.04287295415997505, Dice_loss: 0.00448840856552124, Consistency_loss: 0.0006348821916617453\n",
      "[Training] Epoch: 39 [===========>   ] 79.4% Loss: 0.0472, Epoch 39, Batch 99, CE_loss: 0.038126543164253235, Dice_loss: 0.004065956454724073, Consistency_loss: 0.0005269180983304977\n",
      "[Training] Epoch: 39 [============>  ] 80.2% Loss: 0.0471, Epoch 39, Batch 100, CE_loss: 0.029711656272411346, Dice_loss: 0.002954113529995084, Consistency_loss: 0.0005873646587133408\n",
      "[Training] Epoch: 39 [============>  ] 81.0% Loss: 0.0470, Epoch 39, Batch 101, CE_loss: 0.03245251998305321, Dice_loss: 0.0034598216880112886, Consistency_loss: 6.615307938773185e-05\n",
      "[Training] Epoch: 39 [============>  ] 81.7% Loss: 0.0471, Epoch 39, Batch 102, CE_loss: 0.0507223978638649, Dice_loss: 0.005762954242527485, Consistency_loss: 0.0009864415042102337\n",
      "[Training] Epoch: 39 [============>  ] 82.5% Loss: 0.0470, Epoch 39, Batch 103, CE_loss: 0.02945576049387455, Dice_loss: 0.0031367363408207893, Consistency_loss: 0.001051003928296268\n",
      "[Training] Epoch: 39 [============>  ] 83.3% Loss: 0.0469, Epoch 39, Batch 104, CE_loss: 0.0357968844473362, Dice_loss: 0.0037965106312185526, Consistency_loss: 0.0004411393019836396\n",
      "[Training] Epoch: 39 [============>  ] 84.1% Loss: 0.0469, Epoch 39, Batch 105, CE_loss: 0.04219074174761772, Dice_loss: 0.004626484587788582, Consistency_loss: 5.8473618992138654e-05\n",
      "[Training] Epoch: 39 [============>  ] 84.9% Loss: 0.0471, Epoch 39, Batch 106, CE_loss: 0.057305775582790375, Dice_loss: 0.006150493398308754, Consistency_loss: 0.0014192472444847226\n",
      "[Training] Epoch: 39 [============>  ] 85.7% Loss: 0.0470, Epoch 39, Batch 107, CE_loss: 0.0369601771235466, Dice_loss: 0.0038983093108981848, Consistency_loss: 0.0011599216377362609\n",
      "[Training] Epoch: 39 [============>  ] 86.5% Loss: 0.0470, Epoch 39, Batch 108, CE_loss: 0.03897492587566376, Dice_loss: 0.004340033512562513, Consistency_loss: 0.0005014846683479846\n",
      "[Training] Epoch: 39 [=============> ] 87.3% Loss: 0.0470, Epoch 39, Batch 109, CE_loss: 0.04313682019710541, Dice_loss: 0.004751636181026697, Consistency_loss: 0.0004024864174425602\n",
      "[Training] Epoch: 39 [=============> ] 88.1% Loss: 0.0469, Epoch 39, Batch 110, CE_loss: 0.035017650574445724, Dice_loss: 0.0035423533990979195, Consistency_loss: 5.313832298270427e-05\n",
      "[Training] Epoch: 39 [=============> ] 88.9% Loss: 0.0469, Epoch 39, Batch 111, CE_loss: 0.042511533945798874, Dice_loss: 0.004044311121106148, Consistency_loss: 0.0005980335990898311\n",
      "[Training] Epoch: 39 [=============> ] 89.7% Loss: 0.0469, Epoch 39, Batch 112, CE_loss: 0.039142027497291565, Dice_loss: 0.00411548325791955, Consistency_loss: 0.000840843771584332\n",
      "[Training] Epoch: 39 [=============> ] 90.5% Loss: 0.0469, Epoch 39, Batch 113, CE_loss: 0.036576900631189346, Dice_loss: 0.003849694272503257, Consistency_loss: 0.000715963717084378\n",
      "[Training] Epoch: 39 [=============> ] 91.3% Loss: 0.0467, Epoch 39, Batch 114, CE_loss: 0.025075746700167656, Dice_loss: 0.0025239454116672277, Consistency_loss: 5.627651626127772e-05\n",
      "[Training] Epoch: 39 [=============> ] 92.1% Loss: 0.0466, Epoch 39, Batch 115, CE_loss: 0.03633010759949684, Dice_loss: 0.004030636046081781, Consistency_loss: 0.0006121967453509569\n",
      "[Training] Epoch: 39 [=============> ] 92.9% Loss: 0.0468, Epoch 39, Batch 116, CE_loss: 0.059533968567848206, Dice_loss: 0.0066851782612502575, Consistency_loss: 5.802820305689238e-05\n",
      "[Training] Epoch: 39 [==============>] 93.7% Loss: 0.0468, Epoch 39, Batch 117, CE_loss: 0.039552439004182816, Dice_loss: 0.004456034395843744, Consistency_loss: 0.0004854561702813953\n",
      "[Training] Epoch: 39 [==============>] 94.4% Loss: 0.0468, Epoch 39, Batch 118, CE_loss: 0.0428323931992054, Dice_loss: 0.004918782506138086, Consistency_loss: 0.0005771778523921967\n",
      "[Training] Epoch: 39 [==============>] 95.2% Loss: 0.0467, Epoch 39, Batch 119, CE_loss: 0.03678634390234947, Dice_loss: 0.004128018394112587, Consistency_loss: 0.0001010815249173902\n",
      "[Training] Epoch: 39 [==============>] 96.0% Loss: 0.0471, Epoch 39, Batch 120, CE_loss: 0.08008210361003876, Dice_loss: 0.008756657131016254, Consistency_loss: 0.0003735088394023478\n",
      "[Training] Epoch: 39 [==============>] 96.8% Loss: 0.0472, Epoch 39, Batch 121, CE_loss: 0.05541952699422836, Dice_loss: 0.0063470457680523396, Consistency_loss: 0.0002018696686718613\n",
      "[Training] Epoch: 39 [==============>] 97.6% Loss: 0.0471, Epoch 39, Batch 122, CE_loss: 0.02918202057480812, Dice_loss: 0.003038062248378992, Consistency_loss: 0.000193412255612202\n",
      "[Training] Epoch: 39 [==============>] 98.4% Loss: 0.0470, Epoch 39, Batch 123, CE_loss: 0.028303423896431923, Dice_loss: 0.002973760711029172, Consistency_loss: 0.00019017208251170814\n",
      "[Training] Epoch: 39 [==============>] 99.2% Loss: 0.0469, Epoch 39, Batch 124, CE_loss: 0.038806136697530746, Dice_loss: 0.004373257048428059, Consistency_loss: 0.00010048742842627689\n",
      "[Training] Epoch: 39 [DONE]                                 \n",
      "Epoch 39, Batch 125, CE_loss: 0.047027017921209335, Dice_loss: 0.005322454962879419, Consistency_loss: 8.031460311030969e-05\n",
      "[Validation] Epoch: 39 [DONE]                                 \n",
      "[Epoch: 39, TrainLoss: 0.0470, TrainDice: 0.0045, ValLoss: 0.1679                                            \n",
      "Number of batches:  126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\nicos\\anaconda3\\lib\\threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\nicos\\anaconda3\\lib\\site-packages\\tensorboard\\summary\\writer\\event_file_writer.py\", line 244, in run\n",
      "    self._run()\n",
      "  File \"c:\\Users\\nicos\\anaconda3\\lib\\site-packages\\tensorboard\\summary\\writer\\event_file_writer.py\", line 275, in _run\n",
      "    self._record_writer.write(data)\n",
      "  File \"c:\\Users\\nicos\\anaconda3\\lib\\site-packages\\tensorboard\\summary\\writer\\record_writer.py\", line 40, in write\n",
      "    self._writer.write(header + header_crc + data + footer_crc)\n",
      "  File \"c:\\Users\\nicos\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\io\\gfile.py\", line 775, in write\n",
      "    self.fs.append(self.filename, file_content, self.binary_mode)\n",
      "  File \"c:\\Users\\nicos\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\io\\gfile.py\", line 167, in append\n",
      "    self._write(filename, file_content, \"ab\" if binary_mode else \"a\")\n",
      "  File \"c:\\Users\\nicos\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\io\\gfile.py\", line 171, in _write\n",
      "    with io.open(filename, mode, encoding=encoding) as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: b'runs\\\\Dec16_09-03-18_PCDuDieuDesMathsNico\\\\events.out.tfevents.1734357798.PCDuDieuDesMathsNico.33924.0'\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: b'runs\\\\Dec16_09-03-18_PCDuDieuDesMathsNico\\\\events.out.tfevents.1734357798.PCDuDieuDesMathsNico.33924.0'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_33924\\3049218308.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    148\u001b[0m             \u001b[0mprobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m             writer.add_figure('predictions vs. actuals',\n\u001b[0m\u001b[0;32m    151\u001b[0m                         \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_net_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m                         global_step=epoch * len(supervised_loader) + idx)\n",
      "\u001b[1;32mc:\\Users\\nicos\\anaconda3\\lib\\site-packages\\torch\\utils\\tensorboard\\writer.py\u001b[0m in \u001b[0;36madd_figure\u001b[1;34m(self, tag, figure, global_step, close, walltime)\u001b[0m\n\u001b[0;32m    751\u001b[0m             )\n\u001b[0;32m    752\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 753\u001b[1;33m             self.add_image(\n\u001b[0m\u001b[0;32m    754\u001b[0m                 \u001b[0mtag\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    755\u001b[0m                 \u001b[0mfigure_to_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nicos\\anaconda3\\lib\\site-packages\\torch\\utils\\tensorboard\\writer.py\u001b[0m in \u001b[0;36madd_image\u001b[1;34m(self, tag, img_tensor, global_step, walltime, dataformats)\u001b[0m\n\u001b[0;32m    622\u001b[0m         \"\"\"\n\u001b[0;32m    623\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_log_api_usage_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tensorboard.logging.add_image\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 624\u001b[1;33m         self._get_file_writer().add_summary(\n\u001b[0m\u001b[0;32m    625\u001b[0m             \u001b[0mimage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataformats\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataformats\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwalltime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m         )\n",
      "\u001b[1;32mc:\\Users\\nicos\\anaconda3\\lib\\site-packages\\torch\\utils\\tensorboard\\writer.py\u001b[0m in \u001b[0;36madd_summary\u001b[1;34m(self, summary, global_step, walltime)\u001b[0m\n\u001b[0;32m    113\u001b[0m         \"\"\"\n\u001b[0;32m    114\u001b[0m         \u001b[0mevent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevent_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEvent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwalltime\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0madd_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph_profile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwalltime\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nicos\\anaconda3\\lib\\site-packages\\torch\\utils\\tensorboard\\writer.py\u001b[0m in \u001b[0;36madd_event\u001b[1;34m(self, event, step, walltime)\u001b[0m\n\u001b[0;32m     97\u001b[0m             \u001b[1;31m# since protobuf might not convert depending on version\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m             \u001b[0mevent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevent_writer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0madd_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msummary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwalltime\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nicos\\anaconda3\\lib\\site-packages\\tensorboard\\summary\\writer\\event_file_writer.py\u001b[0m in \u001b[0;36madd_event\u001b[1;34m(self, event)\u001b[0m\n\u001b[0;32m    115\u001b[0m                 \u001b[1;34m\" but got %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m             )\n\u001b[1;32m--> 117\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_async_writer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nicos\\anaconda3\\lib\\site-packages\\tensorboard\\summary\\writer\\event_file_writer.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, bytestring)\u001b[0m\n\u001b[0;32m    169\u001b[0m             \u001b[1;31m# multiple threads passing the check and then switching just before\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m             \u001b[1;31m# blocking on putting to the queue which might result in a deadlock.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_worker_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Writer is closed\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nicos\\anaconda3\\lib\\site-packages\\tensorboard\\summary\\writer\\event_file_writer.py\u001b[0m in \u001b[0;36m_check_worker_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    210\u001b[0m         \u001b[0mexception\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_worker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mexception\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nicos\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36m_bootstrap_inner\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    978\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    979\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 980\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    981\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    982\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_invoke_excepthook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nicos\\anaconda3\\lib\\site-packages\\tensorboard\\summary\\writer\\event_file_writer.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 244\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    245\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexception\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nicos\\anaconda3\\lib\\site-packages\\tensorboard\\summary\\writer\\event_file_writer.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    273\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shutdown_signal\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m                     \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 275\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_record_writer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    276\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_has_pending_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nicos\\anaconda3\\lib\\site-packages\\tensorboard\\summary\\writer\\record_writer.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mheader_crc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"<I\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmasked_crc32c\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mfooter_crc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"<I\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmasked_crc32c\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_writer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheader\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mheader_crc\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfooter_crc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nicos\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\io\\gfile.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, file_content)\u001b[0m\n\u001b[0;32m    773\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    774\u001b[0m                 \u001b[1;31m# append the later chunks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 775\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_content\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    776\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# add to temp file, but wait for flush to write to final filesystem\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nicos\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\io\\gfile.py\u001b[0m in \u001b[0;36mappend\u001b[1;34m(self, filename, file_content, binary_mode)\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[0mbinary_mode\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrite\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mbinary\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0motherwise\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m         \"\"\"\n\u001b[1;32m--> 167\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_write\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_content\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ab\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mbinary_mode\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"a\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_write\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_content\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nicos\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\io\\gfile.py\u001b[0m in \u001b[0;36m_write\u001b[1;34m(self, filename, file_content, mode)\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_write\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_content\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"utf8\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m             \u001b[0mcompatify\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_bytes\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompatify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_content\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: b'runs\\\\Dec16_09-03-18_PCDuDieuDesMathsNico\\\\events.out.tfevents.1734357798.PCDuDieuDesMathsNico.33924.0'"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter()\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(\"~~~~~~~~  Starting the training... ~~~~~~\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "num_classes = 4\n",
    "\n",
    "# Set device depending on the availability of GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "# elif torch.mps.is_available():  # Apple M-series of chips\n",
    "#     device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "print(\"~~~~~~~~~~~ Creating the UNet model ~~~~~~~~~~\")\n",
    "print(\" Model Name: {}\".format(modelName))\n",
    "\n",
    "## CREATION OF YOUR MODEL\n",
    "net = UNet(num_classes).to(device)\n",
    "\n",
    "print(\n",
    "    \"Total params: {0:,}\".format(\n",
    "        sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "    )\n",
    ")\n",
    "\n",
    "# DEFINE YOUR OUTPUT COMPONENTS (e.g., SOFTMAX, LOSS FUNCTION, ETC)\n",
    "softMax = torch.nn.Softmax(dim=1)\n",
    "CE_loss = torch.nn.CrossEntropyLoss()\n",
    "consistency_regularizer = ConsistencyRegularization(transformation_fn=random_transformation_fn)\n",
    "\n",
    "\n",
    "## PUT EVERYTHING IN GPU RESOURCES\n",
    "if torch.cuda.is_available():\n",
    "    net.cuda()\n",
    "    softMax.cuda()\n",
    "    CE_loss.cuda()\n",
    "\n",
    "## DEFINE YOUR OPTIMIZER\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "### To save statistics ####\n",
    "train_losses = []\n",
    "train_dc_losses = []\n",
    "val_losses = []\n",
    "val_dc_losses = []\n",
    "\n",
    "best_loss_val = 1000\n",
    "\n",
    "directory = \"Results/Statistics/\" + modelName\n",
    "\n",
    "print(\"~~~~~~~~~~~ Starting the training ~~~~~~~~~~\")\n",
    "if os.path.exists(directory) == False:\n",
    "    os.makedirs(directory)\n",
    "\n",
    "## START THE TRAINING\n",
    "\n",
    "## FOR EACH EPOCH\n",
    "for epoch in range(total_epochs):\n",
    "    net.train()\n",
    "    supervised_iter = iter(supervised_loader)\n",
    "    unsupervised_iter = iter(unsupervised_loader)\n",
    "    \n",
    "    num_batches = max(len(supervised_loader), len(unsupervised_loader))\n",
    "    print(\"Number of batches: \", num_batches)\n",
    "\n",
    "    running_train_loss = 0\n",
    "    running_dice_loss = 0\n",
    "\n",
    "    # Training loop\n",
    "    for idx in range(num_batches):\n",
    "        ### SUPERVISED BATCH\n",
    "        try :\n",
    "            supervised_data = next(supervised_iter)\n",
    "        except StopIteration:\n",
    "            supervised_iter = iter(supervised_loader)\n",
    "            supervised_data = next(supervised_iter)\n",
    "\n",
    "        ### Set to zero all the gradients\n",
    "        net.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        ## GET IMAGES, LABELS and IMG NAMES\n",
    "        images, labels, img_names = supervised_data\n",
    "\n",
    "        ### From numpy to torch variables\n",
    "        labels = utils.to_var(labels).to(device)\n",
    "        images = utils.to_var(images).to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        net_predictions = net(images)\n",
    "\n",
    "        # Get the segmentation classes\n",
    "        segmentation_classes = utils.getTargetSegmentation(labels)\n",
    "        # Modify segmentation classes to be one-hot encoded (shape [batch_size, num_classes, height, width])\n",
    "        dice_target = F.one_hot(segmentation_classes, num_classes = num_classes).permute(0,3,1,2).contiguous()\n",
    "\n",
    "        # Compute the loss\n",
    "        ce_loss = ce_loss_weight * CE_loss(net_predictions, segmentation_classes) \n",
    "        dice_loss = dice_loss_weight * DiceLoss()(net_predictions, dice_target)  \n",
    "        loss = ce_loss + dice_loss \n",
    "        running_train_loss += ce_loss.item() + dice_loss.item() \n",
    "        # dice_loss = dice_coefficient(net_predictions, labels)\n",
    "        # dice_loss = utils.compute_dsc(net_predictions, labels)\n",
    "        running_dice_loss += dice_loss\n",
    "\n",
    "        # Backprop\n",
    "        # loss.backward()\n",
    "        # optimizer.step()\n",
    "\n",
    "        ### UNSUPERVISED BATCH\n",
    "        try :\n",
    "            unsupervised_data = next(unsupervised_iter)\n",
    "        except StopIteration:\n",
    "            unsupervised_iter = iter(unsupervised_loader)\n",
    "            unsupervised_data = next(unsupervised_iter)\n",
    "        \n",
    "        unsupervised_images, _, __ = unsupervised_data\n",
    "        unsupervised_images = utils.to_var(unsupervised_images).to(device)\n",
    "\n",
    "        # net.zero_grad()\n",
    "        # optimizer.zero_grad()\n",
    "\n",
    "        consistency_loss = weight_TC * consistency_regularizer(net, unsupervised_images) \n",
    "        loss += consistency_loss\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_train_loss += consistency_loss.item()\n",
    "        running_dice_loss += 0\n",
    "\n",
    "        # Add the loss to the tensorboard every 5 batches\n",
    "        if idx % 10 == 0:\n",
    "            writer.add_scalar(\n",
    "                \"Loss/train\", running_train_loss / (idx + 1), epoch * len(supervised_loader) + idx\n",
    "            )\n",
    "            writer.add_scalar(\n",
    "                \"Dice/train\", running_dice_loss / (idx + 1), epoch * len(supervised_loader) + idx\n",
    "            )\n",
    "\n",
    "        if idx % 100 == 0:\n",
    "            # Also add visualizations of the images\n",
    "            probs = torch.softmax(net_predictions, dim=1)\n",
    "            y_pred = torch.argmax(probs, dim=1)\n",
    "            writer.add_figure('predictions vs. actuals',\n",
    "                        utils.plot_net_predictions(images, labels, y_pred, batch_size),\n",
    "                        global_step=epoch * len(supervised_loader) + idx)\n",
    "\n",
    "        # THIS IS JUST TO VISUALIZE THE TRAINING\n",
    "        printProgressBar(\n",
    "            idx + 1,\n",
    "            num_batches,\n",
    "            prefix=\"[Training] Epoch: {} \".format(epoch),\n",
    "            length=15,\n",
    "            suffix=\" Loss: {:.4f}, \".format(running_train_loss / (idx + 1)),\n",
    "        )\n",
    "        print(f\"Epoch {epoch}, Batch {idx}, CE_loss: {ce_loss.item()}, Dice_loss: {dice_loss.item()}, Consistency_loss: {consistency_loss.item()}\")\n",
    "\n",
    "    train_loss = running_train_loss / num_batches\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    train_dc_loss = running_dice_loss / num_batches\n",
    "    train_dc_losses.append(train_dc_loss)\n",
    "    # print(f\"Epoch {epoch}, Batch {idx}, CE_loss: {ce_loss.item()}, Dice_loss: {dice_loss.item()}, Consistency_loss: {consistency_loss.item()}\")\n",
    "    net.eval()\n",
    "    val_running_loss = 0\n",
    "    val_running_dc = 0\n",
    "\n",
    "    # Validation loop\n",
    "    with torch.no_grad():\n",
    "        for idx, data in enumerate(val_loader):\n",
    "            images, labels, img_names = data\n",
    "\n",
    "            labels = utils.to_var(labels).to(device)\n",
    "            images = utils.to_var(images).to(device)\n",
    "\n",
    "            net_predictions = net(images)\n",
    "\n",
    "            segmentation_classes = utils.getTargetSegmentation(labels)\n",
    "\n",
    "            loss = CE_loss(net_predictions, segmentation_classes) \n",
    "            val_running_loss += loss.item()\n",
    "\n",
    "            # dice_loss = dice_coefficient(net_predictions, labels)\n",
    "            dice_loss = utils.compute_dsc(net_predictions, labels)\n",
    "            val_running_dc += dice_loss\n",
    "\n",
    "            if idx % 10 == 0:\n",
    "                writer.add_scalar(\n",
    "                    \"Loss/val\",\n",
    "                    val_running_loss / (idx + 1),\n",
    "                    epoch * len(val_loader) + idx,\n",
    "                )\n",
    "                writer.add_scalar(\n",
    "                    \"Dice/val\",\n",
    "                    val_running_dc / (idx + 1),\n",
    "                    epoch * len(val_loader) + idx,\n",
    "                )\n",
    "\n",
    "            printProgressBar(\n",
    "                idx + 1,\n",
    "                len(val_loader),\n",
    "                prefix=\"[Validation] Epoch: {} \".format(epoch),\n",
    "                length=15,\n",
    "                suffix=\" Loss: {:.4f}, \".format(val_running_loss / (idx + 1)),\n",
    "            )\n",
    "\n",
    "    val_loss = val_running_loss / len(val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    dc_loss = val_running_dc / len(val_loader)\n",
    "    val_dc_losses.append(dc_loss)\n",
    "\n",
    "    # Check if model performed best and save it if true\n",
    "    if val_loss < best_loss_val:\n",
    "        best_loss_val = val_loss\n",
    "        if not os.path.exists(\"./models/\" + modelName):\n",
    "            os.makedirs(\"./models/\" + modelName)\n",
    "        torch.save(\n",
    "            net.state_dict(), \"./models/\" + modelName + \"/\" + str(epoch) + \"_Epoch\"\n",
    "        )\n",
    "\n",
    "    printProgressBar(\n",
    "        num_batches,\n",
    "        num_batches,\n",
    "        done=\"[Epoch: {}, TrainLoss: {:.4f}, TrainDice: {:.4f}, ValLoss: {:.4f}\".format(\n",
    "            epoch, train_loss, train_dc_loss, val_loss\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    np.save(os.path.join(directory, \"Losses.npy\"), train_losses)\n",
    "writer.flush()  # Flush the writer to ensure that all the data is written to disk\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd48e84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4172410f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
